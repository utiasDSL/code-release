"{\"Conference\":{\"0\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"1\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"2\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"3\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"4\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"5\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"6\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"7\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"8\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"9\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"10\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"11\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"12\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"13\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"14\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"15\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"16\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"17\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"18\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"19\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"20\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"21\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"22\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"23\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"24\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"25\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"26\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"27\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"28\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"29\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"30\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"31\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"32\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"33\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"34\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"35\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"36\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"37\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"38\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"39\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"40\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"41\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"42\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"43\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"44\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"45\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"46\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"47\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"48\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"49\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"50\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"51\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"52\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"53\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"54\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"55\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"56\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"57\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"58\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"59\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"60\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"61\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"62\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"63\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"64\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"65\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"66\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"67\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"68\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"69\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"70\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"71\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"72\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"73\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"74\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"75\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"76\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"77\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"78\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"79\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"80\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"81\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"82\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"83\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"84\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"85\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"86\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"87\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"88\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"89\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"90\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"91\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"92\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"93\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"94\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"95\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"96\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"97\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"98\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"99\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"100\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"101\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"102\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"103\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"104\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"105\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"106\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"107\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"108\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"109\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"110\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"111\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"112\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"113\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"114\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"115\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"116\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"117\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"118\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"119\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"120\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"121\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"122\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"123\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"124\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"125\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"126\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"127\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"128\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"129\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"130\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"131\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"132\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"133\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"134\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"135\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"136\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"137\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"138\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"139\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"140\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"141\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"142\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"143\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"144\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"145\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"146\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"147\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"148\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"149\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"150\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"151\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"152\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"153\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"154\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"155\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"156\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"157\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"158\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"159\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"160\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"161\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"162\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"163\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"164\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"165\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"166\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"167\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"168\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"169\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"170\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"171\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"172\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"173\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"174\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"175\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"176\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"177\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"178\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"179\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"180\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"181\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"182\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"183\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"184\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"185\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"186\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"187\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"188\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"189\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"190\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"191\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"192\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"193\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"194\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"195\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"196\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"197\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"198\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"199\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"200\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"201\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"202\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"203\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"204\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"205\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"206\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"207\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"208\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"209\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"210\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"211\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"212\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"213\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"214\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"215\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"216\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"217\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"218\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"219\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"220\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"221\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"222\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"223\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"224\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"225\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"226\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"227\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"228\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"229\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"230\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"231\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"232\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"233\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"234\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"235\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"236\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"237\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"238\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"239\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"240\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"241\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"242\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"243\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"244\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"245\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"246\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"247\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"248\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"249\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"250\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"251\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"252\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"253\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"254\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"255\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"256\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"257\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"258\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"259\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"260\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"261\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"262\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"263\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"264\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"265\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"266\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"267\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"268\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"269\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"270\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"271\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"272\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"273\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"274\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"275\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"276\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"277\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"278\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"279\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"280\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"281\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"282\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"283\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"284\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"285\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"286\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"287\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"288\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"289\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"290\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"291\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"292\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"293\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"294\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"295\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"296\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"297\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"298\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"299\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"300\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"301\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"302\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"303\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"304\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"305\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"306\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"307\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"308\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"309\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"310\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"311\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"312\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"313\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"314\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"315\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"316\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"317\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"318\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"319\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"320\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"321\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"322\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"323\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"324\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"325\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"326\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"327\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"328\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"329\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"330\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"331\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"332\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"333\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"334\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"335\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"336\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"337\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"338\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"339\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"340\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"341\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"342\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"343\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"344\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"345\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"346\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"347\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"348\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"349\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"350\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"351\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"352\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"353\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"354\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"355\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"356\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"357\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"358\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"359\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"360\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"361\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"362\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"363\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"364\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"365\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"366\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"367\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"368\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"369\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"370\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"371\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"372\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"373\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"374\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"375\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"376\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"377\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"378\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"379\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"380\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"381\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"382\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"383\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"384\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"385\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"386\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"387\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"388\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"389\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"390\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"391\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"392\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"393\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"394\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"395\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"396\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"397\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"398\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"399\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"400\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"401\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"402\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"403\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"404\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"405\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"406\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"407\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"408\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"409\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"410\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"411\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"412\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"413\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"414\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"415\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"416\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"417\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"418\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"419\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"420\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"421\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"422\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"423\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"424\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"425\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"426\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"427\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"428\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"429\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"430\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"431\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"432\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"433\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"434\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"435\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"436\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"437\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"438\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"439\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"440\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"441\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"442\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"443\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"444\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"445\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"446\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"447\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"448\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"449\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"450\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"451\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"452\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"453\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"454\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"455\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"456\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"457\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"458\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"459\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"460\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"461\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"462\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"463\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"464\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"465\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"466\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"467\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"468\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"469\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"470\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"471\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"472\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"473\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"474\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"475\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"476\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"477\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"478\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"479\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"480\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"481\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"482\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"483\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"484\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"485\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"486\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"487\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"488\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"489\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"490\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"491\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"492\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"493\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"494\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"495\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"496\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"497\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"498\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"499\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"500\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"501\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"502\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"503\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"504\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"505\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"506\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"507\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"508\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"509\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"510\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"511\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"512\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"513\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"514\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"515\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"516\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"517\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"518\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"519\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"520\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"521\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"522\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"523\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"524\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"525\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"526\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"527\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"528\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"529\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"530\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"531\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"532\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"533\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"534\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"535\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"536\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"537\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"538\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"539\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"540\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"541\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"542\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"543\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"544\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"545\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"546\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"547\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"548\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"549\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"550\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"551\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"552\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"553\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"554\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"555\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"556\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"557\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"558\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"559\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"560\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"561\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"562\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"563\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"564\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"565\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"566\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"567\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"568\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"569\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"570\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"571\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"572\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"573\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"574\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"575\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"576\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"577\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"578\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"579\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"580\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"581\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"582\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"583\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"584\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"585\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"586\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"587\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"588\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"589\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"590\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"591\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"592\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"593\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"594\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"595\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"596\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"597\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"598\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"599\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"600\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"601\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"602\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"603\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"604\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"605\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"606\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"607\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"608\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"609\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"610\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"611\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"612\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"613\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"614\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"615\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"616\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"617\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"618\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"619\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"620\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"621\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"622\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"623\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"624\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"625\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"626\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"627\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"628\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"629\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"630\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"631\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"632\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"633\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"634\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"635\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"636\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"637\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"638\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"639\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"640\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"641\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"642\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"643\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"644\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"645\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"646\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"647\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"648\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"649\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"650\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"651\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"652\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"653\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"654\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"655\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"656\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"657\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"658\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"659\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"660\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"661\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"662\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"663\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"664\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"665\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"666\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"667\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"668\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"669\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"670\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"671\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"672\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"673\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"674\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"675\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"676\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"677\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"678\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"679\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"680\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"681\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"682\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"683\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"684\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"685\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"686\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"687\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"688\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"689\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"690\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"691\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"692\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"693\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"694\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"695\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"696\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"697\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"698\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"699\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"700\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"701\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"702\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"703\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"704\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"705\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"706\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"707\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"708\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"709\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"710\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"711\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"712\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"713\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"714\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"715\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"716\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"717\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"718\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"719\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"720\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"721\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"722\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"723\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"724\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"725\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"726\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"727\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"728\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"729\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"730\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"731\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"732\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"733\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"734\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"735\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"736\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"737\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"738\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"739\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"740\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"741\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"742\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"743\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"744\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"745\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"746\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"747\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"748\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"749\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"750\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"751\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"752\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"753\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"754\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"755\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"756\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"757\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"758\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"759\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"760\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"761\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"762\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"763\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"764\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"765\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"766\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"767\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"768\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"769\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"770\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"771\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"772\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"773\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"774\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"775\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"776\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"777\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"778\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"779\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"780\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"781\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"782\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"783\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"784\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"785\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"786\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"787\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"788\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"789\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"790\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"791\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"792\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"793\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\"},\"Year\":{\"0\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"1\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"2\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"3\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"4\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"5\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"6\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"7\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"8\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"9\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"10\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"11\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"12\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"13\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"14\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"15\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"16\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"17\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"18\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"19\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"20\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"21\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"22\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"23\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"24\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"25\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"26\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"27\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"28\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"29\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"30\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"31\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"32\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"33\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"34\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"35\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"36\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"37\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"38\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"39\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"40\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"41\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"42\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"43\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"44\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"45\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"46\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"47\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"48\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"49\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"50\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"51\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"52\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"53\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"54\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"55\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"56\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"57\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"58\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"59\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"60\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"61\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"62\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"63\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"64\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"65\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"66\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"67\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"68\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"69\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"70\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"71\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"72\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"73\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"74\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"75\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"76\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"77\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"78\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"79\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"80\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"81\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"82\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"83\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"84\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"85\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"86\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"87\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"88\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"89\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"90\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"91\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"92\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"93\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"94\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"95\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"96\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"97\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"98\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"99\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"100\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"101\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"102\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"103\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"104\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"105\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"106\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"107\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"108\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"109\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"110\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"111\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"112\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"113\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"114\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"115\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"116\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"117\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"118\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"119\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"120\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"121\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"122\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"123\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"124\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"125\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"126\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"127\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"128\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"129\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"130\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"131\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"132\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"133\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"134\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"135\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"136\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"137\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"138\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"139\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"140\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"141\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"142\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"143\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"144\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"145\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"146\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"147\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"148\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"149\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"150\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"151\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"152\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"153\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"154\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"155\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"156\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"157\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"158\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"159\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"160\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"161\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"162\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"163\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"164\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"165\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"166\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"167\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"168\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"169\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"170\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"171\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"172\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"173\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"174\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"175\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"176\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"177\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"178\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"179\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"180\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"181\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"182\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"183\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"184\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"185\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"186\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"187\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"188\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"189\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"190\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"191\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"192\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"193\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"194\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"195\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"196\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"197\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"198\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"199\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"200\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"201\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"202\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"203\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"204\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"205\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"206\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"207\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"208\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"209\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"210\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"211\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"212\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"213\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"214\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"215\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"216\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"217\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"218\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"219\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"220\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"221\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"222\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"223\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"224\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"225\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"226\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"227\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"228\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"229\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"230\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"231\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"232\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"233\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"234\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"235\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"236\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"237\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"238\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"239\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"240\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"241\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"242\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"243\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"244\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"245\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"246\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"247\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"248\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"249\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"250\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"251\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"252\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"253\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"254\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"255\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"256\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"257\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"258\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"259\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"260\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"261\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"262\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"263\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"264\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"265\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"266\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"267\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"268\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"269\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"270\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"271\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"272\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"273\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"274\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"275\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"276\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"277\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"278\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"279\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"280\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"281\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"282\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"283\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"284\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"285\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"286\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"287\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"288\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"289\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"290\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"291\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"292\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"293\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"294\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"295\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"296\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"297\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"298\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"299\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"300\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"301\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"302\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"303\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"304\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"305\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"306\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"307\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"308\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"309\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"310\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"311\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"312\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"313\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"314\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"315\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"316\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"317\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"318\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"319\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"320\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"321\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"322\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"323\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"324\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"325\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"326\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"327\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"328\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"329\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"330\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"331\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"332\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"333\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"334\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"335\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"336\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"337\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"338\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"339\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"340\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"341\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"342\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"343\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"344\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"345\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"346\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"347\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"348\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"349\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"350\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"351\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"352\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"353\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"354\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"355\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"356\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"357\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"358\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"359\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"360\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"361\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"362\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"363\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"364\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"365\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"366\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"367\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"368\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"369\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"370\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"371\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"372\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"373\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"374\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"375\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"376\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"377\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"378\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"379\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"380\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"381\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"382\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"383\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"384\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"385\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"386\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"387\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"388\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"389\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"390\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"391\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"392\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"393\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"394\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"395\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"396\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"397\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"398\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"399\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"400\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"401\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"402\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"403\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"404\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"405\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"406\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"407\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"408\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"409\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"410\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"411\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"412\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"413\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"414\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"415\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"416\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"417\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"418\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"419\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"420\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"421\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"422\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"423\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"424\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"425\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"426\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"427\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"428\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"429\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"430\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"431\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"432\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"433\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"434\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"435\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"436\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"437\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"438\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"439\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"440\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"441\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"442\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"443\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"444\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"445\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"446\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"447\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"448\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"449\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"450\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"451\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"452\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"453\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"454\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"455\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"456\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"457\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"458\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"459\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"460\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"461\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"462\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"463\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"464\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"465\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"466\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"467\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"468\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"469\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"470\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"471\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"472\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"473\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"474\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"475\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"476\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"477\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"478\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"479\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"480\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"481\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"482\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"483\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"484\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"485\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"486\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"487\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"488\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"489\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"490\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"491\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"492\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"493\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"494\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"495\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"496\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"497\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"498\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"499\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"500\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"501\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"502\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"503\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"504\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"505\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"506\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"507\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"508\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"509\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"510\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"511\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"512\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"513\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"514\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"515\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"516\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"517\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"518\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"519\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"520\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"521\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"522\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"523\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"524\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"525\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"526\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"527\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"528\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"529\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"530\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"531\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"532\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"533\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"534\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"535\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"536\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"537\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"538\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"539\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"540\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"541\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"542\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"543\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"544\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"545\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"546\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"547\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"548\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"549\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"550\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"551\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"552\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"553\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"554\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"555\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"556\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"557\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"558\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"559\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"560\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"561\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"562\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"563\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"564\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"565\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"566\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"567\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"568\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"569\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"570\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"571\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"572\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"573\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"574\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"575\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"576\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"577\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"578\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"579\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"580\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"581\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"582\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"583\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"584\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"585\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"586\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"587\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"588\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"589\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"590\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"591\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"592\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"593\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"594\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"595\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"596\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"597\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"598\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"599\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"600\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"601\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"602\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"603\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"604\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"605\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"606\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"607\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"608\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"609\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"610\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"611\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"612\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"613\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"614\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"615\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"616\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"617\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"618\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"619\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"620\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"621\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"622\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"623\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"624\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"625\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"626\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"627\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"628\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"629\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"630\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"631\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"632\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"633\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"634\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"635\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"636\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"637\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"638\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"639\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"640\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"641\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"642\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"643\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"644\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"645\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"646\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"647\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"648\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"649\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"650\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"651\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"652\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"653\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"654\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"655\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"656\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"657\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"658\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"659\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"660\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"661\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"662\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"663\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"664\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"665\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"666\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"667\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"668\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"669\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"670\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"671\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"672\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"673\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"674\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"675\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"676\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"677\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"678\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"679\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"680\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"681\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"682\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"683\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"684\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"685\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"686\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"687\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"688\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"689\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"690\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"691\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"692\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"693\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"694\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"695\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"696\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"697\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"698\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"699\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"700\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"701\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"702\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"703\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"704\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"705\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"706\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"707\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"708\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"709\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"710\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"711\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"712\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"713\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"714\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"715\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"716\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"717\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"718\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"719\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"720\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"721\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"722\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"723\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"724\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"725\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"726\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"727\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"728\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"729\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"730\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"731\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"732\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"733\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"734\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"735\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"736\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"737\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"738\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"739\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"740\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"741\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"742\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"743\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"744\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"745\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"746\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"747\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"748\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"749\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"750\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"751\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"752\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"753\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"754\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"755\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"756\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"757\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"758\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"759\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"760\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"761\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"762\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"763\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"764\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"765\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"766\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"767\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"768\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"769\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"770\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"771\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"772\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"773\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"774\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"775\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"776\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"777\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"778\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"779\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"780\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"781\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"782\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"783\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"784\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"785\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"786\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"787\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"788\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"789\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"790\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"791\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"792\":\"Date of Conference: 29 May 2017 - 03 June 2017\",\"793\":\"Date of Conference: 29 May 2017 - 03 June 2017\"},\"Paper Title\":{\"0\":\"A structure preserving nondimensionalization of hydraulic rotational joints\",\"1\":\"Mechanical design of a compact Serial Variable Stiffness Actuator (SVSA) based on lever mechanism\",\"2\":\"Toward compliant, fast, high-precision, and low-cost manipulator with hydraulic hybrid servo booster\",\"3\":\"Design of a structure-controlled variable stiffness actuator based on rotary flexure hinges\",\"4\":\"Intrinsically backdrivable hydraulic servovalve for interactive robot control\",\"5\":\"A reconfigurable hybrid actuator with rigid and soft components\",\"6\":\"Scalable pneumatic and tendon driven robotic joint inspired by jumping spiders\",\"7\":\"Position-based PD control design for hydraulic robots using passive subsystems in multi-time scales\",\"8\":\"Fast second-order cone programming for safe mission planning\",\"9\":\"Exact and efficient Hamilton-Jacobi guaranteed safety analysis via system decomposition\",\"10\":\"An efficient optimal planning and control framework for quadrupedal locomotion\",\"11\":\"A \\u03baITE in the wind: Smooth trajectory optimization in a moving reference frame\",\"12\":\"DAP3D-Net: Where, what and how actions occur in videos?\",\"13\":\"LS-ELAS: Line segment based efficient large scale stereo matching\",\"14\":\"Growth measurement of Tomato fruit based on whole image processing\",\"15\":\"Development of precise mobile gaze tracking system based on online sparse Gaussian process regression and smooth-pursuit identification\",\"16\":\"A comparative analysis of tightly-coupled monocular, binocular, and stereo VINS\",\"17\":\"SE3-nets: Learning rigid body motion using deep neural networks\",\"18\":\"Evaluation of automated vehicles in the frontal cut-in scenario \\u2014 An enhanced approach using piecewise mixture models\",\"19\":\"Find your own way: Weakly-supervised segmentation of path proposals for urban autonomy\",\"20\":\"Ego-centric traffic behavior understanding through multi-level vehicle trajectory analysis\",\"21\":\"Embedding structured contour and location prior in siamesed fully convolutional networks for road detection\",\"22\":\"A Model-Predictive Motion Planner for the IARA autonomous car\",\"23\":\"Vehicle tracking using extended object methods: An approach for fusing radar and laser\",\"24\":\"An online probabilistic road intersection detector\",\"25\":\"Risk assessment for automatic lane change maneuvers on highways\",\"26\":\"Detachable modular robot capable of cooperative climbing and multi agent exploration\",\"27\":\"Formation of differential-drive vehicles with field-of-view constraints for enclosing a moving target\",\"28\":\"Safe decentralized and reconfigurable multi-agent control with guaranteed convergence\",\"29\":\"Distributed multi-robot coordination for dynamic perimeter surveillance in uncertain environments\",\"30\":\"Distributed data gathering with buffer constraints and intermittent communication\",\"31\":\"Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning\",\"32\":\"Decentralized matroid optimization for topology constraints in multi-robot allocation problems\",\"33\":\"Learning task constraints in operational space formulation\",\"34\":\"Autonomous interpretation of demonstrations for modification of dynamical movement primitives\",\"35\":\"Learning multimodal models for robot dynamics online with a mixture of Gaussian process experts\",\"36\":\"A learning-based shared control architecture for interactive task execution\",\"37\":\"Learning from the hindsight plan \\u2014 Episodic MPC improvement\",\"38\":\"High-precision trajectory tracking in changing environments through L1 adaptive feedback and iterative learning\",\"39\":\"A systematic approach for minimizing physical experiments to identify optimal trajectory parameters for robots\",\"40\":\"Comparing human-centric and robot-centric sampling for robot deep learning from demonstrations\",\"41\":\"Multi-label tactile property analysis\",\"42\":\"Reliable object handover through tactile force sensing and effort control in the Shadow Robot hand\",\"43\":\"Touch based localization of parts for high precision manufacturing\",\"44\":\"Passivity-based stability in explicit force control of robots\",\"45\":\"Efficient event-driven reactive control for large scale robot skin\",\"46\":\"Skin normal force calibration using vacuum bags\",\"47\":\"A highly sensitive multimodal capacitive tactile sensor\",\"48\":\"Effects of discretization on the K-width of series elastic actuators\",\"49\":\"WRAP: Wearable, restricted-aperture pneumatics for haptic guidance\",\"50\":\"Blindfolded robotic teleoperation using spatial force feedback to the toe\",\"51\":\"Proton 2: Increasing the sensitivity and portability of a visuo-haptic surface interaction recorder\",\"52\":\"On the passivity of mechanical integrators in haptic rendering\",\"53\":\"Collision representation using vibrotactile cues to bimanual impact localization for mobile robot operations\",\"54\":\"A rehabilitation exercise robot for treating low back pain\",\"55\":\"A novel framework for optimizing motor (Re)-learning with a robotic exoskeleton\",\"56\":\"A 3 wire body weight support system for a large treadmill\",\"57\":\"Design and validation of a torque dense, highly backdrivable powered knee-ankle orthosis\",\"58\":\"Design and validation of a multi-axis robotic platform for the characterization of ankle neuromechanics\",\"59\":\"A robotic orthosis with a cable-differential mechanism\",\"60\":\"Stability of the human ankle in relation to environmental mechanics\",\"61\":\"Static and dynamic partitions of inequalities and their application in supervisor simplification\",\"62\":\"Close-down process scheduling of wafer residence time-constrained multi-cluster tools\",\"63\":\"Constraint-based sample propagation for improved state estimation in robotic assembly\",\"64\":\"CoSTAR: Instructing collaborative robots with behavior trees and vision\",\"65\":\"Planning cuts for mobile robots with bladed tools\",\"66\":\"Self-folded soft robotic structures with controllable joints\",\"67\":\"A new design concept of magnetically levitated 4 pole hybrid mover driven by linear motor\",\"68\":\"Soft sheet actuator generating traveling waves inspired by gastropod's locomotion\",\"69\":\"Modified nonlinear pressure estimator of pneumatic actuator for force controller design\",\"70\":\"Design and development of a Magneto-Rheological linear clutch for force controlled human safe robots\",\"71\":\"Underactuated four-fingered hand with five electro hydrostatic actuators in cluster\",\"72\":\"Pneumatic Reel Actuator: Design, modeling, and implementation\",\"73\":\"Deep reinforcement learning for tensegrity robot locomotion\",\"74\":\"T-LQG: Closed-loop belief space planning via trajectory-optimized LQG\",\"75\":\"Real-time distributed receding horizon motion planning and control for mobile multi-robot dynamic systems\",\"76\":\"Approximately optimal continuous-time motion planning and control via Probabilistic Inference\",\"77\":\"Online optimal active sensing control\",\"78\":\"On the structure of the time-optimal path parameterization problem with third-order constraints\",\"79\":\"Multiscale abstraction, planning and control using diffusion wavelets for stochastic optimal control problems\",\"80\":\"Differential dynamic programming with nonlinear constraints\",\"81\":\"Visibility enhancement for underwater visual SLAM based on underwater light scattering model\",\"82\":\"Multi-sensor payload detection and acquisition for truck-trailer AGVs\",\"83\":\"Reconstructing vehicles from a single image: Shape priors for road scene understanding\",\"84\":\"Catenary-based visual servoing for tethered robots\",\"85\":\"Robustifying correspondence based 6D object pose estimation\",\"86\":\"Driving in the Matrix: Can virtual worlds replace human-generated annotations for real world tasks?\",\"87\":\"Machine learning and coresets for automated real-time video segmentation of laparoscopic and robot-assisted surgery\",\"88\":\"Multi-objective search for optimal multi-robot planning with finite LTL specifications and resource constraints\",\"89\":\"Dynamic coverage control for mobile robot network with limited and nonidentical sensory ranges\",\"90\":\"Decentralized motion planning with collision avoidance for a team of UAVs under high level goals\",\"91\":\"A layered HMM for predicting motion of a leader in multi-robot settings\",\"92\":\"An aspect representation for object manipulation based on convolutional neural networks\",\"93\":\"Algorithm for optimal chance constrained linear assignment\",\"94\":\"Tunneling-based self-reconfiguration of heterogeneous sliding cube-shaped modular robots in environments with obstacles\",\"95\":\"Distributed fixed-time cooperative tracking control for multi-robot systems\",\"96\":\"Hybrid system for target tracking in triangulation graphs\",\"97\":\"Smooth joint motion planning for high precision reconfigurable robot manipulators\",\"98\":\"Multi-robot active information gathering with periodic communication\",\"99\":\"Bipartite graph matching-based coordination mechanism for multi-robot path planning under communication constraints\",\"100\":\"Scalable accelerated decentralized multi-robot policy search in continuous observation spaces\",\"101\":\"Semantic-level decentralized multi-robot decision-making using probabilistic macro-observations\",\"102\":\"Preference learning on the execution of collaborative human-robot tasks\",\"103\":\"Learning composable models of parameterized skills\",\"104\":\"Self-supervised learning of tool affordances from 3D tool representation through parallel SOM mapping\",\"105\":\"Constrained Bayesian optimization of combined interaction force\\/task space controllers for manipulations\",\"106\":\"Learning to gather information via imitation\",\"107\":\"Apprenticeship learning in an incompatible feature space\",\"108\":\"Development of an optical fiber-based sensor for grasping and axial force sensing\",\"109\":\"Sensorless kinesthetic teaching of robotic manipulators assisted by observer-based force control\",\"110\":\"Shape-independent hardness estimation using deep learning and a GelSight tactile sensor\",\"111\":\"Accurate contact localization and indentation depth prediction with an optics-based tactile sensor\",\"112\":\"Low-cost 3-axis soft tactile sensors for the human-friendly robot Vizzy\",\"113\":\"Safe navigation and experimental evaluation of a novel tire workshop assistant robot\",\"114\":\"Using intentional contact to achieve tasks in tight environments\",\"115\":\"Reducing errors in object-fetching interactions through social feedback\",\"116\":\"Transparent role assignment and task allocation in human robot collaboration\",\"117\":\"Simulating gait assistance of a hip exoskeleton: Case studies for ankle pathologies\",\"118\":\"Mobile robot companion for walking training of stroke patients in clinical post-stroke rehabilitation\",\"119\":\"Development of a block machine for volleyball attack training\",\"120\":\"The Multilegged Autonomous eXplorer (MAX)\",\"121\":\"Empirical validation of a spined sagittal-plane quadrupedal model\",\"122\":\"A testbed that evolves hexapod controllers in hardware\",\"123\":\"Between-leg coupling schemes for passively-adaptive non-redundant legged robots\",\"124\":\"Quasi-static and dynamic mismatch for door opening and stair climbing with a legged robot\",\"125\":\"Trajectory and foothold optimization using low-dimensional models for rough terrain locomotion\",\"126\":\"Biologically-inspired auditory perception during robotic bone milling\",\"127\":\"A high-force, high-stroke distal robotic add-on for endoscopy\",\"128\":\"Deployable stabilization mechanisms for endoscopic procedures\",\"129\":\"Magnetically actuated soft capsule endoscope for fine-needle aspiration biopsy\",\"130\":\"Preliminary results on energy efficient 3D prosthetic walking with a powered compliant transfemoral prosthesis\",\"131\":\"A rolling-diaphragm hydrostatic transmission for remote MR-guided needle insertion\",\"132\":\"First demonstration of simultaneous localization and propulsion of a magnetic capsule in a lumen using a single rotating magnet\",\"133\":\"A virtual paper model of a three piece brassiere cup to improve the efficiency of cup design process\",\"134\":\"RoboFDM: A robotic system for support-free fabrication using FDM\",\"135\":\"An improved toolpath generation algorithm for fused filament fabrication\",\"136\":\"Interactive, iterative robot design\",\"137\":\"Computational abstractions for interactive design of robotic devices\",\"138\":\"PaintPots: Low cost, accurate, highly customizable potentiometers for position sensing\",\"139\":\"Enhancing joint torque control of series elastic actuators with physical damping\",\"140\":\"Efficiently tunable positive-negative stiffness actuator\",\"141\":\"Analytical conditions for the design of variable stiffness mechanisms\",\"142\":\"A self-adaptive variable impedance actuator based on intrinsic non-linear compliance and damping principles\",\"143\":\"Tank based unified torque\\/impedance control for a pneumatically actuated antagonistic robot joint\",\"144\":\"A geometrically-amplified in-plane piezoelectric actuator for mesoscale robotic systems\",\"145\":\"Planning method for a wrapping-with-fabric task using regrasping\",\"146\":\"Online estimation of object-environment constraints for planning of humanoid motion on a movable object\",\"147\":\"A general formal framework for multi-agent meeting problems\",\"148\":\"Towards robotic MAGMaS: Multiple aerial-ground manipulator systems\",\"149\":\"Plan explicability and predictability for robot task planning\",\"150\":\"Optimal path planning and coverage control for multi-robot persistent coverage in environments with obstacles\",\"151\":\"Sampling-based approximate optimal temporal logic planning\",\"152\":\"Toward robust, whole-hand caging manipulation with underactuated hands\",\"153\":\"Lidar-histogram for fast road and obstacle detection\",\"154\":\"Semi-supervised vision-language mapping via variational learning\",\"155\":\"Vote3Deep: Fast object detection in 3D point clouds using efficient convolutional neural networks\",\"156\":\"A deep representation for depth images from synthetic data\",\"157\":\"A deep learning approach to traffic lights: Detection, tracking, and classification\",\"158\":\"A dataset for developing and benchmarking active vision\",\"159\":\"Multi-view self-supervised deep learning for 6D pose estimation in the Amazon Picking Challenge\",\"160\":\"Self-paced cross-modality transfer learning for efficient road segmentation\",\"161\":\"Predictive positioning and quality of service ridesharing for campus mobility on demand systems\",\"162\":\"Toward human-like lane following behavior in urban environment with a learning-based behavior-induction potential map\",\"163\":\"Global outer-urban navigation with OpenStreetMap\",\"164\":\"Accurate stereo visual odometry with gamma distributions\",\"165\":\"Direct visual-inertial navigation with analytical preintegration\",\"166\":\"A learning-based framework for handling dilemmas in urban automated driving\",\"167\":\"Automated generation of diverse and challenging scenarios for test and evaluation of autonomous vehicles\",\"168\":\"A distributed algorithm for mapping the graphical structure of complex environments with a swarm of robots\",\"169\":\"Bearing rigidity maintenance for formations of quadrotor UAVs\",\"170\":\"A portable, 3D-printing enabled multi-vehicle platform for robotics research and education\",\"171\":\"Minimum-violation scLTL motion planning for mobility-on-demand\",\"172\":\"Distributed aggregation for modular robots in the pivoting cube model\",\"173\":\"Duckietown: An open, inexpensive and flexible platform for autonomy education and research\",\"174\":\"Decentralized coordinated motion for a large team of robots preserving connectivity and avoiding collisions\",\"175\":\"Efficient learning of constraints and generic null space policies\",\"176\":\"From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots\",\"177\":\"Supervisory teleoperation with online learning and optimal control\",\"178\":\"Rapidly exploring learning trees\",\"179\":\"Hitting the sweet spot: Automatic optimization of energy transfer during tool-held hits\",\"180\":\"Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization\",\"181\":\"A grasping approach based on superquadric models\",\"182\":\"Control of linear and rotational slippage based on six-axis force\\/tactile sensor\",\"183\":\"Grasp quality evaluation done right: How assumed contact force bounds affect Wrench-based quality metrics\",\"184\":\"Supervision via competition: Robot adversaries for learning tasks\",\"185\":\"A hybrid deep architecture for robotic grasp detection\",\"186\":\"A cloud robot system using the dexterity network and berkeley robotics and automation as a service (Brass)\",\"187\":\"Show, attend and interact: Perceivable human-robot social interaction through neural attention Q-network\",\"188\":\"Two-eye model-based gaze estimation from a Kinect sensor\",\"189\":\"ModLight: Designing a modular light signaling tool for human-robot interaction\",\"190\":\"Towards real-time 3D sound sources mapping with linear microphone arrays\",\"191\":\"Learning social affordance grammar from videos: Transferring human interactions to human-robot interactions\",\"192\":\"Emotional intelligence in robots: Recognizing human emotions from daily-life gestures\",\"193\":\"Modeling cooperative navigation in dense human crowds\",\"194\":\"The Robotarium: A remotely accessible swarm robotics research testbed\",\"195\":\"Design, development and experimental assessment of a robotic end-effector for non-standard concrete applications\",\"196\":\"Information theoretic MPC for model-based reinforcement learning\",\"197\":\"Probabilistic data association for semantic SLAM\",\"198\":\"Estimating unknown object dynamics in human-robot manipulation tasks\",\"199\":\"A framework for sensorless and autonomous probe-tissue contact management in robotic endomicroscopic scanning\",\"200\":\"Controlling the Stormram 2: An MRI-compatible robotic system for breast biopsy\",\"201\":\"RAFS: A computer-assisted robotic system for minimally invasive joint fracture surgery, based on pre- and intra-operative imaging\",\"202\":\"EEG-controlled meal assistance robot with camera-based automatic mouth position tracking and mouth open detection\",\"203\":\"Towards active variable stiffness manipulators for surgical robots\",\"204\":\"Effects of exoskeleton weight and inertia on human walking\",\"205\":\"Real time welding parameter prediction for desired character performance\",\"206\":\"An ultra-compact infinitely variable transmission for robotics\",\"207\":\"Toward controlling a KUKA LBR IIWA for interactive tracking\",\"208\":\"Quick positional health assessment for industrial robot prognostics and health management (PHM)\",\"209\":\"Automatic robot taping with force feedback\",\"210\":\"Biomimetic robotic joint mechanism driven by soft linear actuators\",\"211\":\"Electric phase-change actuator with inkjet printed flexible circuit for printable and integrated robot prototyping\",\"212\":\"Multi-objective design optimization of a soft, pneumatic robot\",\"213\":\"Design of a compact rotary series elastic actuator for improved actuation transparency and mechanical safety\",\"214\":\"A robotic manipulator design with novel soft actuators\",\"215\":\"A self-locking-type expansion mechanism to achieve high holding force and pipe-passing capability for a pneumatic in-pipe robot\",\"216\":\"Human body part multicontact recognition and detection methodology\",\"217\":\"Collision avoidance with limited field of view sensing: A velocity obstacle approach\",\"218\":\"Parallel autonomy in automated vehicles: Safe motion generation with minimal intervention\",\"219\":\"Parallel collision check for sensor based real-time motion planning\",\"220\":\"Efficient probabilistic collision detection for non-convex shapes\",\"221\":\"Depth from stereo polarization in specular scenes for urban robotics\",\"222\":\"Compressive tracking with locality sensitive histograms features\",\"223\":\"Detecting, localizing, and recognizing trees with a monocular MAV: Towards preventing deforestation\",\"224\":\"Combined image- and world-space tracking in traffic scenes\",\"225\":\"Visual tracking of multiple moving targets in 2D ultrasound guided robotic percutaneous interventions\",\"226\":\"Deep representation of industrial components using simulated images\",\"227\":\"6-DoF object pose from semantic keypoints\",\"228\":\"Falling in line: Visual route following on extreme terrain for a tethered mobile robot\",\"229\":\"Reducing drift in visual odometry by inferring sun direction using a Bayesian Convolutional Neural Network\",\"230\":\"DeepVO: Towards end-to-end visual odometry with deep Recurrent Convolutional Neural Networks\",\"231\":\"Visual servoing using model predictive control to assist multiple trajectory tracking\",\"232\":\"Visual triage: A bag-of-words experience selector for long-term visual route following\",\"233\":\"Satellite image-based localization via learned embeddings\",\"234\":\"Rate impact analysis in robotic systems\",\"235\":\"Achieving the desired dynamic behavior in multi-robot systems interacting with the environment\",\"236\":\"Distributed computation of forces in modular-robotic ensembles as part of reconfiguration planning\",\"237\":\"Distributed cooperative object parameter estimation and manipulation without explicit communication\",\"238\":\"Active target tracking with self-triggered communications\",\"239\":\"Multi-robot coordination through dynamic Voronoi partitioning for informative adaptive sampling in communication-constrained environments\",\"240\":\"Modular robot using helical magnet for bonding and transformation\",\"241\":\"Combining self-supervised learning and imitation for vision-based rope manipulation\",\"242\":\"Learning to jump in granular media: Unifying optimal control synthesis with Gaussian process-based regression\",\"243\":\"Learning to push by grasping: Using multiple tasks for effective learning\",\"244\":\"Learning modular neural network policies for multi-task and multi-robot transfer\",\"245\":\"Incorporating side-channel information into convolutional neural networks for robotic tasks\",\"246\":\"Learning feedback terms for reactive planning and control\",\"247\":\"Computing the best grasp in a discrete point set\",\"248\":\"A novel actuation configuration of robotic hand and the mechanical implementation via postural synergies\",\"249\":\"Grasp quality evaluation and planning for objects with negative curvature\",\"250\":\"Hierarchical salient object detection for assisted grasping\",\"251\":\"Grasp stability assessment through unsupervised feature learning of tactile images\",\"252\":\"Grasping posture estimation for a two-finger parallel gripper with soft material jaws using a curved contact area friction model\",\"253\":\"Decoupled limbs yield differentiable trajectory outcomes through intermittent contact in locomotion and manipulation\",\"254\":\"Design of an SSVEP-based BCI system with visual servo module for a service robot to execute multiple tasks\",\"255\":\"Making gait recognition robust to speed changes using mutual subspace method\",\"256\":\"End-effector airbags to accelerate human-robot collaboration\",\"257\":\"Modeling user expertise for choosing levels of shared autonomy\",\"258\":\"Port-Hamiltonian based control for human-robot team interaction\",\"259\":\"A multiple-predictor approach to human motion prediction\",\"260\":\"Backchannel opportunity prediction for social robot listeners\",\"261\":\"Recognizing social touch gestures using recurrent and convolutional neural networks\",\"262\":\"Data-driven design of implicit force control for industrial robots\",\"263\":\"Motion planning with movement primitives for cooperative aerial transportation in obstacle environment\",\"264\":\"1-Actuator 3-DoF parts feeding using hybrid joint mechanism with twisted axis layout\",\"265\":\"Robust policy search with applications to safe vehicle navigation\",\"266\":\"Autonomous robotic stone stacking with online next best object target pose planning\",\"267\":\"A learning based training and skill assessment platform with haptic guidance for endovascular catheterization\",\"268\":\"Roboscope: A flexible and bendable surgical robot for single portal Minimally Invasive Surgery\",\"269\":\"Multilateral surgical pattern cutting in 2D orthotropic gauze with deep reinforcement learning policies for tensioning\",\"270\":\"Three-dimensional robotic-assisted endomicroscopy with a force adaptive robotic arm\",\"271\":\"Improving the safety of telerobotic drilling of the skull base via photoacoustic sensing of the carotid arteries\",\"272\":\"Autonomous suturing via surgical robot: An algorithm for optimal selection of needle diameter, shape, and path\",\"273\":\"Orientation estimation of a continuum manipulator in a phantom lung\",\"274\":\"Trajectory tracking and balance control of an autonomous bikebot\",\"275\":\"Obstacle negotiation learning for a compliant wheel-on-leg robot\",\"276\":\"Harnessing steering singularities in passive path following for robotic walkers\",\"277\":\"Path following controller for planar robots with articulated, actuated and independently steerable velocity-limited wheels\",\"278\":\"TOMM: Tactile omnidirectional mobile manipulator\",\"279\":\"Designing for uniform mobility using holonomicity\",\"280\":\"Efficient path planning for mobile robots with adjustable wheel positions\",\"281\":\"Inverse kinematics with strict nonholonomic constraints on mobile manipulator\",\"282\":\"On orientation control of functional redundant robots\",\"283\":\"Recursive second-order inverse dynamics for serial manipulators\",\"284\":\"Multi-arm snake-like robot\",\"285\":\"O (logn) algorithm for forward kinematics under asynchronous sensory input\",\"286\":\"Real-time shape estimation of Kirchhoff elastic rod based on force\\/torque sensor\",\"287\":\"Dense monocular reconstruction using surface normals\",\"288\":\"Learning highly dynamic environments with stochastic variational inference\",\"289\":\"Robust stereo matching with surface normal prediction\",\"290\":\"Robot mapping and localisation in metal water pipes using hydrophone induced vibration and map alignment by dynamic time warping\",\"291\":\"Incremental contour-based topological segmentation for robot exploration\",\"292\":\"Semantic classification by reasoning on the whole structure of buildings using statistical relational learning techniques\",\"293\":\"SkiMap: An efficient mapping framework for robot navigation\",\"294\":\"Multirobot online construction of communication maps\",\"295\":\"Sequence-based multimodal apprenticeship learning for robot perception and decision making\",\"296\":\"Minimum uncertainty latent variable models for robot recognition of sequential human activities\",\"297\":\"Learning a deep network with spherical part model for 3D hand pose estimation\",\"298\":\"Visual stability prediction for robotic manipulation\",\"299\":\"Semantics-aware visual localization under challenging perceptual conditions\",\"300\":\"Simultaneous Feature and Body-Part Learning for real-time robot awareness of human behaviors\",\"301\":\"Visual closed-loop control for pouring liquids\",\"302\":\"Distributed consistent data association via permutation synchronization\",\"303\":\"A cloud service for robotic mental simulations\",\"304\":\"Mobile robots for learning spatio-temporal interpolation models in sensor networks \\u2014 The Echo State map approach\",\"305\":\"Unsupervised camera localization in crowded spaces\",\"306\":\"Automated sequencing of swarm behaviors for supervisory control of robotic swarms\",\"307\":\"Persistent surveillance of events with unknown, time-varying statistics\",\"308\":\"Application of substantial and sustained force to vertical surfaces using a quadrotor\",\"309\":\"Three dimensional moving path following for fixed-wing unmanned aerial vehicles\",\"310\":\"Modeling and control of a saucer type Coand\\u00e4 effect UAV\",\"311\":\"Implementation of a parametrized infinite-horizon model predictive control scheme with stability guarantees\",\"312\":\"A global controller for flying wing tailsitter vehicles\",\"313\":\"Short-term UAV path-planning with monocular-inertial SLAM in the loop\",\"314\":\"Control of statically hoverable multi-rotor aerial vehicles and application to rotor-failure robustness for hexarotors\",\"315\":\"Gesture-based robot control: Design challenges and evaluation with humans\",\"316\":\"Learning individual motion preferences from audience feedback of motion sequences\",\"317\":\"Semantic web-mining and deep vision for lifelong object discovery\",\"318\":\"Deep visual foresight for planning robot motion\",\"319\":\"Deep multimodal embedding: Manipulating novel objects with point-clouds, language and trajectories\",\"320\":\"Learning to represent haptic feedback for partially-observable tasks\",\"321\":\"Learning to guide task and motion planning using score-space representation\",\"322\":\"Design of a novel variable stiffness gripper using permanent magnets\",\"323\":\"Force and moment constraints of a curved surface gripper and wrist for assistive free flyers\",\"324\":\"Design of parallel-jaw gripper tip surfaces for robust grasping\",\"325\":\"Vision-based model predictive control for within-hand precision manipulation with underactuated grippers\",\"326\":\"Optimal design of a soft robotic gripper with high mechanical advantage for grasping irregular objects\",\"327\":\"A framework for robot-assisted doffing of personal protective equipment\",\"328\":\"A system for learning continuous human-robot interactions from human-human demonstrations\",\"329\":\"A study of bidirectionally telepresent tele-action during robot-mediated handover\",\"330\":\"A game-theoretic approach for adaptive action selection in close proximity human-robot-collaboration\",\"331\":\"Maestro: An EMG-driven assistive hand exoskeleton for spinal cord injury patients\",\"332\":\"Admittance control parameter adaptation for physical human-robot interaction\",\"333\":\"Interactive force control of an elastically actuated bi-articular two-link manipulator\",\"334\":\"An intervening ethical governor for a robot mediator in patient-caregiver relationship: Implementation and evaluation\",\"335\":\"Toward monocular camera-guided retinal vein cannulation with an actively stabilized handheld robot\",\"336\":\"A balloon endomicroscopy scanning device for diagnosing barrett's oesophagus\",\"337\":\"Design of a flexure-based micro-motion stage with constant output force\",\"338\":\"Iteratively Learned and Temporally Scaled Force Control with application to robotic assembly in unstructured environments\",\"339\":\"A probabilistic data-driven model for planar pushing\",\"340\":\"A distributed approach to automated manufacturing systems with complex structures using Petri nets\",\"341\":\"UAV-based crop and weed classification for smart farming\",\"342\":\"NimbRo picking: Versatile part handling for warehouse automation\",\"343\":\"Planning and executing optimal non-entangling paths for tethered underwater vehicles\",\"344\":\"A sliding mode controller design for the robust position control problem of series elastic actuators\",\"345\":\"Realizing natural springy motion of a robotic leg by cancelling the undesired damping factors\",\"346\":\"3DFlex: A rapid prototyping approach for multi-material compliant mechanisms in millirobots\",\"347\":\"Compliant, bi-stable mechanisms with multiple stiffnesses through controlled spring buckling\",\"348\":\"On the role of stiffness design for fingertip trajectories of underactuated modular soft hands\",\"349\":\"AtomMap: A probabilistic amorphous 3D map representation for robotics and surface reconstruction\",\"350\":\"Bayesian generalized kernel inference for occupancy map prediction\",\"351\":\"Deliberative object pose estimation in clutter\",\"352\":\"Coupling conditionally independent submaps for large-scale 2.5D mapping with Gaussian Markov Random Fields\",\"353\":\"Efficient descriptor learning for large scale localization\",\"354\":\"FLAG: Feature-based Localization between Air and Ground\",\"355\":\"Action recognition: From static datasets to moving robots\",\"356\":\"Visual place recognition with probabilistic voting\",\"357\":\"Map quality evaluation for visual localization\",\"358\":\"Incremental robot learning of new objects with fixed update time\",\"359\":\"Temporal persistence modeling for object search\",\"360\":\"Deep learning features at scale for visual place recognition\",\"361\":\"A stable adaptive attitude estimator on SO(3) for true-North seeking gyrocompass systems: Theory and preliminary simulation evaluation\",\"362\":\"Ground substrate classification for adaptive quadruped locomotion\",\"363\":\"Monocular vision-based human following on miniature robotic blimp\",\"364\":\"Daily activity recognition with inertial ring and bracelet: An unsupervised approach\",\"365\":\"Real-time inertial lower body kinematics and ground contact estimation at anatomical foot points for agile human locomotion\",\"366\":\"Photometric patch-based visual-inertial odometry\",\"367\":\"Robust sensor fusion for finding HRI partners in a crowd\",\"368\":\"Stability of load lifting by a quadrotor under attitude control delay\",\"369\":\"Safe certificate-based maneuvers for teams of quadrotors using differential flatness\",\"370\":\"Crazyswarm: A large nano-quadcopter swarm\",\"371\":\"UAV with two passive rotating hemispherical shells for physical interaction and power tethering in a complex environment\",\"372\":\"Piccolissimo: The smallest micro aerial vehicle\",\"373\":\"PLATO: Policy learning using adaptive trajectory optimization\",\"374\":\"Bayesian optimization with adaptive kernels for robot control\",\"375\":\"Target-driven visual navigation in indoor scenes using deep reinforcement learning\",\"376\":\"A robust stability approach to robot reinforcement learning based on a parameterization of stabilizing controllers\",\"377\":\"Reset-free guided policy search: Efficient deep reinforcement learning with stochastic initial states\",\"378\":\"Path integral guided policy search\",\"379\":\"Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates\",\"380\":\"Optimized vehicle-specific trajectories for cooperative process estimation by sensor-equipped UAVs\",\"381\":\"Design and actuation of a magnetic millirobot under a constant unidirectional magnetic field\",\"382\":\"Efficient kinematic planning for mobile manipulators with non-holonomic constraints using optimal control\",\"383\":\"Empirical evaluation of common contact models for planar impact\",\"384\":\"Optimal, sampling-based manipulation planning\",\"385\":\"Design of a simplified compliant anthropomorphic robot hand\",\"386\":\"Integrating motion and hierarchical fingertip grasp planning\",\"387\":\"Analyzing achievable stiffness control bounds of robotic hands with coupled finger joints\",\"388\":\"A two-fingered robot gripper with large object reorientation range\",\"389\":\"Robust walking by resolved viscoelasticity control explicitly considering structure-variability of a humanoid\",\"390\":\"Context-driven movement primitive adaptation\",\"391\":\"Supervised learning for stabilizing underactuated bipedal robot locomotion, with outdoor experiments on the wave field\",\"392\":\"Dynamic manipulability of the center of mass: A tool to study, analyse and measure physical ability of robots\",\"393\":\"A study of nonlinear forward models for dynamic walking\",\"394\":\"Invariant funnels for underactuated dynamic walking robots: New phase variable and experimental validation\",\"395\":\"Robust bipedal locomotion control based on model predictive control and divergent component of motion\",\"396\":\"Path following for a biomimetic underwater vehicle based on ADRC\",\"397\":\"A drift diffusion model of biological source seeking for mobile robots\",\"398\":\"Closed-loop path following of traveling wave rectilinear motion through obstacle-strewn terrain\",\"399\":\"High speed trajectory control using an experimental maneuverability model for an insect-scale legged robot\",\"400\":\"Learning multisensory cue integration on mobile robots\",\"401\":\"Adaptive L\\u00e9vy Taxis for odor source localization in realistic environmental conditions\",\"402\":\"From Rousettus aegyptiacus (bat) landing to robotic landing: Regulation of CG-CP distance using a nonlinear closed-loop feedback\",\"403\":\"A prey-predator model for efficient robot tracking\",\"404\":\"In vivo tracking and measurement of pollen tube vesicle motion\",\"405\":\"Development of a tele-nursing mobile manipulator for remote care-giving in quarantine areas\",\"406\":\"Autonomous scanning for endomicroscopic mosaicing and 3D fusion\",\"407\":\"Introducing BigMag \\u2014 A novel system for 3D magnetic actuation of flexible surgical manipulators\",\"408\":\"Experimental validation of the pseudo-rigid-body model of the MRI-actuated catheter\",\"409\":\"Robot assisted tapping control for therapeutical percussive massage applications\",\"410\":\"Visual servoing controller for time-invariant 3D path following with remote centre of motion constraint\",\"411\":\"Deep fruit detection in orchards\",\"412\":\"The Robotanist: A ground-based agricultural robot for high-throughput crop phenotyping\",\"413\":\"Improving octree-based occupancy maps using environment sparsity with application to aerial robot navigation\",\"414\":\"Feasibility study of IoRT platform \\u201cBig Sensor Box\\u201d\",\"415\":\"Autonomous robotic system using non-destructive evaluation methods for bridge deck inspection\",\"416\":\"High-precision microinjection of microbeads into C. elegans trapped in a suction microchannel\",\"417\":\"Wire-tension control using Compact Planetary geared Elastic Actuator\",\"418\":\"A feasibility study on tension control of Bowden-cable based on a dual-wire scheme\",\"419\":\"Design of a 6-DOF collaborative robot arm with counterbalance mechanisms\",\"420\":\"Position and orientation control of passive wire-driven motion support system using servo brakes\",\"421\":\"Using compliant leg design for impact attenuation of airdrop landings of quadruped robots\",\"422\":\"Passive returning mechanism for twisted string actuators\",\"423\":\"Performance evaluation of a new design of cable-suspended camera system\",\"424\":\"Path following control of skid-steered wheeled mobile robots at higher speeds on different terrain types\",\"425\":\"Adaptive motion planning with high-dimensional mixture models\",\"426\":\"On-line trajectory planning with time-variant motion constraints for industrial robot manipulators\",\"427\":\"Focused model-learning and planning for non-Gaussian continuous state-action systems\",\"428\":\"Dynamic risk tolerance: Motion planning by balancing short-term and long-term stochastic dynamic predictions\",\"429\":\"Densification strategies for anytime motion planning over large dense roadmaps\",\"430\":\"Stochastic functional gradient for motion planning in continuous occupancy maps\",\"431\":\"Consistent sparsification for efficient decision making under uncertainty in high dimensional state spaces\",\"432\":\"A unified leader-follower scheme for mobile robots with uncalibrated on-board camera\",\"433\":\"Visual servoing through mirror reflection\",\"434\":\"A robotic control framework for 3-D quantitative ultrasound elastography\",\"435\":\"Towards markerless visual servoing of grasping tasks for humanoid robots\",\"436\":\"Exploring convolutional networks for end-to-end visual servoing\",\"437\":\"PennCOSYVIO: A challenging Visual Inertial Odometry benchmark\",\"438\":\"MSGD: Scalable back-end for indoor magnetic field-based GraphSLAM\",\"439\":\"Multi-UAV collaborative monocular SLAM\",\"440\":\"Direct monocular odometry using points and lines\",\"441\":\"4D crop monitoring: Spatio-temporal reconstruction for agriculture\",\"442\":\"Attention and anticipation in fast visual-inertial navigation\",\"443\":\"Active exposure control for robust visual odometry in HDR environments\",\"444\":\"Bringing Mobile Robot Olfaction to the next dimension \\u2014 UAV-based remote sensing of gas clouds and source localization\",\"445\":\"Design and experiments for a transformable solar-UAV\",\"446\":\"Design and implementation of a quadrotor tail-sitter VTOL UAV\",\"447\":\"Sampling-based motion planning for active multirotor system identification\",\"448\":\"Model-based transition optimization for a VTOL tailsitter\",\"449\":\"Model-based wind estimation for a hovering VTOL tailsitter UAV\",\"450\":\"Joint pose and principal curvature refinement using quadrics\",\"451\":\"De-noising, stabilizing and completing 3D reconstructions on-the-go using plane priors\",\"452\":\"Fast task-specific target detection via graph based constraints representation and checking\",\"453\":\"Fast odometry and scene flow from RGB-D cameras based on geometric clustering\",\"454\":\"Tracking objects with point clouds from vision and touch\",\"455\":\"RISAS: A novel rotation, illumination, scale invariant appearance and shape feature\",\"456\":\"Manipulation planning: Addressing the crossed foliation issue\",\"457\":\"Noninteracting constrained motion planning and control for robot manipulators\",\"458\":\"Multi-bound tree search for logic-geometric programming in cooperative manipulation domains\",\"459\":\"Open world assistive grasping using laser selection\",\"460\":\"C-LEARN: Learning geometric constraints from demonstrations for multi-step manipulation in shared autonomy\",\"461\":\"Planning and control for dynamic, nonprehensile, and hybrid manipulation tasks\",\"462\":\"Parts assembly planning under uncertainty with simulation-aided physical reasoning\",\"463\":\"Feasibility evaluation of object manipulation by a humanoid robot based on recursive estimation of the object's physical properties\",\"464\":\"Real-time pursuit-evasion with humanoid robots\",\"465\":\"Passivity-based control of underactuated biped robots within hybrid zero dynamics approach\",\"466\":\"Control of humanoid robot motions with impacts: Numerical experiments with reference spreading control\",\"467\":\"Dynamic multi-contact transitions for humanoid robots using Divergent Component of Motion\",\"468\":\"Smooth-path-tracking control of a biped robot at variable speed based on dynamics morphing\",\"469\":\"Influence of compliance modulation on human locomotion\",\"470\":\"CPG-based control of smooth transition for body shape and locomotion speed of a snake-like robot\",\"471\":\"Design and control of an inchworm-inspired soft robot with omega-arching locomotion\",\"472\":\"Guidelines for the design and control of bio-inspired hovering robots\",\"473\":\"Implementing caterpillar inspired roll control of a spherical robot\",\"474\":\"Design of hair-like appendages and their coordination inspired by water beetles for steady swimming on the water surface\",\"475\":\"Development and validation of modeling framework for interconnected tendon networks in robotic and human fingers\",\"476\":\"Mechanical specialization of robotic limbs\",\"477\":\"Pose optimization of a C-arm imaging device to reduce intraoperative radiation exposure of staff and patient during interventional procedures\",\"478\":\"Preoperative planning for the multi-arm surgical robot using PSO-GP-based performance optimization\",\"479\":\"Magnetic laser scanner for endoscopic microsurgery\",\"480\":\"MagNex \\u2014 Expendable robotic surgical tooltip\",\"481\":\"Modeling and analysis of a laparoscopic camera's interaction with abdomen tissue\",\"482\":\"Implicit gaze-assisted adaptive motion scaling for highly articulated instrument manipulation\",\"483\":\"Improving the reliability of service robots in the presence of external faults by learning action execution models\",\"484\":\"Deploying social robots as teaching aid in pre-school K2 classes: A proof-of-concept study\",\"485\":\"Instruction completion through instance-based learning and semantic analogical reasoning\",\"486\":\"What no robot has seen before \\u2014 Probabilistic interpretation of natural-language object descriptions\",\"487\":\"Control of liquid handling robotic systems: A feed-forward approach to suppress sloshing\",\"488\":\"Informative planning and online learning with sparse Gaussian processes\",\"489\":\"Optimizing guidance for an active shooter event\",\"490\":\"3D-printed ionic polymer-metal composite soft crawling robot\",\"491\":\"A versatile conducting interpenetrating polymer network for sensing and actuation\",\"492\":\"Asymmetric stable deformations in inflated dielectric elastomer actuators\",\"493\":\"Networked soft actuators with large deformations\",\"494\":\"Design, modeling and control of a SMA-actuated biomimetic robot with novel functional skin\",\"495\":\"A high speed soft robot based on dielectric elastomer actuators\",\"496\":\"Tunable friction through constrained inflation of an elastomeric membrane\",\"497\":\"Collision detection for 3D rigid body motion planning with narrow passages\",\"498\":\"Automated tuning and configuration of path planning algorithms\",\"499\":\"Perfect tracking control using a phase plane for a wheeled inverted pendulum under hardware constraints\",\"500\":\"Maximizing mutual information for multipass target search in changing environments\",\"501\":\"Efficient multi-agent global navigation using interpolating bridges\",\"502\":\"Accelerating energy-aware spatiotemporal path planning for the lunar poles\",\"503\":\"Adaptive trajectory control of off-road mobile robots: A multi-model observer approach\",\"504\":\"Smooth extensions of feedback motion planners via reference governors\",\"505\":\"Set space visual servoing of a 6-DOF manipulator\",\"506\":\"Illumination insensitive efficient second-order minimization for planar object tracking\",\"507\":\"Correlation filter-based self-paced object tracking\",\"508\":\"Real-time visual tracking via robust Kernelized Correlation Filter\",\"509\":\"Multi-robot control and tracking framework for bio-hybrid systems with closed-loop interaction\",\"510\":\"Mixed-domain biological motion tracking for underwater human-robot interaction\",\"511\":\"Event-based feature tracking with probabilistic data association\",\"512\":\"Co-fusion: Real-time segmentation, tracking and fusion of multiple objects\",\"513\":\"Towards efficient inference update through planning via JIP \\u2014 Joint inference and belief space planning\",\"514\":\"Nonmyopic data association aware belief space planning for robust active perception\",\"515\":\"MonoRGBD-SLAM: Simultaneous localization and mapping using both monocular and RGBD cameras\",\"516\":\"PL-SLAM: Real-time monocular visual SLAM with points and lines\",\"517\":\"O-POCO: Online point cloud compression mapping for visual odometry and SLAM\",\"518\":\"ROS2D: Image feature detector using rank order statistics\",\"519\":\"Illumination change robustness in direct visual SLAM\",\"520\":\"Cyrillic manual alphabet recognition in RGB and RGB-D data for sign language interpreting robotic system (SLIRS)\",\"521\":\"Orientation filter and angular rates estimation in monocopter using accelerometers and magnetometer with the Extended Kalman Filter\",\"522\":\"High altitude monocular visual-inertial state estimation: Initialization and sensor fusion\",\"523\":\"Real-time monocular dense mapping on aerial robots using visual-inertial fusion\",\"524\":\"Real-time local 3D reconstruction for aerial inspection using superpixel expansion\",\"525\":\"Uncertainty-aware receding horizon exploration and mapping using aerial robots\",\"526\":\"Autonomous swing-angle estimation for stable slung-load flight of multi-rotor UAVs\",\"527\":\"Active estimation of mass properties for safe cooperative lifting\",\"528\":\"MF3D: Model-free 3D semantic scene parsing\",\"529\":\"What can i do around here? Deep functional scene understanding for cognitive robots\",\"530\":\"Semantic analysis of manipulation actions using spatial relations\",\"531\":\"Analyzing modular CNN architectures for joint depth prediction and semantic segmentation\",\"532\":\"SemanticFusion: Dense 3D semantic mapping with convolutional neural networks\",\"533\":\"Online learning for scene segmentation with laser-constrained CRFs\",\"534\":\"AdapNet: Adaptive semantic segmentation in adverse environmental conditions\",\"535\":\"A robust control scheme for 3D manipulation of a microparticle with electromagnetic coil system\",\"536\":\"Toward improving path following motion: Hybrid continuum robot design\",\"537\":\"The manifold particle filter for state estimation on high-dimensional implicit manifolds\",\"538\":\"Unobservable Monte Carlo planning for nonprehensile rearrangement tasks\",\"539\":\"The ACRV picking benchmark: A robotic shelf picking benchmark to foster reproducible research\",\"540\":\"Feature selection for learning versatile manipulation skills based on observed and desired trajectories\",\"541\":\"Overlap-based ICP tuning for robust localization of a humanoid robot\",\"542\":\"Control walking speed by approximate-kinetic-model-based self-adaptive control on underactuated compass-like bipedal walker\",\"543\":\"Stability regions for standing balance of biped humanoid robots\",\"544\":\"Humanoid whole-body planning for loco-manipulation tasks\",\"545\":\"Footstep and motion planning in semi-unstructured environments using randomized possibility graphs\",\"546\":\"Collision detection, isolation and identification for humanoids\",\"547\":\"QP-based adaptive-gains compliance control in humanoid falls\",\"548\":\"Angular momentum compensation in yaw direction using upper body based on human running\",\"549\":\"Blade-type crawler vehicle with gyro wheel for stably traversing uneven terrain at high speed\",\"550\":\"A lobster-inspired robotic glove for hand rehabilitation\",\"551\":\"Quadrupedal locomotion using trajectory optimization and hierarchical whole body control\",\"552\":\"Biological undulation inspired swimming robot\",\"553\":\"Introducing rotary force to a template model can explain human compliant slope walking\",\"554\":\"Autonomous locomotion of a miniature, untethered origami robot using hall effect sensor-based magnetic localization\",\"555\":\"Predictive filtering in motion compensation with steerable cardiac catheters\",\"556\":\"The tethered magnet: Force and 5-DOF pose control for cardiac ablation\",\"557\":\"Shared control of a magnetic microcatheter for vitreoretinal targeted drug delivery\",\"558\":\"Towards MRI-guided flexible needle steering using fiber Bragg grating-based tip tracking\",\"559\":\"Experimental evaluation of various machine learning regression methods for model identification of autonomous underwater vehicles\",\"560\":\"Assisted painting of 3D structures using shared control with a hand-held robot\",\"561\":\"Underwater localization and 3D mapping of submerged structures with a single-beam scanning sonar\",\"562\":\"Phytoplankton hotspot prediction with an unsupervised spatial community model\",\"563\":\"An artificial fish lateral line sensory system composed of modular pressure sensor blocks\",\"564\":\"One-way travel-time inverted ultra-short baseline localization for low-cost autonomous underwater vehicles\",\"565\":\"Acoustic-inertial underwater navigation\",\"566\":\"Robots going round the bend \\u2014 A comparative study of estimators for anticipating river meanders\",\"567\":\"Position control of a robot finger with variable stiffness actuated by shape memory alloy\",\"568\":\"Control of cardiomyocyte contraction for actuation of bio-syncretic robots\",\"569\":\"Real-time simulation of hydraulic components for interactive control of soft robots\",\"570\":\"Localized differential sensing of soft deformable surfaces\",\"571\":\"A method for sensorizing soft actuators and its application to the RBO hand 2\",\"572\":\"Variable Stiffness Link (VSL): Toward inherently safe robotic manipulators\",\"573\":\"Morphological computation in tactile sensing: The role of wrinkle\",\"574\":\"Design, modeling, and control of pneumatic artificial muscles with integrated soft sensing\",\"575\":\"Sampling-based algorithms for optimal motion planning using closed-loop prediction\",\"576\":\"Randomized algorithm for informative path planning with budget constraints\",\"577\":\"Robot Coverage Path planning for general surfaces using quadratic differentials\",\"578\":\"Torque efficient motion through singularity\",\"579\":\"Real-time stochastic kinodynamic motion planning via multiobjective search on GPUs\",\"580\":\"Persistent pursuit-evasion: The case of the preoccupied pursuer\",\"581\":\"Functional co-optimization of articulated robots\",\"582\":\"Motion planning for mobile robots using inverse kinematics branching\",\"583\":\"Enabling aggressive motion estimation at low-drift and accurate mapping in real-time\",\"584\":\"Parse geometry from a line: Monocular depth estimation with partial laser observation\",\"585\":\"Fast segmentation of 3D point clouds: A paradigm on LiDAR data for autonomous vehicle applications\",\"586\":\"Learning-based feature extraction for active 3D scan with reducing color crosstalk of multiple pattern projections\",\"587\":\"Real-time 3D human tracking for mobile robots with multisensors\",\"588\":\"Pre-touch sensing for sequential manipulation\",\"589\":\"AUV motion-planning for photogrammetric reconstruction of marine archaeological sites\",\"590\":\"A novel method for the extrinsic calibration of a 2-D laser-rangefinder & a camera\",\"591\":\"Keyframe-based dense planar SLAM\",\"592\":\"Random forests versus Neural Networks \\u2014 What's best for camera localization?\",\"593\":\"Monocular visual odometry: Sparse joint optimisation or dense alternation?\",\"594\":\"Initialization of 3D pose graph optimization using Lagrangian duality\",\"595\":\"Automatic color correction for 3D reconstruction of underwater scenes\",\"596\":\"RRD-SLAM: Radial-distorted rolling-shutter direct SLAM\",\"597\":\"VINS on wheels\",\"598\":\"On the utility of additional sensors in aquatic simultaneous localization and mapping\",\"599\":\"Flight controller design and demonstration of a thrust-vectored tailsitter\",\"600\":\"Whole-body aerial manipulation by transformable multirotor with two-dimensional multilinks\",\"601\":\"Deep neural networks for improved, impromptu trajectory tracking of quadrotors\",\"602\":\"6D physical interaction with a fully actuated aerial robot\",\"603\":\"Dynamic collaboration without communication: Vision-based cable-suspended load transport with two quadrotors\",\"604\":\"Adaptive closed-loop speed control of BLDC motors with applications to multi-rotor aerial vehicles\",\"605\":\"Design of the I-BoomCopter UAV for environmental interaction\",\"606\":\"Towards unsupervised weed scouting for agricultural robotics\",\"607\":\"Bayesian estimation based real-time fire-heading in smoke-filled indoor environments using thermal imagery\",\"608\":\"TSDF-based change detection for consistent long-term dense reconstruction and dynamic object discovery\",\"609\":\"Embedded real-time multi-baseline stereo\",\"610\":\"3D tracking of water hazards with polarized stereo cameras\",\"611\":\"Improved semantic segmentation for robotic applications with hierarchical conditional random fields\",\"612\":\"SegMatch: Segment based place recognition in 3D point clouds\",\"613\":\"Cross-modal visuo-tactile object recognition using robotic active exploration\",\"614\":\"Combined inverse-dynamics\\/passivity-based control for robots with elastic joints\",\"615\":\"Feedforward control of Variable Stiffness Joints robots for vibrations suppression\",\"616\":\"Model-based policy search for automatic tuning of multivariate PID controllers\",\"617\":\"Whole-body trajectory optimization for non-periodic dynamic motions on quadrupedal systems\",\"618\":\"Online walking motion and foothold optimization for quadruped locomotion\",\"619\":\"Leveraging experience for computationally efficient adaptive nonlinear model predictive control\",\"620\":\"Extended tau theory for robot motion control\",\"621\":\"Haptic intention augmentation for cooperative teleoperation\",\"622\":\"Visual-based shared control for remote telemanipulation with integral haptic feedback\",\"623\":\"Improving humanoid posture Teleoperation by Dynamic Synchronization through operator motion anticipation\",\"624\":\"Vision-based predictive assist control on master-slave systems\",\"625\":\"Flexible virtual fixture interface for path specification in tele-manipulation\",\"626\":\"A generative human-robot motion retargeting approach using a single depth sensor\",\"627\":\"Goal-predictive robotic teleoperation from noisy sensors\",\"628\":\"Decentralized estimation and control for bilateral teleoperation of mobile robot network with task abstraction\",\"629\":\"A high-precision robot-aided single-cell biopsy system\",\"630\":\"Detect-Focus-Track-Servo (DFTS): A vision-based workflow algorithm for robotic image-guided micromanipulation\",\"631\":\"An actuated gaze stabilization platform for a flapping-wing microrobot\",\"632\":\"Geometric flight control of a hovering robotic hummingbird\",\"633\":\"Design optimization and system integration of robotic hummingbird\",\"634\":\"Robust visual localization in changing lighting conditions\",\"635\":\"On parameter estimation of space manipulator systems using the angular momentum conservation\",\"636\":\"Pop-up mars rover with textile-enhanced rigid-flex PCB body\",\"637\":\"LEMUR 3: A limbed climbing robot for extreme terrain mobility in space\",\"638\":\"A mobile robot for locomotion through a 3D periodic lattice environment\",\"639\":\"Caging-based grasp with flexible manipulation for robust capture of a free-floating target\",\"640\":\"Locally-adaptive slip prediction for planetary rovers using Gaussian processes\",\"641\":\"Simple texture descriptors for classifying monochrome planetary rover terrains\",\"642\":\"Series pneumatic artificial muscles (sPAMs) and application to a soft continuum robot\",\"643\":\"Fabric sensory sleeves for soft robot state estimation\",\"644\":\"Design and fabrication of a soft three-axis force sensor based on radially symmetric pneumatic chambers\",\"645\":\"Functionalized textiles for interactive soft robotics\",\"646\":\"3D printed soft actuators for a legged robot capable of navigating unstructured terrain\",\"647\":\"Model based control of fiber reinforced elastofluidic enclosures\",\"648\":\"Sensorized pneumatic muscle for force and stiffness control\",\"649\":\"Autonomous navigation of hexapod robots with vision-based controller adaptation\",\"650\":\"Multi-objective UAV path planning for search and rescue\",\"651\":\"Multi-robot path planning for a swarm of robots that can both fly and drive\",\"652\":\"MT-LQG: Multi-agent planning in belief space via trajectory-optimized LQG\",\"653\":\"Motion planning with graph-based trajectories and Gaussian process inference\",\"654\":\"Cooperative relative positioning of mobile users by fusing IMU inertial and UWB ranging information\",\"655\":\"Compression of topological models and localization using the global appearance of visual information\",\"656\":\"Real-time stereo matching failure prediction and resolution using orthogonal stereo setups\",\"657\":\"Delving deeper into convolutional neural networks for camera relocalization\",\"658\":\"Using 2 point+normal sets for fast registration of point clouds with small overlap\",\"659\":\"Shape reconstruction using a mobile robot for demining and UXO classification\",\"660\":\"A learning approach for real-time temporal scene flow estimation from LIDAR data\",\"661\":\"Progressive object modeling with a continuum manipulator in unknown environments\",\"662\":\"RGB-T SLAM: A flexible SLAM framework by combining appearance and thermal information\",\"663\":\"A discrete-time attitude observer on SO(3) for vision and GPS fusion\",\"664\":\"Gaussian process estimation of odometry errors for localization and mapping\",\"665\":\"Fast-SeqSLAM: A fast appearance based place recognition algorithm\",\"666\":\"Underwater cave mapping using stereo vision\",\"667\":\"Application-oriented design space exploration for SLAM algorithms\",\"668\":\"Guidance algorithm for smooth trajectory tracking of a fixed wing UAV flying in wind flows\",\"669\":\"Aerial picking and delivery of magnetic objects with MAVs\",\"670\":\"Online informative path planning for active classification using UAVs\",\"671\":\"Aggressive 3-D collision avoidance for high-speed navigation\",\"672\":\"Collaborative transportation using MAVs via passive force control\",\"673\":\"Aggressive quadrotor flight through narrow gaps with onboard sensing and computing using active vision\",\"674\":\"Probabilistically safe policy transfer\",\"675\":\"Achieving robustness by optimizing failure behavior\",\"676\":\"Generating semi-explicit DAEs with Structural Index 1 for fault diagnosis using structural analysis\",\"677\":\"Safe open-loop strategies for handling intermittent communications in multi-robot systems\",\"678\":\"Learning robust failure response for autonomous vision based flight\",\"679\":\"Quadrotor collision characterization and recovery control\",\"680\":\"Adapting learned robotics behaviours through policy adjustment\",\"681\":\"Variable stiffness adaptation to mitigate system failure in inflatable robots\",\"682\":\"High-performing adaptive grasp for a robotic gripper using super twisting sliding mode control\",\"683\":\"Balancing control of a robot bicycle with uncertain center of gravity\",\"684\":\"Simultaneous orientation and positioning control of a microscopic object using robotic tweezers\",\"685\":\"Coordinative optical manipulation of multiple microscopic objects using micro-hands with multiple fingertips\",\"686\":\"Robust obstacle avoidance for aerial platforms using adaptive model predictive control\",\"687\":\"Robust online motion planning via contraction theory and convex optimization\",\"688\":\"Reproducing physical dynamics with hardware-in-the-loop simulators: A passive and explicit discrete integrator\",\"689\":\"Learning task-parametrized assistive strategies for exoskeleton robots by multi-task reinforcement learning\",\"690\":\"Gesture-based piloting of an aerial robot using monocular vision\",\"691\":\"Physical symbol grounding and instance learning through demonstration and eye tracking\",\"692\":\"Power-augmentation control approach for arm exoskeleton based on human muscular manipulability\",\"693\":\"Local driving assistance from demonstration for mobility aids\",\"694\":\"The MantisBot: Design and impedance control of supernumerary robotic limbs for near-ground work\",\"695\":\"A framework for efficient teleoperation via online adaptation\",\"696\":\"Independent, voluntary control of extra robotic limbs\",\"697\":\"High-rate controlled turning with a pair of miniature legged robots\",\"698\":\"Phase control for a legged microrobot operating at resonance\",\"699\":\"Near-surface effects on the controlled motion of magnetotactic bacteria\",\"700\":\"Robotics-based micro-reeling of magnetic microfibers to fabricate helical structure for smooth muscle cells culture\",\"701\":\"Gaze contingent control for optical micromanipulation\",\"702\":\"Non-contact transportation and rotation of micro objects by vibrating glass needle circularly under water\",\"703\":\"Towards hybrid microrobots using pH- and photo-responsive hydrogels for cancer targeting and drug delivery\",\"704\":\"Steerable miniature legged robot driven by a single piezoelectric bending unimorph actuator\",\"705\":\"Semi-endoskeleton-type waist assist AB-wear suit equipped with compressive force reduction mechanism\",\"706\":\"Estimation of EMG signal for shoulder joint based on EEG signals for the control of upper-limb power assistance devices\",\"707\":\"Comparative experimental validation of human gait tracking algorithms for an intelligent robotic rollator\",\"708\":\"Assistive robot operated via P300-based brain computer interface\",\"709\":\"A collaborative control framework for driver assistance systems\",\"710\":\"Haptic simulation for robot-assisted dressing\",\"711\":\"Human CoG estimation for assistive robots using a small number of sensors\",\"712\":\"What does the person feel? Learning to infer applied forces during robot-assisted dressing\",\"713\":\"Improving contour accuracy of a 2-DOF planar parallel kinematic machine by smart structure based compensation method\",\"714\":\"Certified detection of parallel robot assembly mode under Type 2 singularity crossing trajectories\",\"715\":\"Crossing type 2 singularities of parallel robots without pre-planned trajectory with a virtual-constraint-based controller\",\"716\":\"A novel adaptive terminal sliding mode control for parallel manipulators: Design and real-time experiments\",\"717\":\"Estimating inertial parameters of suspended cable-driven parallel robots \\u2014 Use case on CoGiRo\",\"718\":\"Kinematic design of a novel 4-DOF parallel manipulator\",\"719\":\"hTetro: A tetris inspired shape shifting floor cleaning robot\",\"720\":\"A physics based model for twisted and coiled actuator\",\"721\":\"A two-level approach for solving the inverse kinematics of an extensible soft arm considering viscoelastic behavior\",\"722\":\"Modeling parallel continuum robots with general intermediate constraints\",\"723\":\"Towards a soft robotic skin for autonomous tissue palpation\",\"724\":\"Magnetic motion control and planning of untethered soft grippers using ultrasound image feedback\",\"725\":\"Kinodynamic motion planning on Gaussian mixture fields\",\"726\":\"UB-ANC planner: Energy efficient coverage path planning with multiple drones\",\"727\":\"CWave: High-performance single-source any-angle path planning on a grid\",\"728\":\"Harmonic potential based communication-aware navigation and beamforming in cluttered spaces with full channel-state information\",\"729\":\"PiPS: Planning in perception space\",\"730\":\"Fast discovery of influential outcomes for risk-aware MPDM\",\"731\":\"Online inspection path planning for autonomous 3D modeling using a micro-aerial vehicle\",\"732\":\"Modelling scene change for large-scale long term laser localisation\",\"733\":\"Robust localization and localizability estimation with a rotating laser scanner\",\"734\":\"Algorithm for searching and tracking an unknown and varying number of mobile targets using a limited FoV sensor\",\"735\":\"Consistent map-based 3D localization on mobile devices\",\"736\":\"Semi-dense visual odometry for RGB-D cameras using approximate nearest neighbour fields\",\"737\":\"Gaussian processes online observation classification for RSSI-based low-cost indoor positioning systems\",\"738\":\"Find your way by observing the sun and other semantic cues\",\"739\":\"Robust visual-inertial localization with weak GPS priors for repetitive UAV flights\",\"740\":\"RFM-SLAM: Exploiting relative feature measurements to separate orientation and position estimation in SLAM\",\"741\":\"Room layout estimation from rapid omnidirectional exploration\",\"742\":\"Cooperative inchworm localization with a low cost team\",\"743\":\"SLAMinDB: Centralized graph databases for mobile robotics\",\"744\":\"Quadrotor trajectory generation in dynamic environments using semi-definite relaxation on nonconvex QCQP\",\"745\":\"Aerial grasping of cylindrical object using visual servoing based on stochastic model predictive control\",\"746\":\"CNN-based single image obstacle avoidance on a quadrotor\",\"747\":\"Dynamic decentralized control for protocentric aerial manipulators\",\"748\":\"Sequential Bayesian optimization as a POMDP for environment monitoring with UAVs\",\"749\":\"Design and dynamic analysis of a Transformable Hovering Rotorcraft (THOR)\",\"750\":\"Distance control of rocket-propelled miniature exploration robot\",\"751\":\"Regression of 3D rigid transformations on real-valued vectors in closed form\",\"752\":\"No-regret replanning under uncertainty\",\"753\":\"Bayesian uncertainty modeling for programming by demonstration\",\"754\":\"Empowered skills\",\"755\":\"Layered direct policy search for learning hierarchical skills\",\"756\":\"On-line Bayesian regression mixture model for robot model learning\",\"757\":\"Active sample selection in scalar fields exhibiting non-stationary noise with parametric heteroscedastic Gaussian process regression\",\"758\":\"Modeling of rolling friction by recurrent neural network using LSTM\",\"759\":\"A direct formulation for camera calibration\",\"760\":\"Visual-inertial self-calibration on informative motion segments\",\"761\":\"A branch-and-bound algorithm for checkerboard extraction in camera-laser calibration\",\"762\":\"On field radiometric calibration for multispectral cameras\",\"763\":\"Discrete-time dynamic modeling and calibration of differential-drive mobile robots with friction\",\"764\":\"Generating persistently exciting trajectory based on condition number optimization\",\"765\":\"Drift-correcting self-calibration for visual-inertial SLAM\",\"766\":\"Enabling independent navigation for visually impaired people through a wearable vision-based feedback system\",\"767\":\"Using multisensory cues for direction information in teleoperation: More is not always better\",\"768\":\"Leveraging the urban soundscape: Auditory perception for smart vehicles\",\"769\":\"Stochastic sEMG processor based manipulator control toward man-machine interface with minimal electro-mechanical delay\",\"770\":\"Clinical patient tracking in the presence of transient and permanent occlusions via geodesic feature\",\"771\":\"Correcting robot mistakes in real time using EEG signals\",\"772\":\"Interpretable models for fast activity recognition and anomaly explanation during collaborative robotics tasks\",\"773\":\"Mobile paramagnetic nanoparticle-based vortex for targeted cargo delivery in fluid\",\"774\":\"Three-dimensional robotic control of a 5-micrometer magnetic bead for intra-embryonic navigation and measurement\",\"775\":\"Velocity characterization and control strategies for nano-robotic systems based on piezoelectric stick-slip actuators\",\"776\":\"Planning spin-walking locomotion for automatic grasping of microobjects by an untethered magnetic microgripper\",\"777\":\"On-chip micromanipulation method based on mode switching of vibration-induced asymmetric flow\",\"778\":\"Comparison of different error signals driving the adaptation in assist-as-needed controllers for neurorehabilitation with an upper-limb robotic exoskeleton\",\"779\":\"Exomuscle: An inflatable device for shoulder abduction support\",\"780\":\"Time-varying human ankle impedance in the sagittal and frontal planes during stance phase of walking\",\"781\":\"Actively variable transmission for robotic knee prostheses\",\"782\":\"Design of a quasi-passive ankle-foot prosthesis with biomimetic, variable stiffness\",\"783\":\"Design of an under-actuated wrist based on adaptive synergies\",\"784\":\"A cable-based series elastic actuator with conduit sensor for wearable exoskeletons\",\"785\":\"A compliant four-bar linkage mechanism that makes the fingers of a prosthetic hand more impact resistant\",\"786\":\"A hybrid plastic-fabric soft bending actuator with reconfigurable bending profiles\",\"787\":\"Design of a 3D-printed polymeric compliant constant-force buffering gripping mechanism\",\"788\":\"Analytic modeling and experiments of tri-layer, electro-thermal actuators for thin and soft robotics\",\"789\":\"On the impact force of human-robot interaction: Joint compliance vs. link compliance\",\"790\":\"Intraocular snake integrated with the steady-hand eye robot for assisted retinal microsurgery\",\"791\":\"Incorporating tube-to-tube clearances in the kinematics of concentric tube robots\",\"792\":\"Chromatic surface microstructures on bionic soft robots for non-contact deformation measurement\",\"793\":\"The admissible gap (AG) method for reactive collision avoidance\"},\"First and Last Author Affiliations\":{\"0\":null,\"1\":null,\"2\":null,\"3\":null,\"4\":null,\"5\":null,\"6\":null,\"7\":null,\"8\":null,\"9\":null,\"10\":null,\"11\":null,\"12\":null,\"13\":null,\"14\":null,\"15\":null,\"16\":null,\"17\":null,\"18\":null,\"19\":null,\"20\":null,\"21\":null,\"22\":null,\"23\":null,\"24\":null,\"25\":null,\"26\":null,\"27\":null,\"28\":null,\"29\":null,\"30\":null,\"31\":null,\"32\":null,\"33\":null,\"34\":null,\"35\":null,\"36\":null,\"37\":null,\"38\":null,\"39\":null,\"40\":null,\"41\":null,\"42\":null,\"43\":null,\"44\":null,\"45\":null,\"46\":null,\"47\":null,\"48\":null,\"49\":null,\"50\":null,\"51\":null,\"52\":null,\"53\":null,\"54\":null,\"55\":null,\"56\":null,\"57\":null,\"58\":null,\"59\":null,\"60\":null,\"61\":null,\"62\":null,\"63\":null,\"64\":null,\"65\":null,\"66\":null,\"67\":null,\"68\":null,\"69\":null,\"70\":null,\"71\":null,\"72\":null,\"73\":null,\"74\":null,\"75\":null,\"76\":null,\"77\":null,\"78\":null,\"79\":null,\"80\":null,\"81\":null,\"82\":null,\"83\":null,\"84\":null,\"85\":null,\"86\":null,\"87\":null,\"88\":null,\"89\":null,\"90\":null,\"91\":null,\"92\":null,\"93\":null,\"94\":null,\"95\":null,\"96\":null,\"97\":null,\"98\":null,\"99\":null,\"100\":null,\"101\":null,\"102\":null,\"103\":null,\"104\":null,\"105\":null,\"106\":null,\"107\":null,\"108\":null,\"109\":null,\"110\":null,\"111\":null,\"112\":null,\"113\":null,\"114\":null,\"115\":null,\"116\":null,\"117\":null,\"118\":null,\"119\":null,\"120\":null,\"121\":null,\"122\":null,\"123\":null,\"124\":null,\"125\":null,\"126\":null,\"127\":null,\"128\":null,\"129\":null,\"130\":null,\"131\":null,\"132\":null,\"133\":null,\"134\":null,\"135\":null,\"136\":null,\"137\":null,\"138\":null,\"139\":null,\"140\":null,\"141\":null,\"142\":null,\"143\":null,\"144\":null,\"145\":null,\"146\":null,\"147\":null,\"148\":null,\"149\":null,\"150\":null,\"151\":null,\"152\":null,\"153\":null,\"154\":null,\"155\":null,\"156\":null,\"157\":null,\"158\":null,\"159\":null,\"160\":null,\"161\":null,\"162\":null,\"163\":null,\"164\":null,\"165\":null,\"166\":null,\"167\":null,\"168\":null,\"169\":null,\"170\":null,\"171\":null,\"172\":null,\"173\":null,\"174\":null,\"175\":null,\"176\":null,\"177\":null,\"178\":null,\"179\":null,\"180\":null,\"181\":null,\"182\":null,\"183\":null,\"184\":null,\"185\":null,\"186\":null,\"187\":null,\"188\":null,\"189\":null,\"190\":null,\"191\":null,\"192\":null,\"193\":null,\"194\":null,\"195\":null,\"196\":null,\"197\":null,\"198\":null,\"199\":null,\"200\":null,\"201\":null,\"202\":null,\"203\":null,\"204\":null,\"205\":null,\"206\":null,\"207\":null,\"208\":null,\"209\":null,\"210\":null,\"211\":null,\"212\":null,\"213\":null,\"214\":null,\"215\":null,\"216\":null,\"217\":null,\"218\":null,\"219\":null,\"220\":null,\"221\":null,\"222\":null,\"223\":null,\"224\":null,\"225\":null,\"226\":null,\"227\":null,\"228\":null,\"229\":null,\"230\":null,\"231\":null,\"232\":null,\"233\":null,\"234\":null,\"235\":null,\"236\":null,\"237\":null,\"238\":null,\"239\":null,\"240\":null,\"241\":null,\"242\":null,\"243\":null,\"244\":null,\"245\":null,\"246\":null,\"247\":null,\"248\":null,\"249\":null,\"250\":null,\"251\":null,\"252\":null,\"253\":null,\"254\":null,\"255\":null,\"256\":null,\"257\":null,\"258\":null,\"259\":null,\"260\":null,\"261\":null,\"262\":null,\"263\":null,\"264\":null,\"265\":null,\"266\":null,\"267\":null,\"268\":null,\"269\":null,\"270\":null,\"271\":null,\"272\":null,\"273\":null,\"274\":null,\"275\":null,\"276\":null,\"277\":null,\"278\":null,\"279\":null,\"280\":null,\"281\":null,\"282\":null,\"283\":null,\"284\":null,\"285\":null,\"286\":null,\"287\":null,\"288\":null,\"289\":null,\"290\":null,\"291\":null,\"292\":null,\"293\":null,\"294\":null,\"295\":null,\"296\":null,\"297\":null,\"298\":null,\"299\":null,\"300\":null,\"301\":null,\"302\":null,\"303\":null,\"304\":null,\"305\":null,\"306\":null,\"307\":null,\"308\":null,\"309\":null,\"310\":null,\"311\":null,\"312\":null,\"313\":null,\"314\":null,\"315\":null,\"316\":null,\"317\":null,\"318\":null,\"319\":null,\"320\":null,\"321\":null,\"322\":null,\"323\":null,\"324\":null,\"325\":null,\"326\":null,\"327\":null,\"328\":null,\"329\":null,\"330\":null,\"331\":null,\"332\":null,\"333\":null,\"334\":null,\"335\":null,\"336\":null,\"337\":null,\"338\":null,\"339\":null,\"340\":null,\"341\":null,\"342\":null,\"343\":null,\"344\":null,\"345\":null,\"346\":null,\"347\":null,\"348\":null,\"349\":null,\"350\":null,\"351\":null,\"352\":null,\"353\":null,\"354\":null,\"355\":null,\"356\":null,\"357\":null,\"358\":null,\"359\":null,\"360\":null,\"361\":null,\"362\":null,\"363\":null,\"364\":null,\"365\":null,\"366\":null,\"367\":null,\"368\":null,\"369\":null,\"370\":null,\"371\":null,\"372\":null,\"373\":null,\"374\":null,\"375\":null,\"376\":null,\"377\":null,\"378\":null,\"379\":null,\"380\":null,\"381\":null,\"382\":null,\"383\":null,\"384\":null,\"385\":null,\"386\":null,\"387\":null,\"388\":null,\"389\":null,\"390\":null,\"391\":null,\"392\":null,\"393\":null,\"394\":null,\"395\":null,\"396\":null,\"397\":null,\"398\":null,\"399\":null,\"400\":null,\"401\":null,\"402\":null,\"403\":null,\"404\":null,\"405\":null,\"406\":null,\"407\":null,\"408\":null,\"409\":null,\"410\":null,\"411\":null,\"412\":null,\"413\":null,\"414\":null,\"415\":null,\"416\":null,\"417\":null,\"418\":null,\"419\":null,\"420\":null,\"421\":null,\"422\":null,\"423\":null,\"424\":null,\"425\":null,\"426\":null,\"427\":null,\"428\":null,\"429\":null,\"430\":null,\"431\":null,\"432\":null,\"433\":null,\"434\":null,\"435\":null,\"436\":null,\"437\":null,\"438\":null,\"439\":null,\"440\":null,\"441\":null,\"442\":null,\"443\":null,\"444\":null,\"445\":null,\"446\":null,\"447\":null,\"448\":null,\"449\":null,\"450\":null,\"451\":null,\"452\":null,\"453\":null,\"454\":null,\"455\":null,\"456\":null,\"457\":null,\"458\":null,\"459\":null,\"460\":null,\"461\":null,\"462\":null,\"463\":null,\"464\":null,\"465\":null,\"466\":null,\"467\":null,\"468\":null,\"469\":null,\"470\":null,\"471\":null,\"472\":null,\"473\":null,\"474\":null,\"475\":null,\"476\":null,\"477\":null,\"478\":null,\"479\":null,\"480\":null,\"481\":null,\"482\":null,\"483\":null,\"484\":null,\"485\":null,\"486\":null,\"487\":null,\"488\":null,\"489\":null,\"490\":null,\"491\":null,\"492\":null,\"493\":null,\"494\":null,\"495\":null,\"496\":null,\"497\":null,\"498\":null,\"499\":null,\"500\":null,\"501\":null,\"502\":null,\"503\":null,\"504\":null,\"505\":null,\"506\":null,\"507\":null,\"508\":null,\"509\":null,\"510\":null,\"511\":null,\"512\":null,\"513\":null,\"514\":null,\"515\":null,\"516\":null,\"517\":null,\"518\":null,\"519\":null,\"520\":null,\"521\":null,\"522\":null,\"523\":null,\"524\":null,\"525\":null,\"526\":null,\"527\":null,\"528\":null,\"529\":null,\"530\":null,\"531\":null,\"532\":null,\"533\":null,\"534\":null,\"535\":null,\"536\":null,\"537\":null,\"538\":null,\"539\":null,\"540\":null,\"541\":null,\"542\":null,\"543\":null,\"544\":null,\"545\":null,\"546\":null,\"547\":null,\"548\":null,\"549\":null,\"550\":null,\"551\":null,\"552\":null,\"553\":null,\"554\":null,\"555\":null,\"556\":null,\"557\":null,\"558\":null,\"559\":null,\"560\":null,\"561\":null,\"562\":null,\"563\":null,\"564\":null,\"565\":null,\"566\":null,\"567\":null,\"568\":null,\"569\":null,\"570\":null,\"571\":null,\"572\":null,\"573\":null,\"574\":null,\"575\":null,\"576\":null,\"577\":null,\"578\":null,\"579\":null,\"580\":null,\"581\":null,\"582\":null,\"583\":null,\"584\":null,\"585\":null,\"586\":null,\"587\":null,\"588\":null,\"589\":null,\"590\":null,\"591\":null,\"592\":null,\"593\":null,\"594\":null,\"595\":null,\"596\":null,\"597\":null,\"598\":null,\"599\":null,\"600\":null,\"601\":null,\"602\":null,\"603\":null,\"604\":null,\"605\":null,\"606\":null,\"607\":null,\"608\":null,\"609\":null,\"610\":null,\"611\":null,\"612\":null,\"613\":null,\"614\":null,\"615\":null,\"616\":null,\"617\":null,\"618\":null,\"619\":null,\"620\":null,\"621\":null,\"622\":null,\"623\":null,\"624\":null,\"625\":null,\"626\":null,\"627\":null,\"628\":null,\"629\":null,\"630\":null,\"631\":null,\"632\":null,\"633\":null,\"634\":null,\"635\":null,\"636\":null,\"637\":null,\"638\":null,\"639\":null,\"640\":null,\"641\":null,\"642\":null,\"643\":null,\"644\":null,\"645\":null,\"646\":null,\"647\":null,\"648\":null,\"649\":null,\"650\":null,\"651\":null,\"652\":null,\"653\":null,\"654\":null,\"655\":null,\"656\":null,\"657\":null,\"658\":null,\"659\":null,\"660\":null,\"661\":null,\"662\":null,\"663\":null,\"664\":null,\"665\":null,\"666\":null,\"667\":null,\"668\":null,\"669\":null,\"670\":null,\"671\":null,\"672\":null,\"673\":null,\"674\":null,\"675\":null,\"676\":null,\"677\":null,\"678\":null,\"679\":null,\"680\":null,\"681\":null,\"682\":null,\"683\":null,\"684\":null,\"685\":null,\"686\":null,\"687\":null,\"688\":null,\"689\":null,\"690\":null,\"691\":null,\"692\":null,\"693\":null,\"694\":null,\"695\":null,\"696\":null,\"697\":null,\"698\":null,\"699\":null,\"700\":null,\"701\":null,\"702\":null,\"703\":null,\"704\":null,\"705\":null,\"706\":null,\"707\":null,\"708\":null,\"709\":null,\"710\":null,\"711\":null,\"712\":null,\"713\":null,\"714\":null,\"715\":null,\"716\":null,\"717\":null,\"718\":null,\"719\":null,\"720\":null,\"721\":null,\"722\":null,\"723\":null,\"724\":null,\"725\":null,\"726\":null,\"727\":null,\"728\":null,\"729\":null,\"730\":null,\"731\":null,\"732\":null,\"733\":null,\"734\":null,\"735\":null,\"736\":null,\"737\":null,\"738\":null,\"739\":null,\"740\":null,\"741\":null,\"742\":null,\"743\":null,\"744\":null,\"745\":null,\"746\":null,\"747\":null,\"748\":null,\"749\":null,\"750\":null,\"751\":null,\"752\":null,\"753\":null,\"754\":null,\"755\":null,\"756\":null,\"757\":null,\"758\":null,\"759\":null,\"760\":null,\"761\":null,\"762\":null,\"763\":null,\"764\":null,\"765\":null,\"766\":null,\"767\":null,\"768\":null,\"769\":null,\"770\":null,\"771\":null,\"772\":null,\"773\":null,\"774\":null,\"775\":null,\"776\":null,\"777\":null,\"778\":null,\"779\":null,\"780\":null,\"781\":null,\"782\":null,\"783\":null,\"784\":null,\"785\":null,\"786\":null,\"787\":null,\"788\":null,\"789\":null,\"790\":null,\"791\":null,\"792\":null,\"793\":null},\"Keywords or Approach\":{\"0\":\"hydraulic systems\\nmathematical model\\nrobots\\nnonlinear dynamical systems\\ndamping\\nnumerical models\\nresource management\\ncouplings\\nhydraulic control equipment\\nmanipulators\\nrods (structures)\\nstructure preserving nondimensionalization\\nhydraulic rotational joints\\nnondimensional representation\\nhydraulic arms\\nnonlinear dynamics\\nphysical parameters\\nparametric structure\\ndamping constant\\nsource pressure\\nrod area\\ncylinder allocation\",\"1\":\"springs\\nforce\\nactuators\\nspirals\\ntorque\\nsynchronous motors\\nshafts\\nmechanical design\\ncompact serial variable stiffness actuator\\nphysical human-robot interaction\\ndynamic performance improvements\\nenergy saving abilities\\nvariable ratio lever mechanism\\narchimedean spiral relocation mechanism\\nasrm\\nadjustable stiffness\\nsvsa design\\nstiffness adjustment\\nvariable stiffness mechanism\\nvsm\\nlinear springs\\nspring shaft\\nspring force\\nstiffness modeling\",\"2\":\"servomotors\\nvalves\\nservice robots\\npistons\\npumps\\nhydraulic control equipment\\nmanipulator dynamics\\nservomechanisms\\nlow-cost manipulator\\nhydraulic hybrid servo booster\\nhydraulic hybrid servo drive\\nrobotic applications\\nservo-controlled pump\\nhydraulic metering circuit\\nlow-pressure line\\nboosting effect\\nsingle-rod cylinder\\nthree-joint manipulator prototype\\npiston velocity\\nlarge piston force\\nservo-pump\\nexternal perturbations\\nbackdrivability\",\"3\":\"shafts\\ntorque\\nlayout\\nsprings\\ngears\\nradio frequency\\nactuators\\ncontrol system synthesis\\nelastic constants\\nhinges\\nstructure-controlled variable stiffness actuator design\\nrotary flexure hinges\\nactuator mechanical structure\\nflexure hinges\\nprinciple driving motor serial arrangement\\nvariable stiffness mechanism\\nsmall-stiffness variation motor\\nvsm\\nouter-stationary hinge housing\\ninner-rotary flexure shaft\\nvsa output angle\\nflexure rotational angle\\nvsa working principle\",\"4\":\"actuators\\nrobots\\nhydraulic systems\\ntorque\\ndynamics\\nimpedance\\nforce\\nforce control\\nhydraulic actuators\\npressure control\\nservomechanisms\\ntorque control\\nvalves\\nbackdrivable hydraulic servovalve\\ninteractive robot control\\nhydraulic actuator\\ninteractive robot applications\\ndurability\\nforce\\/torque servo control\\nelastic components\\nsensor problems\\nbackdrivability\\ninteractive hydraulic robot systems\\nvalve-controlled hydraulic system\\nload pressure feedback mechanism\\nflexible joint robot\\nbackdrivable servovalve dynamics\\npressure control valve\",\"5\":\"actuators\\nforce\\nfabrication\\nsoft robotics\\nrobustness\\ngeometry\\nbending\\nhuman-robot interaction\\nmechanical testing\\nshear modulus\\nclassical rigid-bodied robotic system\\nphysical human-robot interactions\\nrobust hybrid bending actuator\\nrigid components\\nsoft components\\ncrustaceans\\nbending radius\\nmechanically programmed axis\\nselective activation\\nrigid exterior joints\\nsoft actuators\\nbending tests\\nforce tests\\nobject geometry\\nindustrial applications\",\"6\":\"legged locomotion\\ntorque\\nforce\\nmuscles\\nactuators\\ntendons\\nbiomimetics\\nfluidic devices\\nmotion control\\npneumatic actuators\\npressure control\\nrobot dynamics\\nscalable pneumatic robotic joint\\ntendon driven robotic joint\\njumping spiders\\nfluidic actuators\\nversatile motions\\nagile motions\\nbiological systems\\nhydraulically actuated joint extension\\nmuscle-based joint flexion\\nelectrically-actuated tendons\\ndynamic rapid joint movement\\nfoldable structured membrane\\npressure energy\\ntorque energy\\nstatic joint models\\nsingle jumping leg robot\\nrobot locomotion\\nspider-inspired joint mechanism modeling\\nspider dynamics\\nfunctional biomechanics\",\"7\":\"hydraulic systems\\ntorque\\npd control\\nimpedance\\nrobot sensing systems\\nfrequency control\\nclosed loop systems\\ncompliance control\\ncontrol system synthesis\\nelectrohydraulic control equipment\\nfeedback\\nflexible structures\\nmanipulators\\nposition control\\nservomechanisms\\nstability\\ntorque control\\nposition-based pd control design\\npassive subsystems\\nmultitime scales\\nposition-based proportional-derivative controller\\ninner torque feedback loops\\ncompliant behavior\\nclosed-loop system\\njoint position sensor\\ncontrol units\\nelectrohydraulic servovalves\\njoint flexibility\\njoint position-based pd control strategy\\ncompliant hydraulic robot system\\nvirtual internal leakage\\nflexible joints\\nrobot manipulator\\npassive system\\nstability guarantee\",\"8\":\"planning\\nrobots\\nuncertainty\\noptimization\\nprobabilistic logic\\nminimization\\nreal-time systems\\ngaussian processes\\noptimisation\\npath planning\\nsecond-order cone programming\\nsafe mission planning\\ndynamic systems\\nsocp\\nrealtime robotic tasks\\noptimization methods\\nlinear function\\nwolfe algorithm\\ngaussian process\\ntwo-level sensing method\",\"9\":\"trajectory\\nsafety\\nsystem dynamics\\noptimal control\\nheuristic algorithms\\ncomplexity theory\\nthree-dimensional displays\\nreachability analysis\\nset theory\\nstate estimation\\nefficient hamilton-jacobi guaranteed safety analysis\\nhamilton-jacobi reachability\\ndynamical system safety properties\\nbackward reachable set\\nsafety property violation\\nbrs computation complexity\\nexponential complexity\\nstate dimension\\ndynamical system decomposition\\n3d dubins car model\\n6d acrobatic quadrotor model\",\"10\":\"optimization\\nswitches\\nlegged locomotion\\noptimal control\\nswitched systems\\nplanning\\nlinear quadratic control\\npath planning\\nquadratic programming\\noptimal planning framework\\ncontrol framework\\nquadrupedal locomotion\\ndynamic programming framework\\nmultilevel optimization approach\\noptimal switching times\\noptimal continuous control inputs\\ncontinuous-time constrained lqr algorithm\\nlinear quadratic regulator\\ncenter of mass dynamics\\nswitched system model\",\"11\":\"planning\\ntrajectory optimization\\nhelicopters\\nvehicle dynamics\\naerodynamics\\nautonomous aerial vehicles\\ntrajectory optimisation (aerospace)\\nvelocity control\\nwind\\n\\u03baite\\nsmooth trajectory optimization\\nmoving reference frame\\nunmanned aerial vehicles\\nwind field\\ntrajectory optimization problem\\npath optimization\\nfixed ground frame\\nvelocity profile optimization\\ndecoupling framework\\nfinal fused trajectory\\nhigh-quality solutions\\nhelicopter\\nautonomous systems\\npilot-like behavior\",\"12\":\"videos\\nnasa\\nthree-dimensional displays\\nsolid modeling\\ndata models\\nyoutube\\nneural networks\\ncomputer vision\\nimage classification\\nimage segmentation\\nlearning (artificial intelligence)\\nneural nets\\nvideo signal processing\\ndap3d-net\\ncomplex scenes\\n3d cnn\\nconvolutional neural network\\nmulti-task learning\\nlong-short-term memory module\\nlstm module\\ndeep-action parsing\\naction clip\\naction dynamic information\\nupcoming test video\\nnumerous-category aligned synthetic action dataset\\nnasa dataset\\nhuman-action understanding dataset\\npublic thumos dataset\\nhau\",\"13\":\"image edge detection\\nimage segmentation\\ncomplexity theory\\nfeature extraction\\ncorrelation\\nrobustness\\nadaptive signal processing\\nbayes methods\\nedge detection\\nimage matching\\nmesh generation\\nstereo image processing\\nls-elas\\nline segment based efficient large scale stereo matching\\nbinocular dense stereo matching algorithm\\nbayesian stereo matching method\\nconstrained delaunay triangulation\\ntriangulation mesh\\ndepth discontinuities\\nadaptive method\\nedge segments\\nmiddlebury benchmark\",\"14\":\"image color analysis\\nrobots\\nvolume measurement\\nfeature extraction\\nsensors\\ncameras\\ncrops\\nestimation theory\\nimage processing\\npattern clustering\\nregression analysis\\ntomato fruit\\nwhole image processing\\ncrop grow measurement\\nfarm productivity\\nfruit volume detection\\nfruit volume measurement\\nsub-image clustering\\nregression model\\nfruit volume estimation\\nagriculture\\nfield robotics growth measurement\\ntomato volume\\nregression\",\"15\":\"calibration\\nhead\\ngaze tracking\\ntraining data\\ncameras\\nmobile communication\\ngeometry\\ngaussian processes\\noptimisation\\npose estimation\\nregression analysis\\nprecise mobile gaze tracking system\\nonline sparse gaussian process regression\\nsmooth-pursuit identification\\nparallax error\\ninflexible calibration procedure\\ncalibration points\\nhead position\\neye movements\\nhead movements\\npca analysis\\nfitc approximation\\nimage pupil centers\\nepipolar geometry\\nparallax errors\\nnonlinear optimization problem\\nimage gaze point\\nepipolar lines\\nbinocular data\",\"16\":\"cameras\\nvisualization\\nfeature extraction\\nmathematical model\\nsimultaneous localization and mapping\\nnoise measurement\\ntime measurement\\nimage sensors\\ninertial navigation\\ninverse problems\\nstereo image processing\\nsliding-window two-camera vision aided inertial navigation system\\nsquare-root inverse domain\\ntwo-camera image processing\\ntightly-coupled monocular binocular stereo vins\\nmobile processor\",\"17\":\"three-dimensional displays\\ntransforms\\npredictive models\\ndecoding\\nmotion segmentation\\ndynamics\\nimage motion analysis\\nimage sequences\\nlearning (artificial intelligence)\\nneural nets\\nse3-nets\\nrigid body motion learning\\ndeep neural networks\\npoint cloud data\\ndepth image sequence\\naction vectors\\npoint wise data associations\\ntable top scene\\nrobot manipulator\\ndepth camera\\nbaxter robot\",\"18\":\"acceleration\\nmaximum likelihood estimation\\nmonte carlo methods\\nsafety\\ngaussian distribution\\nprobability density function\\nexponential distribution\\nimportance sampling\\nroad safety\\nroad vehicles\\nautomated vehicles\\nfrontal cut-in scenario\\npiecewise mixture models\\nav\\npublic roads\\naccelerated evaluation\\nimportance sampling theory\\npiecewise mixture distribution models\\nsingle distribution models\\nvehicle safety\\nlane change scenarios\\ncut-in vehicles\\nnaturalistic driving lane changes\\nautomated vehicle\\nactive safety\\nlane change\\ncut-in\\nevaluation\\ntest\",\"19\":\"image segmentation\\ncameras\\nroads\\nsensors\\nsemantics\\ndata collection\\nlaser radar\\ncollision avoidance\\nlearning (artificial intelligence)\\nmobile robots\\nroad traffic control\\nweakly-supervised segmentation\\npath proposals\\nurban autonomy\\ndrivable path image segmentation\\nautonomous driving\\ncomplex urban environments\\nrecorded routes\\ndata collection vehicle\\nlabelled images\\ndeep semantic segmentation network training\\nmonocular camera\\nexplicit road modelling\\nlane markings\\nlarge-scale kitti\\noxford robotcar datasets\\nobstacle segmentation\\ntraffic conditions\\nautonomous urban driving\",\"20\":\"trajectory\\nhidden markov models\\nanalytical models\\nvehicle dynamics\\npredictive models\\nvideos\\nadaptation models\\nautomobiles\\ndata mining\\nnatural scenes\\noptical radar\\nroad traffic control\\nego-centric traffic behavior modeling\\nmultilevel vehicle trajectory analysis\\non-road vehicle trajectories\\non-board system\\nmultiple 2d lidar sensors\\nhot regions\\nhdp-hmm\\ntrajectory transitions\\nfrequent-subsequence mining\\nhierarchical hidden markov model\\nhhmm\\nintrapath dynamics\\nhot region\\ninterpath transition\\nmarkovian\\nbehavior prediction\\nvehicle detection\\ntime horizons\\nmotorways\\nbeijing\",\"21\":\"roads\\nsemantics\\nfeature extraction\\nstreaming media\\nimage segmentation\\ntraining\\nimage edge detection\\nconvolution\\nimage colour analysis\\nintelligent transportation systems\\nlearning (artificial intelligence)\\nstructured contour embedding\\nsiamesed fully convolutional networks\\nroad detection\\nautonomous driving\\ndeep learning methods\\nroad boundary detection\\ns-fcn-loc\\nvgg-net architecture\\nroad region segmentation\\nrgb images\\ncontour maps\\nintelligent vehicles\",\"22\":\"trajectory\\nautomobiles\\ncomputational modeling\\nmathematical model\\nhardware\\nplanning\\noptimization\\ncollision avoidance\\nintelligent robots\\nmobile robots\\nmotion control\\npredictive control\\nmodel-predictive motion planner\\niara autonomous car\\nintelligent autonomous robotic automobile\\npath planner\\niara mpmp\\nsmooth trajectories\\noccasional obstacles\\nhuman driver\",\"23\":\"radar tracking\\nlaser radar\\nsensors\\nmeasurement by laser beam\\nlaser fusion\\nlaser modes\\nautomotive engineering\\nradar\\ntracking\\nvehicle tracking\\nextended object methods\\nheterogeneous sensors\\ntracking systems\\nredundancy\\ncomplementary sensor characteristics\\nvehicle environment perception\\nlaser data\\nrandom-finite-set-based tracking filter\\nmathematical formulation\\nmultiobject problem\\nfusion center\\nobject measurement models\\nraw sensor data\",\"24\":\"roads\\nthree-dimensional displays\\nimage reconstruction\\npipelines\\nprobabilistic logic\\ndetectors\\ngeometry\\nimage classification\\nimage sequences\\nprobability\\nroad vehicles\\ntraffic engineering computing\\nvideo signal processing\\nonline probabilistic road intersection detector\\nurban road intersections classification\\nmoving vehicle\\nonboard stereo rig\\npixel-level classification\\nroad components\\nintersection geometry\\nvideo sequence\\nkitti datasets\",\"25\":\"measurement\\nrisk management\\nroad transportation\\nuncertainty\\nsafety\\ncognition\\nprobabilistic logic\\nbelief networks\\ncontrol engineering computing\\ninference mechanisms\\nobject tracking\\nroad safety\\ntraffic engineering computing\\novertaken scenarios\\novertaking scenarios\\nvehicle testing\\nclosed high-speed test track\\npublic highways\\nvehicle tracking\\nspatial aspects\\ntemporal aspects\\nrisk metrics\\nbayesian networks\\ncollision risks\\nhighway situation\\nrisk assessment algorithm\\nhighways\\nautomatic lane change maneuvers\",\"26\":\"robot kinematics\\nwheels\\nsprings\\nservomotors\\nstability analysis\\nfasteners\\nactuators\\nmobile robots\\nmulti-agent systems\\nmulti-robot systems\\ncomposite modular robot\\nstair climbing\\nreattaching capability\\nturning problem\\ncrammed spaces\\nmap coverage improvement\\nconcurrent scene exploration\\ndcmr\\ndetachable compliant modular robot\\nmas\\nmultiagent systems\\nuneven terrain navigation\\nmultiagent exploration\\ncooperative climbing\",\"27\":\"robot kinematics\\ncameras\\nrobot vision systems\\ntarget tracking\\ntrajectory\\ngeometry\\nmulti-robot systems\\npattern recognition\\nvehicles\\ndifferential-drive vehicles formation\\nfield-of-view constraints\\nmoving target\\nmultirobot systems\\ngeometric formation\\ncircular pattern configuration\\nonboard vision sensor\\ndifferential-drive robots\\nfov\",\"28\":\"convergence\\nnavigation\\nsafety\\nrobot sensing systems\\ntrajectory\\ncomputational geometry\\nconstraint satisfaction problems\\ndecentralised control\\nmulti-agent systems\\nmulti-robot systems\\nnetworked control systems\\npath planning\\nreconfigurable multiagent control\\nnetworked multirobot system\\nsingle leader-multiple followers architecture\\ndecentralized reconfiguration strategy\\ndecentralized navigation functions based controller\\nsafety requirements\\ndistributed constraint satisfaction problem\\nlocal voronoi partition\\ntree configuration\\nformation topology\\nprescribed performance technique\",\"29\":\"shape\\nrobot kinematics\\ntrajectory\\nplanning\\nrobot sensing systems\\ndynamics\\nmulti-robot systems\\npath planning\\ndistributed multi-robot coordination\\ndynamic perimeter surveillance\\nvirtual fence\\nrobot team\\ndistributed planning method\\ntwice differentiable function\\ntime-varying perimeter\",\"30\":\"robot kinematics\\nbuffer storage\\ncollision avoidance\\ndata transfer\\ntemperature sensors\\nrobot sensing systems\\nmulti-robot systems\\nrobot dynamics\\ntemporal logic\\ndistributed data gathering\\nbuffer constraints\\nintermittent communication\\nmultiple dynamical robot\\nheterogeneous robot\\ntype-a robots\\ndata center\\ntype-b robots\\nhigh-level linear temporal logic\\nltl\\ndistributed task coordination\",\"31\":\"collision avoidance\\nlearning (artificial intelligence)\\nkinematics\\ndecision making\\nreal-time systems\\nnavigation\\nplanning\\ndecentralised control\\nmobile robots\\nmulti-robot systems\\nrobot kinematics\\ndecentralized noncommunicating multiagent collision avoidance\\ndeep reinforcement learning\\ncollision-free paths\\nmultiagent systems\\nonline computation\\ninteraction pattern prediction\\noffline learning procedure\\nagent joint configuration\\nagent positions\\nagent velocities\\ncollision-free velocity vector\\nagent motion uncertainty\\npath quality improvement\",\"32\":\"resource management\\ngreedy algorithms\\noptimization\\nrobot sensing systems\\nsurveillance\\nmulti-robot systems\\ncombinatorial mathematics\\nmatrix algebra\\nmonte carlo methods\\noptimisation\\nresource allocation\\ntopology\\ntrees (mathematics)\\ndecentralized matroid optimization\\ntopology constraints\\nmulti-robot allocation problems\\ntopological constraints\\ntask allocation\\ncombinatorial matroid theory\\narbitrary combinatorial relationships\\ncommunication spanning tree constraint\\nmatroid intersection\\noptimality bounds\\ndecentralized algorithm\\nauction methods\\nurban environment surveillance\\nmonte carlo results\",\"33\":\"aerospace electronics\\nnull space\\npressing\\nglass\\nlinear programming\\nredundancy\\njacobian matrices\\ndexterous manipulators\\nhumanoid robots\\nlearning (artificial intelligence)\\nmatrix decomposition\\nlearning task constraints\\noperational space formulation\\nhuman skills\\ncontrol policy\\nself-imposed constraints learning\\noperational space control\\nconstraint matrix\\nthree degree-of-freedom arm\\nar10 humanoid hand\",\"34\":\"trajectory\\nmanipulators\\nlearning (artificial intelligence)\\neducation\\ncollision avoidance\\nniobium\\nrobot dynamics\\ntrajectory control\\ndynamical movement primitives modification\\ndmp\\nrobot operator\\nlead-through programming\\ncorrective trajectory\\nfaulty trajectory\",\"35\":\"robots\\ndata models\\nheuristic algorithms\\naerodynamics\\nsystem dynamics\\ngaussian processes\\nsafety\\nlearning (artificial intelligence)\\nmixture models\\nrobot dynamics\\nmultimodal model learning\\nmixture of gaussian process experts\\ncontrolled industrial environment\\nhuman operator\\ndirichlet process mixture model\",\"36\":\"trajectory\\nmanipulators\\nforce feedback\\nadaptation models\\nforce\\nhuman-robot interaction\\nlearning systems\\ntelerobotics\\nlearning-based shared control architecture\\ninteractive task execution\\nrobotic applications\\nlearning from demonstration\\ntrajectory distributions\\nlearned expert distributions\\ncontroller autonomy\\ncollaborative task executions\\nmaster-slave system\",\"37\":\"planning\\nrobots\\ntrajectory\\nheuristic algorithms\\nsystem dynamics\\noptimal control\\nstandards\\nlearning systems\\nmanipulators\\npath planning\\npredictive control\\nhindsight plan\\nepisodic mpc improvement\\nmodel predictive control\\niterative learning\\npolicy improvement scheme\\nshort horizon planning\\nlong-term reasoning\\ncontact-rich manipulation tasks\\npr2 robot\",\"38\":\"adaptive control\\ntrajectory tracking\\naerodynamics\\noutput feedback\\ntrajectory\\nfeedback\\niterative learning control\\nrobots\\nrobust control\\ntrajectory control\\nhigh-precision trajectory tracking\\nl1 adaptive feedback\\nilc\\nautomated systems\\nsystem robustness\\nsystem repeatability\\nl1 adaptive controller\",\"39\":\"robots\\noptimization\\ntrajectory\\ntools\\nforce\\ncleaning\\nbuildings\\niterative methods\\noptimal control\\noptimisation\\nprobability\\noptimal trajectory parameters\\nphysics-based models\\nsurrogate model\\niterative process\\nrobotic cleaning problem\\noptimization problem\\nblack box constraints\",\"40\":\"trajectory\\ntraining\\nrobot sensing systems\\nloss measurement\\naerospace electronics\\nstandards\\ngrippers\\nlearning by example\\nneural nets\\nrobot programming\\nsupport vector machines\\nrobot-centric sampling\\nhuman-centric sampling\\nrobot deep learning\\nlearning from demonstrations\\nsupervised learning algorithm\\nrobot teleoperation\\nstate-control pairs\\nhc sampling\\nrc sampling\\ngripper\\nlinear svm\",\"41\":\"dictionaries\\nkernel\\noptimization\\nencoding\\ncorrelation\\ntraining\\nsilicon\\niterative methods\\nsignal processing\\nmultilabel tactile property analysis\\nmultilabel dictionary learning\\nsparse coding\\nlabel correlation information\\nglobally-convergent iterative algorithms\\ntactile sequence dataset\\nphac-2\",\"42\":\"force\\nhandover\\nrobot sensing systems\\ngrasping\\nreliability\\nfeedback\\nhuman-robot interaction\\nmanipulators\\ntactile sensors\\nreliable object handover\\ntactile force sensing\\nshadow robot hand\\neffort control\\nhumanrobot interaction\\nreliable robot mechanism\\nhuman object handover\\ntactile sensing\\nbiotac sensors\\nfeedback signal\",\"43\":\"atmospheric measurements\\nparticle measurements\\nrobot sensing systems\\nmeasurement uncertainty\\nsolid modeling\\nmanufacturing processes\\nparticle filtering (numerical methods)\\nprecision engineering\\ntactile sensors\\nhigh-precision manufacturing\\npart touch-based localization\\ninformation gathering action\\nnongaussian belief\\ninitial 6dof uncertainty\\narbitrary error model\\nparticle filter\\nlaser sensors\",\"44\":\"force\\nforce control\\nrobots\\niron\\nstability criteria\\nports (computers)\\nmanipulators\\nstability\\npassivity-based stability\\nexplicit force control\\ndirect force control\\ncontrol loop passivation\\ncontrol loop stabilisation\\ntime domain passivity approach\\nelectrical circuit\\nnetwork-port representations\\nanalytical evaluation\\ncontrol architectures\\nqualitative analysis\\nquantitative analysis\\nenergy behavior\\nstable high-bandwidth force control\\nrobotic manipulators\",\"45\":\"skin\\nrobot sensing systems\\ntorque\\nrobot kinematics\\nforce\\ncontrol system synthesis\\nmanipulators\\ntorque control\\nlarge-scale robot skin\\nefficient event-driven reactive skin controller\\nstandard jacobian torque controller\\nmultimodal event-driven robot skin\\nsynchronous reactive skin controller design\\nrobot tomm\\nur5 robot arms\\nmultimodal skin cells\\ncpu usage reduction\",\"46\":\"skin\\nforce\\ncalibration\\ncapacitance\\ndielectrics\\ntactile sensors\\ngeometry\\nhumanoid robots\\nleast squares approximations\\npolynomials\\nskin normal force calibration\\nvacuum bags\\ndistributed capacitive sensors\\nuniform pressure distribution\\ndifferential pressure\\nleast square fitting\\nfifth order polynomial model\\nskin geometry\\nnet normal force\\nforearm skin\\nicub humanoid robot skin\\nforce prediction\",\"47\":\"dielectrics\\nrobot sensing systems\\ncapacitance\\ndynamics\\ncapacitive sensors\\ndesign engineering\\ngrippers\\nindustrial manipulators\\nmechanical contact\\nslip\\ntactile sensors\\nhighly sensitive multimodal capacitive tactile sensor\\nmanufacture process\\nrobotic grippers\\nmanipulation tasks\\nunstructured flexible objects\\nmultimodal sensor\\nmechanical design\\ndirect written microstructured dielectric\\nforce sensing\\ncontact events\\nslippage\",\"48\":\"haptic interfaces\\nactuators\\nrobots\\nforce\\nnumerical models\\nimpedance\\nsprings\\nseries elastic actuators\\nrigid haptic devices\\nvirtual environment\\nsea\\nrobot perceived stiffness\\nelastic element equilibrium position\\ncomputer-control architecture\\nrigid haptic systems\\ncontinuous time sea models\\ndiscrete time analysis\",\"49\":\"haptic interfaces\\npneumatic actuators\\nskin\\nwrist\\nvibrations\\nshape\\nbiomedical imaging\\nfeedback\\nhuman computer interaction\\ntactile sensors\\ntouch (physiological)\\nwrap\\nwearable restricted-aperture pneumatics\\nhaptic guidance\\nvirtual reality\\nhuman-robot interaction\\nmotion guidance\\nlightweight actuator\\nwearable pneumatically actuated haptic feedback device\\ntactile sensation\\nthermoplastic pneumatic actuator\\nimage guided medical intervention\\nhuman-computer interaction\\ntranslation cue identification\\nrotation cue identification\",\"50\":\"rails\\nforce\\nrobot sensing systems\\nforce feedback\\nvisualization\\nend effectors\\nhaptic interfaces\\noptical tracking\\ntelerobotics\\nblindfolded robotic teleoperation\\nspatial force feedback\\nhuman toe\\nrobotic arm\\nteleoperated systems\\nspatial toe-feedback\\ndlr light-weight robot\\nlwr\\nhaptic feedback\\nthree-dimensional spatial force\\ncontact forces\\nrobotic end-effector\\nvisual feedback\\nsensorimotor loop\",\"51\":\"protons\\nrobot sensing systems\\naccelerometers\\ntracking\\nforce\\nvibrations\\nplastics\\ncalibration\\ncameras\\ncomputerised instrumentation\\nend effectors\\nimage sensors\\nlearning (artificial intelligence)\\nmotion measurement\\noptical sensors\\nportable instruments\\nrecorders\\nsupport vector machines\\ntactile sensors\\nproton 2\\nvisuohaptic surface interaction recorder\\nprotonpack\\nportable robotic optical-tactile observation package\\nhandheld visuohaptic sensing system\\nexternal motion tracking\\naccelerometer\\ndifferently-sized steel tooling ball end-effector speed\\ncontact vibration\\nmulticlass svm training\\ncamera\\nportable data collection\\nfiltering\\nsize 6.35 mm\\nsize 9.525 mm\\nsize 2 mm\\ntime 50 ms\",\"52\":\"rendering (computer graphics)\\nhaptic interfaces\\nmechanical systems\\nsprings\\nstability analysis\\nharmonic analysis\\noscillators\\nmechanical integrators\\npassive midpoint integrator\\nnoniterative passive mechanical integrator\\nnpmi\\ncomplex articulated rigid bodies simulation\\nmultipoint intermittent contact\\nlinear complementarity problem\\nlcp\\npmi-based haptic rendering\\nmechanical system simulation\\nmultiuser virtual co-manipulation\\nshared rigid object\\nse(3)\\ninternet\",\"53\":\"vibrations\\nbars\\naluminum\\nmobile robots\\ncorrelation\\ndelays\\nrobot sensing systems\\ncollision avoidance\\nfeedback\\ntactile sensors\\ntelerobotics\\ncollision representation\\nvibrotactile cues\\nbimanual impact localization\\nremote exploratory tasks\\nvibrotactile stimulation\\nfrontal collisions\\nimpact vibration amplitude differences\\nimpact vibration duration differences\\npsychophysical function\\ndifferential drive mobile robot\\nhigh speed tactile sensor\\nteleoperation task\\nvibrotactile feedback\",\"54\":\"robots\\nmuscles\\nforce\\nback\\nstability analysis\\ntorque\\npain\\nactuators\\nelectromyography\\nmedical robotics\\npatient rehabilitation\\nrehabilitation exercise robot\\nlow back pain\\nserious health problems\\nstabilization exercises\\nlow back stability\\nrehabilitation robot sera\\nstabilization exercise robot assistance system\\nvoluntary control\\nanti-gravity force\\nseries elastic actuators\\nsea\\nsurface electromyograph\\nsemg sensors\",\"55\":\"training\\nrobot kinematics\\nmedical treatment\\nadaptation models\\nneuromuscular\\nperformance evaluation\\ndexterous manipulators\\nfeedback\\nmedical robotics\\noptimal control\\noptimisation\\npatient rehabilitation\\npatient treatment\\ntorque control\\noptimization\\nrobotic exoskeleton\\nrobotic rehabilitation\\noptimal rehabilitation environment\\ntherapy\\nrobot-assisted motor relearning\\nsubject-specific training\\ncontinuous multijoint task\\ncoordinated multijoint task\\nlearning-from-demonstration approach\\ndexterous manipulation\\ntorque\",\"56\":\"winches\\nlegged locomotion\\nbelts\\ngravity\\nforce control\\ntracking\\ncables (mechanical)\\nsupports\\n3 wire body weight support system\\nlarge treadmill\\n3 dof parallel cable\\nbws system\\nuniversity of utah treadport locomotion interface\\nsteep slope simulation\\nreduced gravity environment display\\nmulticable support system\\nsystem model\",\"57\":\"torque\\nactuators\\nlegged locomotion\\ntorque control\\nknee\\ngears\\ntraining\\northotics\\npowered knee-ankle orthosis\\ntorque-driven rehabilitation control strategies\\nlow-ratio transmission\\nmechanical transparency\\njoint kinematics\\ngait training\\naluminum alloy\\ncarbon fiber\\nelastic components\",\"58\":\"impedance\\nactuators\\nhaptic interfaces\\nrobots\\nmuscles\\ntorque\\nservomotors\\ndesign engineering\\nelastic constants\\nneuromuscular stimulation\\nperturbation techniques\\nposition control\\nrobot kinematics\\nmultiaxis robotic platform validation\\nmultiaxis robotic platform design\\nankle neuromechanics characterization\\nneuromuscular properties\\nmechanical impedance\\nposition perturbations\\nangular speed\\nhaptic environments\\ntwo-degree-of-freedom\\ntwo-dof\\ndorsiflexion-plantarflexion\\ninversion-eversion\\nsagittal plane\\nfrontal plane\\nmechanical environments\\nposition controller\\nloading condition\\nhaptic controller\\nstiffness estimation\\nmedium-latency reflex responses\\nlong-latency reflex responses\",\"59\":\"actuators\\npulleys\\nlegged locomotion\\ntorque\\nhip\\nknee\\nmedical robotics\\northotics\\npatient treatment\\nrobotic orthosis\\nneurological disorders\\nwearer\\ninstability\\ncable differential mechanism\\nstroke patients\\nhemiplegia\\ninertial effect\\ntorques\\ncowalk-mobile 2\",\"60\":\"robots\\nhaptic interfaces\\nstability criteria\\nimpedance\\nextremities\\ndamping\\nbiomechanics\\nelasticity\\nhuman-robot interaction\\nhuman ankle stability\\nenvironmental mechanics\\nmultidimensional ankle stability\\nstiffness-defined haptic environments\\nsagittal plane\\nfrontal plane\\nperturbation\\nenvironmental stiffness\",\"61\":\"manganese\\ntools\\nconcrete\\nmanufacturing systems\\ncomplexity theory\\ncomputer science\\nmathematical model\\nmathematical analysis\\nsupervisor simplification\\ndynamic inequality partition\\nstatic inequality partition\\nautomated manufacturing system\\ngeneralized mutual exclusion constraint\\ngmec\",\"62\":\"tools\\nrobots\\noptimal scheduling\\nschedules\\nsteady-state\\njob shop scheduling\\nindustrial manipulators\\nlinear programming\\nmulti-robot systems\\npreventive maintenance\\nscheduling\\nsemiconductor industry\\nsemiconductor technology\\nsynchronisation\\nclose-down process scheduling\\nwafer residence time-constrained multicluster tools\\nsemiconductor manufacturing industry\\nwafer fabrication equipment\\nwafer lot switches\\nemergency maintenance\\ndynamical-noncyclic maintenance\\nsynchronization conditions\\nmultiple robots\\nconcurrent activities\\noptimal schedule\\nlinear program model\\ncluster tools\\nrobotic manufacturing cells\\nsemiconductor manufacturing automation\",\"63\":\"uncertainty\\nmanipulators\\ncomputational modeling\\nkinematics\\nsolid modeling\\ntorque\\nindustrial manipulators\\nmonte carlo methods\\nmotion compensation\\nrobotic assembly\\nconstraint-based sample propagation\\nimproved state estimation\\ntask execution\\ngeometric uncertainty estimation\\ncontact state estimation\\nassembly execution\\nsequential monte carlo method\\nsmc method\\nrelative pose tracking\\njoint torque measurements\\njoint position measurements\\ntable surface\\nconstraint-based propagation model\\ncompensation motion\\ncontact constraints\\nkuka lbr iiwa robot arms\",\"64\":\"service robots\\nrobustness\\ngrippers\\ncollaboration\\nontologies\\nuser interfaces\\nflexible manufacturing systems\\nindustrial robots\\ntrees (mathematics)\\ncostar\\ncollaborative robots\\nbehavior trees\\ncollaborative system for task automation and recognition\\nkuka innovation award competition\\nhannover messe trade show\\nflexible manufacturing\\nbehavior tree-based task editor\\nobject segmentation\\npose estimation\\nrobust task plans\",\"65\":\"blades\\ntools\\ntrajectory\\nshape\\nturning\\nmobile robots\\ncutting tools\\npath planning\\nplanning cuts\\nbladed tools\\nlinear bladed cutting tools\\njigsaws\\nvital manufacturing tools\\ncut structures\\ngeneric path planner\\nreeds-shepp cars\\ngeneric path planning algorithm\\nclosed curves\\nautonomous mobile robot\\n2d plane\",\"66\":\"fabrication\\nadditives\\ngeometry\\nalgorithm design and analysis\\nrobots\\nstrips\\ntendons\\nbending\\ncompliance control\\ncontrollability\\nelastic deformation\\nrobot kinematics\\nthree-dimensional printing\\nself-folded soft robotic structures\\ncontrollable joints\\norigami-inspired rapid fabrication approach\\nactuatable compliant structures\\n3d printing\\nrapid fabrication process\\nsoft robots\\nelastic materials\\n3d object\\npleat folding\\nzigzag pattern\\nlarge bending movement\\ndeformation\\nshape accuracy\\nplanar fabrication\\nself-folding technique\\nhighly compliant structure\\ncomplex 3d geometry\\n3d meshe\\nadditive self-folding design\\nmagnetic field\\nlocal bending\\ntendon-driven control\\nbunny\\ntuna fish\\nstarfish\\nmagnetic control\",\"67\":\"permanent magnet motors\\ninduction motors\\nsynchronous motors\\ncoils\\nmagnetic levitation\\nmagnetic cores\\nlinear synchronous motors\\nmagnetically levitated 4 pole hybrid mover\\n4 pole hybrid electromagnetic levitation system\\nlinear synchronous motor\\nzero power control algorithm\\nplanar motion\\nvector controlled linear motor\\ndiagonal drive integration\",\"68\":\"actuators\\nelectron tubes\\nrubber\\nrobots\\nshape\\nfabrics\\nsurface waves\\npneumatic actuators\\nwave propagation\\nsoft sheet actuator\\ntraveling waves\\ngastropod locomotion\\nwavy-sheet\\nmobile soft mat\\npneumatics\\nflexible rubber tubes\",\"69\":\"force\\nvalves\\nmathematical model\\npneumatic systems\\nservomotors\\nrobot sensing systems\\nforce control\\nnonlinear estimation\\npneumatic actuators\\nservomechanisms\\nmodified nonlinear pressure estimator\\npneumatic actuator\\nforce controller design\\nmodified nonlinear pneumatic model\\npneumatic force servo systems\\npneumatic cylinder\\nflow coefficient maps\\nmodel-based controller design\\nforce servo controls\\nforce sensor\",\"70\":\"robots\\nfluids\\nactuators\\nmagnetic fields\\nforce\\nshafts\\ncoils\\nclutches\\ncompliant mechanisms\\nforce control\\nlinear systems\\nmagnetorheology\\nmanipulators\\nprototypes\\nmagneto-rheological linear clutch development\\nmagneto-rheological linear clutch design\\nforce controlled human safe robots\\nrobot links\\nsmart electrical fields\\nmr clutch\\nlinear actuator\\nelectromechanical model\\none-degree-of-freedom arm prototype\",\"71\":\"pistons\\nforce\\nhydraulic systems\\nrobots\\nrotors\\nactuators\\nparticle separators\\nelectric actuators\\nfriction\\nhumanoid robots\\nhydrostatics\\nunderactuated four-fingered hand\\nheavy duty tasks\\nrough terrain\\nactuated anthropomorphic hand\\nhumanoid robot hydra\\nback-drivable electro hydrostatic actuators\\nminiature linear cluster eha\\nlight weight tie-rod cylinder cluster\\nlow friction trochoid pumps\\ncrescent separator\\nforearm structure\\ntendon tension\\nfriction tendon routing\\nlow friction wire guiding link\\nparallel link wrist driving mechanism\",\"72\":\"actuators\\nsprings\\nspirals\\nforce\\nshape\\nrobots\\nplastics\\ndesign\\nmanipulators\\npneumatic actuators\\npneumatic reel actuator\\npra\\ncompression\\nextension\\npressure\\nspeed\\nparallel robotic applications\\nthree degree of freedom robot arm\\ntetrahedral robot\",\"73\":\"robot sensing systems\\nmirrors\\nneural networks\\ntraining\\ngravity\\nrobustness\\nlearning (artificial intelligence)\\nmobile robots\\nplanetary rovers\\ndeep reinforcement learning\\ntensegrity robot locomotion\\nrigid rods\\nelastic cables\\nplanetary exploration rovers\\ncomplex dynamics\\nlocomotion gaits\\nmirror descent guided policy search\\nmdgps\\nperiodic locomotion movements\\nsuperball tensegrity robot\\nunreliable sensor measurements\\npower-efficient feedback policies\\nrolling gaits\\nonboard sensing\\nsuperball accelerometers\\nopen-loop policies\\nhand-engineered controllers\\nreliable locomotion gait\\nsuperball robot\",\"74\":\"trajectory\\naerospace electronics\\nplanning\\nmathematical model\\nestimation\\ncost function\\nclosed loop systems\\ncontrol system synthesis\\nfeedback\\nlinear quadratic gaussian control\\nnonlinear programming\\nopen loop systems\\noptimal control\\npath planning\\nstochastic systems\\ntrajectory control\\nt-lqg\\nclosed-loop belief space planning\\ntrajectory-optimized lqg\\nmotion planning\\nstochastic control\\nlinear feedback polices\\nopen-loop optimal control policies\\nlinear quadratic gaussian design\\nlqg design\\nnonlinear program\\nnlp\",\"75\":\"robots\\ncollision avoidance\\nplanning\\ntrajectory\\ndynamics\\noptimization\\nvehicle dynamics\\ndistributed control\\nminimisation\\nmobile robots\\nmulti-robot systems\\npath planning\\npredictive control\\nrobot dynamics\\ntrajectory control\\nreal-time distributed receding horizon motion planning\\nreal-time distributed receding horizon motion control\\nmobile multirobot dynamic systems\\nmodified model predictive control\\nmpc\\ndynamical wheeled mobile robots\\nnavigation problem\\ndistributed receding horizon algorithm\\nconstrained optimization problems\\nrobot travel time minimization\\nunicycle-like vehicles\\ntrajectory tracking\",\"76\":\"planning\\ngaussian processes\\nheuristic algorithms\\nprobabilistic logic\\napproximation algorithms\\ntrajectory\\nrobots\\napproximation theory\\ncontinuous time systems\\nmotion control\\nnonlinear control systems\\noptimal control\\npath planning\\nstochastic systems\\napproximately optimal continuous-time motion planning\\napproximately optimal continuous-time motion control\\ncontinuous-time stochastic systems\\nnoninstantaneous nonlinear performance\\npipc\\nprobabilistic inference-for-planning-and-control\\nhigher-order nonlinear performance indices\\nnonlinear factors\\nreceding horizon setting\\ngaussian process representation\",\"77\":\"robot sensing systems\\ntrajectory\\nobservability\\nestimation\\neigenvalues and eigenfunctions\\noptimization\\nmobile robots\\noptimal control\\nsplines (mathematics)\\ntrajectory control\\nonline optimal active sensing control\\nnonlinear differentially flat systems\\nobservability gramian\\nog\\nb-spline curves\\nonline gradient descent strategy\\nextended kalman filter\\nekf\\nsensory data\\nonline replanning\\nstate trajectories\\noptimal trajectory\\nrobot motion\\nstate estimation\\nplanar robot\",\"78\":\"acceleration\\ntorque\\nrobots\\njoining processes\\nperiodic structures\\nforce\\nconvex functions\\noptimal control\\noptimisation\\ntime-optimal path parameterization problem\\ntopp3\\nthird-order constraints\\noptimal profiles\\nrobot configuration space\",\"79\":\"markov processes\\nmultiresolution analysis\\noptimal control\\naerospace electronics\\nplanning\\nrobots\\ndiscrete wavelet transforms\\nmotion control\\npath planning\\nwavelet transforms\\ndiffusion wavelets\\nstochastic optimal control problems\\nmultiscale framework\\nrobot motion planning\\nrobot motion control\\ndiffusion wavelet representation\\nmarkov chain\\nhierarchical abstraction\\ndesirability function-based representation\\nmarkov decision process\\nmdp\\nwavelet bases\\nreceding horizon implementation\\ncontinuous-time optimal control policy\",\"80\":\"trajectory\\noptimal control\\noptimization\\ndynamic programming\\napproximation algorithms\\nstandards\\niterative methods\\napproximation theory\\ncollision avoidance\\nnonlinear control systems\\ntrajectory control\\ndifferential dynamic programming\\ntrajectory optimization technique\\nnonlinear optimal control problems\\nnonlinear cost functions\\narbitrary nonlinear inequality constraints\\nrecursive backward pass\\nrecursive formulae\\nunconstrained problems\\nrecursive quadratic approximation formula\\nconstrained-ddp\\ncddp algorithm\\nactive set iterative determination\\nunderactuated optimal control problems\\nobstacle avoidance\",\"81\":\"scattering\\nimage color analysis\\nattenuation\\nsimultaneous localization and mapping\\natmospheric modeling\\nlight sources\\nvisualization\\nautonomous underwater vehicles\\nimage colour analysis\\nimage enhancement\\nimage registration\\nrobot vision\\nslam (robots)\\nvisibility enhancement\\nunderwater visual slam\\nunderwater light scattering model\\nunderwater visual simultaneous localization-and-mapping\\naerial environment\\nunderwater environment\\nimage degradation model\\nunderwater particle physics\\nunderwater image enhancement\\nartificial light model\\ngray images\\ncolor images\\nsimulated synthetic images\\nreal-world underwater images\\nunderwater image sets\\ncamera registration improvement\",\"82\":\"containers\\nthree-dimensional displays\\nwheels\\npayloads\\ntwo dimensional displays\\nlasers\\ncameras\\nimage fusion\\nlifting equipment\\nmobile robots\\nobject detection\\noptical scanners\\nautomated guided vehicles\\nlarge containers\\ncart\\ncaster wheels\\ncombined detection and control architecture\\nagv\\ncontainer detection\\ncontainer acquisition\\nglobal localization system\\nhorizontally mounted 2d laser scanner\\nforward facing 3d time-of-flight camera\\nasymmetric agv\\ndifferentially driven base\\ntrailer\\nlifting unit\",\"83\":\"shape\\nthree-dimensional displays\\ntwo dimensional displays\\nsolid modeling\\nimage reconstruction\\ncameras\\npipelines\\nimage retrieval\\niterative methods\\nneural nets\\nobject detection\\noptimisation\\nregression analysis\\nroad traffic\\nroad vehicles\\nshape recognition\\ntraffic engineering computing\\nvehicles reconstruction\\nsingle rgb image\\nshape priors learning\\nroad scene\\nvehicles 3d shapes\\nshape-aware adjustment problem\\nquery object\\nconvolutional neural networks\\ncnn\\nobject localization\\nkeypoint localization\\niteratively reweighted least squares scheme\\nirls scheme\\nrobust optimization\",\"84\":\"robot kinematics\\nshape\\nmobile robots\\nvisual servoing\\ncameras\\nmathematical model\\nmotion control\\nrobot vision\\ntelerobotics\\ncatenary-based visual servoing\\ntethered robots\\nteleoperated robots\\nrobot workspace\\nvisual servoing scheme\\ncatenary shaped deformable objects\\ntether parametric shape control\\nvisual servoing approach\\nmotion capabilities\\nslack rope\\ntether handling\",\"85\":\"three-dimensional displays\\npose estimation\\nrobustness\\nrobots\\nsilicon\\nsolid modeling\\ntools\\nimage filtering\\nimage segmentation\\n6d object pose estimation\\ncurvature filtering\\nregion pruning\\nrobustifying methods\\ncorrespondence selection\\ngeometric consistency\\nhough grouping\\nsearch of inliers\",\"86\":\"engines\\ntraining\\nmachine learning\\ndata models\\nrobots\\ntraining data\\nautomobiles\\nlearning (artificial intelligence)\\npattern classification\\nvirtual world\\nhuman-generated annotation\\ndeep learning\\nphoto-realistic computer image\\nmachine learning algorithm\\ndata classification\\nsensor-based classification problems\\nsimulation\\nobject detection\\nautonomous driving\",\"87\":\"surgery\\nstreaming media\\ninstruments\\nlaparoscopes\\nrobots\\nhidden markov models\\nvisualization\\nlearning (artificial intelligence)\\nmedical robotics\\nsupport vector machines\\nvideo signal processing\\nmachine learning\\ncoresets\\nautomated real-time video segmentation\\nlaparoscopic surgery\\nrobot-assisted surgery\\ncontext-aware segmentation\\nrobot assisted surgical video\\nperioperative workflow efficiency\\ntime-critical consultation\\nproductivity\\nvideo analysis\\nhospital policies\\nlegacy infrastructure\\nrobot-assisted procedures\\nsvm\\nhmm\\naugmented feature space\\nvideo streams\\ndata reduction\\nonline k-segment coreset algorithms\\npiloting\\nrisk factors\",\"88\":\"planning\\nautomata\\npareto optimization\\nsearch problems\\nindexes\\ncontrol engineering computing\\nformal specification\\ngraph theory\\nmulti-robot systems\\noperating systems (computers)\\npath planning\\nrobot programming\\ntemporal logic\\nmultiobjective search\\noptimal multirobot planning\\nfinite ltl specifications\\nresource constraints\\ngraph based search method\\nros implementation\",\"89\":\"robot sensing systems\\nmobile robots\\ndensity functional theory\\nlinear programming\\nsilicon\\nmulti-robot systems\\ntime-varying systems\\nnonidentical sensory ranges\\nmultiple mobile robot system\\nmodified partitioning approach\\ndynamic coverage controllers\\ntime-varying density function\\ncoverage partition\\ncoverage control\\nmobile robot network\\nr-limited voronoi partitions\",\"90\":\"planning\\nnavigation\\ncollision avoidance\\nstandards\\nvehicle dynamics\\ntrajectory\\nautomation\\nautonomous aerial vehicles\\ndecentralised control\\nformal verification\\nhelicopters\\nmulti-robot systems\\naerial agents\\nhybrid control strategy\\nlocal goal specification\\ntemporal logic formula\\ninter-agent collision avoidance\\n3-d spheres\\nagent volume\\ndecentralized motion planning problem\\ndecentralized navigation functions\\ncontrol laws\\nfinite transition systems\\nstandard formal verification techniques\\nhigh-level control algorithm\\nquadrotors\",\"91\":\"hidden markov models\\ntracking\\nrobot sensing systems\\nmonte carlo methods\\npredictive models\\nlearning (artificial intelligence)\\nmobile robots\\nmulti-robot systems\\nparticle filtering (numerical methods)\\nmobile robot\\nrobot motion model\\nnested particle filter\\ntraditional particle filter generalization\\nself-localization\\nrobot tracking\\nweight nested particles\\npropagation step\\nmotion model\\nlayered hidden markov model\\nonline algorithm\\nhmm parameter learning\\nleading mobile robot\\nleader motion prediction\",\"92\":\"robots\\nfeature extraction\\nthree-dimensional displays\\nplanning\\nbackpropagation\\nobject recognition\\nimage segmentation\\ndirected graphs\\nimage colour analysis\\nmanipulators\\nneural nets\\nrobot vision\\nobject manipulation\\nconvolutional neural networks\\nintelligent visuomotor system\\naspect transition graph\\natg\\ndirected multi-graph\\nhierarchical cnn features\\nrgb-d images\\nrobot observations\\nwashington rgb-d object dataset\\nrobonaut-2\\ndrill grasping task\\nreachability constraints\",\"93\":\"robots\\noptimization\\nresource management\\nuncertainty\\nrandom variables\\nlinear programming\\nprobabilistic logic\\ngaussian processes\\nmulti-robot systems\\noptimal chance constrained linear assignment\\nprovably-good algorithm design\\ntask allocation\\nrobot group\\ngaussian random variables\\nrobot payoff\\nchance constrained optimization problem\\nrisk-averse task allocation problem\\nrisk aversion parameter\\nlinear assignment problem\",\"94\":\"robots\\ntunneling\\nalgorithm design and analysis\\nnavigation\\nmobile communication\\ntransforms\\nlattices\\ncollision avoidance\\ntunneling-based self-reconfiguration\\nheterogeneous sliding cube-shaped modular robots\\nobstacles\\ntunneling robot\\npermutation algorithm\\nsliding motion\\nconvex motions\\n3d 2\\u00d72\\u00d72 metamodule\\nmobile modules\\nconnected robot structure\",\"95\":\"multi-robot systems\\nobservers\\nprotocols\\nupper bound\\nheuristic algorithms\\nmobile robots\\ndistributed control\\nrobot dynamics\\nvariable structure systems\\ndistributed fixed-time cooperative tracking control\\nmultirobot systems\\ndouble-integrator dynamics\\ndistributed observer\\nleader state estimation\\nlocal tracking controller\\nsliding mode technique\\nstationary leader\\ndynamic leader\\nnonholonomic dynamics\\nsettling time\",\"96\":\"target tracking\\nmobile communication\\nautomata\\nmathematical model\\nobservers\\nreachability analysis\\nautomata theory\\ngraph theory\\nmobile robots\\nmulti-robot systems\\npath planning\\ntriangulation graph\\nart gallery problem\\nmobile guard team\\nsimply-connected polygonal environment\\nevent-triggered strategies\\nhybrid automaton\\npersistent surveillance\",\"97\":\"trajectory\\nplanning\\nrobot kinematics\\nkinematics\\nacceleration\\nservice robots\\nmanipulators\\npath planning\\nsmooth joint motion planning\\nhigh precision reconfigurable robot manipulators\\nindustrial adoption\\njoint motion profiles\\nmodular robots\\nsmooth motion profiles\\nproduction task\\njerk-bounded trajectories\",\"98\":\"robot sensing systems\\nhistory\\nuncertainty\\nrobot kinematics\\ntarget tracking\\ndecision making\\ndecentralised control\\nmarkov processes\\nmulti-robot systems\\nmulti-robot active information gathering\\nperiodic communication\\ninformation gathering task\\nmulti-agent optimal decision-making\\ndecentralized partially observable markov decision process\\ndec-pomdp\",\"99\":\"robot kinematics\\ncollision avoidance\\npath planning\\njoining processes\\nbipartite graph\\nnavigation\\ngraph theory\\nmobile robots\\nmulti-robot systems\\nbipartite graph matching\\ncoordination mechanism\\nmultirobot path planning\\ncommunication constraints\\ninterrobot collisions\\nweighted bipartite matching\",\"100\":\"convergence\\nentropy\\nacceleration\\ndecision making\\nrobot sensing systems\\nscalability\\nmarkov processes\\nmulti-robot systems\\nsearch problems\\nscalable accelerated decentralized multirobot policy search\\ncontinuous observation space\\ncontinuous-observation decentralized partially observable markov decision processes\\ndec-pomdp\\ncontinuous-observation policy representation\\nstochastic kernel-based finite state automata\\nsk-fsa search algorithm\\nentropy-based policy search using continuous kernel observations\\nepscko algorithm\\nempirical analysis\\nentropy injection policy\",\"101\":\"robots\\ndecision making\\nsemantics\\nscalability\\nprobabilistic logic\\nuncertainty\\nnoise measurement\\nbayes methods\\nconvolution\\ndecentralised control\\nhelicopters\\nmarkov processes\\nmulti-robot systems\\nneurocontrollers\\nobservability\\npattern classification\\nstatistics\\nsemantic-level decentralized multirobot decision-making\\nprobabilistic macroobservations\\nrobust environment perception\\nintelligent task execution\\nrobot observation model\\nsemantic object labels\\ndecentralized partially observable semimarkov decision processes\\nhierarchical bayesian approach\\nnoise statistics\\nlow-level classifier outputs\\ndomain noise characteristics\\nhierarchical bayesian noise inference\\nhbni\\ndec-posmdp planner\\ndynamic quadrotors\\nreal-time convolutional neural net-based classification framework\",\"102\":\"robots\\ncollaboration\\nadaptation models\\nregression tree analysis\\ndecision making\\nplanning\\nreal-time systems\\ncontrol engineering computing\\ngroupware\\nhuman-robot interaction\\ninteractive systems\\nlearning (artificial intelligence)\\nmarkov processes\\nmulti-robot systems\\npreference learning\\ncollaborative human-robot tasks\\nconcurrent joint human-robot tasks\\nrobot helper\\nconcurrent multi-agent cooperation\\nsemi markov decision process\\ninteractive learning algorithms\",\"103\":\"planning\\nrobots\\ntraining\\nuncertainty\\ngenerators\\nintelligent systems\\nexplosions\\ncontrol engineering computing\\nintelligent robots\\nlearning (artificial intelligence)\\nrobot programming\\ncomposable models\\nparameterized skills\\nrobot skills\\nintelligent system\\ncompositionality\\nlearning models\\ngenerative planning and execution system\",\"104\":\"tools\\nrobots\\nthree-dimensional displays\\nfeature extraction\\nhistograms\\ngeometry\\nmathematical model\\nhumanoid robots\\nintelligent robots\\nneurocontrollers\\nregression analysis\\nself-organising feature maps\\nunsupervised learning\\nself-supervised learning\\n3d tool representation\\nparallel som mapping\\n3d geometry\\ntool-pose descriptors\\naffordance vectors\\ntool affordance learning\\nunsupervisedly mapping\\nself-organizing maps\\nneurons\\ntool-pose som\\nneural based regression model\",\"105\":\"aerospace electronics\\nrobots\\nbayes methods\\nforce\\ntuning\\ncost function\\nforce control\\nmanipulators\\nconstrained bayesian optimization\\ncombined interaction force\\/task space controller\\nmanipulation\\ncontrol concept\",\"106\":\"robot sensing systems\\nhistory\\ntrajectory\\nthree-dimensional displays\\ntraining\\ntime measurement\\nintelligent robots\\nlearning (artificial intelligence)\\nmobile robots\\nbudgeted information gathering\\nautonomous exploration\\ninspection\\ndata-driven imitation learning framework\\nexplore\\nnonmyopic solutions\\n2d exploration problem\\n3d exploration problem\\nobject distributions\",\"107\":\"robots\\nestimation\\nlearning (artificial intelligence)\\nkernel\\nsolid modeling\\nmarkov processes\\nsampling methods\\ndecision theory\\nmulti-agent systems\\napprenticeship learning\\nincompatible feature space\\nnonidentical markov decision processes\\nmapping function\\nfeature expectation\\nagent space\\nconditional density estimation\\nheterogeneous mdps\",\"108\":\"force measurement\\nforce\\ngrasping\\ninstruments\\nsurgery\\nrobot sensing systems\\nbragg gratings\\nbiomedical transducers\\nfibre optic sensors\\nforce sensors\\nneedles\\noptical fiber-based sensor\\ninvasive surgery\\nforce feedback\\naxial sterilizable force sensing technology\\ngrasping force measurement\\naxial force measurement\\ninnovative partial grasper has\\nlaparoscopic needle driver\\nfiber bragg grating sensor\\ngrasping sensor\",\"109\":\"friction\\nrobot sensing systems\\ntorque\\nforce\\nobservers\\nadmittance\\nforce control\\nhuman-robot interaction\\nindustrial manipulators\\nkalman filters\\nproduction management\\nsmall-to-medium enterprises\\nsensorless kinesthetic teaching\\nrobotic manipulators\\nobserver-based force control\\nproduction rates\\nsmall and medium scale enterprises\\nlead-through programming\\nltp\\nphysical interaction\\nsensorless approach\\nredundant robots\\nadmittance control\\nkalman filter\\ngeneralized momentum formulation\\ndithering technique\\nabb yumi robot\",\"110\":\"force\\ntactile sensors\\nforce measurement\\nshape\\ngeometry\\ncomputerised instrumentation\\nhardness\\nimage resolution\\nimage sensors\\nlearning (artificial intelligence)\\nmechanical variables measurement\\nrecurrent neural nets\\nshape measurement\\nshape-independent hardness estimation\\ndeep learning\\ngelsight tactile sensor\\nrobot hand\\ncontact condition control\\nobject shape control\\nsoft contact interface\\nhigh resolution tactile imaging\\ncontact geometry\\ncontact force\\nslip condition\\nhardness measurement\\ndeep constitutional recurrent neural network\\ndata analysis\",\"111\":\"light emitting diodes\\nreceivers\\ntactile sensors\\nphotodiodes\\nmanipulators\\noptical sensors\\ncontact localization\\nindentation depth prediction\\noptics-based tactile sensor\\noptic components\\nelastomer\\nlight emitters\\nlight receivers\\nrobot manipulators\",\"112\":\"robot sensing systems\\nforce\\nmagnetic hysteresis\\nsensitivity\\nforce sensors\\nhall effect\\nmagnetic sensors\\nmanipulators\\ntactile sensors\\nlow-cost 3-axis soft tactile sensors\\nhuman-friendly robot vizzy\\nmagnetic technology\\n3-axis hall-effect sensor\\nforce vector\\nobject manipulation\\nshear forces\",\"113\":\"wheels\\nmobile robots\\nnavigation\\ntires\\nconferences\\nservice robots\\nindustrial robots\\nlifting\\npath planning\\ntyres\\nsafe navigation\\ncooperative navigation\\ntire workshop assistant robot\\ntirebot\\ntire-workshop robotic coworker\\nwheels lifting\\nwheels transportation\",\"114\":\"collision avoidance\\nrobot sensing systems\\nforce\\nskin\\nrobot kinematics\\nhaptic interfaces\\nrobots\\nintentional contact concept\\nskin technology\\nrobotic systems\\nhierarchy policy\\ntactile feedback\",\"115\":\"robots\\nnoise measurement\\nspeech\\nmarkov processes\\nreal-time systems\\ncomputational modeling\\nnatural languages\\ndecision theory\\nhuman-robot interaction\\nmanipulators\\nobject-fetching interactions\\nsocial feedback\\nsocial robot\\nsignal extraction\\nitem-fetching domain\\nitem-delivery domain\\npartially observable markov decision process\\npomdp\",\"116\":\"robot kinematics\\ncollaboration\\nuncertainty\\nlegged locomotion\\nresource management\\nplanning\\ncognitive systems\\nhuman-robot interaction\\nindustrial robots\\nmanufacturing systems\\nproductivity\\nrole assignment\\ntask allocation\\nhuman robot collaboration\\ncollaborative robots\\nmanufacturing\\ncognitive load\",\"117\":\"legged locomotion\\nfoot\\npathology\\nmuscles\\nhip\\noptimization\\nexoskeletons\\ngait analysis\\nhuman-robot interaction\\nmedical robotics\\nneuromuscular stimulation\\noptimisation\\npatient rehabilitation\\ngait assistance\\nhip exoskeleton\\nankle pathologies\\nneuromuscular walking model\\ndynamic optimizations\\nhuman-exoskeleton interactive dynamics\\nfoot drop\\nplantarflexion failure\",\"118\":\"training\\nlegged locomotion\\nnavigation\\nmobile communication\\nmeters\\ngait analysis\\nmedical robotics\\nmobile robots\\npatient rehabilitation\\nmobile robot\\nwalking training\\nstroke patients\\nclinical post-stroke rehabilitation\\nself-training\\nassistive robots\",\"119\":\"training\\nrails\\ngames\\ntiming\\nrubber\\nmanipulators\\ndexterous manipulators\\ngraphical user interfaces\\nsport\\nblock machine development\\nvolleyball attack training\\nspike decision rate improvement\\nspike decision rates\\niterative spiking training\\noperating speed\\nmechanical strength\\nfive degree-of-freedom robot\\nvolleyball net\\ngraphical user interface\\nrobot manipulators\\nblock motion control\\nrobot positions\\nrobot operation timing\",\"120\":\"legged locomotion\\nactuators\\nplanning\\nfoot\\npayloads\\npath planning\\nmultilegged autonomous explorer\\nsix-legged robot\\nindoor environments\\noutdoor environments\\nmax design\\nmass-size ratio\\nlocomotion efficiency\\npayload capability\\nultralight legged robot control\\ngait planning\\nmotion planning\\nnavigation planning\\ncomplex 3d terrains\\nsystem performance\",\"121\":\"legged locomotion\\nreduced order systems\\nbelts\\nsprings\\nbiology\\nmodeling\\nlimit cycles\\nrobot dynamics\\ntrajectory control\\nspined sagittal-plane quadrupedal model\\nstable bounding\\nactively powered spine\\ninu quadrupedal robot\\nreduced-order model\\nactuated spine degree of freedom\\nmass center trajectory\\nbounding limit cycle\\nspine actuation\",\"122\":\"legged locomotion\\noptimization\\nrobot sensing systems\\nhardware\\nservomotors\\nfoot\\nclosed loop systems\\nevolutionary computation\\nhexapod controllers\\nlegged robots\\nevolutionary generations\\nperformance degradation\\nclosed-loop system\\nmultiobjective evolutionary algorithms\\nper-mission basis\\ninitial controller parameters\\nmotor wear\\nrobot mass distribution\",\"123\":\"legged locomotion\\nfasteners\\nfoot\\ncouplings\\nactuators\\nhip\\nadaptive systems\\nrobot kinematics\\nbetween-leg coupling schemes\\npassively-adaptive nonredundant legged robots\\nhighly actuated legged robots\\nfeet location\\nactive control\\nkinematics\\nground contact\\ncomplex redundant control\\nstable locomotion\\npassive sprung joints\\nminimal passive adaptability\\nterrain variability\\npractical travel limits\\n4-rr platform\\nparallel adaptive couplings\\nscrew theory-based mobility analysis methods\\nstance platform control\",\"124\":\"friction\\nforce\\ndynamics\\nlegged locomotion\\nsprings\\nlatches\\ndoors\\ndoor opening\\nstair climbing\\nlegged robot\\nquasi-static mismatch\\ndynamic mismatch\\nrobotic fitness notion\\nnecessary conditions\\nquasi-static maneuvers\\nminitaur quadrupedal platform\\ndynamical maneuvers\",\"125\":\"trajectory optimization\\nlegged locomotion\\nplanning\\nacceleration\\naerospace robotics\\nhelicopters\\npath planning\\nstability\\ntorque control\\ntrajectory optimisation (aerospace)\\nfoothold optimization\\nlow-dimensional models\\nrough terrain locomotion\\ncenter of mass motion\\nfoothold location\\ngait adaptability\\ntrunk attitude\\nguaranteed stability\\nparametric models\\nstochastic-based exploration\\nreceding horizon planning\\nlocal minima\\nterrain conditions\\nwalking patterns\\nrobust motion plans\\nhydraulic torque controlled quadruped robot\",\"126\":\"milling\\nbones\\nneurons\\nsurgery\\nmicrophones\\nrobot sensing systems\\nacoustic signal processing\\nbone\\nhearing\\nmanipulators\\nmedical robotics\\nmedical signal processing\\nself-organising feature maps\\nwavelet transforms\\nbiologically-inspired auditory perception\\nrobotic bone milling\\nhard tissue surgical procedures\\nhigh-speed rotating tool\\nhuman auditory system\\nmicrophone\\nrobot arm\\nbandpass filtering\\nrecorded sound pressure signal\\nwavelet packet transform\\nencoding and perception mechanisms\\nself-organizing feature map\\nmanhattan distances\\nwinning neurons\\nin vitro porcine spine milling\\nrobot-assisted milling surgery\",\"127\":\"actuators\\nforce\\nmathematical model\\nrobot sensing systems\\nstrain\\nstress\\nendoscopes\\nmanipulators\\nmedical robotics\\nshape memory effects\\nhigh-force high-stroke distal robotic add-on\\nendoscopy\\nsnap-on robotic modules\\nendoscopic equipment\\ndexterity\\nbilateral manipulation\\nfeedback sensing\\nclinical workflow\\noff-the-shelf actuators\\nsma actuators\\nhelical shape memory alloy\\nantagonistic configuration\\nphenomenological modeling\\ncontinuous mechanical coupling\\ncontrollable robotic wrist\\ntargeted fluid cooling\",\"128\":\"actuators\\nendoscopes\\nforce\\nstrain\\nfabrication\\ninstruments\\nlimiting\\nmanipulators\\nmedical robotics\\nstability\\nsurgery\\ndeployable stabilization mechanisms\\nendoscopic procedures\\nflexible endoscopes\\nnatural orifice translumenal endoscopic surgery\\nnotes\\ngi tract\\ndistal manipulation\\ndeployable endoscopic add-on\\nhybrid soft-folded design\\nsoft actuator\\nmagic cube origami structure\",\"129\":\"needles\\nbiopsy\\nstomach\\ncouplings\\nendoscopes\\nmagnetic forces\\nlesions\\nbiological tissues\\nbiomagnetism\\nelectromagnets\\nmagnetic sensors\\npermanent magnets\\nmagnetically actuated soft capsule endoscope\\nfine-needle aspiration biopsy\\nupper gastrointestinal tract\\nthin needle\\nhollow needle\\nsubsurface biopsy sample\\nsoft elastomer body\\ninternal permanent magnet\\nbiopsy needle\\nmultiple custom-designed electromagnet\\nmagnetic sensor array\\nswine tissue locomotion\\nswine tissue biopsy\\nanatomical human stomach model\",\"130\":\"prosthetics\\nthree-dimensional displays\\nlegged locomotion\\nsystematics\\ncontrol systems\\nsprings\\nenergy efficient 3d prosthetic walking\\npowered compliant transfemoral prosthesis\\nsystematic prosthetic control strategy\\n3d multicontact prosthetic walking\\nrealistic amputee-prosthesis system\\n3d asymmetric hybrid system model\\nformal gait design\\ncontrol construction\\ntwo-step direct collocation optimization\\nmulticontact prosthetic gait\\n3d capable powered transfemoral prosthetic device\\n3d prosthetic gaits\\ncompliant components\\nenergy saving\\nhuman-like behaviors\\nhardware design\",\"131\":\"needles\\nforce\\nbiopsy\\nhaptic interfaces\\nmagnetic resonance imaging\\nrobots\\nbiomedical mri\\nmedical robotics\\nradiology\\nrolling-diaphragm hydrostatic transmission\\nremote mr-guided needle insertion\\nmri\\nunsurpassed soft-tissue characterization\\niterative positioning\\nrobotic assistants\\nteleoperation technology\\npercutaneous procedures\\nradiologists\\nmr environment\\n1-dof needle insertion procedure\\nrolling diaphragms\\ncable-capstan drive\\nneedle teleoperation\\nlight membrane punctures\\nspring stiffnesses\\nhand manipulation\",\"132\":\"propulsion\\nmagnetic sensors\\nrobot sensing systems\\nactuators\\nrobot kinematics\\nclosed loop systems\\nendoscopes\\nhall effect devices\\nkalman filters\\nmagnetic actuators\\nmedical control systems\\nnonlinear filters\\nsimultaneous localization\\nlumen\\nsingle rotating magnet\\nclosed-loop propulsion\\nscrew-type magnetic capsule\\nembedded hall-effect sensors\\nsingle rotating actuator magnet\\nsix-degree-of-freedom pose\\nactive capsule endoscopy\\nintestines\\nextended kalman filter\\n2-dof process model\\nrotation speed\\nmagnetic coupling\\ndecoupled localization\",\"133\":\"shape\\nsolid modeling\\nribs\\npredictive models\\nintegrated circuit modeling\\nwires\\nthree-dimensional displays\\nclothing industry\\nvirtual paper model\\nthree piece brassiere cup\\ncup design process efficiency improvement\\npaper model\\nwire parts\\ncloth parts\\ngeometric constraints\",\"134\":\"fabrication\\nshape\\nthree-dimensional printing\\nmanipulators\\nfrequency division multiplexing\\nforming processes\\nrapid prototyping (industrial)\\nrobofdm\\nfused decomposition modeling\\nrobotic system\\nsupport-free fabrication\\n3d model fabrication\\n3d printing flexibility\\nrobotic arm\\nmaterial accumulation\\nextruder\\nmolten filament formation\\npolylactic acid\\npla\\nmodel decomposition computation\\nfreeform object printing\",\"135\":\"computational modeling\\nthree-dimensional displays\\nsolid modeling\\nprinters\\nfabrication\\nprinting\\ngreedy algorithms\\ninteger programming\\nlinear programming\\nrapid prototyping (industrial)\\nrelaxation theory\\nimproved toolpath generation algorithm\\nfused filament fabrication\\ngreedy algorithm\\ntoolpath optimality\\ninteger linear programming formulation\\nlinear programming relaxation\",\"136\":\"legged locomotion\\neducational robots\\nactuators\\nrobot kinematics\\nmorphology\\nkinematics\\ndesign engineering\\nrobot dynamics\\ninteractive iterative robot design\\nkinematic parameter\\ndynamic parameter\\ngeometric parameter\\nmanipulation function\\nlocomotion function\\nmultirigid body simulation\\nmorphological parameters\",\"137\":\"pins\\nlegged locomotion\\nlibraries\\nrobot kinematics\\nactuators\\ncontrol system synthesis\\nmobile robots\\nthree-dimensional printing\\ncomputational abstractions\\ninteractive design\\ncomputational design system\\ncustom robotic devices\\nmodular electromechanical components\\ndesign abstraction\\ncomplex robotic systems\\nvisual design environment\\nmounting brackets\\n3d-printable components\\ndesign auto-completion operations\\nrobotic device creation\\nrobot designs\\nlegged robotic devices\\nwheeled robotic devices\\n5-dof arm\\nquadrupedal robot\",\"138\":\"potentiometers\\nrobot sensing systems\\nsurface treatment\\npaints\\nplastics\\nmobile robots\\nposition measurement\\nposition sensing\\npaintpot manufacturing process\\nlow-cost-low-profile-highly customizable potentiometers\\nrobotic applications\\ncalibration process\\nsmores-ep modular robot\\nresistive surfaces\",\"139\":\"torque\\ntorque control\\ndamping\\naerodynamics\\nrobots\\nactuators\\nrobustness\\ncontrol system synthesis\\nfeedback\\nfeedforward\\nobservers\\npi control\\nrobot dynamics\\nrobust control\\nshock absorbers\\nvibration control\\njoint torque control capability\\nphysical damper\\nseries elastic actuator\\njoint torque tracking\\nstandard sea\\ntorque dynamics\\nphysical damping\\nrobust controller design\\ndisturbance observer technique\\ncontrol law\\nfeed-forward term\",\"140\":\"actuators\\nforce\\nsprings\\nmodulation\\nnegative feedback\\nload modeling\\nrobots\\ncompliant mechanisms\\ncontrol system synthesis\\nelastic constants\\nhuman-robot interaction\\nlegged locomotion\\nposition control\\nprosthetics\\npositive-negative stiffness actuator\\ncompliant actuators\\nrehabilitation\\nrobot locomotion\\nrobot-environment interaction\\nequilibrium position control\\njoint stiffness control\\nstiffness tunability\\nequilibrium point controllability\\nprototype prosthetic limb design\",\"141\":\"force\\npotential energy\\nactuators\\nmathematical model\\nmodulation\\nanalytical models\\nload modeling\\nelasticity\\nforce control\\nrobot kinematics\\nvariable stiffness mechanisms\\npotential energy function\\ninfinite range stiffness modulation\\nbounded motor forces\\nconstant motor force\",\"142\":\"springs\\ndamping\\nshock absorbers\\nactuators\\nrobots\\ntorque\\nforce\\nadaptive systems\\ncompliant mechanisms\\nelastic constants\\nelasticity\\nnonlinear systems\\nsliding motion\\nrolling motion\\ncam-follower mechanism\\nnon-linear damper\\nnon-linear stiffness compliant module\\npassive damping mechanisms\\nunder-damped vibration modes\\nrobotics actuators\\nintrinsic non-linear compliance\\nself-adaptive variable impedance actuator\",\"143\":\"impedance\\nforce\\ntorque\\npistons\\npneumatic systems\\ntendons\\nrobots\\ncascade control\\ncompliant mechanisms\\nfeedback\\nforce control\\nobservers\\npneumatic actuators\\nrobot dynamics\\ntorque control\\ntank based unified torque control\\npneumatically actuated antagonistic robot joint\\npneumatically cascaded structure\\ncylinder-based force controllers\\nvirtual tank\\ncontrol loop passivity\\nforce level\\nshaping function\\ntorque control operation\\nexternal torques\\nfeedback loop\\ncontact force regulation\\nmomentum observer\\nmaximum deflection\\nstep torque tracking\\nsinusoidal torque tracking\\ntank based unified impedance control\\ncompliance and impedance control\\nhydraulic\\/pneumatic actuators\\ntendon\\/wire mechanism\",\"144\":\"carbon\\nactuators\\ncouplings\\nchemical lasers\\nforce\\nfasteners\\ngeometry\\nmicromechanical devices\\npiezoelectric actuators\\ngeometrically-amplified in-plane piezoelectric actuator\\nmesoscale robotic systems\\npiezoelectric materials\\nelectromechanical transduction\\nintrinsic high force production\\nscaling characteristics\\nrobotic systems\\ndisplacement amplification\\npiezoelectric displacement\\npower density\\nprinted circuit mems\\nmesoscale manufacturing paradigm\\nterrestrial crawling robots\\nflapping wing micro-air vehicles\",\"145\":\"fabrics\\ngrasping\\nwrapping\\nreliability\\ncollision avoidance\\nmanipulators\\nindustrial manipulators\\nmotion control\\nwrapping-with-fabric task\\nregrasping\\nmotion planning\\noffhand paths\\ngrasping point movement\\nrobot motion\\ncollisions\\ninter-hand passing motions\\nintra-hand passing motions\\nmovement reliability\\ndual-arm robot\",\"146\":\"planning\\nestimation\\nhumanoid robots\\nrobot sensing systems\\nreal-time systems\\nfeedback\\nmobile robots\\npath planning\\nsensors\\nonline estimation\\nobject-environment constraints\\nhumanoid motion planning\\nmulticontact motion\\nmotion on a movable object\\nhumanoid momo\\nmass properties\\nbalance constraints\\nrobot constraints\\nreal-time sensor feedback controller\\nlife-sized humanoid robot\",\"147\":\"roads\\nrobots\\ntime complexity\\nmeetings\\npublic transportation\\noptimization\\nformal logic\\ngraph theory\\nmulti-agent systems\\nmulti-robot systems\\ngeneral formal framework\\nmultiagent meeting problems\\nmam\\nmeeting location\\nmultiple heterogeneous agents\\ntransportation modes\\ngraph problem\\nformal method\\nlogic-based ai methods\\nartificial benchmarks\\nistanbul map\\nhong kong map\",\"148\":\"unmanned aerial vehicles\\nforce\\nmanipulator dynamics\\ntorque\\nrobot kinematics\\naerospace robotics\\nforce control\\ngrippers\\nhelicopters\\nmulti-robot systems\\nnonlinear control systems\\nobservers\\noptimal control\\ntorque control\\ntrajectory control\\nheterogeneous multirobot\\nmultiple aerial-ground manipulator systems\\nrobotic magmas\\naerial robots\\ngripper manipulator\\nphysical strength\\nlarge workspace\\ndynamic model\\ncharacteristic structure\\ndynamical structure\\nnonlinear control scheme\\ndisturbance observer\\ntrajectory tracking\\nsystem redundancy\\noptimal force-torque allocation\\nheterogeneous system constraints\\nforce manipulability\\nforce manipulability ellipsoid\\nheterogeneous robotic system\\nprototypical mechanical design\\npreliminary experimental evaluation\\nkuka lwr4\\nquadrotor based aerial robot\",\"149\":\"planning\\nrobots\\nlabeling\\ncomputational modeling\\ntraining\\npredictive models\\nintelligent robots\\nlearning (artificial intelligence)\\nrandom processes\\nrobot programming\\nplan explicability\\nplan predictability\\nrobot task planning\\nintelligent machines\\nhuman safety risks\\nhuman-robot interaction\\nlabeling process\\ntraining examples\\nconditional random fields\\ncrfs\",\"150\":\"robot sensing systems\\nplanning\\ntrajectory\\ncollision avoidance\\nproduction\\nmobile robots\\nmulti-robot systems\\npath planning\\noptimal path planning\\ncoverage control\\nmultirobot persistent coverage\\nfast marching methods\\ncoverage quality\\ndynamic window navigation\",\"151\":\"planning\\napproximation algorithms\\ntrajectory\\nfunction approximation\\nnonlinear systems\\noptimal control\\nautomata\\ncontinuous systems\\ncontrol engineering computing\\ndiscrete systems\\nformal specification\\nlinear systems\\nmobile robots\\nnonlinear control systems\\npath planning\\nsampling methods\\ntemporal logic\\napproximate optimal temporal logic planning\\ntemporal logic constraints\\nimportance sampling\\nformal methods\\nlinear temporal logic\\nhybrid system\\nmodel reference adaptive search\\noptimization algorithm\\nformal logic specifications\\nlinear system\\nnonlinear mobile robot\",\"152\":\"thumb\\nactuators\\ngrippers\\nrobot kinematics\\ngeometry\\nend effectors\\nmanipulator dynamics\\nstability\\nwhole-hand caging manipulation\\nunderactuated hands\\nhuman in-hand dexterity\\nrobotic manipulation\\nwell-controlled motions\\ncontact points\\ngrasp stability\\ncomplex within-hand manipulation motions\\nhand frame\\nhand-object system configuration space\\nmanipulation primitives\\nhand workspace\\ntwo-finger underactuated gripper\\nyale openhand\\ndexterous manipulation\\ncaging\\nwhole-hand manipulation\\nopen-loop\",\"153\":\"roads\\nthree-dimensional displays\\nlaser radar\\nhazards\\ntwo dimensional displays\\nhistograms\\nlasers\\nimage classification\\nimage representation\\nobject detection\\noptical radar\\nradar detection\\nradar imaging\\nroad vehicle radar\\nroad detection\\nobstacle detection\\nwater hazards\\nautonomous driving vehicles\\nlidar point cloud\\nlidar-imagery\\n3d point cloud\\nlidar-specific 2d coordinate system\\nlidar-histogram representation\\n3d traversable road plane\\nlinear classification task\\n2d space\",\"154\":\"training\\ndata models\\nneural networks\\nprobabilistic logic\\nbayes methods\\nsemantics\\nstochastic processes\\ncomputer vision\\nimage retrieval\\nlearning (artificial intelligence)\\nsemi-supervised vision-language mapping\\nvariational learning\\nrobotic systems\\nartificial intelligence\\nsentence cross-modal retrieval\\nbayes framework\\nimage-sentence mapping task\\ntwo-level variational embedding structure\\nunpaired data\",\"155\":\"three-dimensional displays\\nconvolution\\ntwo dimensional displays\\nobject detection\\nrobots\\nneural networks\\nbenchmark testing\\nimage filtering\\nneural nets\\nstereo image processing\\n3d point clouds\\nconvolutional neural networks\\ncnns\\nfeature-centric voting scheme\\nl1 penalty\\nfilter activations\\nsparse convolutional layers\\nl1 regularisation\\nlarge-scale processing\\n3d data\\nkitti object detection benchmark\\nvote3deep models\",\"156\":\"solid modeling\\ndatabases\\nthree-dimensional displays\\nmachine learning\\nfeature extraction\\nprotocols\\nneural networks\\ndata analysis\\ndatabase management systems\\nimage colour analysis\\nimage texture\\nlearning (artificial intelligence)\\nneural nets\\nrobot vision\\ndepth images\\nsynthetic data\\nconvolutional neural networks\\nrgb databases\\ncnn\\nrgb-d data\\ncolorization techniques\\n2d images\\ndata collection\\ndepth database\\nsynthetic images\\nvisual data\\n2d datasets\",\"157\":\"training\\nneural networks\\ncomputer architecture\\nagriculture\\nmachine learning\\nmicroprocessors\\nkernel\\ndistance measurement\\nimage classification\\nimage sequences\\nintelligent transportation systems\\nlearning (artificial intelligence)\\nmotion estimation\\nneural nets\\nobject detection\\nstereo image processing\\nvideo signal processing\\ndeep learning\\ntraffic light detection\\ntraffic light classification\\ntraffic light tracking\\nautomated driving\\nreal-time traffic light perception\\nsmooth urban driving\\nstereo vision\\nvehicle odometry\\nlabeled traffic light dataset\\nvideo sequence\\nbosch small traffic lights dataset\\nconfidence threshold selection\\nneural network\",\"158\":\"cameras\\nimage reconstruction\\nthree-dimensional displays\\nrobot vision systems\\ntwo dimensional displays\\nactive vision\\nimage classification\\nimage colour analysis\\nindoor environment\\nlearning (artificial intelligence)\\nneural nets\\nobject detection\\nrobot vision\\nrobotic vision\\nindoor environments\\nrgb-d images\\n2d bounding boxes\\nobject category detector\\ninstance detection\\ndeep-network-based system\\nobject classification\\nreinforcement learning\",\"159\":\"three-dimensional displays\\ncameras\\nsolid modeling\\nmachine vision\\nrobot vision systems\\nconvolution\\nimage colour analysis\\nimage segmentation\\nlearning (artificial intelligence)\\nobject recognition\\npose estimation\\nrobot vision\\nwarehouse automation\\nmulti-view self-supervised deep learning\\n6d pose estimation\\namazon picking challenge\\nrobot warehouse automation\\nautonomous warehouse pick-and-place system\\nrobust vision\\nmultiview rgb-d data\\nself-supervised learning\\ndata-driven learning\\nmit-princeton team system\\nstowing tasks\\npicking tasks\\nconvolutional neural network\\n3d object models\\n6d object pose segmentation\\ndeep neural network training\",\"160\":\"roads\\nimage segmentation\\nsemantics\\ntraining\\nnoise measurement\\nconvolution\\nmachine learning\\nimage annotation\\nimage colour analysis\\nlearning (artificial intelligence)\\nneural nets\\nstereo image processing\\ntraffic engineering computing\\nself-paced cross-modality transfer learning\\nroad segmentation\\nautonomous driving\\nconvolutional neural networks\\nstereo images\\nfree-space detection\\ndepth modality\\nsingle rgb modality\\nself-paced cnn learning\\nannotated images\\nkitti road benchmark\",\"161\":\"quality of service\\nmeasurement\\nprediction algorithms\\nschedules\\npredictive models\\ncost function\\nartificial neural networks\\ncustomer satisfaction\\nmobile robots\\nposition control\\nroad vehicles\\nquality of service ridesharing\\ncampus mobility\\ndemand systems\\nautonomous mobility on demand\\nfleet management strategies\\ncustomer quality of service\\nautonomous mod systems\\nsingle capacity vehicles\\nlarge fleet sizing\\npredictive positioning method\\ncustomer wait time minimization\\ncustomer qos\\ncustomer ratings model\\ncustomer preference learning\\ncampus mod system\",\"162\":\"merging\\nurban areas\\ndetectors\\nroads\\nvehicle detection\\ncomputer architecture\\nautomobiles\\nbelief networks\\nlearning (artificial intelligence)\\nremotely operated vehicles\\nroad traffic control\\nrobot vision\\nstatistical analysis\\nstereo image processing\\nhuman-like lane following behavior\\nurban environment\\nlearning-based behavior-induction potential map\\nautonomous vehicles\\nvision-based approach\\nvehicle hypothesis\\nimage evidence\\nstatistical support\\nbayesian network\\nurban traffic scenes\",\"163\":\"robot sensing systems\\nroads\\nsemantics\\nglobal positioning system\\nplanning\\nmarkov processes\\nmobile robots\\nmonte carlo methods\\npath planning\\nprobability\\nglobal outer-urban navigation\\nopenstreetmap\\nmap services\\nroad network data\\nautonomous navigation\\nprobabilistic approach\\nautonomous robot navigation\\n3d-lidar data\\nsemantic terrain information\\nmarkov-chain monte-carlo technique\\nsensor data\\nnavigation planning\",\"164\":\"robustness\\ncost function\\ncameras\\nvisualization\\nhistograms\\nminimization\\nprobabilistic logic\\ngamma distribution\\nmotion estimation\\nprobability\\nstereo image processing\\ngamma distributions\\npoint-based stereo visual odometry systems\\ncamera motion\\nerror distribution\",\"165\":\"current measurement\\noptimization\\njacobian matrices\\nquaternions\\ncameras\\nvisualization\\natmospheric measurements\\ngraph theory\\nimage fusion\\ninertial navigation\\npose estimation\\nslam (robots)\\ndirect visual-inertial navigation\\nanalytical preintegration\\ncamera affordability\\ninertial measurement units\\npreintegrated inertial measurement fusion\\nimage alignment\\nclosed-form solutions\\ncontinuous-time imu kinematic model\\nbias jacobians\\ngraph-based methods\\npose constraints\\nslam\\nsimultaneous localization and mapping\",\"166\":\"trajectory\\ngaussian processes\\nautomobiles\\nroads\\nentropy\\nlearning (artificial intelligence)\\nlearning systems\\nmaximum entropy methods\\npath planning\\nroad traffic control\\nroad vehicles\\ntrajectory control\\nlearning-based framework\\nurban automated driving\\nautomated vehicles\\nurban environments\\nmaximum entropy inverse reinforcement learning\\ngaussian process\\nseoul national university\\ntrajectory planning\",\"167\":\"software\\nautonomous vehicles\\nrobustness\\nfault detection\\nsoftware testing\\ncontrol engineering computing\\nfault diagnosis\\npattern clustering\\nrobust control\\nstate-space methods\\nvehicles\\nautomated generation\\nblack box autonomous system\\nsystem requirements\\nstate space\\nunsupervised clustering\",\"168\":\"robot sensing systems\\nrobot kinematics\\nbuildings\\ncollision avoidance\\nmeasurement\\ndistributed algorithms\\ngraph theory\\nmulti-robot systems\\ndistributed algorithm\\ngraphical structure\\ncomplex environments\\nrobot swarm\\nmultirobot mapping algorithm\\nmultiple disjoint subregions\\ncave network\\ndisk graph representation\",\"169\":\"cameras\\nrobot vision systems\\nrobot kinematics\\nmaintenance engineering\\nautonomous aerial vehicles\\ndecentralised control\\ndirection-of-arrival estimation\\nhelicopters\\nmatrix algebra\\nmobile robots\\nmulti-robot systems\\nposition control\\nrobot vision\\nbearing rigidity maintenance\\nquadrotor uav formation\\nformation control\\nonboard camera\\nsensing constraint\\ncamera field of view\\nocclusion\\ndecentralized gradient-based control action\\ndegree of infinitesimal rigidity\\nspectral properties\\nbearing rigidity matrix\",\"170\":\"robot kinematics\\nmobile robots\\ncameras\\nrobot sensing systems\\nhardware\\nsoftware\\napplication program interfaces\\ncontrol engineering computing\\ncontrol engineering education\\neducational robots\\nmulti-robot systems\\npath planning\\nsoftware architecture\\nthree-dimensional printing\\nportable 3d-printing enabled multivehicle platform\\nrobotics research and education\\nopen source microscale mobile robot platform\\nmicrovehicles\\ntracking platform\\nhardware architecture\\nmicromvp api\\nmultirobot path planning algorithms\\nsingle-robot motion planning algorithms\\nmultirobot motion planning algorithms\",\"171\":\"roads\\nplanning\\nvehicle dynamics\\nsensors\\nlabeling\\nrouting\\npath planning\\nroad vehicles\\nvehicle routing\\nminimum-violation scltl motion planning\\nmobility-on-demand\\nminimum-violation trajectory\\nrrt*-based motion planner\\nperiodically interacting routing algorithm\\nreceding horizon approach\\nscltl formulas\\nroad rules\\ncustomer demands\\nroad network\\nautonomous vehicle\\nintegrated routing\",\"172\":\"robot sensing systems\\nthree-dimensional displays\\nrobot kinematics\\nlattices\\nhardware\\naggregates\\ndecentralised control\\ndistributed control\\nmulti-robot systems\\ndistributed aggregation\\ndistributed control strategy\\nmultiple modular robots\\n3d modular pivoting cube robots\\ndecentralized control algorithm\\ngeneric modular robots\\n3d m-blocks platform\",\"173\":\"cameras\\nroads\\nrobot sensing systems\\nimage color analysis\\neducation\\nlighting\\ncalibration\\ncollision avoidance\\ncontrol engineering education\\neducational robots\\nmobile robots\\npedestrians\\nrobot vision\\nslam (robots)\\nopen platform\\nflexible platform\\nautonomy education and research\\ninexpensive platform\\nautonomous vehicles\\nduckiebots\\noff-the-shelf components\\ntransportation\\nduckietown platform\\nmonocular camera\\nraspberry pi 2\\nlane following\\nobstacle avoidance\\nglobal map\",\"174\":\"robot sensing systems\\nrobot kinematics\\ncollision avoidance\\nmulti-robot systems\\ntopology\\ndecentralised control\\ngraph theory\\nnetworked control systems\\ndecentralized coordinated motion\\ninterrobot collision avoidance\\nnetworked robots\\nnetwork communication connectivity\\ndecentralized online behavior-based algorithm\\nmultirobot communication\\nsensing graphs\\ncommunication graph\\nforward motion\",\"175\":\"null space\\nrobots\\nredundancy\\nmeasurement\\nlearning systems\\ncomputational modeling\\nmathematical model\\nmanipulators\\ngeneric null space policies\\nlearning from demonstrations\\nmovement policy\\nlow-dimensional scenarios\\nconstraint learning method\\npolicy learning method\\ncomplex motions\\ncomplex surface wiping policy\\n7-dof robotic arm\",\"176\":\"navigation\\ncollision avoidance\\nrobot sensing systems\\nplanning\\ntraining\\ndata mining\\nlearning systems\\nmobile robots\\nneurocontrollers\\npath planning\\nposition control\\nperception\\ndecision\\ndata-driven approach\\nend-to-end motion planning\\nautonomous ground robots\\nlearning from demonstration\\nraw 2d-laser range findings\\ntarget position\\nrobot steering command\\ntarget-oriented end-to-end navigation model learning\\nrobotic platform\\nsupervised model training\\nexpert demonstration\\nsafe navigation\\nobstacle-cluttered environment\\nneural network-based motion planner\\ngrid-based global approach comparison\",\"177\":\"hidden markov models\\nsupervisory control\\nmanipulators\\nadaptation models\\nbayes methods\\nprobabilistic logic\\nautonomous underwater vehicles\\nlearning (artificial intelligence)\\nmarkov processes\\nmotion control\\noptimal control\\npredictive control\\ntelerobotics\\nsupervisory teleoperation\\nonline learning\\nmanipulation tasks\\nunderwater remotely operated vehicles\\nrov\\nonline bayesian nonparametric learning algorithm\\nmanipulation motions\\ntask-parametrized hidden semi-markov models\\ntp-hsmm\\nprobabilistic representation\\nmodel predictive control\\nmpc\\nreceding horizon fashion\\nremote system\\nhigh-frequency control loop\\nhot-stabbing motion\\nunderwater teleoperation scenario\\ndynamically changing task conditions\",\"178\":\"cost function\\nplanning\\nlearning (artificial intelligence)\\nmobile robots\\ntrajectory\\npath planning\\ntelerobotics\\ntrees (mathematics)\\ninverse reinforcement learning\\nrapidly exploring learning trees\\nrlt*\\noptimal rapidly exploring random trees\\noptimal rrt*\\nmaximum margin planning\\nrrt* cost functions\\ncaching scheme\\ncomputational cost reduction\\nreal-robot data\\nsocial navigation scenario\\ncontrol policies\\ntelepresence robot\",\"179\":\"vibrations\\nrobot sensing systems\\nshape\\nenergy exchange\\ntorque\\ntools\\nend effectors\\nmanipulator dynamics\\ntrajectory control\\nautomatic optimization\\nenergy transfer\\ntool-held hitting tasks\\nvibrational dynamics\\ntool vibrations\\nneuroscience\\nend-effector-held bat\\nend-effector torque\\nrobotic baseball hitter\\nswing trajectory\\ndlr lwr iii manipulator\\nend effector position\\ntorque sensors\",\"180\":\"bayes methods\\nrobots\\nlearning (artificial intelligence)\\nentropy\\ncost function\\nkernel\\ncontrol engineering computing\\noptimisation\\nsimulation\\nsimulations\\nreinforcement learning\\nbayesian optimization\\ncontrol policies\\nrobotic platforms\\nentropy search\\ninformation sources\\ncart-pole system\",\"181\":\"grasping\\ncomputational modeling\\nrobots\\nshape\\nsolid modeling\\nmathematical model\\nellipsoids\\nhumanoid robots\\nnonlinear programming\\npose estimation\\nrobot vision\\nsoftware packages\\nstereo image processing\\nsuperquadric models\\ngrasping problem\\nsuperquadric functions\\nstereo vision\\nreal-time computation\\npose computation\\nnonlinear constrained optimization problem\\nipopt software package\\nicub humanoid robot\",\"182\":\"robot sensing systems\\ngrippers\\nforce\\nfriction\\nforce measurement\\ngrasping\\nforce control\\ngeometry\\nlinear systems\\nmanipulators\\ntactile sensors\\nlinear control\\nrotational slippage\\nsix-axis force\\/tactile sensor\\nin-hand manipulation\\nrobotic manipulation\\nparallel gripper\\nslipping avoidance\\ncontact force\\ncontact geometry\\nkuka iiwa\",\"183\":\"measurement\\nforce\\nfriction\\ngrasping\\nellipsoids\\nrobot sensing systems\\ncomputational modeling\\ndexterous manipulators\\nforce control\\ngrasp quality evaluation\\ncontact force\\nwrench-based quality metrics\\ngrasp planning\\ngrasp success prediction\\ngrasping device\",\"184\":\"grasping\\ntraining\\nrobustness\\nrobot sensing systems\\nlearning (artificial intelligence)\\nmanipulators\\nrobot vision\\nsupervision\\ndata-driven learning\\nrobot adversaries\\nlearning tasks\\nself-supervised paradigm\\nadversarial learning framework\\nrobot learning\\nadversarial framework forces\\ngrasping model\",\"185\":\"robot sensing systems\\nvisualization\\ngrasping\\nplanning\\ndata collection\\ngrippers\\nrobot vision\\ntactile sensors\\nhybrid deep architecture\\nrobotic grasp detection\\nvisual sensing\\ntactile sensing\",\"186\":\"cloud computing\\nrobot kinematics\\nrobustness\\nplanning\\nmeasurement\\nautomation\\ncontrol engineering computing\\ndexterous manipulators\\nperturbation techniques\\nsoftware maintenance\\nstochastic processes\\ncloud robot system\\ndexterity network\\nberkeley robotics and automation as a service\\nbrass\\nraaas frameworks\\nsoftware development complexity\\nsoftware installation\\ndata sharing\\nmachine learning\\nrobust grasp-planning system\\ndex-net 1.0\\n3d object meshes\\nperturbation sampling\\nstochastic robustness metric\\ngrasp recommendations\",\"187\":\"random access memory\\nrobot sensing systems\\ntraining\\nneural networks\\nvisualization\\nmathematical model\\nhuman-robot interaction\\nlearning (artificial intelligence)\\nneural nets\\nhuman-robot social interaction\\nneural attention q-network\\nperceivable responsive behaviors\\ninteraction based learning\\nend-to-end reinforcement learning approach\\nmdarqn\\nhit-and-trial method\\nrobot interaction experiences\\nhuman-like social interaction skills\\nmultimodal deep attention recurrent q-network\\ncomplex human behaviors\",\"188\":\"estimation\\niris\\ncalibration\\nthree-dimensional displays\\nsolid modeling\\nhead\\nvisualization\\nconvolution\\ngaze tracking\\ngradient methods\\niris recognition\\ntwo-eye model-based gaze estimation\\nkinect sensor\\nfree head movement tolerance\\nconvolution-based gradients method\\niris center localization\\ncalibration method\\nkappa angles\",\"189\":\"robot kinematics\\nservice robots\\ntools\\nshape\\nlight emitting diodes\\nsoftware\\nhuman-robot interaction\\npublic domain software\\nmodlight\\nmodular light signaling tool\\nsignaling mechanisms\\nlight configurations\\nsignal designs\\nmodular research tool\\nopen-source software tools\\ndesign rationale\",\"190\":\"microphone arrays\\nthree-dimensional displays\\ndirection-of-arrival estimation\\nrobot sensing systems\\nestimation\\nsensor arrays\\nacoustic generators\\naudio signal processing\\noptimisation\\nreal-time 3d sound sources mapping\\nlinear microphone arrays\\noff-the-shelf robotic perception sensor\\nsound sources location\\nmulti hypotheses tracking\\ndirection of arrival observation\",\"191\":\"grammar\\nrobots\\nvideos\\nhuman-robot interaction\\nspatiotemporal phenomena\\ngrounding\\nreal-time systems\\ngraph theory\\nhumanoid robots\\ninference mechanisms\\nlearning (artificial intelligence)\\nvideo signal processing\\nsocial affordance grammar learning\\nhuman interactions\\nhuman-robot interactions\\nhri\\nspatiotemporal and-or graph\\nst-aog\\nhumanoid grammar\\nreal-time motion inference\\ngibbs sampling\\nweakly supervised grammar learning\\ninteraction hierarchical representation\\nrgb-d video dataset\\nbaxter simulation\\nhuman evaluation\\nreal baxter test\\nhuman-like behavior generation\",\"192\":\"robots\\nemotion recognition\\nlogic gates\\nrecurrent neural networks\\nsensors\\nmachine learning\\nsupport vector machines\\naffective computing\\nhuman-robot interaction\\ninference mechanisms\\nintelligent robots\\nlearning (artificial intelligence)\\nrecurrent neural nets\\nemotional intelligence\\nhuman emotion recognition\\ndaily-life gestures\\nrobotic systems\\nartificial systems\\nautomatic emotional clue inference\\nnonstylized motions\\nbehavioural programming\",\"193\":\"trajectory\\nrobots\\ncollision avoidance\\npredictive models\\nnavigation\\ndata models\\nuncertainty\\nhuman-robot interaction\\ncooperative navigation\\ndense human crowds\\nsocially compliant fashion\\nhuman-human interactions\\nhuman-robot interactions\",\"194\":\"robot kinematics\\ncollision avoidance\\nrobot sensing systems\\nhardware\\nsafety\\nservers\\nmobile robots\\nmulti-robot systems\\ntelerobotics\\nrobotarium\\nremotely accessible swarm robotics research testbed\\nmultirobot research facility\\nresource constraints\\nmultirobot test facility\\ncomplex hardware\\ndesign phase\\ncoordinated control programs\\nminimally invasive safety routines\\nperformance guarantees\",\"195\":\"wires\\nsteel\\nconcrete\\nservice robots\\nfabrication\\nthree-dimensional displays\\narchitecture\\nconstruction industry\\nend effectors\\nindustrial manipulators\\nmobile robots\\nnet structures (mechanical)\\nreinforced concrete\\nrobotic end-effector\\nnonstandard concrete applications\\narchitectural processes\\nsteel reinforced concrete structure\\nrobotic fabrication process\\nsteel wire meshes\\nmobile robotic system\\nnonstandard steel reinforced steel meshes\",\"196\":\"robots\\nheuristic algorithms\\ntrajectory\\nlearning (artificial intelligence)\\ncost function\\noptimal control\\ncontrol engineering computing\\ninformation theory\\nmobile robots\\nmultilayer perceptrons\\nnonlinear dynamical systems\\npredictive control\\ninformation theoretic model predictive control\\ninformation theoretic mpc\\nmodel-based reinforcement learning\\nnonlinear dynamics\\nmultilayer neural networks\\ndynamics models\\ncart-pole swing up\\nquadrotor navigation\",\"197\":\"semantics\\nsimultaneous localization and mapping\\noptimization\\nmeasurement\\nfeature extraction\\nobject recognition\\noptimisation\\npose estimation\\nsensor fusion\\nslam (robots)\\nprobabilistic data association\\nsemantic slam\\nsimultaneous localization-and-mapping\\nlow-level geometric features\\nview-independent unambiguous loop closure recognition\\noptimization problem\\nsemantic landmark positions\\nsemantic information\\ndiscrete data association\\nlandmark class probabilities\\nrobot-landmark pose optimization\\nindoor datasets\\noutdoor datasets\",\"198\":\"dynamics\\nrobot kinematics\\nestimation\\nkinematics\\nmanipulator dynamics\\nrobot motion\\nhuman-robot interaction\\nmanipulators\\nmotion tracking\\npartial grasp matrix\\nleast square error\\nparameter identification\\nhuman motion intention recognition\\nrobot wrenches\\nhuman-robot manipulation tasks\\nunknown object dynamics\",\"199\":\"measurement\\nimaging\\naerospace electronics\\nprobes\\nrobot sensing systems\\nimage quality\\nbiological tissues\\nbiomechanics\\nbiomedical optical imaging\\ncontrollers\\ndeformation\\nendoscopes\\nlearning (artificial intelligence)\\nmedical image processing\\nmedical robotics\\noptical microscopy\\nsurgery\\nsensorless probe-tissue contact management\\nautonomous probe-tissue contact management\\nrobotic endomicroscopic scanning\\noptical imaging\\nprobe-based confocal laser endomicroscopy\\nreal-time cellular level information\\nin-vivo tissue characterization\\nlarge area coverage\\nlimited field-of-view\\nimage stream\\noptimal working range\\ncontact force\\ntissue deformation\\nrobotic manipulation\\nhaptic feedback\\nsurgical robot systems\\nclinical adoption\\nquantitative measure representative\\ncontroller\\nmodel-free reinforcement learning\\nendomicroscopy scanning procedures\",\"200\":\"robots\\nneedles\\npneumatic systems\\nmagnetic resonance imaging\\npistons\\nbiopsy\\nkinematics\\nbiomedical mri\\nend effectors\\nmedical robotics\\npatient diagnosis\\nstormram 2\\nmri-compatible robotic system\\npvc breast phantoms\\nfish oil capsules\\nmri scanner\\nend-effector\\nrobotic system\\nmri-guided breast biopsies\",\"201\":\"pins\\ntools\\nbones\\nsurgery\\nthree-dimensional displays\\nrobots\\nsolid modeling\\nmedical robotics\\ncomputer-assisted robotic system\\nminimally invasive joint fracture surgery\\npre-operative imaging\\nintra-operative imaging\\nminimally invasive robotic assistance\\nimage-guidance\\nrafs surgical system\\n3d navigation system\\nclinical workflow\\noperating theatre\\nlaboratory trials\\npreliminary cadaveric trials\\ndistal femur fracture\\ncadaveric specimen\\nreduction accuracy\\njoint fracture surgeries\",\"202\":\"mouth\\nelectroencephalography\\ntracking\\ncameras\\nrobot vision systems\\ncontainers\\nassisted living\\nend effectors\\nhuman factors\\nhuman-robot interaction\\nmedical robotics\\nobject detection\\nobject recognition\\nobject tracking\\npose estimation\\nrobot vision\\nvisual evoked potentials\\neeg-controlled meal assistance robot\\ncamera-based automatic mouth position tracking\\nmouth open detection\\nassistive device\\nupper limb functions\\nself-feeding\\nelectroencephalography signals\\nsolid food item\\nflickering led matrices\\nuser intentions\\nsteady state visual evoked potentials\\nssvep-based intention detection method\\nmotion commands\\nautomatic mouth position detection\\nend effector\\nmouth closed recognition method\\nmouth open recognition method\",\"203\":\"endoscopes\\nelectron tubes\\nmanipulators\\nglass\\nsteel\\nmedical robotics\\nshape\\ncompliance control\\npolymers\\nstainless steel\\nsurgery\\nactive variable stiffness manipulators\\nsurgical robots\\nnatural orifices\\nthermoplastic material\\npolyethylene terephthalate\\npet\\nflexible stainless steel sheath\\nheating solution\\ntendon-driven manipulator\\ncompliant mode\\ncable actuation\",\"204\":\"exoskeletons\\nlegged locomotion\\nknee\\nthigh\\nread only memory\\nhip\\ngravity\\ngait analysis\\npatient rehabilitation\\nprosthetics\\nexoskeleton weight\\nhuman walking\\ngait rehabilitation\\ngait training\\nexoskeleton inertia\\nlight-weight leg exoskeleton\\nc-alex\\nknee flexion\",\"205\":\"welding\\nground penetrating radar\\ndata models\\npredictive models\\nprocess control\\nreal-time systems\\ngaussian processes\\narc welding\\nbayes methods\\nnonparametric statistics\\noptimisation\\nparameter estimation\\nregression analysis\\nwelds\\nreal time welding parameter prediction\\nreal time control algorithms\\nweld quality\\nreal time parameter optimization method\\ngaussian process regression\\nnon-parametric modelling technique\\ngpr surrogated bayesian optimization algorithm\\ngprboa\\nupper confidence bound acquisition functions\\nlower confidence bound acquisition functions\\nlcb acquisition functions\\nucb acquisition function\\ngas tungsten arc welding experiments\\nweld bead geometry prediction\\nreal time parameter tuning\\ncontrol algorithm\",\"206\":\"pulleys\\nbelts\\nservice robots\\nindustries\\npropagation losses\\ngears\\nhaptic interfaces\\nhuman-robot interaction\\npower transmission (mechanical)\\nrobot dynamics\\nultra-compact infinitely variable transmission\\nivt\\ncontinuously variable transmissions\\ncvt\\nenergy savings\\npower bursts\\nmechanical energy conversion applications\\nsystem efficiency\\nhuman-safe robotics\\nhaptic feedback systems\",\"207\":\"torque\\ntracking\\nfriction\\nmathematical model\\ntransfer functions\\nrobot sensing systems\\ncontrol system synthesis\\nhuman-robot interaction\\nmanipulator dynamics\\nposition control\\nstate feedback\\ntorque control\\nkuka lbr iiwa control\\ninteractive tracking\\nkuka fast robot interface\\nkuka fri\\ntracking controller design\\nlightweight robot\\nsmooth link position tracking\\nhuman interaction task\\nlow-level series elastic dynamics\\ninternal torque control structure\\noptical motion capture system\\nindependent external reference measurement\\nfull state feedback\\nmotor position\\njoint torque sensing\\nsystem dynamics\",\"208\":\"robot sensing systems\\nprognostics and health management\\nservice robots\\nrobot kinematics\\nmonitoring\\nmaintenance engineering\\ncalibration\\nindustrial robots\\npositional health assessment\\nindustrial robot\\nphm\\nrobot calibration\\nrobot performance\\nperformance metrics\\nhealth assessment methodology\\nposition accuracy\\norientation accuracy\\nnational institute of standards and technology\\nnist\\nrobot system reliability\",\"209\":\"conferences\\nautomation\\nend effectors\\nforce feedback\\ngeometry\\nindustrial manipulators\\npainting\\npath planning\\nspraying\\nsurface treatment\\nautomatic robot taping\\nplasma spraying\\nspray painting\\nautomatic agile robotic system\\n3d model reconstruction\\nend-effector\\nrobot manipulator\\nsurface covering method\",\"210\":\"actuators\\nforce\\nmuscles\\nrobots\\nprototypes\\nwires\\nstrain\\nalloys\\nbiomimetics\\nelectroactive polymer actuators\\npneumatic actuators\\nshape memory effects\\nbiomimetic robotic joint mechanism\\nsoft linear actuators\\nartificial muscle actuator\\nsliding filament mechanism\\nskeletal muscle contraction\\nshape memory alloy wires\\n3d printed mechanical parts\",\"211\":\"actuators\\nliquids\\nheating systems\\nrobot sensing systems\\nfabrication\\ntime factors\\nelectric actuators\\nrobots\\nelectric phase-change actuators\\ninkjet printed flexible circuit\\nprintable robot prototyping\\nintegrated robot prototyping\\nbody structures\\nsensors\\nelectronic circuits\\nrobot system\\nrobotics\\nliquid-to-gas phase change\\nprintable fluidic actuator\\ninkjet printed electric heater\\norigami robots\\nelectro-fluidic conversion\\nshape-shifting origami structure\\nrobot gripper\\nprinted touch sensor\",\"212\":\"manipulators\\nmeasurement\\noptimization\\ngenetic algorithms\\nrobot sensing systems\\nrobot kinematics\\nmultiobjective design optimization\\npneumatic robot\\ninflatable robot\\nmultiobjective fitness function\\nload-bearing capacity\\ninflatable manipulators\\nmultiobjective optimization\\ngenetic algorithm\\npareto front spanning\\nsoft robot technologies\\ndesign optimization\\nmobile robots\\nsoft robots\",\"213\":\"torque\\ngears\\nimpedance\\nrobots\\nsprings\\ncontrollability\\ndc motors\\nactuators\\nclutches\\nforce control\\nhandicapped aids\\nhuman-robot interaction\\noptimal control\\nsafety\\ntorque control\\ncompact rotary series elastic actuator design\\ncrsea\\nactuation transparency\\nmechanical safety\\nhuman-interactive robot systems\\ntransparent actuation\\nactuation force generation\\nmechanical parameters\\noptimal selection\\ntorque transmissibility\\nmechanical impedance\\nmechanical clutch\\nexcessive actuation torque\\ncontroller malfunction\\nwearable robot\\nincomplete paraplegic patients\",\"214\":\"actuators\\nmanipulators\\nforce\\nmuscles\\nkinematics\\nbellows\\nbiomimetics\\ndeformation\\ndesign engineering\\ndexterous manipulators\\nhuman-robot interaction\\nmanipulator kinematics\\nrobotic manipulator design\\ncompliant adaptive soft robots\\nlinear soft robotic actuator design\\ndeformation ratio\\nquasiconstant output force\\npassive compliance\\nanalytical model\\nactuator behavior\\nactuator design\\n6-dof soft manipulator design\\nsoft manipulator arm\\nserial kinematic structure\\nbiomimetic wrist\\nsoft actuators\\narm links\\nworking air pressure\\nhuman-oriented applications\",\"215\":\"force\\nactuators\\nrobots\\nelectron tubes\\npneumatic systems\\nsprings\\npins\\ndesign engineering\\ninspection\\nmobile robots\\npipes\\npneumatic actuators\\nservice robots\\nself-locking-type expansion mechanism\\nholding force\\npipe-passing capability\\npneumatic in-pipe robot\\nhigh-speed locomotion mechanism\\npneumatic hollow-shaft actuators\\nmechanism design optimization\\npressure optimization\\nrobot bent-pipe-passing capability\\ncomplex pipe configurations\\nvertical pipes\",\"216\":\"robot sensing systems\\nthree-dimensional displays\\nlaser radar\\nmobile communication\\ntwo dimensional displays\\ngesture recognition\\nhuman-robot interaction\\nmobile robots\\nrobot vision\\nwheels\\nhuman body part multicontact recognition\\ndetection methodology\\nhuman operator\\ncontact gesture detection\\nlabmade time-of-flight 3d scanner\\nrotary torque sensors\\ndrivetrain\\nomni-directional wheels\\ntouch-based gestures\\nphysical human-robot cooperative functions\\nsensorized mobile platform\",\"217\":\"collision avoidance\\nrobot sensing systems\\nrobot kinematics\\nautomotive engineering\\nunmanned aerial vehicles\\nvelocity obstacle approach\\nautonomous robots\\nactuation constraints\\nreciprocal collision avoidance algorithm\\ncollision-free maneuvers\\nfov\\nfield-of-view\",\"218\":\"vehicles\\nroads\\noptimization\\nsafety\\nacceleration\\ntrajectory\\nuncertainty\\nmotion control\\nnonlinear control systems\\npredictive control\\nremotely operated vehicles\\nautomated vehicles\\nmotion generation\\nvehicle safety systems\\ndriving situation\\nparallel autonomy shared-control framework\\nnonlinear model predictive control\\nnmpc\\nreceding horizon planner\",\"219\":\"collision avoidance\\ngraphics processing units\\nrobot kinematics\\nreal-time systems\\ncameras\\nsolid modeling\\nmanipulator kinematics\\nparallel processing\\nredundant manipulators\\nsensor based real-time motion planning\\ngpu\\ntask-constrained real-time motion planning problem\\nredundant manipulator\\nrobot motion prediction\\nplanning horizon\\nobstacle avoidance\\nreactive velocities\\ncontrol points\\nnull space\\njacobian matrix\\nv-rep environments\\nkuka lwr-iv 7-dof manipulator\\nparallel collision check algorithm\",\"220\":\"collision avoidance\\nprobabilistic logic\\ngaussian distribution\\nprobability distribution\\nthree-dimensional displays\\nshape\\nrobots\\ncomputational geometry\\ngaussian processes\\nmanipulators\\nstatistical distributions\\ntrajectory control\\nprobabilistic collision detection\\nnonconvex shapes\\nprobabilistic collision queries\\nnonconvex objects\\nobject representation\\ngaussian probability distributions\\nhierarchical representations\\ntrajectory planning\\n7-dof fetch robot arm\",\"221\":\"cameras\\nlighting\\nrobot sensing systems\\noptimization\\nrefractive index\\napproximation theory\\nminimisation\\nrobot vision\\nstereo image processing\\nstereo polarization\\nurban robotics\\n3-d scene perception\\nactive range sensors\\npassive range sensors\\nmicrogrid polarization filter arrays\\nlinearly polarized images\\nenergy minimization formulations\\nsurface orientation constraints\\nquadratic pseudo-boolean optimization method\\nqpbo\\noptimal depth map approximation\\nreal indoor-outdoor images\\nsynthetic indoor-outdoor images\",\"222\":\"target tracking\\nfeature extraction\\nimage color analysis\\nhistograms\\ncomputed tomography\\nprediction algorithms\\nlighting\\ncompressed sensing\\nhaar transforms\\nimage colour analysis\\nimage sequences\\nobject tracking\\ncompressive tracking method\\nlocality sensitive histograms features\\nlsh features\\nfeature expression\\nadaptive ct method\\ntarget position\\nillumination invariant features extraction\\nweighted discriminant function\\nhaar-like characteristics\\ntrajectory rectification method\\ntracking location\\ncolor sequences\",\"223\":\"vegetation\\nglobal positioning system\\ncameras\\nneural networks\\ndatabases\\ncomputer architecture\\nagriculture\\nautonomous aerial vehicles\\ndynamic programming\\nfeedforward neural nets\\ngeophysical image processing\\nhelicopters\\nlearning (artificial intelligence)\\nmicrorobots\\nobject detection\\nobject recognition\\nrobot vision\\nvisual databases\\ntree recognition\\ntree localization\\ntree detection\\nmonocular mav\\ndeforestation prevention\\nquadcoptor\\nmonocular camera\\nsemidense plantation\\nconvolutional neural networks\\ngps coordinate\\nglobal localizing-and-positioning framework\\ntree segmentation\\nfeature descriptors\\ndynamic programming problem\\nbebop 2 drone\\nomnidirectional vision\\ngps tagged locations\",\"224\":\"three-dimensional displays\\nproposals\\nradar tracking\\ntwo dimensional displays\\ntracking\\nlaser radar\\ncameras\\ncomputer vision\\nkalman filters\\nobject tracking\\nstereo image processing\\ntraffic engineering computing\\nimage-space tracking\\nworld-space tracking\\ntraffic scenes\\nurban street scenes\\nautonomous systems\\nself-driving cars\\nvision-based tracking\\nimage-based information\\n3d measurements\\nworld-space 3d information\\ncoupled 2d-3d kalman filter\\nhypothesize-and-select framework\\nkitti benchmark\\n3d localization precision\\ncoupled 2d-3d tracking\",\"225\":\"needles\\ntarget tracking\\nrobots\\nvisualization\\ntwo dimensional displays\\nprobes\\nbiomedical ultrasonics\\nend effectors\\nimage motion analysis\\nimage resolution\\nkalman filters\\nmedical image processing\\nmedical robotics\\nrobot vision\\nmoving target visual tracking\\n2d-ultrasound guided robotic percutaneous interventions\\npercutaneous needle procedures\\n2d ultrasound imaging\\nbiopsy needles\\nbiopsy targets\\n2d us images\\nmoving point visual tracking\\nmutual information similarity functions\\nthin-plate spline motion model\\ndeformable target tracking\\ntarget template images\\nneedle template images\\nkalman filter\\ntracking error reduction\\nneedle insertion robot\\nrobotic arm end effector\\nthe target tracking methods\\noptical tracking system\\n2d us guided percutaneous needle procedures\",\"226\":\"three-dimensional displays\\nrendering (computer graphics)\\ncomputational modeling\\nsolid modeling\\nshape\\ncameras\\nadaptation models\\ndexterous manipulators\\nfeedforward neural nets\\nlearning (artificial intelligence)\\nmonte carlo methods\\nneural net architecture\\npose estimation\\nrobot vision\\nrobotic assembly\\nindustrial components\\nsimulated images\\ndeep representation\\nvisual learning framework\\n3d model retrieval\\nnear infrared band\\nnir band\\nquasimonte carlo method\\nquasimc method\\nscalable photorealistic rendering\\nconvolutional neural network architectures\\ncnn architectures\\nsynthetic data\\nfine-grained shape attributes\\ncategory-specific cnn\\npose regression\\ndomain adaptation\\nattention mechanism\\nqualitative analysis\\ncnn training\\nquantitative analysis\",\"227\":\"shape\\nsolid modeling\\nthree-dimensional displays\\nheating systems\\ntwo dimensional displays\\ncameras\\nsemantics\\nimage colour analysis\\nimage representation\\nobject recognition\\npose estimation\\n6-dof object pose\\nsemantic keypoints\\nsix degree of freedom\\nrgb image\\nconvolutional network\\ntraining image data\\nclass-based object pose estimation\\nlarge-scale pascal3d+ dataset\",\"228\":\"visualization\\nmobile robots\\nrobot sensing systems\\nfeature extraction\\nforce\\ntrajectory\\ncollision avoidance\\nvisual route following\\nextreme terrain\\ntethered mobile robot\\ncliff-climbing\\nintermediate anchors\\nvisual teach & repeat algorithm\\nvt&r algorithm\\nmotion assistance\\nwheel traction\\ntether controller\\ntethered robotic explorer\\ntrex\",\"229\":\"sun\\nbayes methods\\nneural networks\\nvisualization\\npipelines\\ntraining\\nconvolution\\nimage colour analysis\\nimage fusion\\nmonte carlo methods\\nneural nets\\nobject detection\\nstereo image processing\\nvectors\\ndrift reduction\\nbayesian convolutional neural network\\n3d sun direction vector\\nrgb image\\nmonte carlo dropout scheme\\nsliding window stereo visual odometry pipeline\\noptimal data fusion\\nbayesian sun detection model\\nkitti odometry benchmark training set\\ntranslational armse\\nrotational armse\\nbayesian cnn sun estimator\\ncaffe\",\"230\":\"feature extraction\\nneural networks\\npipelines\\ncameras\\nimage sequences\\nvisualization\\nvideos\\ndistance measurement\\nfeedforward neural nets\\nimage matching\\nimage representation\\nlearning (artificial intelligence)\\nmotion estimation\\nrecurrent neural nets\\ndeepvo\\nend-to-end visual odometry\\ndeep recurrent convolutional neural networks\\nmonocular visual odometry\\nfeature matching\\nlocal optimisation\\nrcnn\\nvo pipeline\\nfeature representation\\nsequential dynamics\\nkitti vo dataset\\ndeep learning technique\",\"231\":\"cameras\\nrobot vision systems\\nrobot kinematics\\npredictive control\\ntrajectory\\npredictive models\\nrobot vision\\ntrajectory control\\nvisual servoing\\nmodel predictive control\\nmultiple trajectory tracking\\nactive perception scheme\\nrobots\",\"232\":\"visualization\\nrobots\\nvocabulary\\nreal-time systems\\nalgorithm design and analysis\\nrobustness\\nwindows\\nmobile robots\\nnavigation\\nremotely operated vehicles\\nrobot vision\\ntelerobotics\\nvisual triage\\nbag-of-words experience selector\\nlong-term visual route following\\nvisual teach & repeat 2\\nvt&r2\\nvision-in-the-loop autonomous navigation system\\nroute network construction\\noperator-controlled driving\\nvisual localization\\nmultiexperience localization\\nenvironmental influences\\nreal time loop system\\npointfeature mel paradigm\",\"233\":\"satellites\\ndatabases\\nvisualization\\nrobustness\\nlighting\\nglobal positioning system\\nbuildings\\ncomputer vision\\nimage matching\\nimage sequences\\npose estimation\\nsatellite image-based localization\\nlearned embeddings\\nvision-based method\\nground-level image sequence\\nvehicle pose estimation\\nneural multiview model\",\"234\":\"robot sensing systems\\npublishing\\npublish-subscribe\\ntools\\ncameras\\nsolids\\nobject-oriented programming\\noperating systems (computers)\\nrobot programming\\nrate impact analysis\\nrobotic systems\\nrobot performance\\nrobot behavior\\nsystem change\\ncode patterns\\ndata rate\\nros systems\\ncompilation time\\nrobot operating system\",\"235\":\"multi-robot systems\\ncouplings\\nrobot kinematics\\nforce\\ndamping\\ndynamics\\nrobot dynamics\\ninter-robot coupling relationship scaling\\ninteractive behavior\\npassivity preservation\\nsafe interaction\\nlarge-scale multirobot systems\\ndesired dynamic behavior\",\"236\":\"mathematical model\\nfinite element analysis\\ntopology\\nshape\\nrobot sensing systems\\nplanning\\nmatrix algebra\\nrobots\\ndistributed computation\\nmodular-robotic ensembles\\nreconfiguration planning\\nself-reconfiguration\\ndensely-packed modular robots\\nconnection topology\\nemergent behavior\\nintermodular connections\\nfinite element model\\none-node-per-module discretization\\nbeam elements\\nlinear elasticity\\nstiffness matrix\\niterative solution\",\"237\":\"manipulator dynamics\\nestimation\\nkinematics\\ndynamics\\nrobot sensing systems\\ncooperative systems\\ndistributed algorithms\\nmanipulators\\nmobile robots\\nparameter estimation\\nposition control\\ndistributed cooperative object parameter estimation\\ntwo stages distributed algorithm\\nmobile manipulators\\ncontact wrenches\\nobject dynamic parameters\\nobject kinematic parameters\\ndistributed cooperative algorithm\\nobject pose control\\nsqueezing wrenches\",\"238\":\"target tracking\\nalgorithm design and analysis\\nmotion segmentation\\npartitioning algorithms\\nconvergence\\ndecentralised control\\nmobile robots\\nmulti-robot systems\\noptimal control\\nposition control\\nactive target tracking\\nself-triggered communication\\ndistributed target tracking problem\\nrobot team\\nrobot formation\\ntarget distance measurement\\ndecentralized control\\nasymptotic convergence\\noptimal formation\\nrobot information exchange\\nrobot communication\\nup-to-date information\\nconstant communication\\nstationary target tracking\\nmobile target tracking\",\"239\":\"robot kinematics\\nadaptation models\\nvehicle dynamics\\nentropy\\ndensity functional theory\\nrobot sensing systems\\nautonomous underwater vehicles\\ncomputational geometry\\nmulti-robot systems\\nrobot dynamics\\nsampling methods\\nmultirobot coordination\\ndynamic voronoi partitioning\\ninformative adaptive sampling\\ncommunication-constrained environments\\nauv\\nenvironmental modeling\",\"240\":\"robots\\nforce\\nmagnetic levitation\\ntransforms\\ndc motors\\nbonding\\nlattices\\nmagnetic variables control\\nrobust control\\nhelical magnet\\nself-reconfigurable modular robotic system\\ncompositional modules\\nhelically magnetized axes\\ncubic shaped module\\nslide movement\\ngrid positions\\nstructural configuration\\nhelically magnetized axis\\nfabrication method\",\"241\":\"robot kinematics\\nvisualization\\npredictive models\\nneural networks\\nmathematical model\\ncomputational modeling\\nimage sequences\\nlearning (artificial intelligence)\\nmanipulators\\nrobot vision\\nself-supervised learning\\nimitation\\nvision-based rope manipulation\\ndeformable object manipulation\\nrobotics\\nlearning-based system\\nimage sequence\\nhuman demonstration reproduction\\nmonocular images\\npixel-level inverse dynamics model\\nhuman-provided images\",\"242\":\"optimal control\\nrobots\\nsubstrates\\nmedia\\nmathematical model\\nsprings\\nsolids\\ncontrol system synthesis\\nforce control\\ngaussian processes\\nlegged locomotion\\nregression analysis\\ngranular media\\noptimal control synthesis\\ngaussian process-based regression\\ndeformable terrain\\nlocomotive robotics\\nlegged machines\\nvertical jumping\\ngm\\nuncharacterized deformable terrain\\ngp-based regression\\nground forcing\\none-dimensional jumper\\nforcing profiles\\ngp-based dynamical model\\ndynamical model\\noptimal control trajectories\\njumping height error\\ngp-based approximation\",\"243\":\"grasping\\ntraining\\nrobot sensing systems\\ndata models\\nvisualization\\nforce\\ngrippers\\nlearning (artificial intelligence)\\neffective learning\\nrobot control\\ntorques\\ndata-driven end-to-end learning frameworks\\nmultiple robot tasks\\nmultitask learning\\ntask-specific models\",\"244\":\"neural networks\\nrobot sensing systems\\nlearning (artificial intelligence)\\ngames\\ntraining\\nvisualization\\ndexterous manipulators\\ndirected graphs\\nmanipulator dynamics\\nmanipulator kinematics\\nmulti-robot systems\\nneural nets\\nrobot vision\\nmodular neural network policy learning\\nmultitask multirobot transfer learning\\nrobotic skills\\ndeep reinforcement learning\\ngeneral purpose modular neural network policy training\\nrl\\ntask-specific modules\\nrobot-specific modules\\nrobot dynamics\\nrobot kinematics\\nmix-and-match modules\\nzero-shot generalization\\nvisual tasks\\nnonvisual tasks\",\"245\":\"computer architecture\\nkernel\\nrobots\\ncollision avoidance\\ntensile stress\\ntwo dimensional displays\\nconvolution\\nfeedforward neural nets\\nlearning (artificial intelligence)\\nrobot vision\\nside-channel information\\nconvolutional neural networks\\ncnn\\ndeep learning technique\\nrobot grasping location prediction\\nrgb-d image input\\nimage-like input handling\\nmain-channel input\\nhighly-predictive-nonimage-like input\\nside-channel input\\ncollision-free robot path\\noccupancy grid\\npath start configuration\\npath goal configuration\\nempirical tests\\nrobot collision prediction\\nrobot control problems\\nlearning speed\\nmemory usage\\nlearning capacity\\noverfitting susceptibility\",\"246\":\"couplings\\ncollision avoidance\\nrobot sensing systems\\ntrajectory\\nneural networks\\nplanning\\nfeedback\\nlearning (artificial intelligence)\\nmanipulator dynamics\\nneural nets\\nnonlinear differential equations\\nmachine perception\\nhuman environments\\nmachine learning\\nnominal skilled behavior\\nreactive modification term\\nmovement plans\\ndynamic movement primitives\\nneural network\\nreactive policy\\nhuman demonstrations\\nobstacle avoidance\\nrobot manipulation\\ntest bed\\nphysical insights\\nrobust behavior\\nobstacle settings\\nmovement durations\\nanthropomorphic robotic system\",\"247\":\"force\\nplanning\\nforce measurement\\ngrasping\\nrobots\\nalgorithm design and analysis\\nsearch problems\\nmanipulators\\ndiscrete point set\\nlargest origin-centered ball\\ngrasp wrench set\\nforce closure test\\nmultifingered grasping\",\"248\":\"conferences\\nautomation\\nmanipulators\\nmotion control\\nstatistical analysis\\nactuation configuration\\nrobotic hand design\\nmechanical implementation\\npostural synergies\\nmove characteristics\\nhuman hand joints\\nhand joint angle\\ngrasps\\nstatistical metrics\\nactuation modules\\nfinger joints\\ndifferential motion\\nchain proportion motion\\npulley\\nplanetary gear differential module\\ngear transmission chain\",\"249\":\"measurement\\nforce\\nfriction\\ngrasping\\nrobots\\nresists\\nplanning\\ngrippers\\npath planning\\ngrasp quality evaluation\\nobject planning\\nnegative curvature\\nconcave object grasping\\nmultifingered hand\\ngrasp quality metric\\ngrasp planner\\nrobot system\\nbin picking task\",\"250\":\"image segmentation\\ngrasping\\ntransforms\\nvisualization\\nobject detection\\nrobot sensing systems\\ngrippers\\nmanipulators\\npattern clustering\\nrobot vision\\nhierarchical salient object detection\\nassisted grasping\\nvisual scene decomposition\\nsemantic entities\\nobject grasping system\\nbottom-up hierarchical clustering approach\\nobject segmentation\\ntransform\\nhierarchical saliency function\\neasy-to-use pick-and-place manipulation system\",\"251\":\"dictionaries\\nimage reconstruction\\ngrasping\\ntactile sensors\\nfeature extraction\\nlearning (artificial intelligence)\\nrobot vision\\nstability\\ngrasp stability assessment\\nunsupervised feature learning\\ntactile images\\nvision based algorithms\\nhuman abilities\\ntactile sensing\\nrobotic grasping\",\"252\":\"friction\\ncomputational modeling\\ngrippers\\nforce\\ntorque\\ngrasping\\nellipsoids\\nfinite element analysis\\nmechanical contact\\npolynomials\\npose estimation\\nsolid modelling\\nsurface fitting\\ngrasping posture estimation\\ntwo-finger parallel gripper\\nsoft material jaws\\ncurved contact area friction model\\ndeformable object\\nsoft parallel gripper jaws\\nplanar contact area\\nfrictional force overestimation\\ntorque overestimation\\nfinite element method\\nfriction wrenches\\nsurface models\\nellipsoid model\\nconvex 4th-order polynomial\\nfitting error\\ngrasp quality map\",\"253\":\"trajectory\\nlegged locomotion\\nmechanical systems\\nadaptation models\\nmathematical model\\njacobian matrices\\ntime factors\\nmechanical contact\\ntrajectory control\\ndecoupled limbs\\ndifferentiable trajectory outcome\\nintermittent contact\\nunilateral constraints\\ncontact mode sequence\",\"254\":\"visualization\\nservomotors\\nhistograms\\nservice robots\\nfrequency modulation\\nelectrodes\\nbrain-computer interfaces\\nhandicapped aids\\nhuman-robot interaction\\nvisual servoing\\nssvep-based bci system\\nservice robot\\nvisual servo module\\nbrain-computer interface\\nhuman mind\\ncontrol commands\\nphysically challenged people\\nsingle-channel steady-state visual evoked potentials\\nsinusoidal method\\nservice procedures\",\"255\":\"feature extraction\\ngait recognition\\nprobes\\ncovariance matrices\\nrobustness\\nprincipal component analysis\\ndatabases\\ngait analysis\\nimage recognition\\nvectors\\nrobust gait recognition\\nspeed changes\\nmutual subspace method\\nmsm\\nimage-based approaches\\n2d image matrices\\n1d image vectors\\npca\\ncovariance matrix\\nprobe dataset\\nfrieze pattern\\ngait features\",\"256\":\"robot sensing systems\\ntools\\nsafety\\ncollision avoidance\\nservice robots\\ncollaboration\\nend effectors\\nhuman-robot interaction\\nmobile robots\\nroad safety\\nend-effector airbags\\nhuman-robot collaboration\\nhuman safety\\nco-bots\\ntorque sensors\\nexternal torque observers\\ntactile skins\\nsafety module\\nrobot motion\\niso\\/ts 15066 standard\",\"257\":\"adaptation models\\nmarkov processes\\npredictive models\\ncollaboration\\nconferences\\nmobile robots\\ncollision avoidance\\ndecision theory\\nhuman-robot interaction\\nuser expertise\\nshared autonomy\\npartially observable markov decision process\\npomdp\\nmacroaction controllers\\nobstacle-filled map\\nrobot autonomy\\nobstacle avoidance\",\"258\":\"robot kinematics\\nsprings\\nmanipulators\\ncollision avoidance\\nsafety\\nshock absorbers\\nhuman-robot interaction\\ninterconnected systems\\nmulti-robot systems\\nport-hamiltonian based control\\nhuman-robot team interaction\\nformation constraints\\nsystem complexity\\ncontrol synthesis\\ninterconnected system modeling\\nrobotic team\\nobject manipulation\\nconstrained port-hamiltonian system\\npassivity-based control approach\\ncooperative manipulation system\\nenergy shaping\",\"259\":\"time series analysis\\nhidden markov models\\ntrajectory\\nlegged locomotion\\npredictive models\\nhuman-robot interaction\\ntime series\\nmultiple-predictor approach\\nhuman motion prediction\\nmultiple-predictor system\\nmps\\nvelocity-based position projection\\ntime series classification\\nsequence prediction\\nlook-ahead time values\",\"260\":\"feature extraction\\nrobot sensing systems\\nspeech\\npredictive models\\ntiming\\nadaptation models\\nhuman-robot interaction\\nsocial robot listeners\\nbackchannel opportunity prediction\\nspeaker cues\\nbackchannel timing\\nnonverbal behaviors\\nbop model\\nsocial robot platform\\ntega\\ncontingent backchanneling robot listener\",\"261\":\"robot sensing systems\\ntraining\\nfeature extraction\\nhidden markov models\\nkernel\\ncomputational modeling\\naffective computing\\nfeedforward neural nets\\ngesture recognition\\nhaptic interfaces\\nhuman-robot interaction\\nlearning (artificial intelligence)\\nmicrocontrollers\\npattern classification\\nrecurrent neural nets\\nsensor arrays\\ntactile sensors\\nsocial touch gesture recognition\\ndeep learning\\nhigh-dimensional input data\\naffective touch classification\\nrobotic skin\\nautoencoder-recurrent neural network\\nconvolutional-recurrent neural network\\naffective touch datasets\\ncomputing element collocation\\nsensor array\",\"262\":\"force control\\nservice robots\\nrobot kinematics\\ntransfer functions\\nstandards\\ntuning\\nclosed loop systems\\ncontrol system synthesis\\nfeedback\\nindustrial robots\\nrobust control\\nstandard control design\\nrobot implicit force control\\nmodel-based regulator synthesis\\nclosed-loop performance\\nstandard model-based controllers\\nclosed-loop model matching\\nclosed-loop behaviour\\ndata-driven controller design\\nvirtual reference feedback tuning\\nvrft\\nrobustness\\nforce sensor\",\"263\":\"manipulator dynamics\\nplanning\\ndynamics\\ntrajectory\\ngrasping\\nkinematics\\naerospace robotics\\ncollision avoidance\\ngaussian processes\\nmanipulators\\nmotion control\\nmulti-robot systems\\noptimal control\\nregression analysis\\ntrees (mathematics)\\nmotion planning\\ncooperative aerial transportation\\nobstacle environment\\naerial robots\\nparametric dynamic movement primitives\\npdmp\\noptimal motion\\nrapidly exploring randomized trees star\\nrrt*\\ngaussian process regression\\ngpr\\nenvironmental parameters\",\"264\":\"trajectory\\nactuators\\nmanipulator dynamics\\nlayout\\nend effectors\\nshape\\nmotion control\\nplates (structures)\\nvibrations\\nplate vibration\\n3-degree of freedom motion control\\nend effector\\nflat plate\\nsinusoidal displacement input\\nwhirlpool-like characteristics\\ntrajectory map\\nrotational motions\\ntranslational motions\\nnonprehensile manipulation\\ntwisted axis layout\\nhybrid joint mechanism\\n1-actuator 3-dof parts feeding\",\"265\":\"stochastic processes\\noptimization\\nrobustness\\nrobots\\napproximation algorithms\\npicture archiving and communication systems\\nuncertainty\\nautomobiles\\nautonomous aerial vehicles\\nhelicopters\\nmobile robots\\nroad traffic control\\nstability\\nstochastic programming\\ntelerobotics\\nsafe vehicle navigation\\nrobotic systems\\nstochastic policy optimization\\nprobably approximately correct bounds\\npac bounds\\nquadrotor\\ncar\",\"266\":\"robots\\nphysics\\nsearch problems\\nthree-dimensional displays\\ntransforms\\nstacking\\nengines\\nbuilding materials\\nconstruction\\nindustrial manipulators\\nmaterials handling\\nobject detection\\npose estimation\\nautonomous robotic stone stacking\\npose planning\\nrobotic construction\\nstructured indoor environments\\nautonomous construction\\nstacking pose searching method\\ngradient descent\\nrandom initial orientation\\nrobotic manipulator\\nvertical stacks\\nmortars\\nadhesives\",\"267\":\"haptic interfaces\\nhidden markov models\\ncatheters\\ntraining\\nsolid modeling\\ncatheterization\\nmeasurement\\nbiomedical education\\ncardiovascular system\\ncomputer based training\\nmedical computing\\nstatistical analysis\\nlearning based training\\nendovascular catheterization\\nendovascular intervention\\ntechnical skill training\\ncompetency-based measures\\ntechnical skill assessment\\noperator hand motions\\nactive online training\\nendovascular skill objective assessment\\noptimum catheter motions\\nungrounded handheld haptic device\\nintuitive haptic guidance\\nstatistical models\\nendovascular navigation\\nendovascular training platforms\",\"268\":\"instruments\\ntools\\nsurgery\\nendoscopes\\nmedical robotics\\nprototypes\\nbending\\ncontrol engineering computing\\nflexible manipulators\\ninjuries\\nflexible surgical robot\\nbendable surgical robot\\nsingle portal minimally invasive surgery\\niatrogenic injury\\nflexible endoscopic device\\nbendable endoscopic device\\nminiature scanning fiber endoscopes\\nirrigation port\\nsuction port\\nsteerable robotic surgical systems\\nsheath\\nbending axis\\ninsertion degrees of freedom\\nexternal actuation pack\\nsurgical tools\\nroboscope mechanical system\\nelectrical system\\nsoftware systems\\ncontrol systems\\nsurgical robot\\nflexible and bendable robot\\nsystem design\\nskullbase and sinus surgery\\nneurosurgery\",\"269\":\"trajectory\\nrobots\\ntraining\\nlearning (artificial intelligence)\\nminimally invasive surgery\\ntools\\ndeformable models\\nbiomedical equipment\\nfinite element analysis\\ngrippers\\nmedical robotics\\nsurgery\\nmultilateral surgical pattern cutting\\n2d orthotropic gauze\\ndeep reinforcement learning policies\\nfundamentals-of-laparoscopic surgery standard medical training regimen\\nfls standard medical training regimen\\nsurgical scissors\\ntissue gripper\\nsurgical gauze\\nautomated optimal tensioning policy\\npinch point\\ncutting trajectory\\ntensioning policy conditioned learning\\ngauze deformation\\ntranslation unit vector\\nanalytical model\\nexplicit model\\ndirect policy search methods\\nfinite-element simulator\\nphysical system\\ndeep rl tensioning policies\\nopen curved contours\\nclosed curved contours\\nda vinci research kit\\ndvrk\\nperformance improvement\\nnoise robustness improvement\\nexternal force robustness improvement\",\"270\":\"probes\\nforce\\ntools\\nrobot sensing systems\\nmanipulators\\nbiological tissues\\nendoscopes\\nimage resolution\\nimage segmentation\\nmanipulator kinematics\\nmedical image processing\\nmedical robotics\\nthree-dimensional robotic-assisted endomicroscopy\\nforce adaptive robotic arm\\nin situ tumour margin assessment\\nin vivo tumour margin assessment\\nclinical demand\\nsurgical oncology\\nprobe-based optical imaging tools\\nconfocal endomicroscopy\\ntissue contact\\nrobotic assistance\\nhigh-speed endomicroscopes\\nautonomous scanning\\nroutine surgical workflows\\ncooperatively controlled robotic manipulator\\nmechatronically-enhanced platform\\nmicroscanning tools\\nlocal high resolution mosaics\\n3d undulating moving surfaces\\nkinematic analysis\\noverall system performance analysis\\ncontact force\\norientation control\\nclinical adoption\",\"271\":\"carotid arteries\\nphotoacoustic imaging\\nsurgery\\nultrasonic imaging\\ntelerobotics\\ninstruments\\nacoustic imaging\\nbiomedical ultrasonics\\nblood vessels\\ndrilling\\nmanipulators\\nmedical robotics\\nsafety\\ntelerobotic drilling\\nphotoacoustic sensing\\nskull base surgery\\nphotoacoustic imaging system\\ntelerobotic system\\npulsed laser\\noptical fiber\\nrobot arm\\nultrasound receiver\\nsafe region determination\",\"272\":\"needles\\nsurgery\\nkinematics\\npath planning\\ngeometry\\nshape\\noptimization\\nbiological tissues\\nmanipulator kinematics\\nmedical robotics\\nnonlinear programming\\nautonomous suturing\\nsurgical robot\\noptimal needle diameter selection\\nneedle shape selection\\nneedle path selection\\nsuture depth\\noptimization-based approach\\nparameter specification\\nclinical suturing guidelines\\nkinematic model\\nneedle-tissue interaction\\nconstant curvature needle path planning\\nnonlinear optimization problem\\ntissue geometry\\nsurgeon defined entry-exit points\\noptimization weighting factors\\nneedle geometry\\nclinically relevant input sets\\nraven ii surgical system\\npath planning algorithm\\nminimal tissue trauma\\nsuturing requirements\",\"273\":\"robot sensing systems\\nmanipulators\\nestimation\\njacobian matrices\\nlungs\\nposition measurement\\nfeedback\\nkalman filters\\nlung\\nmedical robotics\\nsurgery\\ntrajectory control\\ntransforms\\norientation estimation\\nphantom lung\\ntendon-driven continuum manipulator\\nminimally invasive surgery\\nautonomous control\\nrobot interaction\\nrobotic manipulator\\nmodel-based jacobian rotation\\nmagnetic position sensor\\nrobot distal tip\\ntask-space control\\nunknown constrained environment\\nunscented kalman filter transforms\\ntip position change measurement\\nmodel-based control\\nmodel-less control\\nautonomous trajectory-following task\\nanatomically accurate silicone phantom\\nhuman lung\\nfeedback control\\nnavigation\",\"274\":\"wheels\\ntrajectory tracking\\nbicycles\\ntrajectory\\ncontrol design\\nhuman-robot interaction\\ncontrol system analysis\\ncontrol system synthesis\\nmobile robots\\nrobot dynamics\\ntrajectory control\\nbalance control\\nautonomous bikebot dynamics\\nsingle-track autonomous mobile robot design\\nunstable physical human-robot interactions\\nexternal-internal convertible structure\\neic-structure\\ncontrol system design\\nrider motor skills\",\"275\":\"wheels\\nlegged locomotion\\ntorque\\ngeometry\\nforce\\ncollision avoidance\\nlearning (artificial intelligence)\\nrobot dynamics\\nobstacle negotiation learning\\ncompliant wheel-on-leg robot\\nwheel-on-leg robot generic control\\narbitrary uneven terrains\\nsurface interactions\\nenvironmental structures\\npassive internal compliance\\nactive internal compliance\\nwheel-ground interaction forces\\ncontinuous state space q-learning approach\\ncontact forces estimates\\nground geometry\\nunanticipated obstacles\\nlearned policy\",\"276\":\"legged locomotion\\nwheels\\nvehicle dynamics\\nangular velocity\\nbicycles\\ncollision avoidance\\ncontrol nonlinearities\\nmedical robotics\\nmobile robots\\nsteering systems\\nsteering singularities\\npassive path following\\nassistive passive robotic walkers\\nrear-driven bicycle\\nfront steering wheels\\nnonsingular passive path\\nvelocity-independent control law\\nsteering angles\\nnonsingular velocity-independent controller\\nsaturation constraints\\nsingularities-avoidance\\nhuman comfort\\nplanned trajectory\",\"277\":\"wheels\\nmobile robots\\nrobot kinematics\\nmathematical model\\nactuators\\nsilicon\\npath planning\\nposition control\\nsteering systems\\nsynchronisation\\npath following controller\\nplanar robots\\nsteerable velocity limited wheels\\npseudo-omnidirectional robots\\nsynchronization\\nwheels steering\\nrolling speeds\\nactuator\",\"278\":\"mobile robots\\nservice robots\\nmanipulators\\nskin\\nrobot sensing systems\\nmobile communication\\ncontrol engineering computing\\nhumanoid robots\\nmanipulator dynamics\\nmiddleware\\ntomm\\ntactile omnidirectional mobile manipulator\\nmechatronic design\\ntactile omnidirectional robot manipulator\\nmiddleware components\\ndynamic behavior\\ntactile interaction system\\nmultimodal tactile information\\nrobot skin\\n12 dof hands\\n1 dof grippers\\nswitchable end-effectors\\nomnidirectional wheels\\n6dof\\ndual arm wheeled humanoid robot\",\"279\":\"wheels\\nmobile robots\\nellipsoids\\nmeasurement\\nmobile communication\\nactuators\\nuniform mobility design\\nhamr holonomicity\\nholonomic systems\\nterrain handling capabilities\\nmobility ellipsoid\\nmanipulability ellipsoid\\nnonholonomic vehicles\",\"280\":\"mobile robots\\nplanning\\nwheels\\nrobot kinematics\\ncollision avoidance\\nlattices\\nagriculture\\nindustrial robots\\npath planning\\nposition control\\nadjustable wheel positions\\nnavigation planning\\ncomplex environments\\nsearch-based planner\\nrobot configuration\\ncomputational burden\\nagricultural fields\\nbonirob agricultural robot\",\"281\":\"mobile communication\\njacobian matrices\\nkinematics\\nend effectors\\ncollision avoidance\\ncompensation\\ndamping\\nleast squares approximations\\nmanipulator kinematics\\nmobile robots\\npath planning\\ninverse kinematics\\nstrict nonholonomic constraints\\nmobile manipulator\\nunified approach algorithm\\nmobile robot\\nhypothetical joints\\ndamped least square method\\njacobian\\nend-effector position error\\ncompensation technique\",\"282\":\"redundancy\\naerospace electronics\\njacobian matrices\\nrobot kinematics\\nkinematics\\nrobot sensing systems\\nmanipulators\\nposition control\\norientation control\\nfunctional redundant robots\\nspatial directions\\ndof\\ndegrees-of-freedom\\nintrinsic redundant robots\\njacobian matrix\\norientation related functional redundancy resolution\\nquaternion control\\ntwo-arm robot system\",\"283\":\"heuristic algorithms\\nfasteners\\nmanipulator dynamics\\nkinematics\\ndynamics\\ncomputational complexity\\ngroup theory\\nindustrial manipulators\\ninverse problems\\nrecursive estimation\\nrecursive second-order inverse dynamics algorithms\\nserial manipulators\\nmodel-based control schemes\\ndenavit-hartenber parameters\\ndh parameters\\nlie group theory\\ntime derivative\\ncomputational efficiency\\nhybrid twists representation\\n6-dof industrial manipulator\\ninverse dynamics\\nseries-elastic actuators\\nfeedback linearization\\nserial manipulator\\no(n) methods\",\"284\":\"manipulators\\ninstruments\\nwires\\nstandards\\nendoscopes\\nsurgery\\nactuators\\nmedical robotics\\nthree-dimensional printing\\nmultiarm snake-like robot\\nminimally invasive surgery\\npatient\\nspecial equipment\\nsurgical field\\nlimited workspace\\noperating field\\nspine like overtube system\\nstandard endoscopic instruments\\ntissue manipulation\\n3d-printed manipulator system\\nmechanical control\\nactuation concepts\\nindividualized disposable system\\n3d-printed surgical robotic system\\nporcine model\",\"285\":\"kinematics\\nrobot kinematics\\nheuristic algorithms\\ntime complexity\\ntactile sensors\\ncomputational complexity\\nmatrix algebra\\nasynchronous sensory input\\nasynchronous forward kinematics\\nafk\\nhomogeneous transformation matrix\\nasynchronous sensory data\\nconventional forward kinematics\\ncfk\",\"286\":\"shape\\nestimation\\nrobot sensing systems\\nreal-time systems\\nmathematical model\\nsprings\\nelasticity\\nflexible manipulators\\nforce sensors\\nmanipulator kinematics\\nrods (structures)\\nshape control\\nshear modulus\\nsprings (mechanical)\\ntorque control\\nreal-time spatial shape estimation\\nsix-axis force\\/torque sensor\\nflexible object shape\\ndiscretized kirchhoff elastic rod\\nthree-degree-of-freedom rotational spring joints\\nrigid-body partition\\nrobot manipulator kinematics\",\"287\":\"surface reconstruction\\ncameras\\nimage reconstruction\\nthree-dimensional displays\\nneural networks\\nsimultaneous localization and mapping\\nrobot vision systems\\nlearning (artificial intelligence)\\nneural nets\\npose estimation\\nrobot vision\\nslam (robots)\\nstereo image processing\\ndense monocular reconstruction\\ndense 3d scene reconstruction\\nmonocular camera\\nvisual slam\\nsimultaneous localisation-and-mapping\\nmoving camera pose tracking\\ndense mapping systems\\nconvolutional neural networks\\ndeep cnn\\npixel-wise surface normals\\nhigh-level scene context learning\",\"288\":\"vehicle dynamics\\ngaussian processes\\ndata models\\nrobots\\nroads\\ncomputational modeling\\nhidden markov models\\ninference mechanisms\\nlearning (artificial intelligence)\\nmobile robots\\npath planning\\nremotely operated vehicles\\nstatistical analysis\\nstochastic variational inference\\nnavigation\\ndynamic gaussian process occupancy maps\\ndgpom\\nspatially-continuous occupancy maps\\nneighborhood information\\nprobabilistic estimation\\nsvi\",\"289\":\"image segmentation\\nimage edge detection\\nthree-dimensional displays\\nestimation\\nrobustness\\nmachine learning\\nedge detection\\nlearning (artificial intelligence)\\nleast squares approximations\\nstereo image processing\\nrobust stereo matching\\nsurface normal prediction\\ntextureless region handling\\nocclusions handling\\nreflective regions\\nlambertian surface assumption\\npredicted surface normal\\ndeep learning\\nedge fusion strategy\\ndisparity map\\nleast squares system\\nfiltering-based completion\\nedge feature refinement\\nmiddlebury dataset\",\"290\":\"robot sensing systems\\nsonar equipment\\nheuristic algorithms\\nvibrations\\nmetals\\nhydrophones\\ninspection\\nkalman filters\\nparticle filtering (numerical methods)\\npipelines\\nslam (robots)\\nvibrational signal processing\\nwater resources\\nwater supply\\nrobot mapping\\nrobot localisation\\nmetal water pipes\\nhydrophone induced vibration signals\\nmap alignment\\ndynamic time warping\\nasset management\\nwater distribution pipe networks\\ninspection robots\\ndamage detection\\nterrain-based extended kalman filtering\\nparticle filtering\",\"291\":\"image segmentation\\ntwo dimensional displays\\nrobots\\nbridges\\nmeasurement\\ntransforms\\nshape\\nrobot vision\\nslam (robots)\\nincremental contour\\ntopological segmentation\\nrobot exploration\\nslam\",\"292\":\"semantics\\nbuildings\\ncognition\\nlabeling\\nsensors\\nfeature extraction\\nperiodic structures\\nbuildings (structures)\\ninference mechanisms\\nlearning (artificial intelligence)\\nmobile robots\\npattern classification\\nstatistical analysis\\ntrees (mathematics)\\nsemantic classification\\nreasoning\\nstatistical relational learning techniques\\nsemantic mapping\\nautonomous mobile robots\\nplace classification task\\nsemantic labels\\nklog\\nextra-trees\",\"293\":\"three-dimensional displays\\nrobot sensing systems\\nnavigation\\ntwo dimensional displays\\noctrees\\ncontrol engineering computing\\ndata structures\\nmobile robots\\npath planning\\nskimap\\nefficient mapping framework\\nrobot navigation\\nmultilevel querying system\\n3d voxel grid\\n2.5d height map\\n2d occupancy grid\\ncore data structure\\nskiplists\\noctree representation\\nmemory footprint\\nsensor tracker\",\"294\":\"robot kinematics\\nrobot sensing systems\\nuncertainty\\nmulti-robot systems\\nmobile robots\\ngaussian processes\\nmobile communication\\nwireless lan\\nmultirobot online construction\\ncommunication maps\\nmultirobot information-gathering tasks\\nradio signal strength\\nautonomous map building\\nrobot-to-robot communication setting\\nsignal distribution\\ngaussian process\\nonline sensing strategies\\nrobot guide\\ndata acquisition\\nturtlebot 2 platforms\\nwifi communication links\",\"295\":\"decision making\\nfeature extraction\\nrobot sensing systems\\ncameras\\nlearning (artificial intelligence)\\nrescue robots\\nrobot vision\\nsensor fusion\\nsequence-based multimodal apprenticeship learning\\nrobot perception\\nlearning from demonstrations\\nstate space\\nstate representations\\nperceptual aliasing\\nsmal approach\\ntemporal information fusion\\nmultimodal data fusion\\nsearch and rescue scenarios\",\"296\":\"activity recognition\\nhidden markov models\\nuncertainty\\nentropy\\nrobots\\ncomputational modeling\\noptimization\\nimage recognition\\nrobot vision\\nstatistical analysis\\nminimum uncertainty latent variable models\\nrobot recognition\\nsequential human activities\\nsitting down activity\\nstanding up activity\\nsequence modeling methods\\nhidden conditional random fields\\nhcrf\\nclosed-form solution\",\"297\":\"pose estimation\\ntraining\\nthree-dimensional displays\\ndetectors\\nrobustness\\nfeature extraction\\nconvolution\\nneural nets\\nstereo image processing\\nspherical part model\\nspm\\n3d hand pose estimation\\nhuman hand detection\\ndepth images\\ndeep convolutional neural network\\ndata-driven approach\",\"298\":\"stability analysis\\npoles and towers\\nvisualization\\npredictive models\\nphysics\\nengines\\nrobots\\nlearning (artificial intelligence)\\nmanipulators\\npsychology\\nrobot vision\\nstability\\nvisual stability prediction\\nrobotic manipulation\\ndevelopmental psychology\\ninfants\\nmodel-based route\\nexplicit 3d representations\\nphysical simulation\\nexplicit simulation\\nlearning-based approach\\nsimulated data\\ntower stability prediction\\nwooden blocks\\nsynthetic data\",\"299\":\"robustness\\nimage segmentation\\nvisualization\\ntraining\\nfeature extraction\\nsemantics\\ncomputer architecture\\nconvolution\\nimage matching\\nimage representation\\nneural nets\\nrobot vision\\nslam (robots)\\nsemantics-aware visual localization\\nvisual place recognition\\nlong-term visual navigation\\nrobot localization\\nimage feature descriptions\\ndeep convolutional neural networks\\nspatially inconsistent image matches\\nnonperfect image matches\\ndiscriminative holistic image representation\\ndense scene description\\nsalient scene description\\nperceptual scene dynamics\\nstructural scene dynamics\\nfreiburg\",\"300\":\"real-time systems\\nrobot sensing systems\\nskeleton\\nfeature extraction\\nthree-dimensional displays\\nbiological system modeling\\nhuman-robot interaction\\nintelligent robots\\noptimisation\\nregression analysis\\nbody-part learning\\nreal-time robot awareness\\nhuman behaviors\\nhuman-robot collaboration\\ndepth sensors\\n3d perception\\nfeature and body-part learning approach\\nfabl approach\\nregression-like optimization problem\\nstructured sparsity-inducing norms\\noptimization algorithm\\nbaxter robot\",\"301\":\"liquids\\ncontainers\\nrobots\\nkernel\\nconvolution\\nhidden markov models\\nsolid modeling\\nclosed loop systems\\nlearning (artificial intelligence)\\nrobot vision\\nthree-term control\\nvisual closed-loop control\\npouring liquids\\nvisual feedback\\nmodel-based method\\nmodel-free method\\ndeep learning\\nliquid volume estimation\\ncontainer\\npid controller\\nbaxter robot\",\"302\":\"distributed databases\\nrobot sensing systems\\ncomputer vision\\nalgorithm design and analysis\\neigenvalues and eigenfunctions\\nimage fusion\\nmatrix algebra\\nstochastic processes\\ndistributed consistent data association\\npermutation synchronization\\nmultisensor systems\\npairwise data associations\\noutlier rejection schemes\\ndecentralized method\\ndistributed averaging scheme\\ndoubly stochastic matrices\",\"303\":\"robots\\ndata models\\ncomputational modeling\\ntrajectory\\ncognition\\nengines\\nplanning\\ncloud computing\\ncontrol engineering computing\\ndigital simulation\\ninference mechanisms\\nlearning (artificial intelligence)\\nmanipulators\\nprolog\\nquery processing\\ncloud service\\nrobotic mental simulations\\nrobotic agents\\neveryday manipulation tasks\\nself computing power\\ncloud robotics\\nstorage capacity\\ncloud engines\\nmental simulation service\\nopenease\\nlearning algorithm\\nreasoning techniques\\nprolog queries\",\"304\":\"robot sensing systems\\nmobile robots\\ninterpolation\\nwireless sensor networks\\nfoundries\\ngaussian processes\\nlearning (artificial intelligence)\\nneurocontrollers\\nspatio-temporal interpolation model learning\\nsensor networks\\necho state map approach\\ngaussian process estimator\\nparticulate matter measurement\\ntemperature concentration\\ngas concentration\",\"305\":\"cameras\\nrobot vision systems\\ntracking\\noptimization\\nnavigation\\nfunction approximation\\nleast squares approximations\\nmobile robots\\nnonlinear programming\\nobject tracking\\npedestrians\\nsensor placement\\nunsupervised learning\\nunsupervised camera localization\\ncrowded spaces\\ncamera network\\npublic spaces\\ntrain terminals\\nmalls\\nsocial robot navigation\\ncrowded scene navigation\\ncamera position\\ncamera pose\\nrelative location estimate\\nnoisy trajectory\\nfully unsupervised learning technique\\nunlabelled pedestrian motion pattern\\npairwise camera parameter estimation\\noptimal single-view pedestrian track matching\\nsocial awareness\\nnonlinear least square optimization problem\\ncontinuous matching function approximation\",\"306\":\"libraries\\nheuristic algorithms\\nrobot sensing systems\\nsilicon\\nalgorithm design and analysis\\ncollision avoidance\\nmulti-robot systems\\nautomated sequencing\\nswarm behaviors\\nsupervisory control\\nrobotic swarms\\nglobal swarm behavior\\nsupervisory operator\\noptimal behavior sequence\\nswarm performance\\ncomplex task\\nswarm behavior library\\nsearch algorithm\\nmaximum performance behavior sequence\\nswarm navigation application\\ndynamic area coverage application\",\"307\":\"surveillance\\nheuristic algorithms\\nrobot sensing systems\\nalgorithm design and analysis\\ntransient analysis\\nmobile robots\\nstatistics\\nstochastic processes\\ntime-varying systems\\npersistent event surveillance\\ntime-varying statistics\\nstochastic time-varying event monitoring\\nevent detections\\nunknown dynamic environments\\ntemporal variations\\nlong-run average optimality\",\"308\":\"force\\nmanipulator dynamics\\nattitude control\\nheuristic algorithms\\ntorque\\nautonomous aerial vehicles\\nhelicopters\\nlinear quadratic control\\nmanipulators\\nmobile robots\\nstability\\nstate feedback\\nsubstantial force\\nsustained force\\nvertical surfaces\\nquadrotor\\naerial robotics\\naerial manipulator stabilization\\nuav attitude control\\nphysical contact forces\\nlqr-optimized state feedback\\nroll angle\\nyaw angle\",\"309\":\"angular velocity\\nthree-dimensional displays\\nkinematics\\naerospace electronics\\nunmanned aerial vehicles\\nquaternions\\nconvergence\\nautonomous aerial vehicles\\nlyapunov methods\\npath planning\\nposition control\\ntime-varying systems\\nthree dimensional moving path following\\nmpf control laws\\nfixed-wing unmanned aerial vehicles\\nautonomous vehicle\\ntime-varying linear velocities\\nangular velocities\\ninertial frame\\n3d mpf error space\\nmpf lyapunov-based control law\\nformal convergence proofs\\nflight test results\",\"310\":\"rotors\\ndrones\\natmospheric modeling\\nforce\\npropellers\\nprototypes\\nattitude control\\nautonomous aerial vehicles\\nhuman-robot interaction\\nmobile robots\\nstability\\ntelerobotics\\nsaucer type coanda effect uav\\nunmanned aerial vehicles\\napproximate servo mapping\\ncrash resistance\\nflight safety\\nflight performance\\nhri applications\",\"311\":\"trajectory\\npredictive control\\noptimization\\nstability analysis\\noptimal control\\nprediction algorithms\\nunmanned aerial vehicles\\nconstraint satisfaction problems\\ninfinite horizon\\niterative methods\\nsampling methods\\nstability\\nparametrized infinite-horizon model predictive control\\nstability guarantees\\ninput trajectories\\nstate trajectories\\nbasis functions\\niterative constraint sampling strategy\\nconstraint satisfaction\\nunmanned aerial vehicle\",\"312\":\"aerodynamics\\npropellers\\nforce\\ntorque\\nvehicle dynamics\\nattitude control\\natmospheric modeling\\nautonomous aerial vehicles\\ncascade control\\nlearning (artificial intelligence)\\nmicrocontrollers\\ntrajectory control\\nglobal controller\\nflying wing tailsitter vehicles\\nnominal trajectory tracking\\nfirst-principles model\\naerodynamic effects\\nonboard parameter learning scheme\\naerodynamic parameter estimation\\ncascaded control architecture\\nouter control loop\\ncoordinated flight\\nlookup table\\nprecomputed optimal attitude trajectories\\nmicrocontroller\",\"313\":\"simultaneous localization and mapping\\nnavigation\\nplanning\\ntrajectory\\nunmanned aerial vehicles\\nautonomous aerial vehicles\\npath planning\\nslam (robots)\\nshort-term uav path-planning\\nmonocular-inertial slam\\nautonomous navigation\\npath-planning algorithm\\nmonocular-inertial system\\npoint-to-point planner\\nnavigation strategy\\nuav navigation\",\"314\":\"propellers\\nrotors\\nspinning\\nrobustness\\nstandards\\nforce\\nattitude control\\nautonomous aerial vehicles\\ncascade control\\nfailure (mechanical)\\nhelicopters\\nmatrix algebra\\nstatically hoverable multirotor aerial vehicle control\\nrotor-failure robustness\\nhexarotors\\nfail-safe multirotor platforms\\ngeneral algebraic conditions\\nstatic hover\\ncontrol moment input matrix\\ncontrol force input matrix\\ninput saturations\\nsafety margins\\nhoverability properties\\ncascaded controller\\nfailed tilted hexarotor\\nuav\",\"315\":\"mobile robots\\nautomobiles\\nrobot kinematics\\nrobot sensing systems\\nrobot control\\nusability\\ncontrol system synthesis\\ngesture recognition\\nhuman-robot interaction\\ntelerobotics\\ngesture-based robot control\\ndesign principles\\nwearable devices\\ndesign guidelines\\ncommercially available devices\\nwheeled mobile robot\",\"316\":\"noise measurement\\nkalman filters\\nrobots\\ndegradation\\nlibraries\\nlearning (artificial intelligence)\\nmarkov processes\\ncomputer animation\\nintelligent robots\\nmotion preference learning\\naudience feedback\\nmotion sequences\\nanimation\\naudience preferences\\nunknown preference value\\nnoisy observations\\nmak\\nmultiarmed bandit-and- kalman filter\",\"317\":\"semantics\\nknowledge based systems\\nthree-dimensional displays\\nvisualization\\nmobile robots\\nservice robots\\ndata mining\\nfeature extraction\\nrobot vision\\nsemantic web\\ndeep vision\\nlifelong object discovery\\nautonomous robots\\nunknown object hypothesis generation\\nsemantic web-mining framework\\ndeep-learning-based object detectors\\nvisual features\\nsemantic features\",\"318\":\"predictive models\\nrobot sensing systems\\nvisualization\\nrobot kinematics\\ndata models\\nthree-dimensional displays\\ncontrol engineering computing\\nlearning (artificial intelligence)\\nmanipulators\\npath planning\\npredictive control\\nrobot programming\\nrobot vision\\nvideo signal processing\\nrobot motion planning\\nrobot learning\\nmodel-based reinforcement learning\\ndeep action-conditioned video prediction models\\nmodel-predictive control\\nnonprehensile manipulation\",\"319\":\"trajectory\\nnatural languages\\nneural networks\\ninference algorithms\\nmachine learning\\nrobot sensing systems\\ncontrol engineering computing\\nmobile robots\\nnatural language processing\\nneural nets\\ndeep multimodal embedding\\npoint-cloud\\nnatural language\\nmanipulation trajectory data\\ndeep neural network\\nloss-based margin\\npr2 robot\",\"320\":\"haptic interfaces\\ntactile sensors\\nbayes methods\\nforce\\ndecision theory\\nlearning (artificial intelligence)\\nmanipulators\\nmarkov processes\\nneurocontrollers\\nrecurrent neural nets\\nvariational techniques\\nhaptic feedback\\npartially-observable tasks\\ntouch\\nsensory system\\nmanipulation interactions\\nmanipulation tasks\\ntactile sensor feedback\\npartially observable markov decision process\\npomdp\\ndeep recurrent neural networks\\nvariational bayes methods\\ndeep q-learning\",\"321\":\"planning\\nprediction algorithms\\nalgorithm design and analysis\\nrobots\\nsearch problems\\nmeasurement\\nreliability\\nlearning (artificial intelligence)\\nmanipulators\\npath planning\\ntask and motion planning guide\\ntamp\\nscore-space representation\\nlearning algorithm\\ntask search\\nmotion planning problems\\nplanning problem instance\\nknowledge transfer\\ngeneric representation\\nproblem instance representation\\nrobot manipulation\",\"322\":\"grippers\\nforce\\nmagnetic levitation\\nmagnetic resonance imaging\\nsprings\\nrobots\\nactuators\\ncollision avoidance\\nelastic constants\\nmagnetic forces\\npermanent magnets\\nvariable stiffness gripper design\\nparallel fingers\\nnonlinear springs\\nfinger stiffness level\\nmagnetic repulsion force modeling\\nmagnetic repulsion stiffness modeling\\ngripper functionality\",\"323\":\"grippers\\nwrist\\nforce\\nrobots\\nadhesives\\noptimization\\ntuning\\nadhesion\\nautonomous aerial vehicles\\nforce constraints\\nmoment constraints\\ncurved surface gripper\\nassistive free flyers\\nfree-flying robots\\nobject manipulation\\nadhesive gripper\\ngrasp optimization\\nadhesion capabilities\\npassive wrist mechanism\\nactive wrist control\\nplanar micro-gravity test bed\",\"324\":\"grippers\\nsurface texture\\nservice robots\\nthree-dimensional displays\\nsurface treatment\\nfriction\\ncasting\\ndexterous manipulators\\nmoulding\\noptimisation\\nrapid prototyping (industrial)\\nsilicone rubber\\nthree-dimensional printing\\nparallel-jaw gripper tip surface design\\nrobust grasping\\nparallel-jaw robot grippers\\ngripper jaw surface texture\\ngripper jaw surface compliance\\ngrasp robustness\\nrigid jaw surfaces\\nplanar jaw surfaces\\nrectangular jaw surfaces\\ndata-driven optimization\\ndesign space\\nrapid prototyping\\njaw surface design variations\\n3d printed casting molds\\nsilicon rubber\\n4-axis robot\\nprobability\\ndex-net 1.0\\nhill-climbing algorithm\\ngrid pattern\\nsilicone polymer\\ndurometer\\nperformance evaluation\\nabb yumi robot\\ngripper tips\\ngecko-inspired surfaces\",\"325\":\"actuators\\nvisual servoing\\noptimization\\njacobian matrices\\npredictive control\\ngrippers\\nthumb\\nrobot vision\\nvision-based model predictive control\\nwithin-hand precision manipulation\\nunderactuated grippers\\nunderactuated hands\\nprecise gripper\\ncontact models\\nvision feedback\\nvisual servoing schemes\\nperformance degradation\\nmpc\\nhigh performance precision manipulation\",\"326\":\"grippers\\noptimization\\ntopology\\ngrasping\\nlinear programming\\nmanufacturing processes\\nforce\\ncompliant mechanisms\\nindustrial manipulators\\nmaterials handling\\nsoft robotic gripper\\nirregular object grasping\\nmechanical advantage\\ncompliant mechanism\\nsilicon rubber material\\ngeometric advantage test\\nma test\\nadaptability test\\ngrasping test\",\"327\":\"trajectory\\nmeasurement\\nrobot motion\\nrobot sensing systems\\nsafety\\nface\\nemergency services\\nservice robots\\nrobot-assisted doffing\\npersonal protective equipment\\nppe\\ninfection risk\\nsemiautonomous robot doffing assistant\\nebola\",\"328\":\"hidden markov models\\nhuman-robot interaction\\nadaptation models\\ncollaboration\\nrobot kinematics\\nruntime\\nlearning by example\\ndata-driven imitation learning system\\nhuman-robot interactions\\nhuman-human demonstrations\\nmotion capture\\ninteraction model\\ncollaborative human-robot assembly\",\"329\":\"robot kinematics\\nhandover\\nrobot sensing systems\\nmanipulators\\nmobile communication\\nhuman-robot interaction\\nmobile robots\\ntelerobotics\\nbidirectionally telepresent teleaction\\nrobot-mediated handover\\nmanipulation capability\\ntelepresence robot\\nremote humans\\ntelelabor\\nhands-on training\\ncollaborative manipulation\\nhuman-human physical interaction\\ntelepresence modality\\nrobot-mediated object handover\\nteleoperation system\\nbimanual mobile manipulator\\ntelepresence head\\nsensing capability\\naudio telepresence conditions\\nvisual telepresence conditions\\nobjective handover fluency\\nintimacy\\nperceived fluency\",\"330\":\"games\\ngame theory\\nservice robots\\nplanning\\nadaptation models\\ncollaboration\\ndecision making\\nhuman-robot interaction\\ngame-theoretic approach\\nadaptive action selection\\nclose proximity human-robot-collaboration\\niterative games\\nhuman-robot team\\nnash-equilibria\\nne\\ndecision-making behavior\\ninteractive pick-and-place scenario\\nkuka lwr 4+ robot\\nhrc-game model\",\"331\":\"electromyography\\nmuscles\\nexoskeletons\\nthumb\\nforce\\nperformance evaluation\\nmechanical engineering\\ndexterous manipulators\\nmedical robotics\\npatient treatment\\nmaestro\\nemg-driven assistive hand exoskeleton\\nspinal cord injury patients\\nsci patients\\nactive assistive orthosis\\nstandardized hand function test\\nsollerman hand function test\",\"332\":\"admittance\\ndamping\\nservice robots\\nstability analysis\\nrobot sensing systems\\nforce\\nhuman-robot interaction\\nstability\\nadmittance control parameter adaptation\\nphysical human-robot interaction\\nparameters selection\\nrobot stability\\nrobot ability\\npassivity\\nkuka lwr 4+\",\"333\":\"gears\\nactuators\\ntorque\\nmanipulator dynamics\\nsprings\\nforce control\\ncontrol system synthesis\\nmanipulator kinematics\\nservice robots\\ninteractive force control\\nelastically actuated bi-articular two-link manipulator\\ncompact planetary geared elastic actuator\\nsea\\nbi-articular muscle coordination\\nbi-articular actuator configuration\\nhigh-performance force control\\nservice robot\\nimpedance controller design\",\"334\":\"interviews\\nvideos\\nsensors\\nmedical services\\nservice robots\\nmonitoring\\ndiseases\\nethical aspects\\nhealth care\\nmedical robotics\\npatient care\\npatient-caregiver relationship\\nrobot mediator\\nethical governor\\nhealth care context\\nparkinson disease\\nfacial musculature\\nstigmatization\\nintervening ethical governor model\\nieg model\\nhuman dignity\\nethical boundaries\\nreal robotics system\\nreal clinical contexts\",\"335\":\"retina\\ntools\\nimage reconstruction\\nsurface reconstruction\\nlaser beams\\nsurgery\\ncameras\\ncomputer vision\\nrobots\\nmonocular camera-guided retinal vein cannulation\\nstabilized handheld robot\\nretinal vessel cannulation\\nmonocular vision\\nautomated laser beam scanning\\ncoordinate transform\\n2d image plane coordinate system\\nglobal 3d frame\\nhemispherical region\\nmotion scaling\\nhomography matrix estimation\\nlaser surface reconstruction\\nmicron guided vein cannulation\\nwet eye phantom\\nstandard stereo reconstruction\",\"336\":\"electron tubes\\nendoscopes\\nwires\\ntorque\\nprobes\\nfluorescence\\noptical fibers\\ncancer\\ncatheters\\nmedical image processing\\nmedical robotics\\noptical microscopy\\npatient diagnosis\\nballoon endomicroscopy scanning device\\nbarretts oesophagus diagnosis\\nsize 3 mm\\noesophageal cancer\\noesophageal mucosa\\nhigh-resolution imaging\\nimage quality evaluations\\nconfocal laser scanning system\\nleached flexible fibre bundle\\nendomicroscopy probe\\nendoscope working channel\\ninflatable balloon\\nrobotic catheter\\nbarrett's oesophagus\\nmechanical design\\nsurgical robot\\nconfocal endomicroscopy\\nimage mosaicing\",\"337\":\"force\\nmathematical model\\nstress\\nanalytical models\\nprototypes\\ntesting\\ncontrol systems\\nbending\\nbuckling\\nfinite element analysis\\nmicromanipulators\\nmotion control\\nflexure-based micromotion stage system\\nconstant output force\\nfolded leaf flexure\\nflf\\npositive-stiffness structure\\nnegative-stiffness structure design\\nbuckling characteristics\\nzero-stiffness structure\\nfea simulation\\n3d printing process\\nmotion repeatability\\nmicro-motion stage\\nzero stiffness\\nconstant force\\ncompliant mechanisms\\nmicro-\\/nanopositioining\",\"338\":\"admittance\\ntrajectory\\ntools\\nforce control\\nmanipulator dynamics\\nrobustness\\ncompliance control\\nelectric admittance\\niterative learning control\\niterative methods\\nmanipulators\\nrobotic assembly\\ntorque control\\niteratively learned temporally scaled force control\\niltsfc\\nunstructured environments\\nrobotic assembly tasks\\ncompliance\\nadmittance control schemes\\ncontact forces\\ncontact torques\\niterative learning controllers\\nabb yumi\\ndual-arm collaborative robot\",\"339\":\"gaussian processes\\nrobots\\nanalytical models\\nkernel\\ntraining\\npredictive models\\ntrajectory\\nrobot dynamics\\nprobabilistic data-driven model\\nmodel planar pushing interaction\\nvariability\\ninput-dependent noise\\nvariational heteroscedastic gaussian processes\\nvhgp\\nstochastic function\\naccurate models\\nquasi-static assumption\",\"340\":\"system recovery\\nelectromyography\\nrobustness\\nmanufacturing systems\\npetri nets\\nsystem performance\\nassembling\\ndistributed processing\\nlarge-scale systems\\nsearch problems\\ndistributed approach\\nautomated manufacturing systems\\ncomplex structures\\nams\\nflexible routes\\nassembly operations\\ndeadlock resolution\\nsearch-based procedure\",\"341\":\"agriculture\\nvegetation mapping\\nfeature extraction\\nsugar industry\\nsoil\\npipelines\\nindexes\\nagrochemicals\\nautonomous aerial vehicles\\nfarming\\nimage classification\\nmobile robots\\nuav-based crop classification\\nweed classification\\nunmanned aerial vehicles\\nsmart farming applications\\nfarm land monitoring\\nper-plant basis\\nherbicides\\npesticides\\nfarmer central information\\nautonomous agriculture robots\\nsurvey capabilities\\nsugar beets\\nvegetation detection\\nplant-tailored feature extraction\\ncrop distribution estimate\\ngermany\\nswitzerland\\nindividual plant classification\",\"342\":\"robot sensing systems\\nproposals\\nsupport vector machines\\nfeature extraction\\ntraining\\nautomation\\nimage registration\\nimage segmentation\\nindustrial manipulators\\nlearning (artificial intelligence)\\nobject detection\\npose estimation\\nrobot vision\\nwarehouse automation\\nversatile part handling\\nnimbro picking\\namazon picking challenge 2016 tasks\\ndeep-learning approach\\nsemantic segmentation\\none item model registration method\\n6d item model registration\\nannotated dataset\",\"343\":\"trajectory\\nplanning\\ninspection\\ncomputational modeling\\nservice robots\\nunderwater vehicles\\nautonomous underwater vehicles\\ngraph theory\\ninteger programming\\nmobile robots\\npath planning\\ntelerobotics\\ntravelling salesman problems\\nnonentangling path planning\\ntethered underwater vehicles\\nnonentangling travelling salesperson problem\\nne-tsp\\nmixed integer programming model\\nhomotopy augmented graphs\\noptimal trajectory planning\\nseabotix vlbv300 underwater vehicle\\nhuman-generated paths\\nrov\\nauv\\nautonomous underwater vehicle\",\"344\":\"conferences\\nautomation\\ntv\\nactuators\\ncontrol system synthesis\\nobservers\\nposition control\\nrobust control\\nvariable structure systems\\nrobust position control problem\\nseries elastic actuators\\nsmc-based robust position controller design\\nsliding mode controller design\\nsecond-order disturbance observer\\ndob\\nsecond-order successive derivatives\\nposition control system dynamic model\\ntwo-mass-spring-damper system\\nnoncollocated disturbances\\ncontrol signal chattering\\nsea-position control performance\\nplant uncertainties\",\"345\":\"legged locomotion\\ndamping\\nsprings\\nmathematical model\\nforce\\npneumatic systems\\nestimation theory\\nfeedback\\nkalman filters\\nmotion control\\nnonlinear control systems\\npendulums\\nsprings (mechanical)\\nnatural springy motion\\nrobotic leg\\ndamping factors\\nspring-loaded-inverted pendulum model\\nslip model\\nlegged robots\\ncontrol algorithm\\nkalman filter\\nlongitudinal velocity estimation\\npositive feedback\\nnonlinear frictions\",\"346\":\"legged locomotion\\nthree-dimensional displays\\nadhesives\\nmanufacturing processes\\nforce\\nrobot sensing systems\\ncompliant mechanisms\\nmicrorobots\\nrapid prototyping (industrial)\\nthree-dimensional printing\\n3dflex\\nrapid prototyping\\nmultimaterial compliant mechanisms\\nsmall-scale robot design\\nsmall-scale robot fabrication\\nrigid components\\n3d printing\\nflexures\\nwalking quadrupedal millirobot\",\"347\":\"springs\\npotential energy\\nforce\\nactuators\\nmathematical model\\nrobots\\nprototypes\\nbuckling\\ncontrol system synthesis\\nelasticity\\nlinear systems\\nmechanical variables control\\nsprings (mechanical)\\nbi-stable mechanisms\\nmultiple stiffness\\ncontrolled spring buckling\\nanimal kingdom\\nrobotics\\nmechanism design\\nlinear springs\",\"348\":\"tendons\\ntrajectory\\nrobots\\nshape\\ngeometry\\nfinite element analysis\\ngrasping\\nactuators\\ncompliance control\\ncontrol system synthesis\\nelastic constants\\ngrippers\\nrapid prototyping (industrial)\\ntrajectory control\\nstiffness design\\nfingertip trajectories\\nunderactuated modular soft hands\\nflexible joint stiffness\\npredefined trajectory tracking\\ntendon-driven underactuated passively compliant hands\\ndeformable joints\\nrigid links\\nspecific stiffness\\nsingle-cable actuation\\nsoft joints realization\\nrapid prototyping techniques\\nstiffness computation\\ntendon-driven hand mechanics\\ncompliant systems\\nbeam theory\\nrobotic soft-sixthfinger\\nwearable robot\\ngrasping compensation\\nparetic hand\\npatients\",\"349\":\"robot sensing systems\\natomic measurements\\nthree-dimensional displays\\nprobabilistic logic\\nsurface reconstruction\\natomic beams\\ncollision avoidance\\nimage reconstruction\\nimage representation\\nmobile robots\\nprobability\\nrobot vision\\nslam (robots)\\nstereo image processing\\natommap\\nprobabilistic amorphous 3d map representation\\nrobotics\\n3d grid structure\\ncollision queries\",\"350\":\"kernel\\ntraining data\\nbayes methods\\ntraining\\nthree-dimensional displays\\ndata models\\npredictive models\\nbelief networks\\ncartography\\ndata structures\\ninference mechanisms\\nmobile robots\\npath planning\\npredictive control\\nprobability\\nbayesian generalized kernel inference\\n3d occupancy maps\\nnoisy range sensor data\\npredictive model\\noccupancy probability\\nquery point\\nmotion planning\",\"351\":\"three-dimensional displays\\nclutter\\nsolid modeling\\npose estimation\\nuncertainty\\ncost function\\nimage colour analysis\\noptimisation\\nrendering (computer graphics)\\nrobot vision\\ndeliberative object pose estimation\\nfundamental robot perception task\\n3d-models\\nrgb-d data\\nmultiobject pose estimation\\nobject rendered scenes\\ndeliberative perception methods\\nextraneous unmodeled clutter\\nuncertainty-aware localization\",\"352\":\"covariance matrices\\nsparse matrices\\nbayes methods\\ncorrelation\\ncomputational modeling\\ntraining\\nmarkov random fields\\ncartography\\ndigital elevation models\\ngaussian processes\\nmarkov processes\\nsensor fusion\\nconditionally independent submap coupling\\nlarge-scale 2.5d mapping\\ngaussian markov random fields\\ngmrf\\nlarge-scale 2.5d map building\\nspatial correlations\\ndata fusion\\noptimal submapping strategies\\ncovariance-form\\ngaussian process\\nconditional independence property\\nglobal 2.5d map\\noptimal information propagation\\ncanadian digital elevation data\",\"353\":\"training\\nthree-dimensional displays\\noptimization\\nvisualization\\nsupervised learning\\nsolid modeling\\nrobots\\nfeature extraction\\nlearning (artificial intelligence)\\nnatural scenes\\nneural nets\\nobject recognition\\nrobot vision\\nslam (robots)\\ndescriptor learning\\nlarge scale localization\\naugmented reality systems\\nar systems\\nsparse keypoint-based visual maps\\nlarge-scale visual place recognition\\nloop-closure\\ndescriptor compression\\nneural networks\\nresource-constrained robotics applications\\nlinear projection\\nlower-dimensional euclidean space\\ncontextual appearance information\\nvisual feature\\nscene changes\\nillumination changes\",\"354\":\"image edge detection\\nfeature extraction\\nthree-dimensional displays\\ncameras\\nrobot kinematics\\nbuildings\\nimage matching\\nmobile robots\\nparticle filtering (numerical methods)\\nrobot vision\\nsensor fusion\\nsensor placement\\nstereo image processing\\nflag\\nfeature-based localization between air and ground\\ngps-denied environments\\nrobot systems\\ndead-reckoning\\nrelative mapping\\nglobal pose estimate\\nglobal position update computing\\nfeature matching\\naerial image features\\nstable descriptorless features\\nvertical structure\\nground robot\\nunmapped areas\\noverhead imagery\\nmultiple-hypothesis data association\\nparticle filter\\ndata association error recovery\\nodometry uncertainty\\nstereo system\\nvertical feature based global positioning approach\",\"355\":\"cameras\\ncomputer vision\\nrobot vision systems\\nproposals\\nimage motion analysis\\noptical imaging\\nimage recognition\\nlearning (artificial intelligence)\\nmotion estimation\\nrobot vision\\naction recognition\\nstatic datasets\\nmoving robots\\ndeep learning models\\nbackground cues\\nstationary camera\\nautonomous robots\\ncamera motion\\nconvnet framework\",\"356\":\"probabilistic logic\\ndatabases\\nnearest neighbor searches\\nvisualization\\nsimultaneous localization and mapping\\nrobustness\\nbinomial distribution\\nimage classification\\nimage matching\\nimage retrieval\\nprobability\\nvisual place recognition\\nprobabilistic voting\\nscoring concept\\nnearest neighbor descriptor voting\\nplace matching\\nbinomial distribution model\\nloop closures\\n2d-2d image matching\\n2d-3d landmark matching\\nnearest neighbor retrieval techniques\",\"357\":\"visualization\\nuncertainty\\nrobots\\nnavigation\\nmeasurement\\npath planning\\nrobustness\\nautonomous aerial vehicles\\nrobot vision\\ntrajectory control\\nmap quality evaluation\\nvisual localization\\nkeypoint-based mapping systems\\nmap data generation\\nvisual landmark-based mapping\\nquery pose\\nfixed-wing unmanned aerial vehicle\\nuav\\nbelief based path planning framework\",\"358\":\"training\\nrobots\\ncomputational modeling\\nobject recognition\\nmachine learning algorithms\\ntraining data\\nstandards\\nimage classification\\nlearning (artificial intelligence)\\nleast squares approximations\\nrobot vision\\nincremental robot learning\\nfixed update time\\nlifelong learning\\nrobotic agent learning\\nincremental variant\\nregularized least squares for classification\\nrlsc algorithm\\nmachine learning benchmark dataset\\nrobotic setting\",\"359\":\"search problems\\nmathematical model\\nsemantics\\nprobabilistic logic\\nvisualization\\nrobot sensing systems\\nfailure analysis\\nmobile robots\\ntemporal persistence modeling\\nobject search problem\\nfailure analysis problem\\ntpm\\nprobabilistic prediction\\nprobabilistic exponential distributions\\ngaussian component\\nprobable object locations\\nvisual observations\\ngps location data set\\nperson tracking\\nmultiobject tracking\\nmobile robot\\nsmall-scale household environment\",\"360\":\"conferences\\nautomation\\ncomputer vision\\nfeature extraction\\nimage classification\\nneural nets\\ndeep learning features\\nvisual place recognition\\ndeep learning techniques\\ncomputer vision domain\\ncnn architecture\\nconvolutional neural networks\\nspecific places dataset\\nsped\\ncondition-invariant features\\nviewpoint-invariant features\\nclassification problem\",\"361\":\"instruments\\nmagnetometers\\naccelerometers\\nsonar navigation\\nacceleration\\nangular velocity\\noptical sensors\\nfibre optic gyroscopes\\ngeomagnetism\\ninertial systems\\nmagnetometry\\nmicrocomputers\\nmicromechanical devices\\nstable adaptive attitude estimator\\nso(3)\\ntrue-north seeking gyrocompass systems\\nattitude adaptive identifier\\ninertial measurement unit\\n3-axis fiber optic gyroscope\\nfog\\n3-axis microelectromechanical systems\\nmems accelerometer\\noptical north-seeking gyrocompass\\nmicroprocessor system\\nlow-level raw sensor values\\nlinear-acceleration\\n3-axis angular-rate sensor data\\n3-axis linear acceleration sensor data\\n3-degrees of freedom\\n3dof\\nroll attitude\\npitch attitude\\nheading\\nearth magnetic field\\nstability proof\\nrotating imu configuration\\nmoving robotic vehicles\",\"362\":\"foot\\nlegged locomotion\\nsubstrates\\nforce\\nrobot kinematics\\nrobot sensing systems\\nadaptive control\\ncontrol engineering computing\\nfeature extraction\\nforce control\\ngyroscopes\\npath planning\\nsupport vector machines\\nground substrate classification\\nadaptive quadruped locomotion\\nterrains\\nfoot-ground contact force\\ngyroscope information\\nfeature vector extraction\\nsupport vector machine\\nsvm\\nquadruped walk gait\\ncentral pattern generators\\ncpg\\ncenter of gravity adjustment method\\ncog adjustment method\\nquadruped limb\\nswing phase\\nfoot path planning\\nlift height control\\nquadruped robot\\nbiodog\",\"363\":\"face\\ncameras\\nface detection\\nstreaming media\\nrobot vision systems\\nfeature extraction\\naerodynamics\\nairships\\nautonomous aerial vehicles\\nface recognition\\nhuman-robot interaction\\nobject detection\\nposition control\\nreal-time systems\\nrobot vision\\nthree-term control\\nvideo streaming\\nmonocular vision-based human following\\nminiature robotic blimp\\ngeorgia tech miniature autonomous blimp\\ngt-mab\\nhuman detection\\nhuman robot interaction\\nhri missions\\nblimp aerodynamics\\nhaar face detector\\nklt feature tracker\\nreal-time video stream\\n3d positions\\nvisionbased pid controllers\\nuav\\nunmanned aerial vehicles\",\"364\":\"robots\\nwearable sensors\\nwrist\\nmachine learning algorithms\\nactivity recognition\\nassisted living\\ncontrol engineering computing\\ngaussian processes\\ngesture recognition\\nhuman-robot interaction\\nmixture models\\nsupport vector machines\\ndaily activity recognition\\ninertial ring\\ninertial bracelet\\ncloud robotics\\ninertial measurement units\\nbody-worn activity recognition\\nunsupervised approach\\ndaily living\\ninertial sensors\\nclassification problem\\nk-mean\\ngaussian mixture model\\nintra-subject analysis\\ninter-subject analysis\\nsupport vector machine\\nrandom forest\\ncross validation analysis\\nleave-one-subject-out analysis\",\"365\":\"foot\\nestimation\\nkinematics\\nmathematical model\\nlegged locomotion\\nacceleration\\nthree-dimensional displays\\ngait analysis\\nreal-time inertial lower body kinematics\\nanatomical foot points\\nagile human locomotion\\nmeasurement system\\nrelevant information\\n3d body segment kinematics\\nspatiotemporal locomotion parameters\\nlocomotion patterns\\nprobabilistic ground contact estimation\\nbiomechanical foot model\\ninertial motion capturing method\\nimu data\\noptical motion capture system\\njumping sequences\\n3d kinematics estimation error\\nglobal accelerations\",\"366\":\"cameras\\nrandom variables\\nlighting\\nfeature extraction\\nsolid modeling\\nthree-dimensional displays\\nlenses\\ndistance measurement\\nmotion estimation\\npose estimation\\nphotometric patch-based visual-inertial odometry\\ndirect visual- inertial odometry algorithm\\nimage patch feature extraction\\nmeasurement residuals\\nimage intensity space\\nirradiance\\nimage pixels\\nrandom variable\\nphotometric residual\\ncamera response function\\nlens vignetting\\nunknown illumination gains\\nunknown illumination biases\\nhigh-precision ground truth\\npose estimation accuracy\\nestimation errors\",\"367\":\"robot sensing systems\\nlegged locomotion\\ndetectors\\ntarget tracking\\ntorso\\nprobabilistic logic\\napproximation theory\\nhuman-robot interaction\\nmobile robots\\nprobability\\nsensor fusion\\nrobust sensor fusion\\nhri partners\\nprobabilistic framework\\nmobile robot\\ncomplementary sensor modalities\\noccupancy grid approximation\\nprobability density function\",\"368\":\"stability analysis\\nunmanned aerial vehicles\\nload modeling\\ndelays\\ntrajectory\\nattitude control\\ncontrol theory\\nasymptotic stability\\nhelicopters\\nload lifting\\nattitude control delay\\nstabilization\\nquadrotor-load system\\ncontrol law gains\\nexponential stability\\nunmanned aerial vehicle\\nuav\\nrigid link\\ntensile forces\\n3d force\\nattitude inner loop\\nintegral action term\\nbattery drainage\\nunknown load mass\",\"369\":\"safety\\ntrajectory\\nplanning\\nshape\\ncollision avoidance\\npropellers\\nminimally invasive surgery\\nair safety\\naircraft control\\nautonomous aerial vehicles\\nhelicopters\\nmobile robots\\nmulti-robot systems\\ntrajectory control\\nsafe certificate-based maneuver\\nquadrotor team\\nsafety barrier certificate\\ncollision-free maneuver\\ndifferential flatness-based quadrotors\\ncontrol barrier function\\nnominal trajectory\\ncollision avoidance strategy\\nflight control\\nflight planning algorithm\\ntrajectory modification\\nprovable safety guarantee\",\"370\":\"trajectory\\ntracking\\nplanning\\niterative closest point algorithm\\nstate estimation\\nbase stations\\nthree-dimensional displays\\nhelicopters\\ntrajectory optimisation (aerospace)\\ncrazyswarm\\nnano-quadcopter swarm\\nsystem architecture\\nminiature quadcopters\\ndense formation indoors\\nmotion-capture marker arrangements\\ncompressed one-way data flow\\nsensor fusion\\ntrajectory planning\",\"371\":\"power cables\\nunmanned aerial vehicles\\nstability analysis\\nmanipulators\\nprototypes\\ngravity\\nautonomous aerial vehicles\\npropellers\\nuav\\npassive rotating hemispherical shells\\nphysical interaction\\npower tethering\\naerial inspection\\nmanipulations\\nexposed propeller\\npassive rotating spherical shell\\nlaboratory-based test flights\",\"372\":\"stability analysis\\npropellers\\nsensitivity\\nforce\\naerodynamics\\nrotors\\nblades\\nautonomous aerial vehicles\\nelectric motors\\nstability\\nvelocity control\\npiccolissimo\\nmicroaerial vehicle\\nself-powered flying vehicle\\nrigid bodies\\nmass distribution\\nrelative rotor speeds\\nhover stability\\ncartesian velocity control\\nrotation axis asymmetry\\nrotating bodies\\ndynamic model\\ncartesion controllable model\\nvertically controllable model\\nsize 28 mm\\nsize 39 mm\",\"373\":\"training\\nneural networks\\nsupervised learning\\nrobots\\nrobustness\\ntrajectory optimization\\nlearning (artificial intelligence)\\nadaptive control\\naerospace robotics\\ncontinuous systems\\nlarge-scale systems\\nlearning systems\\npredictive control\\ntrajectory optimisation (aerospace)\\nplato\\npolicy learning using adaptive trajectory optimization\\npolicy search\\nautonomous systems\\ncontinuous reset-free reinforcement learning algorithm\\ncomplex control policies\\nmodel-predictive control\\nadaptive training method\\nadaptive mpc\\nsimulated aerial vehicle tasks\",\"374\":\"kernel\\noptimization\\nbayes methods\\ngaussian processes\\nrobots\\nadaptation models\\nlearning (artificial intelligence)\\nautonomous aerial vehicles\\ndecision making\\nmobile robots\\nmonte carlo methods\\noptimisation\\nadaptive kernels\\nrobot control\\nactive policy search\\ntrial-and-error methodology\\nreinforcement learning\\nglobal optimization\\ngaussian process\\noptimal decision making\\nmonte carlo method\\nblack-box bayesian optimization\\nuav\",\"375\":\"navigation\\ntraining\\nvisualization\\nlearning (artificial intelligence)\\nthree-dimensional displays\\nphysics\\nrobots\\npath planning\\nrobot vision\\ntarget-driven visual navigation\\nindoor scenes\\ndeep reinforcement learning\\nactor-critic model\\nai2-thor framework\\nhigh-quality 3d scenes\\nphysics engine\\nreal robot scenario\",\"376\":\"learning (artificial intelligence)\\nadaptive control\\nstability analysis\\nrobot control\\nadaptation models\\nstandards\\nfeedback\\nmanipulators\\nrobust control\\nrobust stability approach\\nrobot reinforcement learning\\nstabilizing controllers\\ncontroller stabilization\\nfeedback controller\\nmodel-based control\\nrobot manipulator\",\"377\":\"robots\\nglobal positioning system\\nneural networks\\nlearning (artificial intelligence)\\nsupervised learning\\ntraining\\noptimization\\nneurocontrollers\\nreset-free guided policy search\\ndeep reinforcement learning\\nstochastic initial states\\nautonomous learning\\nrobotic skill learning\\ngeneral-purpose neural network policies\\ngps algorithm\\nhigh-dimensional neural network policies\\nimage pixels\",\"378\":\"global positioning system\\nrobots\\ntrajectory\\nvisualization\\ntraining\\nsearch methods\\nstochastic processes\\nfeedback\\nlearning (artificial intelligence)\\nmanipulator dynamics\\nneural nets\\noptimal control\\npath planning\\nsampled data systems\\ntorque control\\npath integral guided policy search\\npath integral gps\\ncomplex feedback control policy learning\\nmotor torques\\nmanipulation tasks\\ndiscontinuous contact dynamics\\niterative optimization\\nmodel-free local optimizer\\npath integral stochastic optimal control\\npi2\\non-policy sampling\\ndeep neural network policy learning\\ndoor opening task\\npick-and-place task\\nlqr-based local policy optimizer\\nvision-based robotic manipulation skills\",\"379\":\"robots\\ntraining\\ninstruction sets\\nlearning (artificial intelligence)\\nneural networks\\nsafety\\nheuristic algorithms\\nmanipulators\\ndeep reinforcement learning\\nrobotic manipulation\\nasynchronous off-policy updates\\nautonomous robots\\nhand-engineered policy representations\\nhuman-supplied demonstration\\nsample complexity\\ndeep q-functions\\n3d manipulation skills\",\"380\":\"atmospheric modeling\\nvehicle dynamics\\ndynamics\\natmospheric measurements\\npollution measurement\\ndispersion\\nrobot sensing systems\\nautonomous aerial vehicles\\ncontrol system synthesis\\ndecentralised control\\nmobile robots\\noptimal control\\nparameter estimation\\noptimized vehicle-specific trajectories\\ncooperative process estimation\\nsensor-equipped uavs\\nsequential optimum design approach\\natmospheric dispersion process model\\nlocally optimal waypoint sequences\\nuav heterogeneous motion dynamics\\ndecentralized data-driven online control scheme\\nwaypoint calculation\\nvehicle control\",\"381\":\"robots\\nconferences\\nautomation\\nintelligent systems\\nmechanical engineering\\nmagnetic fields\\nforce\\nmagnetic resonance imaging\\nmedical robotics\\nmicrorobots\\nmagnetic millirobot\\nconstant unidirectional magnetic field\\nmagnetic untethered millirobots\\nremote magnetic fields\\nmedical applications\\nmri systems\\n3d gradient coils\\nmagnetic robots\\nuntethered devices\\nactuation methodology\\norientation control\\nspherical permanent magnet\\n3d magnetic field gradients\\n3d planar case\\nopen-loop control\\n2d field gradients\",\"382\":\"kinematics\\nplanning\\ntrajectory\\noptimal control\\nrobot kinematics\\nheuristic algorithms\\nfeedback\\nlinear quadratic control\\nmanipulators\\nmobile robots\\ntime-varying systems\\ntrajectory control\\nkinematic planning\\nmobile manipulators\\nnonholonomic constraints\\nholonomic operational-space tracking constraints\\nwhole-body trajectories\\ntime-varying kinematic feedback controllers\\nconstrained sequential linear quadratic optimal control problem\\ncontinuous-time formulation\\nadaptive step-size integrators\\nlinear complexity\\nkinematic trajectory planning problems\\n26 dof wheeled robot\\nconstrained slq\\nreceding-horizon optimal control fashion\",\"383\":\"predictive models\\ncomputational modeling\\nmathematical model\\nrobots\\nadaptation models\\ndeformable models\\nfriction\\ngeometry\\nimpact (mechanical)\\nindustrial manipulators\\nmotion control\\nshear modulus\\nempirical evaluation\\ncommon-contact models\\nplanar impact\\npredictive performance evaluation\\nrigid body impact models\\nreal planar impacts\\nmotion tracking system\\nperformance evaluation\\npostimpact momentum prediction\\nparametric model\\ngeometric model\\nhybrid impact model\\nconsensus model\\nposthoc model\\nupper bound\\ncombined predictive models\\nperturbation analysis\\nbifurcations\\nstate space regions\",\"384\":\"planning\\nnickel\\nmanipulators\\nkinematics\\nprobabilistic logic\\nbuildings\\npath planning\\nprobability\\nredundant manipulators\\nrobot vision\\noptimal-sampling-based manipulation planning\\nobject releasing\\nobject grasping\\nmultimodal planning problem\\nhigh-dimensional configuration space\\nglobal asymptotically optimal manipulation planner\\noptimal sampling-based roadmap planners\\nconfiguration space\\nprobabilistic completeness\\npick-and-place scenario\",\"385\":\"thumb\\ntendons\\nsprings\\nrobots\\nactuators\\ngrasping\\ncompliance control\\nmanipulators\\nsimplified compliant anthropomorphic robot hand design\\nscca hand\\nmotor robot hand\\nminimalist design\\ngrasping abilities\\nbidirectional tendon underactuated finger design\\nbiases actuator\\nadditive manufactured monocoque steel construction\\nseries elastic actuation\\nshock absorption\\nanthropomorphic speed\\ncanonical grasps\",\"386\":\"planning\\nrobots\\napproximation algorithms\\ncollision avoidance\\noptimization\\nkinematics\\ngeometry\\nmanipulators\\npath planning\\nhierarchical fingertip grasp planning\\ncollision-free path\\nrobot hand-arm system\\nbidirectional sampling\\nmotion planning\\nhierarchical contact optimization process\\ngrasp optimization\\ncollision-free configurations\\nmotion planner\\n13-dof manipulator\",\"387\":\"tendons\\njoints\\ntorque\\nsprings\\nactuators\\nrobot sensing systems\\nmanipulators\\nstability\\nstiffness control bounds\\nrobotic hands\\ncoupled finger joints\\ntendon-driven strategies\\ntendon driven robotic fingers\\ncompliant tendons\\nmultiarticular coupling\\nserial chain linkages\\ncoupled passive joint stiffnesses\\nachievable stiffness control boundaries\\ncompliance elements\\nmechanical springs\\ntransmission strategies\\ntendon routing\\npulley radii\\nintrinsic stability\\ncustomizable controller stiffness limits\\nmanipulation\",\"388\":\"grippers\\nthumb\\ncouplings\\nmathematical model\\nfriction\\nrobots\\ndexterous manipulators\\nmanipulator kinematics\\nposition control\\ntwo-fingered robot gripper\\nobject reorientation range\\ngrasped objects\\nhand-object system\\nkinematic parameter search optimizations\\ntopology\\nternary joints\\nin-hand planar reorientation capabilities\",\"389\":\"kinematics\\njacobian matrices\\ntrajectory\\nviscosity\\nlegged locomotion\\nsprings\\nfoot\\nhumanoid robots\\nrobot dynamics\\nrobot kinematics\\nviscoelasticity\\nstructure-variability\\nhumanoid\\nresolved viscoelasticity control\\nrvc\\nvirtual viscoelasticity\\njoint viscoelasticity\\nopen kinematic chain\\nrobust walking motion\\nuneven terrains\\nforward dynamics simulations\",\"390\":\"trajectory\\nrobots\\noptimization\\nshape\\nmathematical model\\ngaussian distribution\\nstandards\\ncollision avoidance\\nhumanoid robots\\nmanipulators\\nmotion control\\noptimisation\\ncontext-driven movement primitive adaptation\\nhumanlike robot skills\\ntask variations\\ntrained environment changes\\nmotion primitives\\ncontext changes\\nhumanlike motion characteristics\\noptimization technique\\nkullback-leibler divergence\\nobstacle avoidance\\nbroken joint scenarios\",\"391\":\"legged locomotion\\noptimization\\nsupervised learning\\ntraining\\ntesting\\nrobot kinematics\\ncontrol system synthesis\\ncontrollers\\nlearning (artificial intelligence)\\nstability\\nstabilizing underactuated bipedal robot locomotion\\nwave field\\ncontrol policy\\ndynamic walking\\nfull dynamic model\\nvirtual constraints\\nparameter optimization\\ntorque limits\\nfriction cone\\nenvironmental conditions\\nstable periodic walking gaits\\naperiodic gaits\\n3d bipedal robot\\nstable controllers\",\"392\":\"acceleration\\nmeasurement\\njacobian matrices\\nellipsoids\\nrobot kinematics\\ndynamics\\nfriction\\nlegged locomotion\\nmanipulators\\nmatrix algebra\\ndynamic manipulability\\ncenter of mass\\nunilateral contacts\\nfriction cones\\nrobot configuration\\ninertial parameters\\ncom acceleration space\\nweighting matrix\\nlegged robots\",\"393\":\"legged locomotion\\nfoot\\ncomputational modeling\\nmathematical model\\npredictive models\\ndynamics\\ngait analysis\\nhumanoid robots\\nnonlinear control systems\\nrobust control\\nnonlinear forward models\\ndynamic walking\\nnatural walking gaits\\nappropriate foot placement\\nadams\\nopen dynamic engine\\nconventional bent-knee style\",\"394\":\"legged locomotion\\ntrajectory\\nswitches\\nstability analysis\\npower system stability\\nhardware\\nrobot dynamics\\ninvariant funnels\\nunderactuated dynamic walking robots\\nphase variable\\nexperimental validation\\ntransverse dynamics\\nsum-of-squares verification\",\"395\":\"legged locomotion\\nrobustness\\nmathematical model\\ntrajectory\\nmodulation\\nhumanoid robots\\nmotion control\\npredictive control\\nrobust control\\nrobust bipedal locomotion control\\nmodel predictive control\\nmpc\\ndivergent component of motion\\ndcm\\ncenter of pressure\\ncop manipulation\\nstep adjustment\\ncentroidal moment pivot\\ncmp modulation\\nwalking controller\",\"396\":\"propulsion\\nsurges\\nforce\\nunderwater vehicles\\nreal-time systems\\ndamping\\nbiomimetics\\nmultivariable systems\\nvehicle dynamics\\nvelocity control\\nbiomimetic underwater vehicle\\nadrc\\nbuv\\nundulatory fins\\nuncertain model\\nmechanical structure\\nvehicle kinematics models\\nvehicle dynamics models\\nline-of-sight guidance system\\nlos guidance system\\nactive disturbance rejection control\\nlos principle\\nmultivariable system\\nspeed controller\\ncourse controller\\npath following control\",\"397\":\"robot sensing systems\\nmathematical model\\nstochastic processes\\nbiological system modeling\\ndifferential equations\\nwheels\\nbiomimetics\\nmobile robots\\nsensors\\nbraitenberg vehicles\\nreal world robotic implementations\\nbioinspired local navigation\\nsensor based control strategies\\nsensor noise\\nstochastic environments\\ndrift-diffusion model\\nbiological source seeking controller\\nnonholonomic robots\\nstochastic differential equations\\nbioinspired source seeking controller\\nbehaviour simulation\\ndeterministic equations\",\"398\":\"robots\\nshape\\nmathematical model\\ndynamics\\nfriction\\ntracking\\nnumerical models\\nangular velocity control\\nclosed loop systems\\ncollision avoidance\\nmobile robots\\nmotion control\\nrobot dynamics\\nclosed-loop path following\\ntraveling wave rectilinear motion\\nobstacle-strewn terrain\\nhigh-level closed-loop traversal\\ngait shapes\\nfunctional mapping\\ngait parameter space\\naveraged steady-behavior body velocities\\nsystem dynamics\\nfixed forward-velocity unicycle\\naverage body curvature\\ncontrol input\\nangular body velocity modulation\\ntarget body velocities\\nnontrivial planned path tracking\\naverage body curvature commands\\nautonomous path following\\nphysical multilink robotic snake\\nobstacle arrangements\",\"399\":\"legged locomotion\\nheat-assisted magnetic recording\\ntrajectory\\nactuators\\nfrequency control\\nvoltage control\\nmicrorobots\\nnonlinear control systems\\ntrajectory control\\nhigh speed trajectory control\\nexperimental maneuverability model\\ninsect-scale legged robot\\noff-board trajectory controller\\nzero-radius turns\\nholonomic control\\nharvard ambulatory microrobot\\nhamr\\nnonlinear response\\nrms position error\",\"400\":\"robot sensing systems\\nvisualization\\nneurons\\ncameras\\nhead\\nimage coding\\nlearning (artificial intelligence)\\nmobile robots\\nrobot vision\\nmultisensory cue integration learning\\ndevelopmental robotics\\naec framework\\nactive efficient coding\\nvisual system\\nimage stabilization\\noptokinetic response\\nokr\\nvestibulo-ocular reflex\\nvor\\nsparse coding algorithm\\nmotor behavior\\nstabilization performance\",\"401\":\"robots\\npublic transportation\\nalgorithm design and analysis\\nhidden markov models\\nprobability distribution\\ncomplexity theory\\nclassification algorithms\\nmobile robots\\nwind tunnels\\nadaptive levy taxis\\nodor source localization\\nrealistic environmental conditions\\ngas concentration fields\\nalt\\nodor plume tracking\\ncorrelated random walk\\nrobotic platform\\nlatter algorithms\\nodor concentration threshold\\nwind tunnel\",\"402\":\"attitude control\\naerodynamics\\nanimals\\nabdomen\\nrobot kinematics\\nautonomous aerial vehicles\\nbiomimetics\\nclosed loop systems\\ndrag\\nfeedback\\nlinearisation techniques\\nmobile robots\\nnonlinear control systems\\nrobot dynamics\\ntelerobotics\\nrousettus aegyptiacus\\nrobotic landing\\nbat landing maneuvers\\nmicroaerial vehicle\\nallice\\ncenter of gravity\\ncenter of pressure\\nnonlinear closed-loop feedback\\nnonlinear control law\\ninput-output feedback linearization\\nattitude regulations\\ncg-cp distance\\nnewton-euler dynamic model\\naerodynamic coefficients\\nlift\\nmav\",\"403\":\"target tracking\\nkalman filters\\nnavigation\\nmobile robots\\nrobot sensing systems\\nautoregressive processes\\nneurocontrollers\\nposition control\\npredator-prey systems\\nrobots\\nprey-predator model\\nrobot tracking\\nrobotics research\\nhead direction\\npursuer speed\\nonline adaptive autoregressive model\\nonline adaptive echo state network\\nperception uncertainty\",\"404\":\"electron tubes\\noptical imaging\\ntracking\\nvideos\\noptical filters\\nbiomedical optical imaging\\noptical recording\\nbotany\\ncellular biophysics\\nfeature extraction\\nimage matching\\nimage motion analysis\\nimage sequences\\nmicrorobots\\nmotion control\\nmulti-robot systems\\nobject tracking\\noptical microscopes\\nrobot vision\\nvegetation\\npollen tube vesicle motion measurement\\nparticle tracking\\nswarm control\\ndynamic biological processes\\nlife sciences\\nseed plants\\nmale gametophyte\\nplant growth\\ncellular behavior\\nvesicle function\\nvesicle interactions\\nvesicle tracking\\nspatiotemporal image analysis\\nhigh-quality images\\nconstant velocity\\nin vivo tracking\\nspatial distortions\\ntemporal distortions\\npollen tube growth\\noptical flow\\nimage streaming\\nconfocal microscopes\\nvesicles intracellular motion\\nlocal displacement vector field\\nkanade-lucas-tomasi feature matching\\nklt feature matching\\nbiological systems\",\"405\":\"medical services\\nrobot sensing systems\\nrobot kinematics\\ncollision avoidance\\nmobile communication\\nmanipulators\\nbiohazards\\ndiseases\\nhealth care\\nintelligent control\\nmedical robotics\\nmobile robots\\npatient care\\ntelerobotics\\ntelenursing mobile manipulator\\nremote care-giving\\nquarantine areas\\ncontagious diseases\\nhealth care workers\\nremote-controlled robots\\nhazardous clinical areas\\ntelerobotic intelligent nursing assistant\\ntrina\\nhuman operator console\\noperator assistance algorithms\",\"406\":\"probes\\ntrajectory\\nthree-dimensional displays\\nrobots\\nsurface reconstruction\\ncameras\\nsurgery\\nendoscopes\\nimage fusion\\nimage reconstruction\\nimage segmentation\\nmedical image processing\\nmedical robotics\\nstereo image processing\\nvideo streaming\\nvisual servoing\\nautonomous scanning\\nendomicroscopic image mosaicing\\n3d fusion\\nrobot-assisted minimally invasive surgery\\npick-up endomicroscopy probe\\nvideo mosaicing\\nda vinci\\u00ae surgical robot\\ndvrk framework\\nprobe motion\\nimage streaming\\n3d stereo reconstruction\\nmulti-scale image visualisation\",\"407\":\"coils\\nmanipulators\\nmathematical model\\nmobile communication\\nmagnetic hysteresis\\nthree-dimensional displays\\nbandwidth\\ncatheters\\nfinite element analysis\\nmagnetic actuators\\nmean square error methods\\nmedical robotics\\nsteering systems\\nbigmag\\n3d magnetic actuation\\nflexible surgical manipulators\\nremote actuation\\nelectrical subsystem\\ncontinuum manipulators\\nmedical purposes\\n3d mobile coil arrays\\nfinite element data\\nmeasurement-based correction\\nmaximum observed mean error\\nrotating field\\nfield estimation\\n3d trajectories\\nmagnetic catheter actuation\\nuser-controlled steering\",\"408\":\"catheters\\nload modeling\\nmathematical model\\noptimization\\nrobots\\nmagnetic resonance imaging\\nnumerical models\\nbiomedical mri\\ncontinuum mechanics\\nmedical robotics\\nphysiological models\\ncatheter prototype\\nflexible joints\\nrigid links\\ncontinuum catheter\\natrial fibrillation\\ncatheter ablation\\nvisualization\\nremote steering\\nrobotic catheter system\\nmri-actuated catheter\\npseudorigid-body model\",\"409\":\"force\\nacceleration\\nmanipulators\\nmuscles\\ntrajectory\\nimpedance\\nend effectors\\nmedical robotics\\nmotion control\\npatient treatment\\nrobot assisted tapping control\\ntherapeutical percussive massage\\nrobotic tapping motion\\nhuman muscle contact\\nrobot end-effector\\nrobot manipulator\\nonline trajectory generator\\notg\\nimpedance control\\nhuman safety\\niceira lab\\nntu\\ncartesian space teach function\",\"410\":\"tools\\nmathematical model\\ntrajectory tracking\\nvisual servoing\\nsurgery\\nmedical robotics\\npath planning\\nrobot vision\\nvisual servoing controller\\ntime-invariant 3d path following\\nmotion constraint remote centre\\nrcm\\nmedical robotic systems\\nminimal invasive surgeries\\npath following controller\\nsurgical tasks\\ntask priority controller\\nexteroceptive sensor\",\"411\":\"object detection\\nimage color analysis\\ntraining\\nland vehicles\\nrobot sensing systems\\ncomputer vision\\nagricultural products\\nconvolution\\nneural nets\\ndeep fruit detection\\norchards\\nimage based fruit detection system\\nhigher level agriculture tasks\\nfaster r-cnn\\nmangoes\\nalmonds\\napples\\ndata augmentation\\ndeep convolutional neural network\\nimagenet features\\ntiling approach\",\"412\":\"robot sensing systems\\nnavigation\\nagriculture\\ncameras\\npayloads\\ncrops\\ngenetic engineering\\nindustrial manipulators\\nrobotanist\\nground-based agricultural robot\\nhigh-throughput crop phenotyping\\ncrop physiological traits\\ncrop morphological traits\\nfield-based robotic phenotyping\\ngenotypes\\nphenotypes\\nmanipulator\\nplant stalk strength\\nnoncontact sensors\\nsorghum bicolor test plots\\nsouth carolina\\nusa\",\"413\":\"octrees\\nnavigation\\nrobot sensing systems\\nray tracing\\nthree-dimensional displays\\nplanning\\ncomplexity theory\\nautonomous aerial vehicles\\ndivide and conquer methods\\nhelicopters\\nmobile robots\\npath planning\\ntelerobotics\\noctree-based occupancy maps\\nenvironment sparsity\\naerial robot navigation\\nautonomous navigation\\nray tracing method\\nprobabilistic map update\\ndivide-and-conquer volume occupancy inquiry method\\noptimization-based trajectory generation\\noctomap\\nautonomous quadrotor flight\",\"414\":\"service robots\\ncameras\\ndatabases\\nrobot vision systems\\nmobile robots\\ncomputer software\\noperating systems (computers)\\nsensors\\nwheelchairs\\nwheelchair robot\\nautonomous control\\nfetch-and-give task\\nsensor embedding\\nrobot operating system\\ntms functions\\nrobot town project\\ntown management system\\nmanagement system development\\ninformationally structured environment\\nros-tms\\nhardware platforms\\nsoftware platforms\\nbig sensor box\\niort platform\",\"415\":\"bridges\\nground penetrating radar\\ninspection\\nrobot sensing systems\\nerbium\\nbridges (structures)\\ncondition monitoring\\nlearning (artificial intelligence)\\nmaintenance engineering\\npattern recognition\\nrebar\\nroad safety\\nrobots\\nsteel\\nautonomous robotic system\\nnon-destructive evaluation methods\\nbridge deck inspection\\nbridge condition assessment\\nhighway road quality maintainance\\npublic transport\\nbridge deterioration\\naging material\\nenvironmental wear\\nstructure inspection\\nmechanical robot design\\nmachine learning\\nautomated steel rebar picking\\ncorrosive deck environments\",\"416\":\"microchannels\\nmicroinjection\\naxons\\ntools\\nmicroscopy\\nfluorescence\\nsilicon\\nbiomems\\ncell motility\\nmicrochannel flow\\nneurophysiology\\noptical microscopy\\nhigh-precision microinjection\\nsuction microchannel\\nfluorescent microgel beads\\ncaenorhabditis elegans\\nconventional micromanipulation technique\\nnerve axon\\nhead-flrst navigation alignment\\nelectrotaxis\\nconfocal microscopy\",\"417\":\"wires\\nimpedance\\ngears\\nactuators\\nforce\\nsprings\\ntorque\\nsprings (mechanical)\\nwire-tension control\\ncompact planetary geared elastic actuator\\nseries elastic actuator\\nsea\\ncpea\\nspring\\nimpedance compensator\",\"418\":\"wires\\nrobot sensing systems\\nfriction\\nhysteresis\\nshape\\nestimation\\nbending\\ncable sheathing\\ncables (mechanical)\\nend effectors\\nfeedforward\\nropes\\ntension control\\ndual-wire scheme\\nbowden-cable transmission\\nbending-dependent hysteresis\\ncontrol performance degradation\\nbowden-cable hysteresis\\nsensing wire\\nbend angle estimation\\nactuation wire tension\\nsheath bending angle\\nfeedforward control scheme\\nend-effectors\",\"419\":\"couplings\\ntorque\\ncollaboration\\ncollision avoidance\\nsprings\\nmanipulators\\nhuman-robot interaction\\nmanipulator dynamics\\nstability\\ntorque control\\n6-dof collaborative robot arm design\\nhigh-power motors\\nweight-to-payload ratio\\nmanufacturing cost\\ninjury possibility\\nhuman-robot collision\\nlow-power driving units\\nspring-based counterbalance mechanism\\ndouble parallelogram linkage\\nslider-crank mechanism\\ncompact design\\ndurable design\\nrobot body\\nrobot link\\ndynamic simulation software\\njoint torques\\ncollision safety\\nenergy efficiency\",\"420\":\"wires\\nbrakes\\nservomotors\\nhaptic interfaces\\ntraining\\nforce\\nrobots\\nposition control\\nsport\\norientation control\\npassive wire-driven motion support system\\nservo brakes\\nwire-driven haptic devices\\nthin wires\\nsports training\\nservo motors\\nhuman-robot interaction\\npassive wire-driven system\\nrealistic motion support\\nuser motion\\npassive control\\nbrake tensions\\ntennis beginner\",\"421\":\"legged locomotion\\nsprings\\nattenuation\\nknee\\nacceleration\\nservomotors\\ncontrol system synthesis\\nimpact (mechanical)\\nparachutes\\ncompliant leg design\\nimpact attenuation\\nairdrop landings\\nquadruped robots\\nairdropped cargo\\nairborne landings\\nlumped element models\\nthree-segment leg\",\"422\":\"force\\nsprings\\nelectron tubes\\nactuators\\nrubber\\nrobots\\ncontracts\\nbuckling\\nmechanical products\\npassive returning mechanism\\ntwisted string actuators\\nuni-directional action\\npassive extension mechanisms\\nbuckling effect\\nnearly-constant extension force\",\"423\":\"cameras\\nindexes\\nadaptive systems\\nmechanical cables\\npulleys\\nrobot vision systems\\nrobots\\ncable-suspended camera system\\nadaptive cable-driven parallel robots\\naugmented kinematic redundancy\\nadaptive design\",\"424\":\"kinematics\\nwheels\\nmobile robots\\nvelocity control\\nactuators\\nconvergence\\nlyapunov methods\\nnonlinear control systems\\nposition control\\nrobot kinematics\\nskid-steered wheeled mobile robots\\nterrain types\\nnonlinear control law\\nterrain dependent kinematic model\\npath coordinates\\nkinematic parameters\\nkinematic path following control\\nlyapunov approach\\nlinear velocity control\\nactuator saturation\\nrobotnik summit xl\",\"425\":\"planning\\ncollision avoidance\\nadaptation models\\nmanipulators\\npredictive models\\ncomputational modeling\\nadaptive control\\ngaussian processes\\nlearning (artificial intelligence)\\nmixture models\\npath planning\\nadaptive motion planning\\nhigh-dimensional mixture models\\nsampling-based motion planning\\ncollision regions learning models\\ncollision-free regions learning models\\ngaussian mixture models\\ngmm\\nhigh-dimensional configuration spaces\\nrobotic manipulation\\nrrt planning algorithm\\nsampling-based planning methods\\nexperimental robot arm planning scenarios\",\"426\":\"trajectory\\nacceleration\\nrobot sensing systems\\nkinematics\\nservice robots\\nplanning\\nindustrial manipulators\\nmanipulator kinematics\\nmotion control\\npath planning\\ntime-varying systems\\ntrajectory control\\nonline trajectory planning\\ntime-variant motion constraints\\nindustrial robot manipulators\\nonline trajectory generation algorithm\\ntime-variant kinematic motion constraints\\nphysical robot constraints\\ntrajectory parameter adaptation\\nsensor integration\\nlow-level robot motion control\",\"427\":\"planning\\ncomputational modeling\\nstochastic processes\\naerospace electronics\\nrobots\\ndynamic programming\\nheuristic algorithms\\nasymptotic stability\\nlearning (artificial intelligence)\\noptimal control\\nstochastic systems\\nnongaussian continuous state-action systems\\nstochastic domains\\nplanning problem\\nasymptotic optimality\\nsimulated multimodal pushing problem\",\"428\":\"collision avoidance\\nplanning\\nvehicle dynamics\\nrobots\\naerodynamics\\nmonte carlo methods\\npath planning\\nprobability\\nset theory\\nlong-term stochastic dynamic predictions\\ndynamic risk tolerance\\nmotion planning\\nshort-term stochastic dynamic predictions\\ncollision-free path identification\\nstochastically moving obstacles\\ncollision probability\\ndrt\\ntime-varying upper bound\",\"429\":\"planning\\ndispersion\\napproximation algorithms\\nvisualization\\nimage edge detection\\nsearch problems\\nrobots\\ncomputational complexity\\ngraph theory\\nmanipulators\\npath planning\\n7 dof robot arm\\nmanipulation planning problems\\nlow-dispersion deterministic sequence\\n(r-disk) subgraphs\\ndense subgraphs\\nanytime search\\npath-planning algorithm\\ndense motion-planning roadmap\\nanytime motion planning\\ndensification strategies\",\"430\":\"planning\\noptimization\\ntrajectory\\nrobots\\nkernel\\ngaussian processes\\ncollision avoidance\\nmobile robots\\noptimisation\\nsampling methods\\nstochastic functional gradient\\nmotion planning\\ncontinuous occupancy maps\\nautonomous robotics\\ncollision free path\\nsampling-based methods\\ntrajectory optimization\\ngaussian process\",\"431\":\"decision making\\nsparse matrices\\ncovariance matrices\\nuncertainty\\njacobian matrices\\nsimultaneous localization and mapping\\ncomputational complexity\\nmatrix algebra\\nslam (robots)\\nstate-space methods\\nconsistent sparsification\\nhigh dimensional state spaces\\nbelief space planning\\nstate inference\\ninformation matrix\\nslam simulation\",\"432\":\"cameras\\nrobot vision systems\\nkinematics\\nmobile robots\\ncalibration\\nautomation\\nadaptive control\\nasymptotic stability\\nfeature extraction\\nimage sensors\\nlyapunov methods\\nrobot vision\\nunified leader-follower scheme\\nuncalibrated on-board camera\\nimage-based leader-follower formation control\\nadaptive control scheme\\nomnidirectional cameras\\nperspective cameras\\nfeature point\\nuncertain constant parameters\\nadaptive estimator\\nuniform semiglobal practical asymptotic stability\\nuspas\\nlyapunov approach\\nmobile robot\\nvisual servoing\",\"433\":\"mirrors\\ncameras\\nvisual servoing\\nmanganese\\nmathematical model\\nend effectors\\nrobot vision\\nmirror reflection\\ncatadioptric cameras\\ncamera field-of-view\\nprojection equations\\nend effector\",\"434\":\"probes\\nultrasonic imaging\\nstrain\\nforce\\nrobots\\nelastography\\nradio frequency\\ndiseases\\nhaptic interfaces\\nmedical image processing\\nmedical robotics\\ntumours\\nvisual servoing\\nrobotic control\\n3d quantitative ultrasound elastography\\nstiff tissues\\n3d ultrasound volumes\\nmedical 3d ultrasound probe\\nrobotic arm\\nautonomous palpation\\nonline elastography process\\nvolume of interest\\nvoi\\nvisual servoing control\\nhaptic device\\npatient diagnosis\\ntumor location\",\"435\":\"kinematics\\ngrasping\\nvisualization\\nsolid modeling\\nhumanoid robots\\ncalibration\\ncomputer graphics\\nerror analysis\\nmanipulator kinematics\\noptimisation\\npose estimation\\nrobot vision\\nstereo image processing\\ngrasping task visual servoing\\nvision-based grasping\\neye-to-hand kinematics configuration\\nposition estimation\\nhand-to-object relative pose measurement\\nrobust robot pose estimation\\n3d model-based stereo-vision algorithm\\nedge-based distance transform metric\\nsynthetically generated images\\nrobot arm-hand internal computer-graphic model\\nkinematic calibration errors\\nicub robot\\nvisual feedback\\nhumanoid grasping tasks\",\"436\":\"cameras\\nvisual servoing\\nvisualization\\nfeature extraction\\noptical imaging\\njacobian matrices\\nlearning (artificial intelligence)\\nneural nets\\nconvolutional networks\\nend-to-end visual servoing\\nimage based visual servoing\\nhand crafted visual feature extraction\\ndata driven methods\\nend-to-end learning based approach\\nquadrotor\\ncamera pose\",\"437\":\"cameras\\nbenchmark testing\\nvisualization\\nsimultaneous localization and mapping\\nglobal positioning system\\ncalibration\\ndistance measurement\\nimage sensors\\nslam (robots)\\nsynchronisation\\npenncosyvio\\nvisual inertial odometry benchmark\\nvio benchmark\\ndata synchronization\\nvi-sensor\\nstereo camera\\nimu\\nproject tango handheld device\\ngopro hero 4 camera\\nupenn singh center\\nhandheld rig\\nsimultaneous localization and mapping algorithm\\nglass surface\\noptic localization\\ndistance 150 m\",\"438\":\"simultaneous localization and mapping\\ntrajectory\\nalgorithm design and analysis\\nestimation\\noptimization\\ngraph theory\\noptimisation\\nrobot vision\\nslam (robots)\\nground truth system\\nmagnetic-sgd algorithm\\nstochastic gradient descent-based slam algorithm\\nmagnetic loop closures\\npose graph\\ngraph-based optimisation\\ngraphslam framework\\nslam systems\\nsimultaneous localisation and mapping\\nindoor magnetic field-based graphslam\",\"439\":\"simultaneous localization and mapping\\nservers\\ncollaboration\\ncameras\\ncomputer architecture\\nvisualization\\nautonomous aerial vehicles\\nmulti-robot systems\\nnatural scenes\\noptimisation\\nslam (robots)\\nmultiuav collaborative monocular slam\\nrobots team\\ncollaborative scene perception and mapping\\ncentralized architecture\\nunmanned aerial vehicles\\nlimited-memory slam\\ncomputational resources\\nground station\\ncentral server\\nloop closure\\nmap fusion\\noptimization\\ninformation distribution\\nkeyframe-based monocular slam algorithm\",\"440\":\"image edge detection\\ncameras\\nthree-dimensional displays\\nuncertainty\\nmathematical model\\nrobustness\\nsimultaneous localization and mapping\\ndistance measurement\\nedge detection\\nimage matching\\nobject tracking\\npose estimation\\nprobability\\nrobot vision\\nslam (robots)\\nstereo image processing\\ndirect monocular odometry\\nvisual odometry\\nmonocular camera\\ngeometry entity\\ntextureless environments\\nlighting changes\\ndepth map\\ntracking\\ncamera pose\\nphotometric error\\ngeometric error\\nedge matching\\nprobabilistic framework\\nstereo matching\\nslam\",\"441\":\"agriculture\\nimage reconstruction\\nsimultaneous localization and mapping\\nthree-dimensional displays\\nmonitoring\\ncameras\\nvisualization\\nagricultural engineering\\ncrops\\nimage fusion\\nimage motion analysis\\nimage resolution\\nprecision engineering\\nspatiotemporal phenomena\\nstereo image processing\\n4d crop monitoring\\nspatiotemporal reconstruction\\nautonomous crop monitoring\\nspatial temporal resolution\\nmultiview stereo algorithm\\nmotion algorithm\\nfield 3d structure reconstruction\\nlow-cost image sensors\\n4d reconstruction approach\\ndynamic scene spatiotemporal model\\nprecision agriculture applications\\ndata association algorithm\\nground-truth statistics\\nhigh-quality dataset\",\"442\":\"visualization\\nmeasurement\\nrobot sensing systems\\nnavigation\\ncovariance matrices\\ntime factors\\nautonomous aerial vehicles\\ncameras\\ncomputational complexity\\ngreedy algorithms\\ninertial navigation\\nmicrorobots\\nmobile robots\\npath planning\\nrobot dynamics\\nrobot vision\\nstate estimation\\nvisual attention\\ncognitive process\\nsensory data\\ncomputational approach\\nvin problem\\non-board camera\\ninertial sensor\\nresource allocation\\ntime constraints\\nenergy constraints\\nvisual cues\\nanticipation\\nforward-simulation\\ngreedy algorithm\\nformal performance guarantees:\\nagile microaerial vehicles\\nlocalization errors\\nvisual-inertial navigation\",\"443\":\"measurement\\ncameras\\nimage quality\\nfeature extraction\\nrobustness\\nvisualization\\nbrightness\\ndistance measurement\\ngradient methods\\nimage processing\\nactive exposure control\\nrobust visual odometry\\nhdr environments\\nhigh dynamic range environments\\nrobust gradient-based image quality metric\\nsvo\",\"444\":\"measurement by laser beam\\ngas detectors\\nrobot sensing systems\\nlaser beams\\npayloads\\nautonomous aerial vehicles\\nmobile robots\\nmobile robot olfaction\\nuav-based remote sensing\\ngas clouds\\nsource localization\\nrobotic platform\\ngas sources\\nmro\\nversatile hexacopter\\n3-axis aerial stabilization gimbal\\nuav-regas\\nunmanned aerial vehicle\\ntdlas sensors\\ntunable diode laser absorption spectroscopy\\nremote gas sensors\\ngas-sensitive mini-copters\\ngas plumes\\naerial platform\\nsurveillance\\ninspection\\nspectroscopic measurement methods\\naerial remote gas sensing\",\"445\":\"fasteners\\nprototypes\\nservomotors\\naircraft\\npropellers\\nstability analysis\\naerospace propulsion\\nautonomous aerial vehicles\\nhelicopters\\ntransformable solar-uav\\naerial robotic platforms\\nsought-after solution\\nunmanned aerial vehicles\\nfixed-wing system\\nmultirotor system\\nfixed-wing uavs\\nhigh-altitude surveillance\\nquad-rotors\\nsolar powered fixed-wing flight\\nquad-rotor flight\\nsuav:q platform\\ntransformation mechanism\\nairframe design\\nvariable pitch propulsion system\\ncustom-designed power electronics\",\"446\":\"aircraft\\nunmanned aerial vehicles\\naerodynamics\\nvibrations\\natmospheric modeling\\nmathematical model\\naerospace control\\nautonomous aerial vehicles\\ncontrol system synthesis\\nwind tunnels\\nquadrotor tail-sitter vtol uav\\nvertical take-off and landing\\nunmanned aerial vehicle\\nhovering\\nfixed-wing\\nautonomous operation\\nlanding performance\\nwind tunnel test\\nflight controller\\nmatlab simulation\",\"447\":\"trajectory\\nsolid modeling\\nrobots\\nplanning\\nuncertainty\\ncovariance matrices\\ncalibration\\nautonomous aerial vehicles\\nhelicopters\\nidentification\\nkalman filters\\nnonlinear filters\\npath planning\\ntrajectory control\\nsampling-based motion planning\\nactive multirotor system identification\\ntrajectory planning\\nmultirotor microaerial vehicle\\nmav\\nsystem model identification\\nbelief dynamics\\nextended kalman filter\\nekf\",\"448\":\"optimization\\nmathematical model\\nunmanned aerial vehicles\\nattitude control\\ndata models\\npropellers\\naircraft\\naircraft control\\nautonomous aerial vehicles\\nclosed loop systems\\nfeedback\\nmobile robots\\nrobot dynamics\\nstability\\ntrajectory optimisation (aerospace)\\nmodel-based transition optimization\\ntrajectory optimization\\nvertical take-off and landing\\nvtol tailsitter uav\\nunmanned aerial vehicle\\nuav closed-loop dynamics\\nlow-level control\\nattitude stabilization\\nvehicle modeling\\ncost function construction\\nfeedback gain\\nthrottle channel\\naltitude discrepancy\\nrobustness\\nwind disturbance\\nback-transition\\ncruise-to-hover transition\\nwingtra s100 vtol tailsitter\",\"449\":\"wind speed\\nvelocity measurement\\nmathematical model\\nestimation\\natmospheric modeling\\npropellers\\nunmanned aerial vehicles\\naerodynamics\\nautonomous aerial vehicles\\nglobal positioning system\\ninertial systems\\nkalman filters\\nmagnetometers\\nwind\\nhovering vtol tailsitter uav\\nmodel-based wind estimation\\nunmanned aerial vehicle designs\\nwind direction\\nhovering vertical take-off and landing tailsitter uav\\nstandard onboard sensor suite\\ninertial measurement unit\\nimu\\ngps\\nmagnetometer\\nwind velocity vector estimation\\nhorizontal plane\\naerodynamic model\\nkalman filter\\nhorizontal wind velocity vector estimation\\nuav autopilot\\nground truth measurement\\ngrey-box model\\nairframes\",\"450\":\"iterative closest point algorithm\\ncomputational modeling\\noptimization\\nthree-dimensional displays\\njacobian matrices\\nsensors\\nrobots\\ncomputational geometry\\niterative methods\\noptimisation\\npose estimation\\npose refinement\\nprincipal curvature refinement\\nquadrics\\nsurface curvature optimisation\\npose alignment optimisation\\njoint optimisation strategy\\noffline multi-frame approach\\nmagnitude improvement\\npoint-to-plane iterative closest point\\nicp pose alignment\",\"451\":\"three-dimensional displays\\nsurface reconstruction\\nimage reconstruction\\nsolid modeling\\nreal-time systems\\nrobots\\nmobile handsets\\nimage denoising\\nimage segmentation\\nmobile computing\\n3d maps\\nonline 3d reconstruction\\nar\\/vr gaming\\nplanar surfaces\\nmobile devices\\ntango tablet\\nnatural environments\\nocclusion\\nplane fitting\\nsemantic segmentation\\nreal-world scenes\\n3d reconstruction stabilization\\n3d reconstruction denoising\\nmobile reconstruction\\nonline reconstruction\\nintegrated depth image\\nsigned distance fields\\nsdf\",\"452\":\"object detection\\nproposals\\npipelines\\nimage segmentation\\ncomputer vision\\nvisualization\\nhuman-robot interaction\\nfast task-specific target detection\\ngraph based constraints representation\\nreal-world robotics applications\\nintelligent agent\\ntask-specific object target\\nsuboptimal checking order\\noptimal checking sequence\\npolynomial time\\nnonrigid body part detection\\nhuman-robot interaction system\",\"453\":\"cameras\\nmotion segmentation\\nestimation\\nimage segmentation\\nrobustness\\ndynamics\\nthree-dimensional displays\\nimage sensors\\nimage sequences\\nmicroprocessor chips\\nmotion estimation\\nmultiprocessing systems\\npattern clustering\\nfast odometry\\nscene flow\\nrgb-d cameras\\ngeometric clustering\\ncamera motion estimation\\nrgb-d sequence\\ntwo-fold segmentation\\ngeometric clusters\\ndynamic environments\\nmulticore cpu\",\"454\":\"robot sensing systems\\ncameras\\ngeometry\\nthree-dimensional displays\\noptimization\\niterative closest point algorithm\\nimage sensors\\nobject tracking\\ntactile sensors\\nobject-tracking framework\\npoint cloud information fusion\\nrgb-d camera\\ngelsight contact sensor\\npoint-cloud-based articulated object tracker\\nsigned-distance function\\nonline depth reconstruction algorithm\\nmodified second order update\\ncontact-based geometric information\\nrobot end effector\\nocclusion\\nfrequency 12 hz\",\"455\":\"detectors\\nshape\\nrobustness\\nthree-dimensional displays\\nfeature extraction\\nhistograms\\nlighting\\ncomputer vision\\nimage colour analysis\\nimage texture\\nrotation invariant feature\\nillumination invariant feature\\nscale invariant appearance feature\\nshape feature\\nkeypoint detector\\nfeature descriptor\\ntexture information\\ngeometric information\\nappearance channel\\nshape channel\\nresponse function\\nsurface normals\\nharris corner detector\\ndepth information\\nscale estimation\\nbackground elimination\\ninvariant descriptors\\ngrayscale intensity\\nrgb-d feature\\ncshot\\nloind\\nrisas detector\",\"456\":\"grippers\\nrobots\\nplanning\\nmanifolds\\nspace exploration\\nvegetation\\nconferences\\ngraph theory\\nmanipulators\\npath planning\\nmanipulation planning\\ncrossed foliation issue\\nconstraint graph\\nmotion constraints\\nmotion planning\",\"457\":\"planning\\nrobots\\nmanifolds\\naerospace electronics\\nforce\\njacobian matrices\\nkinematics\\ncontrollability\\nmanipulators\\npath planning\\nnoninteracting constrained motion planning\\nrobot manipulators\\nconstrained robot systems\\nconfiguration space zero-measure submanifold\\nfunctional controllability theory\\ndynamical systems\\ngeometric constraint\\nlower-dimensional constraint manifold\\nfull-dimensional boundary layer\\ndecoupled control scheme\\nbimanual manipulation workstation\",\"458\":\"kinematics\\noptimization\\nplanning\\naerospace electronics\\nprogramming\\nrobots\\nsearch problems\\ngeometric programming\\nindustrial manipulators\\nlogic programming\\nmulti-agent systems\\ntree searching\\nmultibound tree search\\nlogic-geometric programming\\ncooperative manipulation domains\\njoint symbolic and geometric planning\\nmultiagent cooperative manipulation\\noptimal paths\\njoint optimization problem\\napproximate solver\\nbranch-and-bound method\\nmcts\\nbaxter robot\",\"459\":\"lasers\\nrobot sensing systems\\nmanipulators\\nmotorcycles\\ngrasping\\ntrajectory\\nassisted living\\nhuman-robot interaction\\nmedical control systems\\nmobile robots\\nlaser selection\\nmotor disabled people\\nactivity-of-daily living\\nadl\\nmobile grasping assistance\\nrobot arm\\nrethink robotics baxter robot\\nassistive mobility device\\ncontrol system\\nuser interface\\ngrasp detection\\ncluttered environments\\nobject selection success rate\\ngrasp detection success rate\\nnonmobile scenario\\nmobile scenario\",\"460\":\"planning\\nsolid modeling\\nknowledge based systems\\ngrasping\\nhidden markov models\\nend effectors\\ncontrol engineering computing\\nlearning (artificial intelligence)\\nlegged locomotion\\nmanipulator kinematics\\npath planning\\nregression analysis\\nsampling methods\\nc-learn\\nlearning geometric constraints\\nmultistep manipulation\\nshared autonomy\\nregression\\nsampling-based motion planners\\noptimization-based motion planners\\nknowledge base\\nmultistep tasks\\nrobot kinematics\\ndual-arm optimas robot\\nlegged dual-arm atlas robot\",\"461\":\"manipulator dynamics\\nplanning\\ndynamics\\naerospace electronics\\ntrajectory\\nfeedback\\npath planning\\nhybrid manipulation tasks\\nmotion planning\\nfeedback control\\ndynamic manipulation tasks\\nnonprehensile manipulation tasks\\npicking transition states\\nplanar 3r manipulator\\nrobot workspace\\nplanned primitives reorient\\nsliding contact modes\",\"462\":\"uncertainty\\nrobots\\ntools\\nplanning\\ngrippers\\ncognition\\ncollision avoidance\\nassembly planning\\ninference mechanisms\\nproduction engineering computing\\nparts assembly planning\\nsimulation-aided physical reasoning\\nmanipulation tasks\\nmotion plan\\nphysics-based simulation\\nmultiheuristic a* search\\nuncertainty reduction\\nparts assembly tasks\",\"463\":\"force\\nrobot sensing systems\\nestimation\\nhumanoid robots\\nrobot kinematics\\nfriction\\nbayes methods\\ndexterous manipulators\\nrecursive estimation\\nstatistical distributions\\nobject manipulation\\nobject physical properties\\nwhole-body manipulation\\nlifting operation\\npushing operation\\ntilting operation\\nphysical properties\\nrobot center-of-mass\\nrobot friction coefficient\\nrobot mass\\nonline manipulation motion\\nprobability distribution\\nbayesian methods\\nphysics-based stability determination\\nhumanoid robot\\ndexterous manipulation\\nprobability and statistical methods\\ncalibration and identification\\ndual arm manipulation\",\"464\":\"trajectory\\nsafety\\nreal-time systems\\nplanning\\nrobot sensing systems\\nhumanoid robots\\ncollision avoidance\\nmotion control\\ntrajectory control\\nrealtime pursuit-evasion\\nfast evasive motion\\ncontrol schemes\\nmaneuver planning module\\nclosed-form expression\\nnao humanoids\\nasymptotic behavior\\ntrajectory generation\",\"465\":\"legged locomotion\\naerodynamics\\nmanifolds\\nfoot\\nconvergence\\norbits\\nasymptotic stability\\nlyapunov methods\\nrobot dynamics\\nstate-space methods\\nunderactuated biped robots\\nhybrid zero dynamics approach\\npassivity-based controller\\ntransverse dynamics\\nlyapunov stability analysis\\nfull-order system\\nconditional stability theorem\\nperiodic orbit\\nstate space\\nseven-link biped robot\\nzero ankle torque\",\"466\":\"humanoid robots\\ntrajectory\\ndynamics\\ntracking\\nmonitoring\\nmotion control\\nstability\\nhumanoid robot motion control\\nstabilization\\ndynamic motion tasks\\nnonnegligible speed\\nreference spreading hybrid control law\\ndynamical model\\nrobot balancing\",\"467\":\"trajectory\\nhumanoid robots\\naerodynamics\\nforce\\nplanning\\nend effectors\\nmanipulator dynamics\\nmanipulator kinematics\\nmotion control\\npath planning\\ntrajectory control\\ndynamic multi-contact transitions\\nmotion planner\\nmulti-contact stances\\nclosed-form reference trajectories\\nrobot center of mass position\\nrobot velocity\\ndivergent component of motion\\ndcm controller\\nend-effector trajectories\\nkinematic constraints\\ndynamic constraints\\ncom trajectory tracking\\ntoro\",\"468\":\"legged locomotion\\nfoot\\noscillators\\nrobot kinematics\\ntrajectory\\nforce\\nmotion control\\nposition control\\nsmooth-path-tracking control\\nbiped robot\\ndynamics morphing\\nlongitudinal walking controller\\nsmooth curved path\\nfixed inertial frame\\nrobot center of mass\\nzero-moment point\\nzmp manipulation\\nreferential path curvature\\nfoot control\\ncom movement\\nautomatic update\\ncom position\\ncomputer simulations\\nmotion references\",\"469\":\"legged locomotion\\nmodulation\\nfoot\\nsprings\\nhip\\nknee\\nmathematical model\\ncompliance control\\ngait analysis\\nhumanoid robots\\nvibration control\\ncompliance modulation\\nhuman locomotion\\nstiffness parameters\\nconstant stiffness assumption\\nhuman walking gait\\nnatural gaits\\nbi-articular stiffness profiles modulation\\nmotion capture data\\nspring damper systems\",\"470\":\"robots\\nmathematical model\\nshape\\ntorque\\nthree-dimensional displays\\ncomputational modeling\\noscillators\\nmobile robots\\nsmooth transition\\nbody shape\\nsnake-like robot\\nlocomotion speed\\nlightweight central pattern generator\\ncpg model\\ngradient system\\nlocomotion speed transitions\\nrolling gait\\nsinusoid based method\\nsmooth transition process\\nabnormal torque\",\"471\":\"robots\\npneumatic systems\\nactuators\\nfoot\\nshape\\nlimiting\\nelectron tubes\\nbiocybernetics\\nbiomimetics\\ncontrol system synthesis\\nfriction\\nlegged locomotion\\ninchworm-inspired soft robot design\\nomega-arching locomotion\\nlocomotion efficiency\\nbionic soft robot\\n\\u03c9 motion shape imitation\\nbiology inchworm\\nsilicone square tube\\nstrain-limiting layers\\n3d printing technology\\nmetal sheet\\nfriction coefficients\\nanchor-motion movement\\ninchworm-like locomotion\",\"472\":\"aerodynamics\\ndrag\\nrobots\\ninsects\\nstrips\\nenergy consumption\\nkinematics\\naerospace components\\nautonomous aerial vehicles\\nrobot dynamics\\nguidelines for the design and control of\\nbioinspired hovering robots\\nhovering mechanisms dynamics\\naerial robots\\nwing flapping\\nwing pronation\\nwing folding\\npower consumption\",\"473\":\"wheels\\nmobile robots\\nfriction\\ndynamics\\nrobot kinematics\\nfeedforward neural networks\\nfeedback\\nfeedforward\\ngait analysis\\nnonlinear control systems\\nrobust control\\nvariable structure systems\\ncaterpillar inspired rolling gait generation\\ncaterpillar inspired rolling gait control mechanism\\npleurotya caterpillar\\nefficient locomotory rolling gaits\\nspherical robot locomotion\\nfeedforward-feedback control strategy\\nfeedforward component\\nconnected pattern generators\\ncpg\\nnonlinear integral sliding mode feedback\\nismc\\nnonlinear robot dynamics\\nrobot stability\\nexternal disturbances\\nparameter uncertainties\\nirregular surfaces\\nsmooth surfaces\\nstable rolling gait\\nspherical robot robust control\\nsurface conditions\\nbiomimetics\\nspherical robot\\nrolling gait\\ncentral pattern generator (cpg)\\nrolling friction\\nintegral sliding mode (ismc) control\",\"474\":\"legged locomotion\\nhair\\nrobot kinematics\\nflexible printed circuits\\nfabrication\\naluminum\\nhair like appendages\\nwater beetles\\nsteady swimming\\nwater surface\\nwater beetles locomotion\\nbiology\\njerky motion\\nbeating frequency\\nhair-like appendages\\nswmming speed\\nrobot locomotion\",\"475\":\"tendons\\nmuscles\\njoining processes\\nforce\\ncomputational modeling\\npredictive models\\nelectronics packaging\\ndexterous manipulators\\nmanipulator kinematics\\ninterconnected tendon networks\\nrobotic fingers\\nhuman fingers\\ncomplex tendon systems\\ntendon kinematics\\njoint posture\\ntendon-driven robotic finger testbed\",\"476\":\"legged locomotion\\noptimization\\ngears\\ntorque\\ndc motors\\nmathematical model\\ndesign engineering\\ngeometry\\noptimisation\\nrobot dynamics\\nmechanical specialization\\ntask-specific complex geometries\\npower consumption\\noptimal gear ratio selection algorithm\\ngeometry optimization\\nspatial hybrid parallel-serial robotic limb structure\\ndesign optimization method\\nelectrical cost\",\"477\":\"imaging\\nx-ray imaging\\nrobots\\noptimization\\nsafety\\nkinematics\\nperformance evaluation\\ngraphics processing units\\nmedical robotics\\nmonte carlo methods\\npose estimation\\nrobot vision\\nsurgery\\npose optimization\\nc-arm imaging device\\nintraoperative radiation exposure reduction\\ninterventional procedure\\nminimally-invasive procedure\\nmi intervention\\nx-ray guidance\\nionizing radiation exposure\\nrobotic capabilities\\nanatomical structure\\ncost function\\ngpu-accelerated monte carlo methods\\ngraphics processing unit\\nimaging configuration\",\"478\":\"manipulators\\nmedical robotics\\nsurgery\\ncollision avoidance\\nindexes\\ninstruments\\ngaussian processes\\nparticle swarm optimisation\\npreoperative planning\\npso-gp-based performance optimization\\nrobotically-assisted minimally invasive surgery\\nsurgeons\\nsurgical site\\npose selection\\nport placement\\nmultiarm cooperation\\nmultiarm surgical robots\\nsurgical workspace\\nglobal isotropy index\\ngii\\ndexterity\\nsingle robot arm\\ncooperation capability index\\ncci\\nminimum distance index\\nmdi\\nrobotic arms\\nparticle swarm optimization\\ngaussian process\\nrobot positioning\\npso-gp-based optimization\\nthree-arm surgical robot\",\"479\":\"laser ablation\\ntools\\nsurgery\\nmagnetic moments\\nmagnetic resonance imaging\\nelectromagnetics\\nbending\\nbiological tissues\\nbiomagnetism\\nbiomedical optical imaging\\nendoscopes\\nfats\\nfibre lasers\\nhyperspectral imaging\\nlaser applications in medicine\\nmean square error methods\\noptical tomography\\npermanent magnets\\ntelemedicine\\ntorque\\nuser interfaces\\nmagnetic laser scanner\\nendoscopic microsurgery\\nfast tissue ablation\\nthermal damage\\nactuators\\ndirect line-of-sight\\nmicrosurgical area\\nmagnetic scanner tool\\nendoscopic scanning laser microsurgery\\nminiature electromagnetic coil pairs\\nflexible optical fiber\\nactuation mechanism\\nelectromagnetic field\\nhigh-speed laser scanning\\nmagnetic torque\\nlaser spot\\nautomatically executing high-speed laser scanning operations\\ncustomized trajectories\\nroot-mean-squared-error\\nreal-time teleoperation\\nappropriate user interface device\\nlaparoscopic procedures\\nflexible endoscopic procedures\\noptical fiber based imaging\\nscanning endoscopic oct\\nhyperspectral probes\\nscanning laser\\nmagnetic actuation\\nlaser microsurgery\\nendoscopic surgery\",\"480\":\"tools\\nmagnetic flux\\nmagnetic separation\\nshafts\\nrobots\\nmagnetic domains\\ncouplings\\nmagnetic forces\\nmedical robotics\\nsurgery\\ntelerobotics\\nmagnex\\nexpendable robotic surgical tooltip\\ndisposable compliant surgical tooltip\\ntele-operated surgical robot\\nbio-fouling\\nsterilization processes\\nsurgical robotic tools\\nbuckling strength\\nmagnetic force based coupling\\nhermetic barrier\\nbiological material\\ntool shaft\\npluggable tooltip\\nmodularity\\nmagnetic nexus\\nmagnetic coupling\",\"481\":\"cameras\\nrobot vision systems\\nforce\\nabdomen\\ncreep\\nsurgery\\nbiomedical transducers\\nmechanical variables measurement\\nmuscle\\nskin\\nwireless sensor networks\\nrobotic camera system\\nminimally invasive surgery\\nmis\\ntraversing abdominal cavity\\ncamera-tissue interaction\\nwireless laparoscopic camera interaction\\nmechanical model\\nabdominal wall bulk tissue behavior\\nconnective tissue layer\\nabaqus\\nporcine tissue\\nnoninvasive method\\nmechanical property measurement\",\"482\":\"instruments\\nmanipulators\\ntools\\nsurgery\\nkinematics\\ncameras\\nergonomics\\nmedical robotics\\nimplicit gaze-assisted adaptive motion scaling\\narticulated instrument manipulation\\nrobotic surgical systems\\nrobotic arms\\narticulated instruments\\nhuman anatomy\\ninstrument control\\nergonomic\\nclutching mechanics\\nbi-manual system\\nself-triangulating 6-degrees-of-freedom tools\\ndof tools\\nflexible elbow\\n9-dof system\\neye tracking\",\"483\":\"data models\\nreliability\\nservice robots\\nsearch problems\\nprediction algorithms\\ncognition\\nstatistical distributions\\naction execution models\\nsymbolic precondition models\\ngeometric precondition models\\n\\u03b4 models\\nsymbolic template representations\\ngeometric success probability distributions\\nphysical robot platforms\\nexecution-specific knowledge\",\"484\":\"education\\natmosphere\\nrobot sensing systems\\ncreativity\\ntools\\ncameras\\neducational robots\\nhumanoid robots\\nmobile robots\\nteaching\\npreschool k2 classes\\nhumanoid social robots\\nteaching aid\\npepper robot\\nnao robot\\nlikert-scale based survey\\ntepi\\nclassroom atmosphere\\nclassroom management\\nclass behavior\\ntime 3 month\",\"485\":\"cognition\\nprobabilistic logic\\nrobots\\nsemantics\\ncomputational modeling\\nknowledge based systems\\nplanning\\ncontrol engineering computing\\ninference mechanisms\\nmobile robots\\nnatural language processing\\nquery processing\\ninstance-based learning\\nknowledge bases\\nsemantic analogical reasoning\\nprobabilistic reasoning\\nnatural-language instruction sheets\\ninstruction completion\\ndatabase queries\\nkb\\nprac natural-language interpreter\\nautonomous mobile robots\",\"486\":\"robots\\nsemantics\\nimage color analysis\\nobject recognition\\nprobabilistic logic\\nnatural languages\\ntaxonomy\\nhuman-robot interaction\\ninternet\\nnatural language processing\\nprobabilistic interpretation\\nnatural language object descriptions\\nhuman environments\\nsemantic representations\\nperceptual characteristics\\nrobot perception system\\nprobabilistic first-order knowledge bases\\nencyclopedic articles\\nonline dictionaries\\ntextual descriptions\\nrobotic system\\nproof-of-concept evaluation\",\"487\":\"liquids\\nservice robots\\nvibrations\\ntrajectory\\ndynamics\\nmathematical model\\nfeedforward\\nflow control\\nmanipulator dynamics\\npendulums\\nsloshing\\ntrajectory control\\nvibration control\\nliquid handling robotic system control\\nfeed-forward approach\\nsloshing dynamics reduction\\nliquid dynamics\\nopen vessel\\nspherical pendulum mechanical model\\nvibration suppression problem\\nsecond-order system\\npendulum model\\nexponential filter\\nreference trajectory\\nsloshing-free liquid motion\",\"488\":\"data models\\nplanning\\ntraining\\ncomputational modeling\\nrobot sensing systems\\npredictive models\\nkernel\\nenvironmental monitoring (geophysics)\\ngaussian processes\\nintelligent robots\\nlearning (artificial intelligence)\\nmarine vehicles\\nmobile robots\\noceanography\\nplanning (artificial intelligence)\\ninformative planning\\nonline learning\\nsparse gaussian processes\\nenvironmental monitoring\\nspatiotemporal variation\\ntime-varying underlying environmental model\\nautonomous marine vehicle\\nocean monitoring\\nsparse gaussian process learning component\",\"489\":\"buildings\\noptimization\\nmathematical model\\ncomputational modeling\\nlaw enforcement\\nstress\\nprobabilistic logic\\ndivide and conquer methods\\ndynamic programming\\nemergency management\\nsafety\\nstochastic programming\\nactive shooter event\\nautomated response system\\nguidance delivery\\ndivide-and-conquer approach\\negress routes\\nstochastic dynamic programming\",\"490\":\"legged locomotion\\npolymers\\nelectrodes\\nactuators\\nrobot sensing systems\\nthree-dimensional printing\\nelectroactive polymer actuators\\nmobile robots\\n3d-printed ionic polymer-metal composite\\nsoft crawling robot\\nipmc\\nionomeric polymer material\\nnafion\\n3d print modular leg\\ncaterpillar-like robot\\nsmart electroactive polymer material\\nhydrated 3d-printed leg\\n3d-printing process\",\"491\":\"electrodes\\nactuators\\npolymers\\nmathematical model\\ndc motors\\nrobot sensing systems\\nforce measurement\\ngrippers\\nmicromanipulators\\nversatile conducting interpenetrating polymer network\\nsensing\\nactuation\\nconducting-interpenetrating polymer network\\nc-ipn\\nrobotics\\nmanipulation\\nmicrogripper\",\"492\":\"actuators\\nrobots\\nswitches\\nshape\\ncompressors\\nstrain\\ndielectrics\\ndeformation\\nelectroactive polymer actuators\\nasymmetric stable deformation\\ninflated dielectric elastomer actuators\\nrobotic systems\\nfluidically connected membrane dielectric elastomer actuators\",\"493\":\"actuators\\ndielectrics\\naerospace electronics\\nelectromagnetic interference\\nshape\\nservice robots\\ndeformation\\nrobots\\nnetworked soft actuators\\nsoft robots\\ndielectric elastomers\\nvoltage-induced deformation\\nair-filled dielectric elastomer actuators\\nactuation range\\nactuation capability\",\"494\":\"springs\\nrobots\\nskin\\nforce\\nactuators\\nwires\\ntemperature measurement\\nbiomimetics\\ncontrol system synthesis\\nfinite element analysis\\nforced convection\\nfuzzy control\\nmedical robotics\\nmimo systems\\nshape memory effects\\nsilicone rubber\\nsprings (mechanical)\\nsma-actuated biomimetic robot\\nfunctional skin\\nthree modular section robot\\nperistaltic motion\\nshape memory alloy\\nsilicone rubber skin\\npassive recovery force\\nair tubes\\nsma springs\\ntraction\\nmultiinput multioutput controller\\nmimo controller\\nfea\\nnear zero steady state error\",\"495\":\"actuators\\nlegged locomotion\\nnonhomogeneous media\\nfabrication\\nforce\\nelectrodes\\nelectroactive polymer actuators\\nrobot kinematics\\nhigh speed soft robot\\ndielectric elastomer actuators\\nmultilayer fabrication method\\ncrawling soft robots\\nfour-legged multigait capable crawler\\nuntethered system\\ninchworm robot\\nsoft devices\\ndeformable devices\\nrigid attachments\",\"496\":\"friction\\nforce\\nsubstrates\\ntuning\\nforce measurement\\ntesting\\nmathematical model\\ngrippers\\nmobile robots\\npneumatic actuators\\nconstrained inflation\\nelastomeric membrane\\ntunable friction mechanism\\npneumatic actuation\\nsoft actuators\\nquantitative force data\\npreload forces\\nsubstrate materials\\ninflation pressures\\nfriction forces\\nhigh-friction states\\nlow-friction states\\none-degree-of-freedom soft crawler\\nsoft gripper\\nactuatable finger friction pads\\nasymmetric strokes\\ngrip force\\nengaged states\\ndisengaged states\",\"497\":\"collision avoidance\\nplanning\\nalgorithms\\ndata structures\\nacceleration\\nthree-dimensional displays\\nimage edge detection\\nmobile robots\\noctrees\\nshear modulus\\ncollision detection\\nnarrow passages\\nsampling-based 3d rigid body motion planning\\ndistance field data structures\\noctree data structures\\nswap algorithm\",\"498\":\"planning\\ntuning\\nrobots\\nalgorithm design and analysis\\nsoftware algorithms\\nprediction algorithms\\nsoftware\\ncontrol system synthesis\\nindustrial manipulators\\npath planning\\npath planning algorithms\\nautomated tuning\\nrobotics communities\\nsequential model-based algorithm configuration tools\\nsmac\\nindustrial pick-and-place tasks\",\"499\":\"wheels\\ntorque\\nrobots\\nhardware\\nacceleration\\nmathematical model\\ntracking\\nmobile robots\\nmotion control\\nnonlinear control systems\\npendulums\\nperfect tracking control\\nphase plane\\nwheeled inverted pendulum\\nhardware constraints\\ncontrol range\\nmotion-planning method\\nmotion equation\\nangular body inclination\",\"500\":\"robot sensing systems\\nmutual information\\ncomputational modeling\\nplanning\\ntarget tracking\\ntrajectory\\nautonomous aerial vehicles\\ncomputational complexity\\nearthquakes\\nemergency management\\noptimisation\\npath planning\\nmultipass target search\\nmotion planning\\nmulti-target autonomous search\\ndisaster scenarios\\ncontested environments\\nrescue worker safety\\nnp-hard problems\\nmicro aerial vehicles\\nmavs\",\"501\":\"bridges\\ntrajectory\\nnavigation\\ntwo dimensional displays\\nthree-dimensional displays\\nrobot kinematics\\ncollision avoidance\\ninterpolation\\nmobile robots\\nmulti-robot systems\\ntrajectory control\\ncollision-free global navigation\\ncontinuous-time multiagent systems\\ngeneral linear dynamics\\n2d workspaces\\n3d workspaces\\nnarrow passages\\ncrowded regions\\ntight regions\\nkinodynamic rrt algorithms\\ngeometric properties\\ncollision-free trajectory\\ninterpolated bridge trajectories\\nlocal multiagent navigation algorithms\\nglobal collision-free paths\",\"502\":\"planning\\nhazards\\nlighting\\npath planning\\nspatiotemporal phenomena\\nmoon\\nspace vehicles\\ncollision avoidance\\nplanetary rovers\\nreachability analysis\\nenergy-aware spatiotemporal path planning acceleration\\nlunar poles\\nrobotic missions\\nmoon poles\\nmercury poles\\nplanetary rover missions\\ncadence\\nillumination conditions\\nlanding site\\nplanning time reduction\\ntime-compression technique\\nend-goal reachability\\nsearch space reduction\\nheuristics\\nstatic obstacles\",\"503\":\"kinematics\\nobservers\\nmobile robots\\nadaptation models\\nmathematical model\\nadaptive control\\nposition control\\nrobot dynamics\\nrobot kinematics\\ntracking\\ntrajectory control\\nadaptive trajectory control\\noff-road mobile robots\\nmultimodel observer approach\\npath tracking control\\noff-road conditions\\nmodel-based adaptive control\\ngrip condition estimation\\nextended kinematic model\\nharsh conditions\",\"504\":\"robots\\ncollision avoidance\\nnavigation\\nstability analysis\\nasymptotic stability\\ndynamics\\ncomputational modeling\\nrobot dynamics\\nstability\\nsmooth extensions\\nfeedback motion planners\\nreference governors\\nrobotics\\nrobot models\\nconstraint satisfaction\\nrobot-governor system\\npath planners\\nvector field planners\\nsecond-order robot dynamics\",\"505\":\"visual servoing\\nvisualization\\ncameras\\nfeature extraction\\naerospace electronics\\nalgorithm design and analysis\\ncalibration\\nimage matching\\nimage sensors\\nmanipulators\\nrobot vision\\nset space visual servoing\\n6-dof manipulator\\ncomplex image processing techniques\\nimage features\\nmatching algorithm\\nvisual errors\\ndecoupled control law\\ncalibrated inner camera parameters\\nimage patterns\\npartial occlusions\",\"506\":\"lighting\\nrobustness\\njacobian matrices\\nvisualization\\nbrightness\\nminimization\\nobject tracking\\nimage denoising\\nimage texture\\nminimisation\\nrobot vision\\nillumination insensitive efficient second-order minimization\\nplanar object tracking\\ndirect visual tracking\\nvision-based robotic applications\\ndvt\\nssd-based esm\\nsum-of-squared differences\\nbrightness constancy assumption\\ngradient orientations\\nlinear illumination changes\\nnonlinear illumination changes\\nimage brightness\\nillumination insensitive esm method\\nperona-malik function\\nmask image\\ndenoising method\\ngo robustness improvement\\nplanar objects\",\"507\":\"object tracking\\nlinear programming\\nreliability\\nrobots\\ncorrelation\\ncomputational modeling\\nminimization\\ncorrelation methods\\nfiltering theory\\nlearning (artificial intelligence)\\nmanipulators\\nrobot vision\\nself-paced object tracking\\nrobot-human interaction\\nobject manipulation\\nappearance model\\nself-paced learning\\nmodel learning\\nkernelized correlation filters\\nreal-valued error-tolerant self-paced function\\nconstraint vector\",\"508\":\"conferences\\nautomation\\nadaptive kalman filters\\ncorrelation methods\\nmotion estimation\\nobject tracking\\nreal-time systems\\nreal-time visual object tracking\\nrobust kernelized correlation filter\\nmotion model\\nconfidence measurement\\nocclusion information\\nadaptive kalman filter\",\"509\":\"software\\ncollision avoidance\\nmobile robots\\ncats\\ncameras\\nbiomimetics\\nclosed loop systems\\nmulti-robot systems\\nposition control\\nbio-hybrid systems\\ncalibrated stimuli\\nrobotic hardware design\\nrobot control\\nbiomimetic model\\nfish behaviour\\nclosed-loop interactions\\nmultirobot control\\nmultirobot tracking\",\"510\":\"tracking\\ntrajectory\\nfrequency-domain analysis\\nhidden markov models\\nrobots\\nunmanned underwater vehicles\\nautonomous underwater vehicles\\nhuman-robot interaction\\nimage sequences\\nmotion control\\npattern recognition\\nmixed-domain biological motion tracking\\nunderwater human-robot interaction\\nautonomous underwater robot\\nspatial-domain features\\nfrequency-domain features\\nhuman swimming patterns\\nimage sequence\\nhidden markov model\\nhmm\\nsearch-space\\nimage intensities\\nmotion signature\\nimage subwindows\",\"511\":\"optical imaging\\noptical sensors\\ncameras\\nspatiotemporal phenomena\\ncomputational modeling\\nintegrated optics\\noptical computing\\nimage sequences\\noptimisation\\nprobability\\nrobot vision\\nsensor fusion\\ntracking\\nevent-based feature tracking\\nprobabilistic data association\\nasynchronous event-based sensors\\nbasic robot vision problems\\noptical flow computation\\noptical flow quality\\nsoft data association\\nintertwined em scheme\",\"512\":\"three-dimensional displays\\nmotion segmentation\\nreal-time systems\\nsolid modeling\\ntracking\\nimage segmentation\\nimage fusion\\nimage motion analysis\\nimage reconstruction\\nobject tracking\\nshape recognition\\nslam (robots)\\nco-fusion\\ndense slam system\\nrgb-d images\\n3d shape reconstruction\\n3d shape tracking\\nmultiple model fitting approach\\nobject label\\ndynamic scenes\\nmoving regions\\nmotion tracking\\nrobot\\n3d models\\nscene description\\nobject level\\nreal-time segmentation\\nmultiple object tracking\\nmultiple object fusion\",\"513\":\"planning\\ndecision making\\njacobian matrices\\naerospace electronics\\nuncertainty\\nrobots\\ncurrent measurement\\ncontrol engineering computing\\ninference mechanisms\\nnavigation\\nplanning (artificial intelligence)\\ninference update\\njip\\njoint inference planning\\nbelief space planning\\nrobotics problems\\nbsp\\nautonomous navigation\\nisam2 paradigm\",\"514\":\"planning\\nrobot sensing systems\\nrobustness\\nuncertainty\\nlinear programming\\nbelief networks\\ngaussian processes\\ninference mechanisms\\nmixture models\\nmobile robots\\nplanning (artificial intelligence)\\nsensor fusion\\nnonmyopic data association aware belief space planning\\nrobust active perception\\nbsp\\ngaussian mixture model\\ngmm belief\\nexplicit reasoning\\nperceptual aliasing\\ninference\\nunified framework\\nrobust passive perception\",\"515\":\"cameras\\nsimultaneous localization and mapping\\nfeature extraction\\nthree-dimensional displays\\nrobot vision systems\\nimage edge detection\\nimage colour analysis\\nimage reconstruction\\nimage registration\\nimage sensors\\nrobot vision\\nslam (robots)\\nmonorgbd-slam\\nrgbd cameras\\nfield of view\\nfov\\ndistant frames\\nmonocular slam systems\\ndepth range limitation\\nwide-angle monocular camera\\n2d point features\\nrgbd-to-rgbd\\nrgbd-to-monocular registration\\nvirtual images\\npairwise registration results\\nminimum spanning trees\\nmst\\nbundle adjustment\\n3d reconstruction\",\"516\":\"simultaneous localization and mapping\\nthree-dimensional displays\\ncameras\\ntrajectory\\npipelines\\nreal-time systems\\nvisualization\\nobject detection\\nrobot vision\\nslam (robots)\\npl-slam\\nreal-time monocular visual slam\\nline correspondence detection\\ntum rgb-d benchmark\\nsequence frames\\npoint and line slam\\ngeometric computer vision algorithms\",\"517\":\"cameras\\nthree-dimensional displays\\ntrajectory\\nvisualization\\nsimultaneous localization and mapping\\nsplines (mathematics)\\ncams\\nslam (robots)\\no-poco system\\nonline point cloud compression mapping\\nvisual odometry\\nslam\\ncamera traveled trajectory\\ninformation layers\\nvisual information\\nspatial information\\norb-slam\",\"518\":\"feature extraction\\nthree-dimensional displays\\ndetectors\\nkernel\\nimage segmentation\\nrobustness\\nlighting\\nstatistics\\ntransforms\\nros2d\\nrank order statistics\\nimage feature detection\\nsegmenting points\\nimage transformations\\noxford dataset\\nmonocular slam systems\\nstereo slam systems\\nsift\\nkitti dataset\",\"519\":\"lighting\\nrobustness\\nmeasurement\\noptimization\\nsimultaneous localization and mapping\\nbrightness\\nvisualization\\nimage matching\\npose estimation\\nrobot vision\\nslam (robots)\\nillumination change robustness\\ndirect visual slam\\ndirect visual odometry\\ncamera pose estimation\\nimage alignment\\nphotometric cost term\\nlucas-kanade method\\nbrightness constancy\\nloop closures\",\"520\":\"assistive technology\\ngesture recognition\\nmanuals\\nsensors\\nimage segmentation\\nhumanoid robots\\nhuman-robot interaction\\nimage colour analysis\\nimage recognition\\nlearning (artificial intelligence)\\nrobot vision\\ncyrillic manual alphabet recognition\\nrgb-d data\\nred-green-blue-depth data\\nsign language interpreting robotic system\\nslirs\\ndeaf-mute communities\\nhearing-impaired people\\nneural network-based learning architecture\\nkazakhstan\\nfingerspelling\\nlearning-based method\\nmotion depth data modeling\\nhuman-robot interaction system\",\"521\":\"accelerometers\\nmagnetometers\\nkalman filters\\ngyroscopes\\nearth\\nmagnetic separation\\ngravity\\nangular measurement\\nattitude control\\nhelicopters\\nnonlinear filters\\nposition control\\norientation filter\\nangular rates estimation\\nextended kalman filter\\nmonocopter flight\\nheading direction\\nmagnetometer reading\\nangular rates direction\\nvertical direction reference\\ndc motor setup\\nmotor encoder\\nattack angle\\nconing angle\\nrotorcraft\",\"522\":\"cameras\\nvisualization\\nrobot vision systems\\nsplines (mathematics)\\ntracking\\naerospace robotics\\nclosed loop systems\\ninertial navigation\\nnonlinear programming\\nrobot vision\\nsensor fusion\\nstate estimation\\nhigh altitude monocular visual-inertial state estimation\\ngps-denied environments\\nvisual measurements\\ninertial measurements\\nnonlinear optimization problem\\nvisual features\\nspline-based high altitude estimator initialization method\\nmonocular visual-inertial navigation system\\nvins\\nclosed-loop system\\nhigh altitude navigation\",\"523\":\"cameras\\nreal-time systems\\ngraphics processing units\\nunmanned aerial vehicles\\nvisualization\\noptimization\\nalgorithm design and analysis\\naerospace robotics\\ncollision avoidance\\nimage denoising\\nimage fusion\\nimage motion analysis\\nmobile robots\\nrobot vision\\nstereo image processing\\nvideo signal processing\\nreal-time monocular dense mapping\\nvisual-inertial fusion\\ntightly-coupled visual-inertial localization module\\nmetric odometry\\nhigh-accuracy odometry\\nmotion stereo algorithm\\nvideo input\\nlocal depth measurements\\nsemiglobal regularization\\nnoise filtering\\nmap refinement\\naerial robot navigation\\nobstacle avoidance\\nnvidia jetson tx1\\nperception-action loop\\nautonomous aerial robots\",\"524\":\"cameras\\nsimultaneous localization and mapping\\nreal-time systems\\nestimation\\npipelines\\nimage reconstruction\\nautomatic optical inspection\\nautonomous aerial vehicles\\ncollision avoidance\\nnatural scenes\\nrobot vision\\nreal-time local 3d reconstruction\\naerial inspection\\nsuperpixel expansion\\nautomatic navigation\\nrobotics platforms\\nunmanned aerial vehicles\\nuav\\nperception capabilities\\nvision-based techniques\\nonline dense scene estimation\\ncomputer vision\\nreal-time local scene reconstruction\\naerial navigation\\nobstacle avoidance\\nreal-time robot interaction\\naerial footage\",\"525\":\"planning\\nuncertainty\\ncollision avoidance\\nunmanned aerial vehicles\\nsimultaneous localization and mapping\\naerospace robotics\\nmobile robots\\npath planning\\nuncertainty-aware receding horizon exploration\\naerial robots\\npath planning algorithm\\nautonomous exploration\\nuncertainty-aware exploration\\nonline computed tree\\nreference viewpoint\\nexpected localization\\nmapping uncertainty\\nonline onboard\\nsmall aerial robot\",\"526\":\"force\\nmathematical model\\nestimation\\nunmanned aerial vehicles\\nload modeling\\nacceleration\\ndynamics\\nautonomous aerial vehicles\\nmulti-robot systems\\nobservers\\nrobot dynamics\\nstability\\nautonomous swing-angle estimation\\nstable slung-load flight\\nmultirotor uav\\nmultirotor unmanned aerial vehicle\\nswing angle monitoring\\ninertial measurement unit\\nsingle-load cell\\ndisturbance observer\\ndob-derived external force estimation\\nswing angle estimation\\ndob-based disturbance force estimation technique\\nimu data\",\"527\":\"estimation\\nrobot sensing systems\\nintegrated circuits\\nforce\\nforce measurement\\nactuators\\nautonomous aerial vehicles\\nconvergence\\nmanipulators\\nmicrorobots\\nmulti-robot systems\\nactive estimation\\nmass properties\\nsafe cooperative lifting\\nmultirobot coordinated lifting\\ncoordinated aerial manipulation\\nactive parameter estimation\\ncooperative manipulation tasks\\ninformation-theoretic framework\\nconvex hull\\ncauchy-schwarz quadratic mutual information\\nnonparametric filters\\nconvergence rate\\ncyclic selection methods\\nactuator constraints\\nlifting configurations\",\"528\":\"three-dimensional displays\\nsemantics\\nsolid modeling\\nlabeling\\ndatabases\\ntwo dimensional displays\\nsurface reconstruction\\nimage classification\\nimage sequences\\nvideo signal processing\\nmf3d\\nmodel-free 3d semantic scene parsing\\nonline 3d semantic scene parsing\\nvideo sequences\\nvoxel labelling\\nsearch-based label transfer\\ndiscriminative classification\\nkitti benchmark\\nunsupervised binary encoding\",\"529\":\"visualization\\nimage color analysis\\ncomputer vision\\npipelines\\nontologies\\nbiological neural networks\\ncognition\\nend effectors\\nimage classification\\ninteractive systems\\nlearning (artificial intelligence)\\nobject recognition\\npipeline processing\\nrobot vision\\ndeep functional scene understanding\\ncognitive robots\\nphysical environment\\nvisual scene\\ntwo-stage deep learning-based detection pipeline\\nscene functionality testing-bed\\nindoor scene datasets\",\"530\":\"robots\\nsemantics\\ncognition\\nthree-dimensional displays\\nvideos\\nimage segmentation\\nvisualization\\nhuman-robot interaction\\nimage classification\\nimage sequences\\nmanipulators\\nmanipulation action semantic analysis\\nspatial relations\\nhuman manipulation action recognition\\nsymbolic human-readable relation extraction\\naxis aligned bounding box object models\\nsemantic event chain framework\\nmaniac dataset\\nmanipulation actions\\nsemantic analysis\\naction semantics\\naction classification\",\"531\":\"semantics\\nimage segmentation\\nestimation\\ncomputer vision\\nlabeling\\ncomputer architecture\\nnetwork architecture\\nimage colour analysis\\nneural nets\\nmodular cnn architecture\\nconvolutional neural networks\\njoint depth prediction\\nsemantic segmentation\\nmodular neural network architecture\\ndepth estimation\\nrgb image\\nred-green-blue image\\ncross-modality influence\\nsemantic prediction maps\\nnyu-depth v2 benchmark\",\"532\":\"semantics\\nsimultaneous localization and mapping\\nthree-dimensional displays\\ngeometry\\ntwo dimensional displays\\nlabeling\\ncameras\\nfeedforward neural nets\\nimage fusion\\nimage segmentation\\nindoor navigation\\nmobile robots\\nrobot vision\\nslam (robots)\\nvideo signal processing\\nsemanticfusion\\ndense 3d semantic mapping\\nconvolutional neural networks\\nvisual sensing\\nrobot intelligence\\nintuitive user interaction\\ncnn\\nsimultaneous localisation and mapping system\\nslam system\\nelasticfusion\\nlong-term dense correspondences\\nindoor rgb-d video frames\\nloopy scanning trajectories\\nsemantic predictions\\nnyuv2 dataset\\n2d semantic labelling\",\"533\":\"labeling\\nsensors\\nstochastic processes\\nrobots\\nnavigation\\ntraining\\nrobustness\\ncameras\\ngradient methods\\nimage segmentation\\nlearning (artificial intelligence)\\noptical sensors\\npattern clustering\\nrandom processes\\nrobot vision\\nrobot navigation\\nlaser-constrained crf\\nconditional random fields\\nscene labelling\\ncontextual information\\ntraining phase\\nonline parameter learning\\nstochastic gradient descent method\\nimage data\\nloss function\\ncamera\\nlaser sensors\\nself-supervised method\\ndata distribution\\nlearning rate selection\\nkitti data set\\nonline crf training\",\"534\":\"convolution\\nkernel\\nrobustness\\nrobots\\nsemantics\\nbenchmark testing\\nimage segmentation\\nexpert systems\\nimage fusion\\nimage representation\\nneural nets\\noptical sensors\\nadapnet\\nadaptive semantic segmentation\\nadverse environmental conditions\\nrobust scene understanding\\noutdoor environments\\npassive optical sensors\\nautonomous navigation\\nsemantic segmentation architecture\\nconvoluted mixture of deep experts fusion technique\\ncmode\\nmultistream deep neural network\\ncomplementary modalities\\nexpert networks\\nscene condition\\nfused representations\\nrobust segmentation\\nforested environment\",\"535\":\"uncertainty\\nthree-dimensional displays\\nelectromagnetics\\nmagnetic fields\\nrobustness\\nstability analysis\\nmagnetic forces\\ncontrol system synthesis\\nfeedback\\nmedical robotics\\nmicromanipulators\\nmotion control\\nperturbation techniques\\nrobust control\\nuncertain systems\\ntargeted material delivery\\nperturbations\\ninput-to-state stability\\ncontroller design\\nactuator energy loss problem\\nenvironmental disturbances\\nmodel uncertainties\\nself-constructed electromagnetic coil system\\nrobust feedback control\\nminimally invasive feature\\nbiomedicine\\nelectromagnetically actuated microparticles\\nmicroparticle 3d manipulation\",\"536\":\"electron tubes\\ntendons\\nmanipulators\\nmotion segmentation\\nshape\\nkinematics\\npath planning\\npath following motion\\nhybrid continuum robot design\\ntendon driven patterned elastic tubes\\npath deviation errors\\nmanipulator\",\"537\":\"robot sensing systems\\nmanifolds\\nparticle filters\\nnoise measurement\\nmanipulators\\ndexterous manipulators\\nparticle filtering (numerical methods)\\nsensors\\nstate estimation\\nstate-space methods\\nhigh-dimensional implicit manifolds\\nnoisy robot arm\\nunderactuated hand\\nimplicit manifold particle filter\\nimplicit mpf\\ncontact sensors\\nsigned distance field\\nstate spaces\\ncontact manifold\",\"538\":\"robots\\nplanning\\nmonte carlo methods\\ntrajectory\\nuncertainty\\nphysics\\nhistory\\nmanipulators\\nopen loop systems\\ntrajectory control\\ntree searching\\nmonte carlo planning\\nnonprehensile rearrangement tasks\\nopen-loop trajectories\\nrearrangement planning problems\\nnonprehensile manipulation\\nmonte carlo tree search algorithm\\n7 degree-of-freedom manipulator\",\"539\":\"benchmark testing\\nrobot kinematics\\nprotocols\\nservice robots\\nstandards\\naustralia\\nmanipulators\\nacrv picking benchmark\\nrobotic shelf picking benchmark\\nrobotic challenges\\namazon picking challenge\\napc\\ndarpa challenges\\nobject arrangement\\nstencils\\nevaluation protocol\\nrobotic systems\\nperception\\nmanipulation\\nbaxter robot\",\"540\":\"robots\\ntrajectory\\nfeature extraction\\nshape\\nthree-dimensional displays\\nlearning (artificial intelligence)\\ninput variables\\nfeature selection\\nmanipulators\\nrobot vision\\ntrajectory control\\nversatile manipulation skills learning\\nobject configurations\\nobject features\\nreinforcement learning\\nfeature selection process\\nobserved trajectories\",\"541\":\"three-dimensional displays\\niterative closest point algorithm\\nrobot sensing systems\\nhumanoid robots\\nlegged locomotion\\nimage filtering\\nimage registration\\npose estimation\\nrobot vision\\nstate estimation\\noverlap-based icp tuning\\nrobust localization\\nhumanoid robot\\nstate estimation technique\\nrobot point-of-view\\nsemistructured environment\\nfov\\noverlap variations\\nregistration performance\\noutlier filtering\\nrobust nonincremental registration\\nprefiltering module\\nplanar macrofeature selection\\ninput clouds\\nnonuniform overlap conditions\\nnasa valkyrie\\nlaboratory environment\\nboston dynamics atlas\\ndarpa robotics challenge finals\",\"542\":\"legged locomotion\\ntrajectory\\nmathematical model\\nlimit-cycles\\nanalytical models\\nactive disturbance rejection control\\nadaptive control\\nangular velocity control\\ncompasses\\nopen loop systems\\ntrajectory control\\nwalking speed control\\napproximate-kinetic-model-based self-adaptive control\\naks control system\\nunderactuated compass-like bipedal walker\\nopen-loop system\\ntrajectory dynamic updating\\napproximate linearized model\\ndisturbance rejection\\nversatility testing\\nsteady-state error\\nlimit cycle walker\\ndisturbance handling\",\"543\":\"humanoid robots\\nstability analysis\\nforce\\ntwo dimensional displays\\nmathematical model\\npathology\\nlegged locomotion\\nlinear systems\\nlyapunov methods\\nposition control\\nrobot dynamics\\nstability\\nstability regions\\nstanding balance\\nlinear inverted pendulum model\\nlipm\\nbiped humanoid robot dynamics\\nzero moment point\\nzmp\\ncenter of mass position\\nvelocity\\nlinear inequalities\\nexternal force disturbance\\nfinite energy\\ndiscrete-time lyapunov equation\",\"544\":\"planning\\nkinematics\\nsynchronization\\ntrajectory\\nrobot kinematics\\nhumanoid robots\\npath planning\\nhumanoid whole-body planning\\nloco-manipulation tasks\\nconfiguration-time space\\ncom movement\\nv-rep\\nnao humanoid\",\"545\":\"manifolds\\nplanning\\nnavigation\\nlegged locomotion\\nshape\\nthree-dimensional displays\\ncollision avoidance\\ngraph theory\\nmotion control\\nfootstep planning\\nmotion planning\\nrandomized possibility graph\\narbitrary obstacle\\nbipedal robots\\nfootstep action\\nwhole body motion continuum\\nsemi-unstructured context\\narbitrary 3d obstacles\",\"546\":\"collision avoidance\\nrobot sensing systems\\nhumanoid robots\\nrobot kinematics\\nacceleration\\nforce control\\nforce sensors\\nmechanoception\\nnonlinear control systems\\nstability\\ntorque control\\ncollision detection\\ncollision isolation\\ncollision identification\\ncollision handling\\nrobot capability\\nstatic manipulators\\nrobot stability\\ncollision reaction phase\\nhigh fidelity contact information\\nproprioceptive sensing\\nnonlinear model-based momentum observers\\ncontact forces\\ninternal force-torque sensors\\nnonlinear compensator\\natlas robot\",\"547\":\"robot kinematics\\nhumanoid robots\\ntrajectory\\ngreen products\\ndamping\\ntorque\\ncollision avoidance\\ncompliance control\\nelasticity\\nimpact (mechanical)\\nmechanical contact\\npd control\\nquadratic programming\\nrobot dynamics\\nhumanoid falling\\ndecoupled strategy\\npre-impact stage\\npost-impact stage\\ngeometrical reasoning\\nimpact points\\nsurrounding environment\\nimpact-singularities\\ncluttered obstacles\\nquadratic program controller\\njoint proportional-derivative gains\\nrobot compliant\\nimpact dynamics\\npost-impact dynamics\\ndamage risks\\nstiffness gains\\ndamping gains\\ndecision variables\\njoint accelerations\\ncontact forces\\nhumanoid robot hrp-4\\nfull-dynamics simulator\\nqp-based adaptive-gain compliance control\",\"548\":\"legged locomotion\\ntorso\\nhumanoid robots\\nshoulder\\nrobot kinematics\\nelbow\\nangular momentum\\nbiomimetics\\ncarbon fibre reinforced plastics\\nmechanical variables control\\nyaw direction\\nhumanoid robot\\nangular momentum control method\\narm motion calculation\\ntorso motion calculation\\nhumanoid upper-body mechanism\\ncarbon fiber reinforced plastic\\nsymmetric structure\\nhuman-like running motion\\nangular momentum compensation\",\"549\":\"crawlers\\nwheels\\nblades\\ntorque\\nlegged locomotion\\nmobile robots\\nrobust control\\nblade-type crawler vehicle\\nuneven terrain\\ngyro wheel design\\nrobust traversal\\ntraveling speed\\nrobustness\",\"550\":\"actuators\\nforce\\nfabrication\\nmotion segmentation\\nthree-dimensional displays\\nsoft robotics\\nbending\\nbiomimetics\\ndesign engineering\\nelectromyography\\nlearning (artificial intelligence)\\nmedical robotics\\npatient rehabilitation\\nlobster-inspired robotic glove\\nhand rehabilitation glove evaluation\\nhand rehabilitation glove development\\nhand rehabilitation glove design\\nrigid components\\nsoft components\\nlobster bending abdomen\\nhybrid actuators\\nserially jointed rigid shells\\npressurized soft chambers\\nbending motions\\nlight-weight-physically safe-adaptive actuation\\nfabrication procedure\\nopen-palm glove design\\nlearning patterns\\nsemg signals\\nassistive glove train\\nhand rehabilitation exercises\",\"551\":\"legged locomotion\\ntracking\\noptimization\\nplanning\\ntrajectory\\nrobot sensing systems\\nnonlinear control systems\\npendulums\\nquadratic programming\\nrobot dynamics\\ntorque control\\ntrajectory control\\nquadrupedal locomotion\\ntrajectory optimization\\nhierarchical whole body control\\nconstrained optimization problem\\nhigh dimensional nonlinear nonsmooth system dynamics\\nsequential quadratic programming\\nreal system\\ninverted pendulum-based reactive stepping\\nfully torque controllable quadrupedal robot\\nanymal\\nwalking\\ntrotting\\ngait transitions\",\"552\":\"legged locomotion\\nservomotors\\nrobot kinematics\\naquatic robots\\nelectronic mail\\nhead\\nbiomechanics\\nhydrodynamics\\nmarine propulsion\\nmobile robots\\npd control\\nbiological undulation inspired swimming robot\\naquatic animal movement\\nmuscular actuation\\nswimmer inertia\\ndamping\\nstiffness\\nfluid environment\\nundulatory propulsion methods\\npropulsion mode transition\\npropulsion mode switching\\nswimming robot design\\nundulation locomotion\\nmathematical simulation\\nmodular robot platform\\nassembling function\\nbiological features\\nmodular dynamic modeling method\\ncpg-based algorithm\\npd control method\",\"553\":\"legged locomotion\\nforce\\nbiological system modeling\\ndata models\\nsprings\\nmathematical model\\nforce control\\ngait analysis\\nmedical robotics\\ntemplate model\\nhuman compliant slope walking\\nlevel-ground walking\\nbiological experiments\\ncompliant leg behavior\\nmechanical cost-of-transportation\\nbiped robots\\nfunctional terrains\\nirregular terrains\\ncharacteristic ground reaction force patterns\\nextended geyer's template biped level-ground walking\\nradial force\\nshifted anterior-posterior grf\\nleg rotary force\\nlegged robotics\\ndynamic walking\",\"554\":\"magnetic sensors\\nrobot sensing systems\\nsensor arrays\\nhall effect\\nmagnetic resonance imaging\\nclosed loop systems\\ncontrol system synthesis\\nhall effect transducers\\npath planning\\nrobot dynamics\\nautonomous locomotion\\nuntethered origami robot\\nmagnetic localization\\nautonomous control\\nmagnetically-actuated miniature robots\\nclosed-loop position feedback control\\nminiature origami robot\\nhall effect sensors\\nrobot actuation\\nmagnetic field\\ncontroller\\nautonomous movement\\nmagnetic detection\",\"555\":\"catheters\\ntarget tracking\\nmotion compensation\\nimaging\\nrobots\\nheart\\nbiomedical ultrasonics\\ncardiology\\nkalman filters\\nmedical image processing\\nmedical robotics\\nnonlinear filters\\npredictive filtering\\nsteerable cardiac catheters\\nrobotic cardiac catheterization\\nultrasound imaging catheters\\n4-dof catheter\\ncyclical physiological motions\\nrespiratory motion\\nextended kalman filter\\nekf\\nphantom vasculature\\nrobotic system\\nintra-procedural treatments\\nvisualization\",\"556\":\"saturation magnetization\\nmagnetic moments\\nmagnetic separation\\ncatheters\\nelectromagnets\\ngravity\\ncardiology\\nforce control\\nmedical control systems\\nposition control\\nsurgery\\ntethered magnet kinematics\\n5-dof pose control\\ncardiac ablation\\ncardiac arrhythmias\\nminimally invasive catheter ablation procedure\\nmagnetic manipulation systems\\nclinical mms\\nheart\\ncatheter tip flexibility\\naeon phocus\\nmagnetic field gradient control\",\"557\":\"retina\\ncatheters\\nmicromagnetics\\nvisualization\\ntools\\ndrugs\\nmagnetic resonance imaging\\ndiseases\\ndrug delivery systems\\neye\\nmedical control systems\\nshared control\\nmagnetic microcatheter\\nvitreoretinal targeted drug delivery\\nretinal diseases\\nage-related macular degeneration\\ndiabetic retinopathy\\nvisual impairment\\nmedical crisis\\ntherapeutic agents\",\"558\":\"needles\\nrobots\\nfiber gratings\\nsensors\\nbiopsy\\ntarget tracking\\nbiological tissues\\nbiomedical mri\\nbragg gratings\\nimage fusion\\nmedical image processing\\nmedical robotics\\nobject tracking\\noptical fibres\\npredictive control\\nrobot vision\\nstrain measurement\\nmri-guided flexible needle steering\\nfiber bragg grating-based tip tracking\\nmagnetic resonance images\\nmedical device electromagnetic compatibility\\nsurgical instrument real-time tracking\\nmr-compatible robot\\nfbg-based needle tip tracker\\nfbg sensors\\nstrain measurements\\nneedle tip position online estimation\\npreoperative planner\\nmodel predictive controller\\nbevel-tipped flexible needle\\ngelatin phantoms\\nflexible nitinol biopsy needle\",\"559\":\"damping\\nkernel\\nsensors\\ndata models\\nsupport vector machines\\nnavigation\\nunderwater vehicles\\nautonomous underwater vehicles\\ncontrol engineering computing\\ngaussian processes\\nlearning (artificial intelligence)\\nmobile robots\\nneural nets\\nnonlinear control systems\\nregression analysis\\nnonlinear methods\\ndamping model\\nauv leng\\ngaussian processes regression\\nkernel ridge regression\\nartificial neural networks\\nrobot on-board navigation sensors\\nmotion model identification\\nmachine learning regression methods\",\"560\":\"paints\\npainting\\nautomobiles\\nservice robots\\nthree-dimensional displays\\npath planning\\napproximation theory\\ngraphics processing units\\nindustrial robots\\nassisted painting\\n3d structures\\nshared control method\\nhand-held robot\\npainting location\\npaint distribution\\nspraying procedure\\nopen loop approximation\\nspray nozzle actuation\\ngpu\\ngraphics processing unit\\nparallelisation\\nrealtime path planning\",\"561\":\"sonar measurements\\nfeature extraction\\nsimultaneous localization and mapping\\nthree-dimensional displays\\ngaussian processes\\ninspection\\niterative methods\\nremotely operated vehicles\\nsensor fusion\\nslam (robots)\\nsonar\\nunderwater vehicles\\n3d mapping\\nsubmerged structures\\nsingle-beam scanning sonar\\nunderwater simultaneous localization and mapping\\nslam\\ninspection-class remotely operated vehicle\\nrov\\nsonar data noise\\ninertial measurements\\nodometry measurements\\ndata association\\niterative joint compatibility test\\nvehicle trajectory\\nincremental smoothing and mapping\\nisam\\ngaussian process occupancy maps\\n3d maps\\nharbor environments\",\"562\":\"data models\\ncomputational modeling\\nrobots\\noceans\\ntraining\\npredictive models\\nsea measurements\\nbayes methods\\nestimation theory\\ngeophysical image processing\\nimage classification\\nmarine control\\nmicroorganisms\\nnonparametric statistics\\noceanographic techniques\\nrobot vision\\nphytoplankton hotspot prediction\\nunsupervised spatial community model\\nsparsely distributed phenomena\\ndensity gradient\\nco-occurrence relations\\nrobot observations\\nbayesian nonparametric topic model\\nrobust estimation\\nspatial distribution\\nhotspot spatial locations\\nphytoplankton taxon\\nimage data classification\\nimaging flowcytobot\\nifcb\\nmicroscopic cells\\ncell colonies\\nphytoplankton community model\\nrobot missions\",\"563\":\"force\\npressure sensors\\nestimation\\nhydrodynamics\\nrobot sensing systems\\nthree-dimensional displays\\ntesting\\nautonomous underwater vehicles\\nbiomimetics\\ncontrol system synthesis\\nforce control\\nsensors\\nartificial fish lateral line sensory system\\nmodular pressure sensor blocks\\naquatic organisms\\nbehavioral activities\\nstation keeping\\nwall detection\\nartificial lateral line design\\nhydrodynamic force estimation\\nautonomous underwater vehicle\",\"564\":\"acoustics\\nsonar equipment\\narray signal processing\\nglobal positioning system\\nacoustic arrays\\ndata acquisition\\nautonomous underwater vehicles\\ncontrol engineering computing\\ngraph theory\\npipeline processing\\nposition control\\nrobust control\\nsensors\\nlow-cost autonomous underwater vehicles\\none-way travel-time inverted ultra-short baseline localization\\nacoustic localization system\\nlow-cost auv\\nmultiauv research\\nconventional auv sensors\\nacoustic positioning systems\\nunderwater localization problem\\nmultiauv localization\\nultra-short baseline receiver array\\nphased-array beamforming\\ngraph-based smoothing algorithm\\nauv trajectory\\nowtt inverted usbl navigation\",\"565\":\"silicon\\nsonar measurements\\nacoustics\\nsonar navigation\\nsensors\\nacoustic measurements\\nautonomous underwater vehicles\\nmonte carlo methods\\nobservability\\nacoustic-inertial underwater navigation systems\\nains\\nauv\\ninertial sensors\\nacoustic observations\\n2d imaging sonar\\ninertial measurements\\nmems inertial measurement unit\\nekf framework\\nstate vector\\ncomputational complexity\\nacoustic feature linear triangulation\\niterative solvers\\nin-depth observability analysis\\nsensor motion\\nextrinsic calibration underwater\\nimu-sonar online\\nmonte carlo simulations\",\"566\":\"rivers\\nkalman filters\\nrobots\\nestimation\\nbiological system modeling\\nstandards\\noptimization\\nmarine vehicles\\nmobile robots\\nparameter estimation\\nremotely operated vehicles\\nmarine robots\\nunmanned surface vehicles\\nriverine environments\\nwatercourse channels\\nsine-generated curves\\ngaussian filters\\nconstrained interval kalman filter\\nriver meander parameter estimation\\ncolorado river\",\"567\":\"three-dimensional displays\\nconferences\\nautomation\\nfingers\\nactuators\\ndexterous manipulators\\nposition control\\nrobot finger\\nvariable stiffness actuator\\nshape memory alloy\\nposition tracking control\\nvariable stiffness mechanism\\nvariable stiffness design\\nsma-3 fibers\\npulling force\\nheating current\\nsma actuator\\nvariable stiffness\",\"568\":\"robots\\nforce\\nmuscles\\nactuators\\nforce measurement\\nautomation\\ncardiology\\ncellular biophysics\\ndrugs\\nion microscopy\\nmedical robotics\\ncardiomyocyte contraction control\\nbiosyncretic robots actuation\\nliving biological materials\\nelectromechanical systems\\nactuation unit cells\\ncell culturing time\\nseeding concentration\\nfunctional drugs\\ncontractile frequency\\ncardiomyocytes force strength\\nscanning ion conductance microscope\\nsicm\\nmicropillars arrays\",\"569\":\"robots\\nhydraulic systems\\ncomputational modeling\\ninstruction sets\\ncavity resonators\\ngraphics processing units\\nactuators\\ncontrol engineering computing\\nparallel processing\\npath planning\\npublic domain software\\nrobot kinematics\\nhydraulic components\\ninteractive control\\nonline motion planning\\nhydraulic actuated soft robots\\ninteractive resolution\\ninverse kinematics\\ndeformable material properties\\nmechanical behavior\\nreal-time computation\\nfluid weight distribution\\ngpu parallel leveraging mechanism\\nopen-source sofa\\nfabricated silicone cylinder\",\"570\":\"strain\\nrobot sensing systems\\nresistance\\nmorphology\\nsensitivity\\ndeformation\\nelastomers\\ngrippers\\nstrain sensors\\nlocalized differential sensing\\nsoft deformable surface\\nrobotic application\\nsoft technologies\\nsensory motor capabilities\\ndeformable continuum body\\nintrinsic soft body dynamics\\nsoft body sensing method\\nconductive thermoplastic elastomer\\nctpe\\nuniversal gripper\\ngrasped object detection\",\"571\":\"actuators\\nlayout\\nrobot sensing systems\\ncapacitive sensors\\ngrasping\\nmetals\\nend effectors\\npneumatic actuators\\npressure sensors\\nstrain sensors\\nrbo hand 2\\nsoft actuators\\nsensorization\\nredundant sensor layout\\npneuflex actuators\\nliquid metal strain sensors\\npressure sensor\\nactuator deformation prediction\",\"572\":\"collision avoidance\\nmanipulators\\nrobot sensing systems\\nservice robots\\nshape\\nelastic constants\\nindustrial robots\\npneumatic actuators\\nvariable stiffness link\\nvsl\\ninherently safe robotic manipulators\\nindustrial robotics\\ncollaborative robots\\nrigid body structures\\nharmful collision risk\\nhuman operators\\nsilicone-based structures\\nfabric materials\\nstiffness-controllable link creation\\npressure sensors\\nmanipulator body\\nrobotic manipulator\\ncollision detection control system\\ncollision detection hardware\",\"573\":\"robot sensing systems\\nskin\\nstrain measurement\\nmorphology\\nsurface morphology\\nintelligent sensors\\npneumatic actuators\\nstrain gauges\\nstrain sensors\\ntactile sensors\\ntouch (physiological)\\nactive tactile sensation\\nsoft morphological computation\\nwet environment\\ntactile sensing system\\npneumatic actuator\\nstrain gauge\\nembedded sensing element\\nindentation contact\\nsliding action\\nsoft morphological control\",\"574\":\"muscles\\nsensor phenomena and characterization\\nresistance\\nrobot sensing systems\\nelectrical resistance measurement\\ncontrol system synthesis\\nelectroactive polymer actuators\\nfeedback\\npneumatic actuators\\nvariable structure systems\\nintegrated soft sensing\\npneumatic artificial muscle actuators\\nintegrated low profile sensors\\n3d manufacturing process\\nmodified lathe approach\\nviscous materials\\nmaximum muscle contraction\\nposition feedback sliding mode controller\\nmuscle-sensor package\\nprecision pneumatic muscle design\\nliquid metal direct writing\\nviscoelastic materials\",\"575\":\"trajectory\\ndata structures\\nheuristic algorithms\\nplanning\\naerospace electronics\\nprediction algorithms\\ndynamics\\nclosed loop systems\\nmobile robots\\noptimal control\\npath planning\\nrandom processes\\nrobot dynamics\\nsampling methods\\nsampling-based algorithms\\noptimal motion planning\\nclosed-loop prediction\\nrobotics\\nkinodynamic variants\\nrapidly-exploring random trees\\nrrts\\ncomplex dynamics\\noptimality\\nopen-loop dynamics\\ncl-rrt# algorithm\\ncomplex unstable dynamics handling\\ncomputationally hard steering procedures\\nautonomous-driving scenario\",\"576\":\"traveling salesman problems\\nrobot sensing systems\\napproximation algorithms\\nspace exploration\\nalgorithm design and analysis\\ncomputational complexity\\npath planning\\nrandomised algorithms\\nrandomized algorithm\\ninformative path planning\\nbudget constraints\\ninformation gathering task\\ncost constraints\\noperating time constraints\\nipp problem\\ncorrelated orienteering\\nnp-hard problem\\nrandomized anytime orienteering algorithm\\nraor algorithm\\nconstraint satisfaction problem\\ntraveling salesman problem\",\"577\":\"trajectory\\nrobot kinematics\\nsurface treatment\\nthree-dimensional displays\\nplanning\\nelliptic equations\\ngraph theory\\nmobile robots\\nmulti-robot systems\\npartial differential equations\\npath planning\\nrobot coverage path planning\\ngeneral surfaces\\nplanar domains\\ncomplex topology\\ncomplex terrain\\n3d space\\nnatural parametrization\\nintrinsic parametrization\\nglobal parametrization\\nholomorphic quadratic differentials\\nuv-coordinates\\ncomplex number\\nnatural robot paths\\ncoordinate systems\\nintrinsic geometry\\nsurface exploration\",\"578\":\"torque\\nforce\\nlegged locomotion\\nknee\\nhip\\nmanipulators\\ntorque efficient motion\\nquasi-static motions\\nmomentum generation\\nrobotic leg\\nminimum torque configuration\\nstroke motion\\ncollinear stroke\",\"579\":\"trajectory\\nplanning\\nuncertainty\\nsafety\\noptimization\\napproximation algorithms\\nmonte carlo methods\\napproximation theory\\ncontrol engineering computing\\ngraphics processing units\\npareto optimisation\\npath planning\\nstochastic processes\\nreal-time stochastic kinodynamic motion planning\\ngpus\\npump\\nparallel uncertainty-aware multiobjective planning\\ncollision probability\\npareto front\\noptimization objective\\nparallel multiobjective search\\nexploration phase\\npareto set\\nparticle-based cp approximation\\ntrajectory execution\\nquadrotor planning\",\"580\":\"robot sensing systems\\nsearch problems\\nsurveillance\\ntrajectory\\ngames\\nimage sensors\\nmobile robots\\nobject detection\\nrobot vision\\npersistent pursuit-evasion\\npreoccupied pursuer\\nvisibility-based pursuit-evasion problem\\nevader detection\\nreal sensor systems\\npessimal unoccluded distance\\noccluded region\\npursuer robot sensor footprint\",\"581\":\"legged locomotion\\ntrajectory optimization\\ndynamics\\nheuristic algorithms\\nactuators\\nflexible structures\\noptimisation\\npath planning\\nrobot dynamics\\ntrajectory control\\nfunctional co-optimization\\narticulated robots\\nparametric trajectory optimization\\nrobot motion planning\\nactuation inputs\\ncontact forces\\nuser domain knowledge\\ntarget robot configuration\\nparameterized robot topology\\nrobot body parameter optimization\\nrobot trajectories\",\"582\":\"kinematics\\nplanning\\nend effectors\\ntrajectory\\nrobot kinematics\\ncollision avoidance\\nmobile robots\\nmotion control\\nquadratic programming\\ntrajectory control\\nmotion planning\\ninverse kinematics branching\\nrobotic manipulation task planning\\nrobot position\\nrobot motion\\nend-effector trajectory\\nvirtual robot arms\\nquadratic program\",\"583\":\"lasers\\ncameras\\noptimization\\nthree-dimensional displays\\nvisualization\\nmeasurement by laser beam\\nmotion estimation\\nimage registration\\ninertial systems\\npipeline processing\\ndata processing pipeline\\nonline ego-motion estimation\\ntraversed environment\\n3d laser\\ncamera\\nimu\\nsequential multilayer processing pipeline\\nhigh-frequency low-latency ego-motion estimation\\ndense accurate 3d map registration\\nsensor degradation\\nautomatic reconfiguration bypassing failure modules\\nhighly dynamic motion\\ndark textureless environments\\nstructure-less environments\\nrelative position drift\\nnavigation\\naggressive motion\",\"584\":\"estimation\\nlasers\\ntwo dimensional displays\\nneural networks\\nrobot sensing systems\\nthree-dimensional displays\\ncameras\\nimage classification\\nlaser ranging\\nneural nets\\nstereo image processing\\nparse geometry\\nmonocular depth estimation\\npartial laser observation\\nfixed 2d laser range finder\\nstandard robotic platforms\\nmonocular camera\\n3d depth sensing capability\\nrobotic activities\\nmonocular images\\n2d planar observation\\ndepth estimation task\\nresidual neural network\\nnyud2\\nkitti\\nobstacle avoidance\\n2d laser range finder\",\"585\":\"three-dimensional displays\\nlaser radar\\nclustering algorithms\\nsurface treatment\\nautonomous vehicles\\nautomobiles\\npipelines\\nimage segmentation\\nmobile robots\\noptical radar\\nradar imaging\\n3d point cloud segmentation\\nautonomous vehicle navigation\\nautomobile industry\\nlidar sensor\\nground surface segmentation\",\"586\":\"image color analysis\\ncameras\\nfeature extraction\\ncrosstalk\\nthree-dimensional displays\\nshape\\npattern matching\\nimage colour analysis\\nlearning (artificial intelligence)\\nneural nets\\nstereo image processing\\nlearning-based feature extraction\\nactive 3d scan\\ncolor crosstalk reduction\\npattern projection\\n3d reconstruction methods\\nactive stereo technique\\nmultiprojector systems\\ncolor channel\\nmachine learning techniques\\nconvolutional neural network\\nlow dimensional pattern features\",\"587\":\"target tracking\\nvisualization\\ncameras\\nacoustics\\nrobot vision systems\\ngaussian processes\\nimage filtering\\nimage fusion\\nimage sensors\\nkalman filters\\nmobile robots\\nnonlinear filters\\nobject tracking\\nregression analysis\\nultrasonic arrays\\nultrasonic devices\\n3-d position\\nreal-time robotic 3-d human tracking system\\nmonocular camera\\nextended kalman filter\\nmonocular camera sensor tracking model\\nultrasonic sensor tracking model\\nmultisensor fusion\\nvisual tracking algorithm\\npartial location estimation\\nscale accuracy\\n3-d information\\nultrasonic sensor array\\nrange information\\ngaussian process regression\\nheterogeneous measurements\\nasynchronous order\\nvision sensor\\nmobile robot\\nindoor scenes\\noutdoor scenes\\nekf\",\"588\":\"optical sensors\\ncameras\\nrobot vision systems\\ntactile sensors\\nmanipulators\\npretouch sensing\\nsequential manipulation\\npretouch sensors\\nclose-range proximity sensing\\nrobotic system\\nrubik cube\",\"589\":\"sonar\\nthree-dimensional displays\\ntrajectory\\nplanning\\ncameras\\nimage reconstruction\\nheuristic algorithms\\narchaeology\\nautonomous underwater vehicles\\nbathymetry\\nmobile robots\\noceanographic techniques\\npath planning\\nphotogrammetry\\nrobot kinematics\\ntrees (mathematics)\\nauv motion-planning\\nphotogrammetric reconstruction\\nmarine archaeological site\\n3d map construction\\nmultiple auv missions\\nhigh altitude lawnmower scan\\ncourse bathymetry map\\nlow altitude fly-over\\ncamera image\\noffboard 3d mapping\\nauv path\\ninformation gain maximization\\nrapidly-exploring random trees\\nsampling strategies\\nrandom node selection\\nnode generation\\nauv kinematics\\nwreck mapping\\nmalta coast\\nvisualization\",\"590\":\"calibration\\ncameras\\nlasers\\nmeasurement by laser beam\\nthree-dimensional displays\\nlaser beams\\nsensors\\nimage sensors\\nlaser ranging\\noptical sensors\\nextrinsic calibration\\n2d laser-rangefinder\\ncamera\\nlrf\\npoint-to-plane constraint\\nv-shaped calibration pattern\\nnoncoplanar triangle suffice\\nsensor\",\"591\":\"simultaneous localization and mapping\\nreal-time systems\\nthree-dimensional displays\\noptimization\\ncameras\\nindoor environments\\ngraphics processing units\\nimage fusion\\nimage segmentation\\nimage sensors\\nmobile robots\\noptimisation\\nprobability\\nrobot vision\\nslam (robots)\\nspatial variables measurement\\nkeyframe-based dense planar slam\\nkdp-slam\\ncpu\\nhand-held rgb-d sensor\\ndense method\\ndepth measurements\\nbaseline images\\nfused depth map\\nincremental smoothing and mapping\\nisam\\nfast odometry estimation\\ncorrect plane correspondences\\nlocal fusion process\\nplane segmentations\\nprobabilistic global optimization\\nrgb-d benchmarks\",\"592\":\"radio frequency\\ncameras\\nartificial neural networks\\nthree-dimensional displays\\ntraining\\nvegetation\\nrobustness\\nimage colour analysis\\nlearning (artificial intelligence)\\nneural nets\\nregression analysis\\nrandom forests\\nneural networks\\ncamera localization\\nsingle input rgb image\\nred-green-blue image\\n3d scene coordinate\\ndense regression task\\nfully-differentiable robust averaging technique\\nregression ensembles\\nscene coordinate regression\\nforestnet\",\"593\":\"simultaneous localization and mapping\\noptimization\\nestimation\\ncameras\\nfeature extraction\\nvisualization\\nimage reconstruction\\nimage motion analysis\\noptimisation\\nrobot vision\\nslam (robots)\\nvideo streaming\\nmonocular visual odometry\\nsparse joint optimisation\\ndense alternation\\nreal-time monocular slam\\nvideo stream\\ndense methods\\nsemi-dense methods\\nimage information\\nscene information\\nlocal-motion estimation accuracy\",\"594\":\"maximum likelihood estimation\\noptimization\\nthree-dimensional displays\\nsymmetric matrices\\nsimultaneous localization and mapping\\nrendering (computer graphics)\\ngraph theory\\niterative methods\\nmathematical programming\\npose estimation\\nslam (robots)\\n3d pose graph optimization\\nlagrangian duality\\npgo\\nslam\\nmle\\nconvex semidefinite programming\\nsdp\\nlocal iterative methods\",\"595\":\"attenuation\\nthree-dimensional displays\\ncameras\\nimage color analysis\\nimage reconstruction\\nscattering\\nsolid modeling\\nimage colour analysis\\nrobot vision\\nsensors\\nstereo image processing\\nautomatic color correction\\nunderwater scenes\\nunderwater environment mapping\\nsubmerged archaeological sites\\ncoral reef habitat monitoring\\ndense 3d-scene reconstructions\\nbrightness constancy constraint\\nterrestrial techniques\\nunderwater 3d-reconstruction\\nnonlinear optimization\\npure water tank\\nstereo camera platform\\nunderwater robotic survey\\nrgb-d sensor\\ncolor calibration board\\nwater-column aware model\\nunderwater 3d reconstruction\\nbundle adjustment\\nstereo vision\",\"596\":\"distortion\\ncameras\\nsimultaneous localization and mapping\\nsplines (mathematics)\\nlenses\\noptical distortion\\ntrajectory\\ncalibration\\ncmos image sensors\\nslam (robots)\\nrrd-slam method\\nradial-distorted rolling-shutter direct slam method\\nmonocular direct semidense slam method\\nsimultaneous localization and mapping method\\nwide-angle lens\\ncmos sensor\\nprecalibrated parameter\\ngeneralized epipolar curve\",\"597\":\"acceleration\\nmobile robots\\nobservability\\nwheels\\nnoise measurement\\nmathematical model\\ninertial navigation\\nmotion control\\nposition control\\nrobot vision\\nvins\\nvision-aided inertial navigation system\\nwheeled robots\\nunobservable directions\\nground vehicle\\nlow-frequency wheel-encoder data\\napproximately planar surface\\nspecial motions\\npositioning accuracy\\ncommercial-grade mobile device\",\"598\":\"simultaneous localization and mapping\\ncompass\\nsonar\\nvisualization\\nglobal positioning system\\nsensors\\nslam (robots)\\naquatic simultaneous localization-and-mapping\\naquatic gps-denied environments\\nautonomous robots\\nmotion estimation problems\\nvisual sensors\\naquatic surface vehicle\\nslam performance improvement\\nautonomous surface vehicles\",\"599\":\"aircraft\\nattitude control\\npropellers\\nswitches\\naerodynamics\\nangular velocity\\naerospace components\\naerospace control\\napproximation theory\\ncontrol system synthesis\\nentry, descent and landing (spacecraft)\\nfeedforward\\nflight controller design\\nflight controller demonstration\\nthrust-vectored tailsitter\\nrotary wing systems\\nfixed wing systems\\nseparable takeoff bracket\\ncontrollable forward landing\\nsix-degrees-of-freedom model\\nattitude representation\\nhorizontal-vertical euler angles\\ncontroller linear-constant acceleration approximation\\nfiltered feed-forward acceleration algorithm\",\"600\":\"unmanned aerial vehicles\\ngrasping\\nplanning\\nmanipulators\\ngrippers\\npropellers\\nmathematical model\\nautonomous aerial vehicles\\nmotion control\\noptimisation\\npath planning\\nwhole-body aerial manipulation\\ntransformable multirotor\\ntwo-dimensional multilinks\\ntransformable aerial robot\\naerial transformation\\ngripper\\nplanning method\\noptimized grasping\\nplanar enveloping algorithm\\ninternal force optimization\\njoint torque optimization\\nforce-closure\\ngrasp motion strategy\\nwhole-body grasp planning\",\"601\":\"trajectory\\ntraining\\ntrajectory tracking\\nfeedback control\\nartificial neural networks\\nautonomous aerial vehicles\\ncontrol engineering computing\\ncontrol system synthesis\\nfeedback\\nhelicopters\\ninteractive systems\\nneurocontrollers\\nthree-term control\\ntrajectory control\\ndeep neural networks\\nquadrotors\\ntrajectory tracking control\\nproportional-integral-derivative controllers\\npid\\ntracking precision\\ndeep neural network\\ndnn-based algorithm\\nadd-on module\\nfeedback controller\\nunity map\\ninteractive fly-as-you-draw application\\ndnn-enhanced control system\\nperiodic trajectories\",\"602\":\"unmanned aerial vehicles\\npropellers\\nrobots\\nforce\\nadmittance\\nobservers\\ntrajectory\\nactuators\\nautonomous aerial vehicles\\nend effectors\\nestimation theory\\nhelicopters\\nvelocity measurement\\n6d physical interaction\\nfully-actuated aerial robot\\nphysically interactive tasks\\ntilt-hex\\ntilted-propeller hexarotor\\ngeometric control\\nend effector\\nadmittance control\\npose tracking\\nmomentum based observer\\nspeed measurement\",\"603\":\"payloads\\nforce\\nrobot sensing systems\\ntrajectory\\ncollaboration\\nmathematical model\\nautonomous aerial vehicles\\nhelicopters\\nmobile robots\\nrobot vision\\ndynamic collaboration\\nvision-based cable-suspended load transport\\nquadrotors\\nobject transport\\nground robots\\naerial robots\\nobject delivery\\narbitrary terrains\\nmultiple flying robots\\ncollaborative transport scheme\\ncable-suspended payload\\ncollaborating robots\\nvisual cues\\ninertial cues\\non-board sensors\",\"604\":\"propellers\\nrotors\\nvelocity control\\nrobot sensing systems\\npermanent magnet motors\\nrobustness\\nadaptive control\\nangular velocity control\\nautonomous aerial vehicles\\nbrushless dc motors\\nclosed loop systems\\nfloating point arithmetic\\nhelicopters\\nmicrocontrollers\\npublic domain software\\nsynchronisation\\nadaptive closed-loop speed control\\nbldc motors\\nmultirotor aerial vehicles\\nadaptive bias and adaptive gain algorithm\\nabag\\nclosed-loop electronic speed control\\nesc\\nbrushless direct current motors\\nbldc\\nmultirotor aerial robots\\nmechanical-electrical parameter\\nmotor-propeller group\\nlow complexity implementation\\nmicrocontroller\\nfloating point unit\\nlimited arithmetic capabilities\\nself-contained open source software architecture\\nclock synchronization\\nover-current\\nblockage safeties\\naerial physical interaction experiments\",\"605\":\"propellers\\nprototypes\\nrotors\\nunmanned aerial vehicles\\nacceleration\\ndynamics\\nforce\\nautonomous aerial vehicles\\nend effectors\\nforce sensors\\nhelicopters\\nmobile robots\\ntelerobotics\\ni-boomcopter uav\\nenvironmental interaction\\ninteracting-boomcopter\\nunmanned aerial vehicle\\nhorizontally mounted four-blade reversible propeller\\nfront boom\\ntri-rotor uav configuration\\nend-effector\\nforce sensor\\nautonomous pushing interaction tasks\\nautonomous pulling interaction tasks\",\"606\":\"robots\\nclustering algorithms\\nimage segmentation\\nimage color analysis\\nfeature extraction\\nneural networks\\ntraining\\nagriculture\\nindustrial robots\\nneural nets\\npattern clustering\\nunsupervised weed scouting\\nagricultural robotics\\nintegrated weed management\\nautomated weed scouting\\nweed destruction\\nclustering approach\\ndeep convolutional neural network\\nagbotii\",\"607\":\"fires\\nrobots\\nestimation\\nfeature extraction\\nbayes methods\\nreflection\\nestimation theory\\nimage texture\\ninfrared imaging\\nnavigation\\nreal-time systems\\nrescue robots\\nrobot vision\\nstatistical analysis\\nbayesian estimation\\nreal-time fire-heading estimation\\nsmoke-filled indoor environments\\nthermal imagery\\nautonomous navigation\\nthermal images\\nstatistical texture features\\nfirefighting robot\",\"608\":\"three-dimensional displays\\nheuristic algorithms\\nrobots\\ncomputational modeling\\ngeometry\\nimage reconstruction\\ndetection algorithms\\nobject detection\\nrobot vision\\ntsdf-based change detection\\nconsistent long-term dense reconstruction\\ndynamic object discovery\\n3d reconstruction algorithm\\ntruncated signed distance function\\ntsdf\\nmap updates\\npoint clouds\\nscene differencing problem\\nunsupervised object discovery\\nclass recognition\",\"609\":\"cameras\\nfield programmable gate arrays\\nreal-time systems\\nrobot vision systems\\ndistortion\\nlenses\\nautonomous aerial vehicles\\ncollision avoidance\\nembedded systems\\nimage matching\\nmicrorobots\\nrobot vision\\nstereo image processing\\nembedded real-time multibaseline stereo\\ndense depth map estimation\\nstereo cameras\\nrobotic vision\\nobstacle detection\\ndepth values\\ntwo-camera stereo setups\\nmatching cost functions\\nmultiimage matching\\nmultibaseline stereo\\nembedded system\\nfpga\\nmav platform\\nautonomous vehicles\",\"610\":\"sun\\ncameras\\nhazards\\nimage color analysis\\nmathematical model\\nazimuth\\nscattering\\nlight polarisation\\nlight reflection\\noptical sensors\\nwater\\n3d water hazard tracking\\nself-driving car system\\nrgb camera\\nlidar technology\\nwater hazard detection\\nstereo-polarization camera system\\nlight polarization sensor\\nprimary sensing modality\\nautonomous car perception\\nhazardous wet condition\",\"611\":\"semantics\\nrobots\\nimage segmentation\\nobject detection\\nlabeling\\ncontext modeling\\nmeasurement\\nrandom processes\\nrobot vision\\nsemantic segmentation\\nrobotic applications\\nhierarchical conditional random fields\\nregion-based conditional random field model\\nobject-level performance\\nsemantic region-level\\npixel-level performance\\nobject-aware performance metric\",\"612\":\"three-dimensional displays\\nfeature extraction\\nhistograms\\nshape\\nimage segmentation\\nrobustness\\nimage matching\\nimage sequences\\nvisual databases\\nsegmatch\\nsegment based place recognition\\n3d point clouds\\nlocal features\\nglobal features\\n3d segment matching\\nlocal descriptions\\nglobal descriptions\\nlarge-scale unstructured environments\\nkitti odometry dataset\\nsource code\",\"613\":\"visualization\\nthree-dimensional displays\\nobject recognition\\nrobot sensing systems\\ntraining\\nhistograms\\nhaptic interfaces\\nimage classification\\nlearning (artificial intelligence)\\nrobot vision\\ncross-modal visuo-tactile object recognition\\nrobotic active exploration\\nvisual data\\ntactile perception\\ntactile data\\ncross-modal perception\\nclassification applications\\nsupervised learning algorithm\",\"614\":\"manipulators\\ncomputational modeling\\nelasticity\\nrobustness\\ntrajectory tracking\\nnumerical models\\ncontrol system synthesis\\nmanipulator dynamics\\nmanipulator kinematics\\nmotion control\\nrecursive estimation\\nrobust control\\ninverse-dynamics control\\npassivity-based control\\nrobots tracking control\\njoint elasticity\\nintrinsic robustness\\nuncertainty modelling\\nrecursive algorithm\\nelastic-joint reconfigurable robotic arm\\non-the-fly control design\",\"615\":\"vibrations\\nfeedforward neural networks\\nmanipulators\\ndamping\\noscillators\\ntrajectory\\nfeedforward\\nfir filters\\nvibration control\\nvariable stiffness joints robots\\nvibrations suppression\\nfeedforward controller\\ncontinuous-time finite impulse response filter\\nrobot manipulators\\nelastic joints\\nvsj robots\\noscillations\\ndecentralized control\\nservomotor\\nreference signals\\nfiltering action\",\"616\":\"tuning\\npd control\\npi control\\ncomputational modeling\\ndata models\\nstate feedback\\nprocess control\\ndexterous manipulators\\nmanipulator dynamics\\nmultivariable control systems\\nnonlinear control systems\\noptimal control\\npendulums\\nsearch problems\\nthree-term control\\nmodel-based policy search\\nautomatic multivariate pid controller tuning\\nmultiple-coupled pid controller tuning\\npilco\\nstatic state feedback policy\\nfinite horizon optimal control problem\\ninverted pendulum balancing task\\nseven-degree-of-freedom robotic arm\\nproportional-integral-and-derivative control\",\"617\":\"legged locomotion\\ncost function\\nkernel\\ntrajectory\\ndynamics\\ncontrol system synthesis\\nhydraulic actuators\\nmotion control\\nperiodic control\\ntrajectory control\\nwhole-body trajectory optimization\\nnonperiodic dynamic motion\\nautonomous legged robot\\ncomplex environment\\nperiodic locomotion task\\ngeneralized strategy\\ndynamic nonperiodic movement\\nmotion design\\nteleoperation\\nhydraulically actuated hyq2max quadrupedal system\\nrearing\\nposture recovery\\nmultiple contacts\\nfeet placement\\nmotion synthesis\\noptimization\\nparametrized policy\\nmulti-legged systems\\nswitching contacts\\nnon-periodic movements\\nquadruped\\nwhole-body trajectory\",\"618\":\"legged locomotion\\noptimization\\nforce\\nacceleration\\ntrajectory\\nmathematical model\\nmotion control\\nnonlinear programming\\npath planning\\nrobot kinematics\\nstability\\ntrajectory control\\nonline walking motion\\nfoothold optimization\\nquadruped locomotion\\nwalking motion generation\\nexplicit footstep planner\\ncenter of mass trajectory optimization\\nstability constraint\\nzero moment point\\nkinematic constraints\\ncom position\\nwalking gait generation\\nquadruped robot\",\"619\":\"adaptation models\\npredictive models\\nvehicle dynamics\\ncomputational modeling\\nnonlinear dynamical systems\\npredictive control\\nsystem dynamics\\nadaptive control\\nfeedback\\nhelicopters\\nnonlinear control systems\\nquadratic programming\\nadaptive nonlinear model predictive control\\nexperience-driven predictive control\\nepc\\nnmpc problems\\nuncertain system dynamics\\naffine dynamics model\\nlocally weighted projection regression\\nlwpr\\nrecast\\nquadratic program\\nqp\\nmultiparametric techniques\\naffine feedback control law\\nbasis functions\\ninput-output relationship\\nredundant optimization problems\\nhardware-in-the-loop simulation\\nquadrotor micro air vehicle\\nexogenous perturbations\",\"620\":\"trajectory\\nanimals\\nestimation\\nmobile robots\\noptical imaging\\ncameras\\nmotion control\\nextended tau theory\\nrobot motion control\\ntime-to-contact\\nimage sequences\\nmobile robot platform\\nnonzero contact velocity\\nonboard vision feedback\",\"621\":\"force\\ndelay effects\\nforce feedback\\nrobot kinematics\\naerospace electronics\\naerospace robotics\\nergonomics\\nfeedback\\nforce sensors\\nhaptic interfaces\\nhuman-robot interaction\\nmanipulators\\nmulti-robot systems\\nreliability\\ntelerobotics\\nhaptic intention augmentation\\ncooperative teleoperation\\nmultiple robotic agents\\nrobotic manipulators\\nrobot cooperation\\nvisual feedback\\nhaptic feedback\\ncooperative telemanipulation\\nforce sensor\\non-ground robot\\ncosmonaut\\ninternational space station\\nteleoperation\\nhaptic augmentation\\noperator intention\\ncooperation\\niss\\ntime delay\",\"622\":\"trajectory\\ngrippers\\ncameras\\nmanipulators\\nforce feedback\\nsplines (mathematics)\\nfeedback\\nforce control\\nhardware-in-the loop simulation\\nmotion control\\ntelerobotics\\ntrajectory control\\nvelocity control\\nwaste handling\\nremote telemanipulation\\nintegral haptic feedback\\nenvironmental challenges\\neuropean countries\\nmaintenance cost optimization\\nnuclear waste sorting\\nnuclear waste segregation\\nradiation level\\nvisual-based shared control architecture\\nremote robotic arms\\ngripper\\nmotion commands\\nlocality issue\\ninstantaneous velocity commands\\ninstantaneous force feedback cues\\ntrajectory steering\\ntask space\\nintegral force feedback\\ncomplex manipulation tasks\\nplanning-based shared control architecture\\nhuman\\/hardware-in-the-loop experiment\\nsimulated slave robots\\nmaster device\",\"623\":\"legged locomotion\\ndynamics\\nfoot\\nforce\\nrobot kinematics\\nmathematical model\\nhumanoid robots\\nhuman-robot interaction\\nmotion control\\nposition control\\nsynchronisation\\ntelerobotics\\nhumanoid posture teleoperation\\ndynamic synchronization\\noperator motion anticipation\\nhuman operator\\nrobot slave\\nreactive controllers\\nposition tracking\\nerror-based control forces\",\"624\":\"robots\\nvisualization\\nestimation\\nacceleration\\npredictive models\\ntrajectory\\nfeedback control\\nfeedback\\nobject recognition\\nparticle filtering (numerical methods)\\npredictive control\\nrobot vision\\ntelerobotics\\nvision-based predictive assist control\\nmaster-slave systems\\nmaster-slave robots\\noperation assist algorithm\\nvisual feedback control\\nvisual object recognition\\nparticle filter\\noperators intention estimation\\nreaching motion\",\"625\":\"force\\nthree-dimensional displays\\nvisualization\\nrobot sensing systems\\nrobot kinematics\\nmanipulators\\nflexible manipulators\\nforce control\\nhuman-robot interaction\\nrobot vision\\ntelerobotics\\ntrajectory control\\nflexible virtual fixture interface\\npath specification\\ntele-manipulation\\nflexible force-vision-based interface\\npath constraint\\nremote robot manipulator\\nteleoperation\\nbilateral configurations\\nunilateral configurations\\ncognitive load\\nunilateral teleop configuration\\nvisual-force constraints\\nbilateral teleop configuration\\ndisplacement error\\nsmoother trajectory\",\"626\":\"robot sensing systems\\nthree-dimensional displays\\njoints\\ncomputational modeling\\nsolid modeling\\ncomputer vision\\ncontrol engineering computing\\nhuman-robot interaction\\npose estimation\\nrobot vision\\nsolid modelling\\ngenerative human-robot motion retargeting approach\\nsingle depth sensor\\nhuman pose estimation\\n3d parametric human-robot model\\njoint configuration\\nstability configuration\\ntransformed surface shape\\nrobot configuration\\nskeleton proportion\",\"627\":\"manipulators\\ncameras\\nrobot vision systems\\nrobot kinematics\\nmotion control\\nmotion estimation\\noptimal control\\nrobot vision\\nsensors\\ntelerobotics\\ngoal-predictive robotic teleoperation\\nnoisy sensors\\nhuman operator pose demonstrations\\nsensor technologies\\nlow-cost depth cameras\\nrobot workspace\\ngoal-predictive teleoperation system\\ninverse optimal control\\nmotion trajectory\\nautonomous completion\\nmicrosoft kinect depth camera\\ninput sensor\\nrethink robotics baxter robot\",\"628\":\"mobile robots\\nrobot kinematics\\nmanipulators\\nreceivers\\nmulti-robot systems\\nestimation\\ndecentralised control\\nestimation theory\\ngraph theory\\nstability\\ntelerobotics\\ndecentralized bilateral teleoperation system\\ntask abstraction\\nmultirobot system\\nhuman command\\nmaster robot\\nlocal side\\nundirected graph\\nconnected graph\\nglobal task function\\nmobile robot network\\nstability analysis\\ndecentralized teleoperation system\\ndecentralized estimation\\ndecentralized control\\nmulti-robot teleoperation\",\"629\":\"cells (biology)\\nbiopsy\\nmicrofluidics\\nsurgery\\nglass\\nbiomembranes\\nrobots\\ncellular biophysics\\nmedical robotics\\nmicromanipulators\\nmouse controllers (computers)\\nhigh-precision robot-aided single-cell biopsy system\\nprecise robot-aided single-cell surgery system\\nmicrofluidic chip\\nmicropipette\\n3-dof micromanipulator\\ncomputer mouse-operated high-precision xy stage\\nhigh-precision high-throughput single-cell biopsy\\norganelles\\nadherent cells\\nfluorescent-labeled nucleus\\nhuman foreskin fibroblast cells\\nsemiautomated biopsy survival rate\\nmitochondrial biopsies\\nnucleus biopsies\",\"630\":\"microscopy\\ntools\\ntracking\\ndiscrete fourier transforms\\nmicromanipulators\\nrobot kinematics\\nobject detection\\nobject tracking\\nrobot vision\\nvisual servoing\\ndetect-focus-track-servo\\nvision-based workflow algorithm\\nrobotic image-guided micromanipulation\\nmicroscope systems\\nblurred images\\ncluttered images\\nself-focus algorithm\\nsubpixel uncertainty\\ndfts workflow algorithm\\nrobotic image-guided cell manipulation\",\"631\":\"cameras\\nactuators\\nfasteners\\noptical sensors\\nrobot vision systems\\nfabrication\\nimage capture\\nimage sensors\\nmicrorobots\\nmobile robots\\nopen loop systems\\nrobot vision\\nstability\\nvideo cameras\\nvideo signal processing\\nactuated gaze stabilization platform\\nflapping-wing microrobot\\nonboard vision sensing\\nmicroscale robotics\\nrobobee\\nonboard vision sensor\\nimage quality\\ncamera\\nvideo capture\\none degree of freedom mechanism\\noutput angles\\nopen-loop roll maneuvers\",\"632\":\"aerodynamics\\ntorque\\ndamping\\nvehicle dynamics\\nforce\\nrobots\\nradiation detectors\\naerospace components\\nasymptotic stability\\nattitude control\\nautonomous aerial vehicles\\nmicrorobots\\nmotion control\\nnonlinear dynamical systems\\ntensors\\ntorque control\\nvibration control\\ngeometric flight control\\nhovering robotic hummingbird\\nhovering control\\nmotor driven flapping wing micro aerial vehicles\\nfwmav\\nnonlinear dynamic model\\nfull inertia tensor\\nnonlinear input mapping\\ndamping effect\\nflapping counter torques\\nfct\\nflapping counter forces\\nfcf\\nexponential stability\\nglobal exponential attractive properties\\nvehicle lifting off\\nattitude stabilization\",\"633\":\"gears\\nprototypes\\nsprings\\ndesign optimization\\nvehicle dynamics\\ndc motors\\nsystem integration\\nautonomous aerial vehicles\\ndesign engineering\\nmicrorobots\\nmotion control\\noptimisation\\nstability\\nrobotic hummingbird\\nflying animals\\nflapping wings\\nnatural selection\\nmaneuverability\\ninsect-hummingbird scale\\nflapping wing micro air vehicle\\nfwmav\\nsize weight and power constraints\\nswap\\nflight stability\\nrigid wings\\nflexible wings\\nonboard sensors\\nmaximum lift\",\"634\":\"lighting\\nvisualization\\ncameras\\nbrightness\\nfeature extraction\\nrobots\\nvocabulary\\naerospace robotics\\nmobile robots\\nchanging lighting conditions\\nillumination-robust visual localization algorithm\\nfree-flying robot\\ninternational space station\\nmonocular camera\\npre-built sparse map\\nnatural visual features\\niss lights\\nlocalization performance\\nvisual feature-based localization systems\\nastrobee localization algorithm\\nillumination level\\ncamera exposure time\",\"635\":\"space vehicles\\nmanipulator dynamics\\ndynamics\\nmathematical model\\nestimation\\naccelerometers\\nangular momentum\\nangular velocity measurement\\nattitude measurement\\nmanipulators\\nparameter estimation\\nspace manipulator systems\\nangular momentum conservation\\nadvanced control strategies\\nsystem parameters\\nfree-floating mode\\nspacecraft\\npayload parameters\\nmodel-based control\\njoint angle measurement\\nspacecraft attitude measurement\\nsensor noise\",\"636\":\"robots\\nprototypes\\ncopper\\nrobustness\\nwheels\\ncouplings\\npolyimides\\naerospace robotics\\nplanetary rovers\\nprinted circuits\\nrobot dynamics\\nshear modulus\\ntextiles\\npop-up mars rover\\ntextile-enhanced rigid-flex pcb body\\nmanufacturing paradigm\\norigami-inspired pop-up robots\\nspace exploration missions\\nprinted circuit board\\nfolding robot chassis\\nspaceflight-tolerant materials\\nchassis flexures\\npuffer\\npop-up flat folding explorer robot\\nlow-payload-cost mobility enhancement\\nnasa missions\",\"637\":\"grippers\\nactuators\\nshafts\\nmobile robots\\ntorque\\ngears\\nadhesives\\nrobot programming\\nsoftware engineering\\nlemur 3\\nlimbed climbing robot\\nextreme terrain mobility\\nfour-limbed robot\\nserial chain\\nmicrospine grippers\\nrocky surface\\ngecko adhesive grippers\\nsoftware systems\\nlimbed mobility\\njpl\\nnasa\",\"638\":\"lattices\\nhip\\nmanipulators\\nsolids\\nmobile robots\\ngeometry\\nfeedback\\nmotion control\\npath planning\\nposition control\\nmobile robot\\nlocomotion\\n3d periodic lattice environment\\nperiodic lattices climbing\\nrelative robots\\nminimal feedback\\ninspection tasks\\nrepair tasks\\ncuboctahedral cellular solids lattice\\ncuboct cellular solids lattice\\nmultiobjective journeying robot\\nmojo\\nrobot orientation\",\"639\":\"grippers\\nmanipulators\\ngrasping\\nforce\\nimpedance\\nrobot kinematics\\nflexible manipulators\\ncaging-based grasp\\nflexible manipulation\\nrobust capture\\nfree-floating target\\nrobotic arm\\nposition error\\nsensor errors\\ntime delay\\ncaging-based rigid gripper\\nimpedance control\\nair-floating system\\nplanar microgravity motion emulation\",\"640\":\"visualization\\npredictive models\\ngaussian processes\\nadaptation models\\ncomputational modeling\\ngeometry\\ndata models\\nplanetary rovers\\nregression analysis\\nlocally-adaptive slip prediction\\ngaussian process regression\\nterrain types\\nterrain geometry\\nspatial correlations\\nonline slip model adaptation\\nregression-based modeling\\nuncertainty bounds\\nhigh-slip sand areas\\nvisual classifier\\nonline model selection\\nslip measurements\",\"641\":\"gabor filters\\nhistograms\\ntraining\\nimage edge detection\\nfilter banks\\nvisualization\\nnavigation\\naerospace computing\\ncomputational complexity\\ngeophysical image processing\\nimage classification\\nimage filtering\\nimage texture\\nmars\\nplanetary rovers\\nrocks\\nsand\\nterrain mapping\\nmonochrome planetary rover terrain classification\\nsimple texture descriptor\\nbedrock\\nrock-strewn terrain\\nvisual classifiers\\nmonochrome navigation image\\nnasa mars exploration rover missions\\nvisual texture\\nedges filter response histograms\\nmonochrome image intensity\\ngradient-based simplified hog descriptor\\nsimplified gist descriptor\\nmr8 textons\\nlocal rotational invariance\\nk-nearest neighbors\",\"642\":\"robots\\npneumatic systems\\nactuators\\nvisualization\\npolyethylene\\nstructural rings\\nforce\\nclosed loop systems\\nend effectors\\nhuman-robot interaction\\nmanipulator kinematics\\npneumatic actuators\\nservomechanisms\\nseries pneumatic artificial muscles\\nspam\\ntubular pneumatic backbone\\ntension force\\nrobot pneumatic backbone\\nhuman interaction\\nsoft-continuum robot kinematics\\nend-effector position\\nclosed-loop control\\neye-in-hand visual servo control law\\nstep-response rise time\\nstep-response settling time\",\"643\":\"robot sensing systems\\nfabrics\\nelectrodes\\ncapacitive sensors\\ncouplings\\nbuckling\\nelasticity\\nelastomers\\nend effectors\\nmanipulator dynamics\\npneumatic control equipment\\nstrain sensors\\nfabric sensory sleeves\\nsoft robot state estimation\\nstretchable fabric sleeve\\nembedded elastic strain sensors\\nstate reconstruction\\nsoft robotic joint\\ngraphite-based conductive composite electrodes\\nsilicone elastomer dielectric\\nsensor-embedded fabric sleeve\\nend effector position\\nsoft pneumatic joint\\nimu\\nfabric buckling\\nnonconstant curvatures\\nsoft material robotics\\nhydraulic\\/pneumatic actuators\\nflexible robots\",\"644\":\"force measurement\\nforce\\nsensor systems\\npressure measurement\\nrubber\\nrobots\\nforce sensors\\nhuman-robot interaction\\npneumatic actuators\\nsoft three-axis force sensor\\nradially symmetric pneumatic chambers\\ninteractive force measurement\\nsoft force measurement system\\nlumped force\\nradially symmetric pattern\",\"645\":\"fabrics\\nrobot sensing systems\\nwires\\nstrips\\nactuators\\ncapacitance\\nbuilding materials\\nelectrical conductivity\\netching\\nrobots\\nsilicones\\nfunctionalized textiles\\ninteractive soft robotics\\nconductive fabric substrate\\nbuilding material\\nsoft sensor\\nsoft actuators\\npcb etching techniques\\nconductive surfaces\\nflexible wire bus\\nsilicone\\nflexible pcb\\ncomposite fabric strip\\npneuflex-style soft actuator\\nself contained sensing strip\\naugmented composite actuator\\ncapacitive touch sensing\\ngrasping\\nhuman-robot interaction\",\"646\":\"actuators\\nlegged locomotion\\nbellows\\ngeometry\\nforce\\nthree-dimensional displays\\nfinite element analysis\\npath planning\\n3d printed soft actuators\\nlegged robot\\nunstructured terrain navigation\\nmobile soft robots\\nmolding process\\nrobot locomotion capabilities\\nfem simulation\\nfinite element method\",\"647\":\"force\\ncomputational modeling\\nload modeling\\nmathematical model\\nrobots\\nloading\\noptical fiber devices\\ndeformation\\nelastomers\\nopen loop systems\\nmodel based control\\nfiber reinforced elastofluidic enclosures\\nfrees\\npneumatic soft robots\\nasymmetric continuously deformable skin\\ndeformations\\nmodel-driven open-loop control\\nforce equilibrium\\nelastomer model\\nsystem identification\\nprecision open-loop control experiment\\nrotational combination lock\",\"648\":\"muscles\\nfinite element analysis\\noptical fiber sensors\\nbladder\\nforce\\nelectroactive polymer actuators\\nforce control\\nforce sensors\\nintelligent sensors\\npneumatic actuators\\nsensorized pneumatic muscle\\nstiffness control\\nsoft pneumatic artificial muscle\\nposition sensing capabilities\\nforce sensing capabilities\\nconductive liquid-based soft sensors\\nfiber-reinforced contractile actuator\\naxial strain deformation\\ndiametral expansion deformation\\nstroke length\\ncontractile force\\nembedded sensors\\none degree-of-freedom hinge joint\",\"649\":\"legged locomotion\\nweaving\\nfoot\\ntrajectory\\nimpedance\\nrobot sensing systems\\ndistance measurement\\npath planning\\nrobot vision\\nautonomous navigation\\nhexapod robots\\nvision-based controller adaptation\\nhybrid control architecture\\nhexapod platform\\nweaver\\nvision-based exteroceptive terrain perception\\nrobot locomotion parameters\\nvirtual stiffness\\nlegs impedance controller\\nvisually perceived terrain properties\\nrobot stride frequency\\nrobot stride height\\nterrain characterization\\nvisual-inertial odometry\\nspatial map\\nautonomous missions\\nglobal navigation\\nterrain adaptation\",\"650\":\"relays\\ntime factors\\nunmanned aerial vehicles\\nmonitoring\\nalgorithm design and analysis\\npath planning\\noptimization\\nautonomous aerial vehicles\\ngenetic algorithms\\nminimisation\\nmultiobjective uav path planning\\nmultiobjective optimization algorithm\\ngenetic algorithm approach\\nmission completion time minimization\",\"651\":\"robot kinematics\\npath planning\\ncollision avoidance\\nplanning\\nbatteries\\nmobile robots\\nautonomous aerial vehicles\\ngraph theory\\nhelicopters\\ninteger programming\\nlinear programming\\nmulti-robot systems\\nmultirobot path planning\\nrobotic swarm\\nquadcopters\\npath selection\\ntime consumption\\nenergy consumption\\nrobust vehicle\\nenergy efficient driving mode\\nagile flight mode\\npriority planning\\nsafe interval path planning\\nmulticommodity network flow\\nilp\\nmultimodal locomotion\\ncollision-free path planning\\nflying-and-driving vehicles\\n3d graphs\\nmotion control\",\"652\":\"trajectory\\naerospace electronics\\nuncertainty\\nplanning\\nsearch problems\\ncost function\\ndecentralised control\\nfeedback\\nlinear quadratic gaussian control\\nmarkov processes\\nnonlinear programming\\noptimal control\\nstochastic systems\\nmt-lqg\\ntrajectory-optimized lqg\\nprocess uncertainties\\nmeasurement uncertainties\\nstochastic control problem\\ndecentralized partially observed markov decision process\\ndec-pomdp\\njoint-value function maximization\\nlinear quadratic gaussian policies\\nnonlinear program\\nlqg\\n3d environments\\n2d environments\\ncomputationally tractable multiagent planning\",\"653\":\"planning\\ninference algorithms\\ngaussian processes\\nsparse matrices\\ntrajectory optimization\\nrobots\\ncontinuous time systems\\ngraph theory\\nmobile robots\\npath planning\\ntrajectory optimisation (aerospace)\\ngraph-based trajectories\\ngaussian process inference\\nperformance metric\\nglobally optimal solution\\nmotion planning algorithm\\ngpmp-graph\\ngraph-based initialization\\nmultiple homotopy classes\\ncontinuous-time trajectories\\nfactor graph\\ninterconnected states\",\"654\":\"distance measurement\\nsensors\\nposition measurement\\nmobile communication\\natmospheric measurements\\nparticle measurements\\nmotion measurement\\nprobability\\nultra wideband technology\\ncooperative relative positioning\\nmobile user\\nimu inertial fusion\\nuwb ranging information\\ndisaster\\nhuman social interaction\\ninertial measurement unit\\nerror accumulation\\nultrawideband ranging information\\ntrilateration based approach\\nlaser-based sensor\\nvision sensor\\ndistance estimation\\nbearing information\\nuwb ranging measurement\\nprobabilistic-based framework\",\"655\":\"visualization\\nclustering algorithms\\ncomputational modeling\\nrobots\\nimage coding\\nhistograms\\nsparse matrices\\nimage capture\\nimage sensors\\nmobile robots\\npattern clustering\\nrobot vision\\ntopological model compression\\nclustering approach\\nrobot localization problem\\nomnidirectional visual information\\nglobal appearance descriptors\\nrobot position estimation\\npanoramic image capture\\ncatadioptric vision sensor\\ncomputational cost\",\"656\":\"field programmable gate arrays\\ncameras\\nreal-time systems\\ngeometry\\ncorrelation\\nhead\\nreliability\\nimage fusion\\nimage matching\\nimage resolution\\nstereo image processing\\nreal-time stereo matching failure prediction\\nstereo matching resolution\\northogonal stereo setups\\ncost function\\ndepth map fusion\\northogonal stereo heads\\nfailure prediction\\nmatching score\",\"657\":\"cameras\\ntraining\\nquaternions\\nrobot vision systems\\nbayes methods\\nfeature extraction\\nneural networks\\nfeedforward neural nets\\nmobile robots\\npose estimation\\nrobot vision\\nconvolutional neural networks\\ncamera relocalization\\nmonocular image\\ncamera pose\\neuler angles\\neuler6\\ndata augmentation method\\npose synthesis\\npose sparsity reduction\\nmultitask cnn\\nbranchnet\\nshared convolutional layers\\norientation prediction\\ntranslation prediction\\n7scenes dataset\\nposenet model\\norientation error reduction\\ntranslation error reduction\\nintel nuc mobile platform\\nrobotic applications\",\"658\":\"three-dimensional displays\\ncomplexity theory\\nrobustness\\niterative closest point algorithm\\nruntime\\nestimation\\nobject detection\\nbayes methods\\ncomputational complexity\\nimage matching\\nimage registration\\nglobal 3d point cloud registration\\npoint cloud matches\\nalignment hypotheses\\nnaive approach\\ncubic runtime complexity\\nsuper4pcs\\ncomplexity reduction\\n2-point-normal sets\\n2pns\\nkinect scans\",\"659\":\"metals\\ndetectors\\nshape\\nmanipulators\\nrobot sensing systems\\nimage classification\\nimage reconstruction\\nlandmine detection\\nmobile robots\\nobject detection\\nland mine localization\\nland mine detection\\nmetallic clutter\\nfalse alarms\\nshape reconstruction\\nsparse data\\nmobile robot\\ncommercial pulse induction metal detector\\ncustom 2dof arm\\nnatural terrains\\nmobile manipulator\\nmetallic objects\\nunexploded ordnance\\nuxo classification\",\"660\":\"laser radar\\nrobot sensing systems\\nthree-dimensional displays\\nreal-time systems\\ndynamics\\nvehicle dynamics\\nfeature extraction\\nimage filtering\\nimage motion analysis\\nimage sequences\\nlearning (artificial intelligence)\\noptical radar\\nradar imaging\\nlearning approach\\nreal-time temporal scene flow estimation\\nlidar data\\nautonomous systems\\ndynamic environment\\nlearned background filter\\nfiltered occupancy grid\\nraw scene flow\\nsuccessive scans\\nkitti dataset\",\"661\":\"manipulators\\ncollision avoidance\\ncameras\\nrobot vision systems\\nthree-dimensional displays\\ncontinuum mechanics\\ndexterous manipulators\\nimage colour analysis\\nimage registration\\nimage sensors\\nrobot vision\\nprogressive object modeling\\ntarget object manipulation\\nappearance-based model\\ntarget object\\nobject manipulation\\nunknown obstacles\\ncontinuum manipulator\\ncrowded environment\\n3d surface model\\nrgb-d sensor\\nunknown obstacle detection\\nunknown obstacle avoidance\\nmanipulator motion\\nrgb-d image registration\\npartial model\\nmotion planning strategy\\ncontinuum robot\\nsimulated continuum robot\\nrgb-d camera\\naugmented reality\",\"662\":\"simultaneous localization and mapping\\ncameras\\nlighting\\nfeature extraction\\nrobot vision systems\\nthree-dimensional displays\\nimage colour analysis\\ninfrared imaging\\nrobot vision\\nslam (robots)\\nrgb-t slam\\nflexible slam\\nappearance information\\nthermal information\\nvisual slam\\nillumination scenes\\nillumination-free recognizable contents\\nrgb-t map\\nthermal map points\\nfeature detection\\nrgb image\\nthermal images\\nsimultaneous location and mapping\\nillumination environments\",\"663\":\"cameras\\nglobal positioning system\\nobservers\\nvisualization\\nvelocity measurement\\nstability analysis\\nposition measurement\\nerror analysis\\nrobot vision\\nsensor fusion\\nso\\ngps fusion\\nmonocular vision\\ngps velocity measurements\\ndiscrete-time geometric attitude observer\\nmonocular image processing\\nvisual odometry attitude estimates\\nnorth-east-down frame\\nobserver convergence rate\\nnorth-east-down orientation\",\"664\":\"gaussian processes\\nmobile robots\\nmathematical model\\nwheels\\nsimultaneous localization and mapping\\ndistance measurement\\nestimation theory\\nmotion control\\nrobot vision\\nslam (robots)\\nstatistical analysis\\ngaussian process estimation\\nodometry errors\\nlocalization and mapping\\nslam\\nstatistical error\\nprobabilistic motion models\\nimage frames\",\"665\":\"sparse matrices\\napproximation algorithms\\nsimultaneous localization and mapping\\ntime complexity\\nimage recognition\\nimage matching\\nimage sequences\\nobject detection\\nrobot vision\\nslam (robots)\\nfast-seqslam\\nappearance based place recognition algorithm\\nrobot simultaneous localization and mapping\\nenvironmental condition changes\\napproximate nearest neighbor\\nann algorithm\\nrobot map\\nimage sequence\\nappearance based loop closure detection\",\"666\":\"cameras\\nlighting\\ncalibration\\nvisualization\\nthree-dimensional displays\\nsonar navigation\\nimage edge detection\\nstereo image processing\\nunderwater cave mapping\\nstereo vision\\n3d mapping\\nhydrogeology\\nwater resources\\nmarine archaeology\\nunderwater cave exploration\\nhuman divers\\nrobotic technology\\nunderwater vision constraints\\nnatural illumination\\nharsh contrasts\\nstate estimation packages\\nstereo camera\\ncave boundaries\\nvisual odometry algorithm\\nstereo reconstruction\\nimmersive experience\",\"667\":\"simultaneous localization and mapping\\nalgorithm design and analysis\\nmeasurement\\nsoftware algorithms\\nspace exploration\\nhardware\\nslam (robots)\\napplication-oriented design space exploration\\nvisual slam\\nsoftware parameters\\nhardware parameters\\nalgorithmic thresholds\\ngpu frequency\\ncamera\\ninformation theory\\nmotion parameters\\nactive slam algorithms\",\"668\":\"trajectory\\nunmanned aerial vehicles\\natmospheric modeling\\nalgorithm design and analysis\\neuclidean distance\\nlevel set\\ntwo dimensional displays\\nautonomous aerial vehicles\\nconvergence\\ntracking\\ntrajectory control\\nfixed-wing uav\\nsmooth trajectory tracking\\nguidance algorithm\\nunmanned aerial vehicle\\nsmooth curve tracking problem\\nuav physical constraints\",\"669\":\"grippers\\nmagnetic resonance imaging\\nmagnetosphere\\nshape\\nservomotors\\nforce\\ncameras\\nautonomous aerial vehicles\\nmanipulators\\nposition control\\nmicroair vehicle control\\nmav control\\naerial picking\\nmagnetic object delivery\\nmav manipulation capabilities\\nmav perception\\nelectro-permanent magnetic gripper\\nservo positioning algorithms\\nstationary objects\\nmoving objects\",\"670\":\"sensors\\noptimization\\nplanning\\ntrajectory\\nentropy\\nthree-dimensional displays\\nheuristic algorithms\\nagriculture\\nautonomous aerial vehicles\\ninformation theory\\npath planning\\nprecision engineering\\ntrajectory control\\nonline informative path planning\\nactive classification\\nuavs\\ninformative path planning framework\\nipp framework\\nunmanned aerial vehicles\\nglobal viewpoint selection\\nevolutionary optimization\\ntrajectory planning\\ncontinuous 3d space\\ndynamic constraints\\nweed detection\\nprecision agriculture\\noccupancy grid\\nadaptive plans\\ninformation-theoretic objectives\\nmultirotor platform\\nartificial farmland set-ups\",\"671\":\"planning\\nthree-dimensional displays\\ncollision avoidance\\nnavigation\\nrobot sensing systems\\ncomputational modeling\\ntrajectory\\nhelicopters\\naggressive 3d collision avoidance\\nhigh-speed navigation\\nautonomous robot navigation\\nquadrotor platforms\\nvehicle top speed\\ninstantaneous perception data\\ninput constrained motion primitives\\nsampling terminal states\\ncollision-free path\\nworst case performance\\ntriple integrator planner\\ntip\\naggressive collision avoidance maneuvers\",\"672\":\"force\\npayloads\\ntorque\\ntransportation\\ncollaboration\\nquaternions\\nadmittance\\naerospace robotics\\nforce control\\nhelicopters\\ninertial navigation\\nkalman filters\\nmicrorobots\\nnonlinear estimation\\nnonlinear filters\\nrobust control\\ntelerobotics\\npassive force control\\ncollaborative object transportation\\nmicroaerial vehicles\\nmavs\\nhexacopters\\nrobust approach\\nmaster-slave paradigm\\nadmittance controller\\nnonlinear estimator\\nunscented kalman filter\\nvisual-inertial navigation system\\nforce estimator\",\"673\":\"trajectory\\nstate estimation\\ncameras\\nplanning\\nvehicle dynamics\\nrobot sensing systems\\nactive vision\\nattitude control\\nautonomous aerial vehicles\\nhelicopters\\nmobile robots\\nrobot vision\\ntrajectory control\\naggressive quadrotor flight\\nnarrow gaps flight\\nonboard sensing\\nonboard computing\\nautonomous quadrotor flight\\ncomplex environments\\noff-board localization systems\\ngap position\\ngap orientation\\ngap detection fusing\\nimu\\norientation control\\ntrajectory generation\",\"674\":\"safety\\ntorque\\noptimization\\ntraining\\nadaptation models\\nmanipulators\\nlearning (artificial intelligence)\\nprobability\\nprobabilistically safe policy transfer\\nlearning-based methods\\nrobotics\\noptimal policy\\nprobabilistic sense\\nrobot manipulator\\nsafety-based torque limits\\nrobot safety\\ndamage constraint\\nlearning process\",\"675\":\"robot sensing systems\\nplanning\\nrobustness\\noptimization\\nestimation\\nswitches\\nmanipulators\\nobservability\\noptimisation\\nrobust control\\nsensors\\nfailure behavior\\nmanipulation skills\\ntask success\\nmanipulation task\\nsoft manipulator\\naction primitive\\nsensor trace\\nclassifier\\ntask failure\",\"676\":\"mathematical model\\ngenerators\\nnumerical models\\nindexes\\nfault diagnosis\\nunmanned aerial vehicles\\nheuristic algorithms\\naerospace components\\nautonomous aerial vehicles\\ndifferential algebraic equations\\nidentification\\nsemiexplicit dae generation\\nstructural-index 1\\nstructural analysis\\nfault detection-and-identification\\nresidual generators\\nautomatic fault-detection\\ndynamic systems\\ndifferential-algebraic equation systems\\ndifferential index\\nstructural analysis algorithms\\nsemiexplicit dae\\nlarge-scale fixed-wing uav model\",\"677\":\"robot kinematics\\ncollision avoidance\\nrobot sensing systems\\napproximation algorithms\\nmobile robots\\nsafety\\ndrives\\nfailure analysis\\nmulti-robot systems\\nopen loop systems\\nintermittent communications handling\\nmultirobot systems\\nindividual robot movement\\nmotion strategy\\ncritical communication failure handling\\nmultirobot architectures\\nvelocity commands\\nsafe time horizons\\nsafe open-loop motion strategy\\ndifferential-drive mobile robots\",\"678\":\"trajectory\\nmachine vision\\ncameras\\nmobile robots\\ntraining\\nrobustness\\nautonomous aerial vehicles\\nfault tolerant control\\nhelicopters\\npath planning\\nrobot vision\\nrobust failure response learning\\nautonomous vision based flight\\nautonomous mobile robots\\nrobotics research\\ncomputer vision\\nautonomous vision based navigation\\nautonomous quadrotor\\nsituational perception failure\",\"679\":\"fuzzy logic\\npropellers\\npipelines\\nattitude control\\nacceleration\\nfuzzy sets\\ncollision avoidance\\naerospace safety\\nautonomous aerial vehicles\\nhelicopters\\nmonte carlo methods\\nquadrotor collision characterization\\ncollision recovery control\\nquadrotor uav collisions\\nfaulty piloting\\nwind gusts\\nobstacle avoidance\\nairspace regulations\\nquadrotor drones\\npropeller protection\\ncollision detection\\nimpact dynamics\\naggressive quadrotor attitude control\\nmonte carlo simulation\\nquadrotor flight controller safety feature\",\"680\":\"robots\\ntrajectory\\ndata models\\ncomputational modeling\\nsupervised learning\\nheuristic algorithms\\nadaptation models\\npendulums\\ntrajectory control\\nrobotics behaviours\\nlearning control policies\\nsource systems\\napproximate dynamics model simulator\\ntrajectories\\nsource robot state\\ntarget robot action space\\npolicy adjustment model\\ncart-pole balancing task\\ntwo link double pendulum\\ncart-pole system\",\"681\":\"actuators\\npneumatic systems\\nbladder\\nvalves\\nadaptive control\\nrobot sensing systems\\nelastic constants\\nend effectors\\ninflatable structures\\nvariable stiffness adaptation\\nsystem failure mitigation\\nair leak detection\\ninternal structure\\nstructural chamber\\nsoft-inflatable-pneumatically actuated robot\\njoint stiffness\\nmass flow rate\\nlong term error\\nsteady state error\\nend effector\\nresource-limited situations\\nfailure mitigation\",\"682\":\"force\\ngrippers\\nsensors\\ngrasping\\nfriction\\nfingers\\nrobots\\nadaptive control\\ndeformation\\nnonlinear control systems\\nvariable structure systems\\nhigh-performing adaptive grasp\\nrobotic gripper\\nunpredictable disturbances\\nrobotic grasping\\nsuper twisting sliding mode control design\\nstsmc\\nslippage prevention\\ngrip force\\nslip feedback\\nslip detection\\nexternal nonlinear disturbances\\nobject deformation\",\"683\":\"bicycles\\nrobots\\ncontrol systems\\nasymptotic stability\\nwheels\\nestimation\\npollution measurement\\nhumanoid robots\\nmechanical stability\\nmechanical variables control\\nmobile robots\\nbalancing control\\nhumanoid robot\\nhandlebar\\nuncertain center of gravity\\nrobot-bicycle system\\ncontrol system design\\nmass imbalance\\nstraight-line steering\",\"684\":\"robots\\nlaser beams\\nbiomedical optical imaging\\nmicroscopy\\noptical microscopy\\nintegrated optics\\ntrajectory\\ncellular biophysics\\nlaser beam applications\\nmedical robotics\\nmicromanipulators\\nposition control\\nsimultaneous orientation and positioning control\\nmicroscopic object\\nrobotic tweezers\\nrobotic control\\nmultiple laser-driven fingertips\\nrobotic motorized stage control\\noptically trapped microparticles\\noptical tweezers\",\"685\":\"laser beams\\nbiomedical optical imaging\\nmicroscopy\\noptical sensors\\nintegrated optics\\nrobot kinematics\\nmicromanipulators\\noptical control\\ncoordinative optical manipulation\\nmicroscopic objects\\nmicrohands\\nmultiple fingertips\\nmicroobjects\\nlaser tweezers\\nrobotic control\\noptically trapped microparticles\\nlaser-driven fingertips\\ngrasping\",\"686\":\"trajectory\\nuncertainty\\nrobustness\\ncollision avoidance\\ncomputational modeling\\nsafety\\noptimization\\nhelicopters\\nminimisation\\nnonlinear control systems\\npath planning\\npose estimation\\nrobot vision\\nrobust control\\ntrajectory control\\naerial platforms\\nadaptive model predictive control\\nmotion planning problem\\nnonlinear model predictive control optimization technique\\nnmpc\\nmodel parameter uncertainty\\nhigh-confidence ellipsoids\\nquadrotor trajectories\\nellipsoid penetration\\ncontrol effort minimization\\nuser-specified goal location\\nrobust obstacle avoidance behavior\\noutdoor scenarios\\nvirtual obstacles\",\"687\":\"electron tubes\\ntrajectory\\nrobustness\\nplanning\\ntracking\\nrobots\\nadaptive control\\ncollision avoidance\\nconvex programming\\nfeedback\\nmobile robots\\nnonlinear control systems\\npredictive control\\nrobot dynamics\\nrobust control\\ntrajectory control\\nrobust online motion planning\\ncontraction theory\\nconvex optimization\\nrobotic systems\\nnonlinear dynamics\\nbounded disturbances\\nonline state constraints\\nfeedback controller\\nnominal trajectory tracking\\nfixed-size tube\\nmotion planner\\nrobustness margin\\ncollision checking\\nfunnel libraries\\ncomplex maneuvers\\n6-state planar quadrotor\\ntube model predictive control\\ntmpc\",\"688\":\"service robots\\naerodynamics\\nvehicle dynamics\\nsatellites\\nstandards\\naerospace robotics\\naerospace simulation\\nindustrial robots\\nphysical dynamic reproduction\\nhardware-in-the-loop simulator\\nexplicit discrete integrator\\npassive discrete integrator\\nenergy preserve\\neuler integrator\\nenergy generation\\nintegration process\\nstability issues\\ntime domain passivity approach\\nindustrial robot facilities\\nvirtual bodies simulation\\ndlr oos-sim facility\",\"689\":\"exoskeletons\\nlearning (artificial intelligence)\\nelectromyography\\nrobot kinematics\\ntraining\\nrobot sensing systems\\nhuman-robot interaction\\nmedical robotics\\nprosthetics\\nlearning task-parametrized assistive strategies\\nexoskeleton robots\\nmulti-task reinforcement learning\\nelectromyography signals\\nemgs\",\"690\":\"unmanned aerial vehicles\\ngesture recognition\\nalgorithm design and analysis\\ncameras\\nrobot vision systems\\nhardware\\nimage color analysis\\naerospace robotics\\nartificial intelligence\\ncontrol engineering computing\\neconomics\\ngesture-based piloting\\naerial robot\\nmonocular vision\\nai\\nnatural user interface\\nnui\\nhand\\/arm gestures\\nhardware requirements\\neconomic point of view\\ndata availability\",\"691\":\"grounding\\ngaze tracking\\ncameras\\nthree-dimensional displays\\nglass\\nrobot kinematics\\ninference mechanisms\\nlearning (artificial intelligence)\\nrobots\\nphysical symbol grounding\\ninstance learning\\nhigh level task descriptions\\nautonomous robot\\nmapping learning\\nabstract plan symbols\\ngrounding and learning instances through demonstration and eye tracking\\nglide\\nfixation programs\\nprobabilistic generative model\\ncomputationally feasible inference\\nfixation location estimation\",\"692\":\"muscles\\nforce\\nexoskeletons\\nrobots\\nforce measurement\\njacobian matrices\\ntorque measurement\\nmotion control\\nmuscle\\nprosthetics\\npower-augmentation control\\narm exoskeleton control\\nhuman muscular manipulability\\nmuscular force manipulability\\nmotion direction\\nanisotropic property\\n2 dof arm-exoskeleton\\nhuman motor control\\nimpaired human limbs\",\"693\":\"training data\\nnavigation\\ndata models\\nlaser beams\\nsensors\\nestimation\\nplanning\\nassisted living\\ncollision avoidance\\ngeriatrics\\nhandicapped aids\\nprobability\\nwheelchairs\\nelderly mobility assistance aid\\nwheelchair\\nreal-time stochastic optimal path generation\\non-line probabilistic short-term destination inference\\nindoor setting\\nactive assistive mobility systems\\nlocal driving assistance\",\"694\":\"impedance\\nrobot kinematics\\nsprings\\nprototypes\\nactuators\\ninjuries\\nhumanoid robots\\nlegged locomotion\\nmantisbot\\nimpedance control\\nsupernumerary robotic limb design\\nnear-ground work\\nwearable robotic device\\nbimanual tasks\\nupper torso\\nsupernumerary robotic limbs\\nsrl\\ncrawling-like position\\nwearer natural arms\\nhuman hands\\nwearer body\\nequilibrium position\\nrestoring forces\\ncontrol laws\\nvirtual impedance\\nwearable robot\\nhuman augmentation\\nbody support\",\"695\":\"robots\\ntrajectory\\nmultiprotocol label switching\\nadaptation models\\nlibraries\\nvehicle dynamics\\natmospheric modeling\\nadaptive control\\nautonomous aerial vehicles\\nhelicopters\\nmobile robots\\nmotion control\\nstatistical distributions\\ntelerobotics\\nonline adaptation\\ntask-independent adaptive teleoperation methodology\\noperator performance\\nuser intent modeling\\npredicted intent adaptation\\nrobot motion\\ndynamically feasible safe motions\\nmotion primitive library\\nprobabilistic distribution\\naction selection\\nquadrotor teleoperation\\nnonaggressive single-intent maneuvers\\nfree-hand helix motion\",\"696\":\"robots\\nmuscles\\ntorso\\nelectromyography\\nsensors\\nprototypes\\nelectrodes\\nhuman-robot interaction\\nvelocity control\\nindependent voluntary control\\nextra robotic limbs\\nwearable robotics\\nindependent robotic limbs\\nvoluntary signals\\nmuscle activation signals\\ntorso muscle contraction\\nphysical robot prototype\",\"697\":\"turning\\nlegged locomotion\\nforce\\ndynamics\\nwheels\\nangular velocity control\\nclosed loop systems\\ntraction motor drives\\nhigh-rate controlled turning\\nwheeled robots\\nhigh turning rate tracking\\nminiaturized legged robot steering\\ncompliant joint\\n12-legged robot\\nvelocity changing\\nleg triples\\ntraction forces\\nclosed-loop steering\\ndifferential drive strategy\\nfigure 8 trajectory tracking\",\"698\":\"legged locomotion\\nactuators\\ntrajectory\\nresonant frequency\\nheat-assisted magnetic recording\\nfrequency response\\nmicrorobots\\nnonlinear dynamical systems\\nopen loop systems\\nphase control\\nphase estimation\\npiezoelectric actuators\\nposition control\\noff-board phase estimator\\noff-board phase controller\\nleg position\\nharvard ambulatory microrobot resonance\\ntwo degree-of-freedom transmission\\ntransmission resonance\\nhamr's transmission\\nactuator phase\\nleg phase\\noperating frequencies\\noff-board position sensors\\nopen-loop resonant leg trajectory\\nfeedforward control inputs\\nresonant trajectory\\nfrequency 1 hz to 120 hz\\nresonance\\ndynamic modeling\\nlegged microrobots\\nbiologically inspired robots\",\"699\":\"magnetic resonance imaging\\nmagnetic moments\\nmicroorganisms\\nimmune system\\ntorque\\ndrag\\nforce\\ndrug delivery systems\\nhydrodynamics\\nmedical control systems\\nmotion control\\nnear-surface effects\\nmagnetotactic bacteria controlled motion\\nstagnant fluids\\ndrug delivery\\nbackground flows\\nsurface interactions\\nhydrodynamic model\\nbipolarly-flagellated magnetotactic bacteria\\nmagnetospirillum gryphiswaldense strain msr-1\\nresistive-force theory\\nswimming characteristics\\nfree-space environment\\nnear flat walls environment\\ncapillary tubes\\nmicrofluidic chips\\ndepth 5 mum\\ndepth 200 mum\",\"700\":\"magnetic flux\\nrobots\\nmagnetic fields\\nsaturation magnetization\\nmicrostructure\\nmicrofluidics\\nmicrochannels\\nend effectors\\nhydrogels\\nmotion control\\nnanoparticles\\nrobotic assembly\\ntrajectory control\\nrobotics-based micro-reeling\\nmagnetic microfibers\\nhelical structure\\nsmooth muscle cells culture\\nhydrogel microfibers\\nrobotics-based assembly\\nelectromagnetic needle\\nemn\\nend-effector\\nmicrofiber encapsulating magnetic nanoparticles\\nmicropillar\\nanticlockwise pushing microfiber\\nstatic force model\\nrobotics-based motion trajectory\",\"701\":\"haptic interfaces\\ncharge carrier processes\\nthree-dimensional displays\\nlasers\\noptical imaging\\noptical sensors\\noptical buffering\\nhuman-robot interaction\\nindustrial manipulators\\nmicroassembling\\nmicromanipulators\\noptical variables control\\ngaze contingent control\\noptical micromanipulation\\noptical tweezers\\not\\nlaser traps\\nhuman-robot interface\\nmicroassembly tasks\\n3d orientation estimation\\ninteractive microassembly platform\\nhaptic constraints\\not user interface\\nthree-dimensional manipulation\",\"702\":\"glass\\nneedles\\nactuators\\nvibrations\\nmetals\\ntransportation\\nresonant frequency\\nfrequency control\\nmicromanipulators\\npiezoelectric actuators\\nposition control\\nrods (structures)\\nswirling flow\\nvibration control\\nnoncontact transportation\\nnoncontact microobject rotation\\ncircularly vibrating glass needle\\nobject manipulation\\nvibration-induced swirl flow\\npiezo actuator\\nmetal rod\\nsine wave\\namplitude control\\nactuator resonance\\nsimple low-cost effective micromanipulation method\",\"703\":\"resists\\nrobots\\nfabrication\\ncancer\\npolymers\\nnavigation\\nprinting\\nmedical robotics\\nmicrorobots\\npath planning\\npatient treatment\\nhybrid microrobots\\nph-responsive hydrogels\\nphoto-responsive hydrogels\\ncancer targeting\\ndrug delivery\\nnaturally occurring ph gradients\\ncancer cell\\nstimuli-responsive microrobots\\nbiocompatible photoresists\\ntwo-photon polymerization\\ntpp\\nmicrofluidic channel\\nmetastatic cells\\nmicroswimmer\\ntumor localization\\nhuman circulatory system\",\"704\":\"legged locomotion\\naluminum\\nresonant frequency\\nforce\\npiezoelectric actuators\\nbending\\nvibration control\\nsteerable miniature legged robot\\npiezoelectric bending unimorph actuator\\nmobile robots\\ndegree of freedom\\ndof\\nlegged piezoelectric miniature robot\\nlpmr\\nbending vibration\\ndifferential-drive-like mechanism\",\"705\":\"force\\nactuators\\nmuscles\\nsprings\\nload modeling\\nbiological system modeling\\nelectromyography\\nforce control\\nhuman-robot interaction\\nmedical robotics\\nsemiendoskeleton-type waist assist ab-wear suit\\ncompressive force reduction mechanism\\njapan\\nlower back pain\\nsocial problem\\nmuscular fatigue\\nexoskeleton-type ab-wear\\nflexible flat spring\\nassistive force\\nmusculoskeletal simulation\\nsurface electromyography\\nemg\",\"706\":\"electroencephalography\\nelectromyography\\nshoulder\\nrobots\\nelectrodes\\nbrain modeling\\nprincipal component analysis\\nbrain-computer interfaces\\nmedical robotics\\nmedical signal processing\\nemg signal\\nshoulder joint\\neeg signals\\nupper-limb power assistance devices\\nbrain-machine interface\\nbmi\\ndisabled people assistance\\npower augmentation\\nmulti-dof robot\\nelectromyography estimation\\nelectroencephalography signals\\nhuman muscular activity\\npca\",\"707\":\"legged locomotion\\ntracking\\nlasers\\nrobot sensing systems\\nrobustness\\ngait analysis\\ngeriatrics\\nhandicapped aids\\nintelligent robots\\nkalman filters\\nmedical robotics\\nmobile robots\\nmotion control\\noptimal control\\nparticle filtering (numerical methods)\\nrobust control\\nhuman gait tracking\\nintelligent robotic rollator\\nsmart robotic walker\\npatients assistance\\nmobility impairment\\ncontext-aware assistive robot\\nuser kinematic state\\ngait status\\noptimal assistance\\nelderly patients\\nkalman filter\\nparticle filters\\nsensorial data\\nlaser rangefinder\\nrobotic platform\\nuser legs movement\\nmotion capture system\",\"708\":\"manipulators\\ngraphical user interfaces\\nmobile robots\\nrobot sensing systems\\ncomputer architecture\\nkinematics\\nbrain-computer interfaces\\nclosed loop systems\\ncontrol engineering computing\\nhandicapped aids\\nmotion control\\nrobot kinematics\\nsoftware architecture\\nassistive robot\\np300-based brain computer interface\\nsevere motion disabilities\\nmanipulation tasks\\ndaily-life operations\\nrobotic system\\nlightweight robot manipulator\\nuser high level commands\\nmanipulator motion control\\nclosed loop inverse kinematic algorithm\\nmultiple set-based tasks\\nequality-based tasks\\nrobot operation\\nbci2000\\nros\\nmanipulator control\",\"709\":\"collaboration\\nautomobiles\\nroads\\nwheels\\nfeature extraction\\nautonomous automobiles\\ncollision avoidance\\ncontrol engineering computing\\ndriver information systems\\ngroupware\\nroad vehicles\\ncollaborative control\\ndriver assistance systems\\nhuman driver\\ncollision avoidance system\\ncas\\ndriver drowsiness\",\"710\":\"hidden markov models\\nrobot sensing systems\\nhaptic interfaces\\nrobot kinematics\\nforce\\nassisted living\\nend effectors\\nhuman-robot interaction\\nhaptic simulation\\nrobot-assisted dressing\\ndisabled people\\nhaptic classifier\\noptimized simulator\\nhaptic sensory data\\nhidden markov model training\\nend effector\",\"711\":\"legged locomotion\\nrobot sensing systems\\nsensor systems\\nmotion measurement\\nposition measurement\\nassisted living\\ndata acquisition\\ngeriatrics\\nmedical robotics\\nsensor fusion\\nstate estimation\\nhuman cog estimation\\nassistive robot\\nassistive machines\\nelderly falling accident prevention\\nrobot technology\\nreal-time state estimation\\nuser motion\\nuser state estimation\\nhousehold\\ncenter of gravity\\nhuman link model parameter\\ncog position\\nhuman state estimation\\nsensor selection\\nsensor placement\\nmotion capture system\",\"712\":\"force\\nclothing\\nend effectors\\nforce measurement\\nestimation\\nlegged locomotion\\nforce control\\nhuman-robot interaction\\nmean square error methods\\nservice robots\\nvelocity control\\napplied forces\\nrobot-assisted dressing\\ngarment\\ncomplex mechanics\\nphysics-based simulation\\ndata-driven methods\\nlong short-term memory network\\nlstm\\n9-dimensional input vector\\nvelocity measurements\\nforce map\\ninferred force magnitudes\\nhospital gown\\nheat maps\\nroot-mean-square error\\nend effector velocity\\ntraining range\",\"713\":\"intelligent structures\\nkinematics\\nactuators\\nintelligent sensors\\nvibrations\\nmotion control\\ncompensation\\ndeformation\\ndesign engineering\\nforce control\\nintelligent robots\\nmanipulator kinematics\\nvibration control\\ncontour accuracy\\n2-dof planar parallel kinematic machine\\nmultiaxis motion system\\npkm\\nintelligent structure\\nsmart structure based compensation\\nssbc\\ninnovative mechanical design\\nvibration suppression\\nmicromotions\\ndriving system\\nkinematic chains\\naxial deformations\\ninternal forces\",\"714\":\"trajectory\\nkinematics\\nparallel robots\\nrobot kinematics\\nmathematical model\\nalgorithm design and analysis\\nend effectors\\nmanipulator dynamics\\nredundant manipulators\\ntrajectory control\\nvelocity control\\nparallel robot assembly mode detection\\ntype 2 singularity crossing trajectories\\ntrajectory generation\\nmultimodel controller\\nredundant information\\ninterval analysis\\nia-based solvers\\nrobot end-effector\\nvelocity tracking\\nforward kinematic problem\",\"715\":\"parallel robots\\nmathematical model\\ntrajectory\\nkinematics\\nmatrices\\ndynamics\\ncontrol system synthesis\\nmotion control\\noptimisation\\nrobots\\ntorque control\\ntrajectory control\\nparallel robot singularities\\nvirtual-constraint-based controller\\nplatform motion control\\nrobot underactuation\\ncontroller design\\noptimized trajectory pre-planning\\nmulti-control architecture\\ntype 2 singularity crossing\",\"716\":\"manipulator dynamics\\nuncertainty\\nkinematics\\ndynamics\\nrobustness\\nadaptive control\\nclosed loop systems\\ncontinuous time systems\\ncontrol system synthesis\\nlinear systems\\nrobust control\\nvariable structure systems\\nadaptive terminal sliding mode control\\nrobust adaptive controller\\nmodel-based adaptive control\\ncontinuous finite-time terminal sliding mode control\\nlinear-in-the-parameters property\\nmanipulator inverse dynamics\\nclosed-loop system robustness\\nfour-degree-of-freedom parallel manipulator\\nveloce\",\"717\":\"mathematical model\\ngravity\\nparallel robots\\nmanipulators\\nkinematics\\nmobile communication\\nclosed loop systems\\nflexible manipulators\\nmanipulator kinematics\\nnewton method\\nopen loop systems\\nparameter estimation\\ninertial parameters estimation\\nsuspended cable-driven parallel robots\\ncogiro\\nmodel based open-loop system\\nclosed-loop control systems\\nkinematic properties\\ninertial parameter identification\\nparallel flexible-link manipulator\\nidentification equations\\nnewton-euler equations of motion\\nrigid-body\",\"718\":\"kinematics\\nfasteners\\nmanipulators\\nautomation\\nconnectors\\nservice robots\\nmanipulator kinematics\\nposition control\\nkinematic design\\nnovel 4-dof parallel manipulator\\ndegrees-of-freedom\\n3-dof translations\\nidentical limbs\\npassive revolute joints\\nmounted collinear prismatic joints\\nkinematic structure\\nsimple kinematics\\nparallel manipulator design\\nmobility analysis\\nscrew theory\\ncritical design analysis\\n4-dof parallel manipulator\\nschonflies motions\\nworkspace\\nsingularity analysis\",\"719\":\"cleaning\\nfloors\\nmorphology\\nrobot sensing systems\\nshape\\nnavigation\\npath planning\\nservice robots\\nhtetro\\ntetris inspired shape shifting floor cleaning robot\\nreconfigurable floor cleaning robot\\npolyominoes theory\\nhinged dissection theory\\none-sided tetromino morphologies\\nnavigating environment\",\"720\":\"force\\nactuators\\ntorque\\ndynamics\\nmuscles\\nrobots\\ntemperature\\nclosed loop systems\\ncoils\\nelectroactive polymer actuators\\npneumatic actuators\\nclosed-loop control\\ndynamic response\\nmaterial property\\nrobotic application\\ntca\\nartificial muscle-twisted and coiled actuator\\nphysics based model\",\"721\":\"aerospace electronics\\nkinematics\\nneural networks\\nmanipulators\\nalgorithm design and analysis\\ncost function\\nflexible manipulators\\nmanipulator kinematics\\nneurocontrollers\\nviscoelasticity\\ntwo-level approach\\ninverse kinematics\\nviscoelastic behavior\\nsoft compliant materials\\nactuation mechanisms\\nflexible motions\\nsoft robots\\nmultisegment extensible soft arm\\n2d plane\\ngradient descent\\ncost functions\\nphysical prototype\\noptional feedback strategy\",\"722\":\"legged locomotion\\nmanipulators\\nsprings\\nrouting\\nload modeling\\nshape\\ndexterous manipulators\\nend effectors\\nmanipulator kinematics\\nmedical robotics\\nsurgery\\nparallel continuum robot design\\ngeneral intermediate constraints\\nparallel arrangement\\nleg flexibility\\ndexterous workspaces\\nminimally invasive surgery\\nnonlinear deformations\\nmulti-dof end effector articulation\\npassive spring backbone\\nleg divergence\\nmanipulator\\nforward kinematics model\\ninverse kinematics model\\ncosserat rod theory\\nleg routing paths\\nintermediate constraint disks\\nrobot-assisted surgery\",\"723\":\"surgery\\nrubber\\nsoft robotics\\ngrippers\\ncalibration\\nrobot sensing systems\\ncancer\\nmedical robotics\\nsoft robotic skin\\nautonomous tissue palpation\\nmanual palpation\\ntumor localization\\nopen surgery\\nminimally invasive surgery\\nrobotic surgery\\nsoft robotic tactile elements\\nsrte\\nsuction gripper\\ntissue cancer intraoperative mapping\",\"724\":\"grippers\\nmagnetic resonance imaging\\ntracking\\nmagnetic moments\\nsaturation magnetization\\nultrasonic imaging\\ncameras\\nbiomedical ultrasonics\\nimage sensors\\nmagnetic variables control\\nmedical control systems\\nmotion control\\nmagnetic motion control\\nultrasound image feedback\\nsoft miniaturized untethered grippers\\nbiological material\\nunstructured environments\\ntortuous environments\\noptical images\\nfeedback modality\\nminiaturized agents\\nwireless magnetic motion control\\nsoft untethered grippers\\nb-mode ultrasound images\",\"725\":\"planning\\nheuristic algorithms\\ntrajectory\\ndynamics\\nrobots\\nvehicle dynamics\\ngaussian mixture model\\ncontinuous systems\\ngaussian processes\\nmixture models\\nmobile robots\\npath planning\\nkinodynamic motion planning\\nmobile robot motion planning\\ncontinuous gaussian mixture fields\\nstatistical multi-modal motion models\\ndiscrete objects\\ncontinuous media\\nsemi-wrapped gmms\\nrrt* algorithm\\nsteer function\\nnon-holonomic mobile robots\",\"726\":\"drones\\npath planning\\nenergy consumption\\nenergy measurement\\npower demand\\nplanning\\noptimization\\nautonomous aerial vehicles\\ncomputational complexity\\nminimisation\\ntravelling salesman problems\\nub-anc planner\\nenergy-efficient coverage path planning\\ndrone design\\nbattle field surveillance\\ncpp problem\\ncoverage path planning problem\\ndrone flight time\\nmaximum energy consumption minimization\\ndrone flight paths\\nenergy-efficient coverage path planning problem\\neecpp\\nload-balanced allocation\\nminimum energy path planning problem\\nmepp\\nnp-hard problem\\ntraveling salesman problem\\ntsp\\nback tracking algorithm\\nunmanned aerial vehicles\",\"727\":\"path planning\\nalgorithm design and analysis\\ntwo dimensional displays\\nnavigation\\nplanning\\nmobile robots\\nrobots\\nwave propagation\\nsingle-source path planning\\nany-angle path planning\\ncwave\\ninteger arithmetics\\nhigh-performance algorithm\\nwave-propagation algorithm\\nrobotics\",\"728\":\"signal to noise ratio\\ntrajectory\\nnavigation\\nwireless communication\\nheuristic algorithms\\nrobot sensing systems\\narray signal processing\\nmobile robots\\nmotion control\\npath planning\\nharmonic potential\\ncommunication-aware navigation\\nbeamforming\\ncluttered space\\nchannel-state information\\ncommunication-aware algorithm\\nmobile agent navigation\\nharmonic potential field\\nhpf approach\\nmotion planning\\nrobot motion\\nchannel spectral efficiency\\ncse\\nwinner-ii wireless channel model\\nnavigation algorithm\",\"729\":\"robot kinematics\\ncollision avoidance\\ntrajectory\\ncameras\\nrobot vision systems\\ncomputational geometry\\nmobile robots\\nrobot vision\\npips\\nplanning in perception space\\npath planning\\ncollision-free trajectories\\nuncertain environment\\nchanging environment\\nfull collision checking\\nonline-revised representations\\nreactive obstacle avoidance\\nreactive vision-based approach\\nrobot modeling\\ndepth space image measurements\\nconsumer range sensors\\nrobot navigation\\ncollision checking\\n3d volume\\n2d image comparisons\",\"730\":\"robots\\ncost function\\ntrajectory\\ndecision making\\nnavigation\\nuncertainty\\ncollision avoidance\\nmobile robots\\noptimisation\\nfast influential outcome discovery\\nrisk-aware mpdm framework\\nmultipolicy decision making\\nrobot policy\\nstate distribution sampling\\nforward simulation\\nrandom sampling\\nperformance bottleneck\\noptimization process\\nperformance improvement\\nrobot platform\\nsemicrowded highly dynamic environment\",\"731\":\"inspection\\nthree-dimensional displays\\nsolid modeling\\ncomputational modeling\\npath planning\\nmobile robots\\nplanning\\nautonomous aerial vehicles\\nmicrorobots\\nonline inspection path planning\\nexploration path planning\\nmicroaerial vehicle\\nnext-best-view\\ninformation gain maximizes\\ncollision-free path planning\\nnbv\\nmav\\nminor unreconstructed region\\noptimal coverage path\\nlocal area modeling\\nautonomous 3d modeling\",\"732\":\"histograms\\nsensors\\nthree-dimensional displays\\nrobustness\\nlaser radar\\nmeasurement by laser beam\\nmathematical model\\nsensor placement\\nlarge-scale long term laser localisation\\nscene change modelling\\ndistraction suppression problem\\nurban driving environments\\ndynamic outliers\\nstatic elements\\nplace-dependent approach\\nlaser measurements\\nmultiple localisation\\nfront-end process\",\"733\":\"robot sensing systems\\nmeasurement uncertainty\\nrobustness\\nthree-dimensional displays\\natmospheric measurements\\nparticle measurements\\nautonomous aerial vehicles\\ngaussian processes\\nimage fusion\\nkalman filters\\noptical radar\\noptical scanners\\nparticle filtering (numerical methods)\\nrobot vision\\nrobust localization\\ninertial measurement unit\\nimu\\nrotating laser scanner\\nerror state kalman filter\\neskf\\nsensor fusion\\ngaussian particle filter\\ngpf\\nkidnapped robot situation\\nlaser range reduction\\n3d map localizability evaluation\\nlocalization error prediction\\nuav system\",\"734\":\"target tracking\\nrobot sensing systems\\nradio frequency\\nmathematical model\\nsearch problems\\ntrajectory\\nbayes methods\\ngaussian processes\\nmixture models\\nrandom processes\\nregression analysis\\nrobots\\nmobile target tracking\\nfov sensor\\nmoving target tracking\\nrobot\\nbayesian random finite sets\\nrfss\\ngaussian mixture probability hypothesis density filter\\ngm-phd filter\\ngaussian process regression\",\"735\":\"noise measurement\\nmeasurement uncertainty\\nmobile handsets\\ntime measurement\\nuncertainty\\ncameras\\nq measurement\\ncovariance matrices\\nkalman filters\\nmobile radio\\nreal-time 3d localization capabilities\\nmobile devices\\ncholesky-schmidt-kalman filter\\nc-skf\\nsparse cholesky factor\\ndense covariance\\nindependent sub-maps\\nloop-closure measurements\\ntemporal distribution\\npositioning accuracy\\nmap-based localization approaches\\nmeasurement-noise-covariance inflation\",\"736\":\"iterative closest point algorithm\\ncameras\\nthree-dimensional displays\\nrobustness\\nrobot sensing systems\\ntwo dimensional displays\\neuclidean distance\\ncomputer vision\\nimage colour analysis\\noptimisation\\npipeline processing\\nsemi-dense visual odometry\\nrgb-d cameras\\napproximate nearest neighbour fields\\n2d-3d icp pipeline\\n2d-semi-dense region\\n3d-semi-dense map\\neuclidean distance criterion\\ncompact gauss-newton updates\\nsensor noise\\nequivalent weighted least-square problem\\nsensor model probabilistic characteristics\",\"737\":\"robot sensing systems\\ngaussian processes\\nestimation\\nreceivers\\nnonlinear optics\\nnoise measurement\\nfeature extraction\\nindoor navigation\\nrssi\\ngaussian processes online observation classification\\nrssi-based low-cost indoor positioning systems\\nreal-time classification scheme\\nradio signal strength indicator\\nposition estimation\\nmultipathing effects\\nshadowing effects\\noperating sensor model\\nmetasensor modeling technique\",\"738\":\"sun\\nroads\\nsemantics\\nvisualization\\nglobal positioning system\\ncameras\\nautomobiles\\ncartography\\nfeedforward neural nets\\nimage classification\\nimage colour analysis\\nprobability\\ntraffic engineering computing\\nself-localization approach\\ncartographic maps\\nprobabilistic model\\nsemantic cues\\nsun direction\\nroad type\\nspeed limit\\nego-car trajectory\\ndriving time\",\"739\":\"global positioning system\\nestimation\\ncameras\\nrobots\\nthree-dimensional displays\\noptimization\\nuncertainty\\nautonomous aerial vehicles\\ninertial navigation\\nmobile robots\\npose estimation\\nrobot vision\\nrobust control\\nrobust visual-inertial localization\\nweak gps priors\\nrepetitive uav flights\\nunmanned aerial vehicles\\nagile robots\\nprecision self-localization\\nvisual-inertial sensor\\nreference map\\nuav workspace\\npiloted reconnaissance flight\\nkeyframe-based visual-inertial odometry\\ngeometric image-based localization\\nuav pose\\nsystem stability\\nglobal registration\\nloop closures\\ngps localization\\nglobal image-based alignment\",\"740\":\"simultaneous localization and mapping\\nestimation\\noptimization\\nposition measurement\\ncorrelation\\nstandards\\ncomputational complexity\\niterative methods\\nleast squares approximations\\nmaximum likelihood estimation\\nnonlinear programming\\npose estimation\\nrobot vision\\nslam (robots)\\nrfm-slam\\nrobot orientation estimation\\nrobot position estimation\\nrobot pose estimation\\nrobot feature locations\\nlinear least squares problem\\nrelative feature-to-feature measurements\\nlinear estimation problem\\npose-to-pose orientation constraints\\niterative nonlinear on-manifold optimization problem\\nrelative rotation constraints\\nmap estimation\\nfeature-based slam\\nodometery\\nslam\\ngraph-based slam\\nnon-linear optimization\\nrelative measurements\",\"741\":\"cameras\\nestimation\\nrobot vision systems\\nthree-dimensional displays\\ncomputational modeling\\nrobot vision\\nslam (robots)\\nstereo image processing\\nroom layout estimation\\nrapid omnidirectional exploration\\nomni-directional slam pipeline\\ndense stereo estimation\\ncomposite maps\",\"742\":\"observers\\nrobot kinematics\\ncameras\\nrobot vision systems\\nadaptive filters\\nimage colour analysis\\nkalman filters\\nmobile robots\\nmulti-robot systems\\npath planning\\nrobot vision\\ncooperative inchworm localization\\nmultirobot localization\\nlow-cost mobile robots\\ninertial measurement unit\\nimu\\nmonocular camera\\nmultiple picket robots\\nrgb light emitting diodes\\nled\\ncamera imagery\\nmotion estimation\\nextended kalman filter\\nekf\\nmeasurement jacobian\\ninchworm strategy\\ncamera-only localization technique\",\"743\":\"simultaneous localization and mapping\\ncomputer architecture\\nrelational databases\\nnavigation\\ncontrol engineering computing\\ndatabase management systems\\ngraph theory\\nmobile robots\\nslam (robots)\\nslamindb\\ncentralized graph databases\\nmobile robotics\\nmemory recall mechanisms\\ncomplex inference schemas\\nshared centralized data persistence layer\\nonline situationally-aware robot states\\nqueryable graph-database\\nkey-value store\\nexperience-based learning\\nlong-term autonomy\\nmultimodal simultaneous localization and mapping\\npersistence model\",\"744\":\"trajectory\\nplanning\\ncollision avoidance\\ndynamics\\nquadratic programming\\nautomobiles\\nvehicle dynamics\\naircraft control\\nautonomous aerial vehicles\\nconcave programming\\nconstraint handling\\nconvex programming\\nhelicopters\\ntrajectory control\\nquadrotor trajectory generation\\ndynamic environment\\nsemidefinite relaxation\\nnonconvex qcqp\\noptimization-based framework\\ncollision-free trajectories\\ndynamic environments\\nstatic obstacles\\nmoving obstacles\\nfinite-horizon motion prediction\\nglobal trajectory optimization\\nquadratically constrained quadratic programming\\nmoving obstacle avoidance problem\\nrandomization method\\nconvex linear restriction\\nnonconvex quadratic program\",\"745\":\"cameras\\nvisual servoing\\nstochastic processes\\nmanipulator dynamics\\nautonomous aerial vehicles\\nmanipulators\\nmobile robots\\nobject detection\\npredictive control\\nstochastic systems\\ntelerobotics\\naerial grasping\\nvision-based guidance command\\nimage-based cylinder detection algorithm\\nstochastic model predictive control\\nmpc framework\\nrotational velocities\\naerial manipulator\\nuav\\ncylindrical object grasping\",\"746\":\"drones\\ncollision avoidance\\ncameras\\ntraining\\nindoor environments\\nrobot sensing systems\\nautonomous aerial vehicles\\nconvolution\\nhelicopters\\nmobile robots\\nneural nets\\nrobot vision\\ncnn-based single image obstacle avoidance\\nquadrotor\\nsingle forward facing camera\\ndepth estimation\\ndepth map\\nbehaviour arbitration based control algorithm\",\"747\":\"manipulator dynamics\\ntorque\\ntrajectory\\nactuators\\nsystem dynamics\\ndecentralised control\\nfeedback\\nmanipulators\\ndynamic decentralized control\\nprotocentric aerial manipulators\\nunderactuated aerial manipulators\\ninput\\/state trajectory generator\\nfull-body dynamics\\nflatness property\\ndecentralized feedback controller\\nrobustness\\nclosed-loop system\\ninput\\/state generator\",\"748\":\"trajectory\\nrobots\\nplanning\\noptimization\\nmonitoring\\nuncertainty\\nautonomous aerial vehicles\\nbayes methods\\ndecision theory\\nmarkov processes\\nmobile robots\\nmonte carlo methods\\noptimisation\\ntree searching\\nsequential bayesian optimization\\nenvironment monitoring\\nuavs\\nglobal optimization technique\\nrobotic system\\nphysical constraints\\ntrajectory constraints\\npartially observable markov decision process\\nmonte-carlo tree search\\nmcts\\nreward function\\nbo-pomdp algorithm\",\"749\":\"aerodynamics\\nblades\\nunmanned aerial vehicles\\npropulsion\\ndrag\\ntorque\\nforce\\naerospace propulsion\\nautonomous aerial vehicles\\ncontrollability\\nhelicopters\\nmobile robots\\nrobot dynamics\\nservomotors\\ntelerobotics\\ntransformable hovering rotorcraft\\ntailless flying wing configuration\\nsingle-axis rotor\\nmonocopter\\naerodynamic surfaces\\npropulsion sources\\ndual servo-motor configuration\\nunder-actuated system\\nuav\\nunmanned aerial vehicle\\nthor design\\ndynamic analysis\",\"750\":\"mobile robots\\nengines\\nwheels\\nrockets\\nforce\\nrobot kinematics\\naerospace robotics\\nmotion control\\nrocket engines\\ntrajectory control\\ndistance control\\nrocket-propelled miniature exploration robot\\nplanetary rovers\\nlocomotion distance\\nflight distance\\nsolid rocket engines\\nthrust axis\\nthrusting force\\nflight distance control strategy\\nflight trajectory forming\\nflight trajectory prediction\\nopposing shot\\nvariance reduction\",\"751\":\"approximation theory\\ncomputational geometry\\nerror analysis\\nregression analysis\\nrobots\\n3d-rigid transformations regression\\nreal-valued vectors\\nblending unit dual quaternions\\nerror metrics\\ngeometric algebra\\nelastic deformation\",\"752\":\"robots\\ntrajectory\\nuncertainty\\nplanning\\nlibraries\\nalgorithm design and analysis\\ncomputational modeling\\ngaussian processes\\noptimal control\\npath planning\\nnoregret replanning\\nonline receding horizon-based planners\\nlatent information\\nlatent environment\\nucb style algorithms\\nonline robotic path planning problems\\nbandit settings\\nnoregret properties\\naircraft flight path planning\",\"753\":\"uncertainty\\ntraining data\\ntraining\\ncovariance matrices\\nrobots\\noptimization\\ntrajectory\\ncontrol engineering computing\\nrobot programming\\nbayesian uncertainty modeling\\nprogramming by demonstration\\nrobotic systems\\nsparse information\\nvariance based impedance adaptation\",\"754\":\"robot sensing systems\\nentropy\\noptimization\\npredictive models\\ntrajectory\\nstandards\\nhuman-robot interaction\\nlearning (artificial intelligence)\\nmobile robots\\nsearch problems\\nrobot reinforcement learning\\nrobot rl algorithms\\nglobal cumulative reward signal maximization\\nhuman feedback\\nlocal optima\\nintrinsic motivation\\nsensorimotor stream\\nreturn position\\nreturn ball speed\\npolicy search algorithm\\ntrade-off maximization\\nplanar reaching task\\nsimulated robot table tennis\\nempowered skills algorithm\",\"755\":\"optimization\\nestimation\\nentropy\\nmixture models\\nrobots\\nlearning (artificial intelligence)\\ncomplexity theory\\ninformation theory\\noptimisation\\nsearch problems\\nlayered direct policy search\\nhierarchical skills learning\\nrobotic tasks\\ncomplex behaviors\\nhigh dimensional continuous state\\naction spaces\\nreinforcement learning\\nhierarchical rl\\nhrl algorithms\\nhierarchical policies\\ntask specific knowledge\\ninformation theoretic principles\\npolicys structure\\nindependent optimization problems\\nsub-policies diversification\\nhigh dimensional continuous tasks\",\"756\":\"data models\\ncomputational modeling\\nbayes methods\\nmixture models\\nrobots\\nadaptation models\\nground penetrating radar\\ngaussian processes\\nintelligent robots\\nlearning (artificial intelligence)\\nregression analysis\\nrobot system\\nonline bayesian regression mixture model\\nrobot model learning\\nalgorithm gaussian mixture model\\nlocal gaussian experts\\nglobal\\nlinear computational cost\\nlocal model set\\nonline implementation\\nprobabilistic criteria\\nnonstationary system\\noutlier system\",\"757\":\"computational modeling\\nkernel\\npredictive models\\nstandards\\nbiological system modeling\\ngaussian processes\\ndata models\\nentropy\\nregression analysis\\nsampling methods\\nactive sample selection\\nscalar fields\\nnonstationary noise\\nparametric heteroscedastic gaussian process regression\\ngp\\nhomoscedastic model\\nlog marginal likelihood\\nkernel hyperparameters\\ncomputational efficiency\\nbathymetric front\\nmutual information\\nfisher information\\nrandom sampling\",\"758\":\"friction\\ntraining\\ntorque\\nhysteresis motors\\nrecurrent neural networks\\nhysteresis\\nsupervised learning\\nindustrial manipulators\\nlearning (artificial intelligence)\\nnonlinear control systems\\npendulums\\nposition control\\nrecurrent neural nets\\nrolling friction\\nrolling friction modeling\\nrecurrent neural network\\nlstm\\nmechanical system identification\\nmechanical system modeling\\ncontrol systems\\nfriction characteristics\\npositioning performance\\nindustrial robots\\nforce estimation accuracy\\ndisturbance observer\\nposture control performance\\ninverted pendulum robot\\novershoot\\nundershoot\\nlimit cycles\\nrnn\\nlong short-term memory\",\"759\":\"cameras\\ncalibration\\nmeasurement uncertainty\\nvisualization\\nuncertainty\\nradiometry\\noptimization\\nimage motion analysis\\nmaximum likelihood estimation\\ncamera calibration techniques\\nvisual state estimation\\ncamera measurement model\\nmaximum likelihood estimator\\nimage intensities\\nline delay\\nrolling shutter camera\\ncamera exposure time estimation\\nmotion blur\",\"760\":\"calibration\\ncameras\\nmotion segmentation\\ngyroscopes\\naccelerometers\\nsensor systems\\ntrajectory\\ncomputer vision\\nimage segmentation\\ninertial navigation\\ninertial systems\\ninformation theory\\nobservability\\noptimisation\\nvisual-inertial self-calibration\\ninformative motion segments\\nenvironmental conditions\\nexternal effects\\ncalibration parameters\\nvisual-inertial sensor systems\\nparameter observability\\ndevice motion\\ndata segments\\ndevice initialization\\nenergy constraints\\nfull-batch approaches\\nbig dataset\\ndata selection\\nresource efficient self-calibration\\nsegment-based optimization problem\\ninformative segments\\ninformation-theoretic selection\\ncomputational burden\",\"761\":\"lasers\\ncameras\\ncalibration\\nmeasurement by laser beam\\ntwo dimensional displays\\nthree-dimensional displays\\nlinear programming\\ncombinatorial mathematics\\nnumerical analysis\\noptical scanners\\noptimisation\\ntree searching\\nbranch-and-bound algorithm\\ncheckerboard extraction measurement\\ncamera-to-laser scanner calibration\\nmultiple image laser scan pair\\ncombinatorial optimization problem\\nclear cut objective function\\n2d laser scanner\\n3d laser scanner\\nnumerical simulation\",\"762\":\"cameras\\ncalibration\\nlighting\\nlenses\\noptical attenuators\\noptical imaging\\noptical sensors\\nautonomous aerial vehicles\\nmaximum likelihood estimation\\nradiometry\\nreflectivity\\nrobot vision\\nvisual databases\\non-field radiometric calibration\\noutdoor robotics\\nenvironmental conditions\\nvision-based perception systems\\nspatio-temporal mapping\\nin-situ illumination estimation\\ndata-driven parameter-free approach\\nmultispectral cameras\\nqualitative analysis\\nrelative reflectance images\\nfield calibration datasets\\nambient conditions\\nuav\",\"763\":\"friction\\nwheels\\nvehicle dynamics\\nnumerical models\\nload modeling\\nsteady-state\\ndc motors\\nangular velocity control\\ndiscrete time systems\\nelectric vehicles\\nhandicapped aids\\nmobile robots\\npath planning\\nrobot dynamics\\ndiscrete-time dynamic modeling\\ndifferential-drive mobile robot calibration\\nfixed-time-step discrete-time dynamic model\\ncomputational cost minimization\\nfriction model\\nwheel lock prediction\\nvelocity steady-state prediction\\ndynamic model\\nphysical platform evaluation\\nelectric powered wheelchair\\nlinear velocity prediction\\nangular velocity prediction\\nwheel speed measurements\\ntime-series\\ncommand inputs\",\"764\":\"trajectory\\nhumanoid robots\\ncost function\\nmatrix decomposition\\nsymmetric matrices\\ngradient methods\\nmatrix algebra\\noptimisation\\nparameter estimation\\nregression analysis\\npersistently exciting trajectory\\ncondition number optimization\\ninertial parameter identification\\nregressor matrix\\nlinear regression model\\njoint trajectory parameters\\nsingular values\\nregressor matrices\\ndirect gradient computation\\ncomputational performance\\nlarge dof systems\\nhumanoid robot hrp-4\",\"765\":\"calibration\\ncameras\\ntrajectory\\nsimultaneous localization and mapping\\ntwo dimensional displays\\nmeasurement uncertainty\\nmobile robots\\nparameter estimation\\nrobot vision\\nslam (robots)\\nstatistical testing\\ndrift-correcting self-calibration\\nvisual-inertial slam\\nonline simultaneous localization and mapping self-calibration\\ncamera focal length\\ncamera-to-imu extrinsics\\ncalibration parameter modeling\\nspatiotemporal quantity\\nsensor-to-sensor spatial calibration\\nsensor intrinsic parameters\\nstatistical tests\\nchange detection\\nregression analysis\\ntime-varying sensor calibration modeling\\nconstant-time operation\",\"766\":\"navigation\\nthree-dimensional displays\\nvibrations\\ncameras\\nlegged locomotion\\nrobot sensing systems\\nhaptic interfaces\\ncomputer vision\\nhandicapped aids\\nimage motion analysis\\npath planning\\nindependent navigation\\nvisually impaired people\\nwearable vision-based feedback system\\nblind people\\ncamera\\nembedded computer\\nhaptic device\\nmotion planning\",\"767\":\"haptic interfaces\\nvisualization\\nnavigation\\nforce\\nrobots\\nspatial resolution\\nanalytical models\\nhuman-robot interaction\\ntelerobotics\\nmultisensory cue\\ndirection information\\nteleoperation\\nmobile robots\\nauditory modality\\nhaptic modality\\nvisual modality\\nauditory feedback\\nhaptic feedback\\nvisual feedback\\nauditory direction cues\\nhaptic cues\\nmultimodal human machine interface design\",\"768\":\"acoustics\\nspectrogram\\nnoise measurement\\nimage reconstruction\\nhidden markov models\\ntraining\\nrobots\\nacoustic signal detection\\nacoustic transducers\\naudio signal processing\\nhearing\\nintelligent sensors\\nroad traffic\\nsignal classification\\nsignal denoising\\nsignal reconstruction\\nsignal representation\\nurban soundscape\\nauditory perception\\ndistinctive audio signal detection\\nsmart vehicle system\\ntwo-stage approach\\nacoustic event presence\\nanomaly detection\\nanomalous sound identification\\nnoise-removal technique\\nwaveform reconstruction\\nspectrogram segmentation\\nsignal segmentation\\nimage segmentation\\nbackground noise\\nurban oxford\\nmel-frequency cepstrum coefficient\",\"769\":\"muscles\\nelectrodes\\nforce\\nsociology\\nstatistics\\nestimation\\nmanipulators\\nelectromyography\\nforce control\\nhuman-robot interaction\\nnonlinear control systems\\nstochastic semg processor\\nmanipulator control\\nman-machine interface\\nminimal electro-mechanical delay\\nmyoelectric processor\\nmuscle activation level\\nmultichannel semg\\nstatic force condition\\ndynamic contraction\\nnonlinear effects\\nsnr\\nisometric force-varying contractions\\ntwo-dof manipulator\",\"770\":\"tracking\\ntransient analysis\\ntraining\\ncameras\\nthree-dimensional displays\\nrobustness\\nsensors\\nmedical image processing\\nobject tracking\\npatient care\\npatient monitoring\\npatient rehabilitation\\nsensor fusion\\nclinical patient tracking\\ngeodesic feature\\nrgb-d cameras\\nmotion tracking\\nhuman spinal cord injury patient\\nspinal stimulation\\nphysical rehabilitation\\ndata association problem\\ngeodesic distances\\nsurface mesh points\\nanchor points\\ntransient occlusions\\npermanent occlusions\\nmultihypothesis tracking framework\",\"771\":\"electroencephalography\\nreal-time systems\\ncollaboration\\ntraining\\nvisualization\\nmobile robots\\nclosed loop systems\\ndexterous manipulators\\nfeedback\\nhuman-robot interaction\\nopen loop systems\\nbrain activity\\nfeedback loop\\nintuitive interaction tasks\\neeg-measured error-related potentials\\neeg-measured errp\\nclosed-loop robotic control\\nerrp signal decoding\\nrethink robotics baxter robot\\nbinary object selection task\\nsecondary interactive error-related potential signal\\nclosed-loop robot task\\nclassification performance improvement\\nhuman feedback\\nreal- time closed-loop experiments\\nreal-time open-loop experiments\\noffline analysis\\nprimary errp signals\\nsecondary errp signals\\neeg-based feedback methods\",\"772\":\"trajectory\\nobject oriented modeling\\nactivity recognition\\nhidden markov models\\nrobots\\ncollaboration\\ntraining\\nimage classification\\nindustrial robots\\nregression analysis\\nrobot vision\\ninterpretable models\\nanomaly explanation\\ncollaborative robotics tasks\\nrapid activity prediction through object-oriented regression\\nraptor\\ngeneric human activity dataset\\ndomain-specific collaborative robotics manufacturing datasets\\ntrajectory classification\\noutlier detection\",\"773\":\"magnetic resonance imaging\\nmagnetic susceptibility\\nmagnetosphere\\nforce\\nmagnetic nanoparticles\\nmobile communication\\nmicrorobots\\nmotion control\\nnanofluidics\\nnanoparticles\\nparamagnetic materials\\nvortices\\nmobile paramagnetic nanoparticle-based vortex\\ntargeted cargo delivery\\nfluid\\ndrug delivery\\nmicro-vortex-based method\\nparticle gathering\\nmobile vortices velocity\\nmobile vortices morphology\\npitch angles\\npolystyrene microbeads\\nmicromanipulation\\nmicrorobotic swarm formation\\nmicrorobotic swarm motion control\\nmicrorobot\\nvortex\\ncollective behaviour\\ntargeted delivery\\nmagnetic nanoparticle\",\"774\":\"magnetosphere\\nmagnetic resonance imaging\\nforce\\nembryo\\nmagnetic noise\\nmagnetic shielding\\nmagnetic levitation\\nmedical robotics\\nmicromanipulators\\nthree-dimensional robotic control\\n5-micrometer magnetic bead\\nintra-embryonic navigation\\nmagnetic micromanipulation\\nuntethered control\\nbiocompatibility\\nmouse embryo\\nmagnetic force scaling\\nrobotic magnetic tweezer system\\nintra embryonic magnetic navigation\\nforce application\\nrobotic microinjection\\ncellular structure mechanical measurements\\ninner cell mass\",\"775\":\"actuators\\nvelocity control\\nfriction\\nvoltage control\\ndynamics\\nfrequency control\\ncontrol system synthesis\\nend effectors\\nfeedback\\nmobile robots\\nmotion control\\npiezoelectric actuators\\nposition control\\nvelocity characterization\\nnanorobotic systems\\npiezoelectric stick-slip actuators\\ncontrol strategies\\nsemi-automated tasks\\nautomated tasks\\npss actuator velocity control\\nend effector\\nvacuum environments\\nair environments\\nforward direction motion\\nbackward direction motion\\ndynamic automated tasks\",\"776\":\"grippers\\nplanning\\ngrasping\\nmagnetic heads\\nmicromagnetics\\ntwo dimensional displays\\ntorque\\nmicromanipulators\\nmobile robots\\npath planning\\nuncertain systems\\nspin-walking locomotion planning\\nmicroobjects\\nuntethered magnetic microgripper\\nmobile microrobot\\nautomated 2d grasping motion planner\\ntime-efficient automatic grasping\\nuntethered microrobots\\nuncertainties\\nmicroscale manipulation\",\"777\":\"vibrations\\nswitches\\nsystem-on-chip\\nloading\\nmicroscopy\\nbiomedical optical imaging\\noptical device fabrication\\nbiocontrol\\ncellular biophysics\\nmicrofluidics\\nmicromanipulators\\nhigh-throughput cell analysis\\nhigh-reliability cell analysis\\nsingle particle loading\\nlocal cell concentration\\nmicroobjects manipulation modes\\nalignment mode\\ntransport mode\\ntrap mode\\nflow pattern switching\\ncircular vibration\\nmicrofluidic chip\\nrotationally asymmetric structures\\nvibration-induced asymmetric flow\\nmode switching\\non-chip micromanipulation method\",\"778\":\"exoskeletons\\nrobot kinematics\\nmedical treatment\\nfeedforward neural networks\\nelbow\\nadaptation models\\nend effectors\\nerror analysis\\nmedical robotics\\npatient rehabilitation\\npatient treatment\\nsignal processing\\nerror signals\\nassist-as-needed controllers\\nneurorehabilitation\\nupper-limb robotic exoskeleton\\nstroke survivors\\nrobotic-led therapies\\nend effector\\nrobot kinematic chain\",\"779\":\"shoulder\\nrobots\\nmuscles\\ncouplings\\ntorso\\nelbow\\nbladder\\nhandicapped aids\\nmedical robotics\\nmuscle\\nexomuscle\\ninflatable device\\nshoulder abduction support\\nstroke\\nadult disability\\nplastic bladder\\nfabric bag\",\"780\":\"impedance\\nforce\\nlegged locomotion\\ntorque\\nfoot\\nestimation\\ncameras\\ndamping\\ngait analysis\\nperturbation techniques\\nprosthetics\\ntime-varying systems\\nvibration control\\ntime-varying human ankle impedance\\nsagittal planes\\nfrontal planes\\nstance phase\\nwalking\\n2-dof powered ankle-foot prostheses\\ninstrumented vibrating platform\\ntorque perturbations\\nmaximum damping\",\"781\":\"prosthetics\\nknee\\ntorque\\nactuators\\nkinematics\\nbrushless dc motors\\nartificial limbs\\ngait analysis\\nlegged locomotion\\northotics\\nactively variable transmission\\nrobotic knee prostheses\\navt\\nmotor torque\\nspring-damper system\\npassive operation modes\\nactive operation modes\\nbypass orthosis\\nreciprocal gait pattern\",\"782\":\"springs\\nprosthetics\\nfoot\\nlegged locomotion\\ntorque\\nmodulation\\ndc motors\\nbiomimetics\\ncams (mechanical)\\nelastic constants\\ngait analysis\\nquasipassive ankle-foot prosthesis design\\nbiomimetic variable stiffness\\nbiomechanics\\nmechanics adjustment\\nmobility task\\nstair traversal\\nquiet standing\\ncustomizable nonlinear torque-angle curve\\ncontinuous stiffness variation\\nmechanics variation\\ncam-based transmission\\nankle joint rotation\\nleaf spring deflection\\nactive sliding support\\nspring effective stiffness\\nhuman walking\\nstiffness transition time\",\"783\":\"wrist\\nprosthetics\\nprototypes\\nsprings\\nshoulder\\nrobot sensing systems\\nadaptive control\\nmanipulators\\nunder-actuated wrist system\\nadaptive synergies\\nrobotic wrist\\nrobotic manipulation\\nsoft synergies\\nrobot hand design\\ngrasping tasks\\nmanipulation tasks\",\"784\":\"actuators\\nexoskeletons\\nforce\\nimpedance\\nmagnetic flux\\nrobots\\ndc motors\\ncables (mechanical)\\ncompliance control\\nfeedback\\nforce control\\nforce sensors\\nhall effect transducers\\nhuman-robot interaction\\nrobot dynamics\\nsprings (mechanical)\\ncable-based series elastic actuator\\nconduit sensor\\nwearable robotic device\\nphysical assistance\\nsoft wearable exoskeleton\\nactuation system design\\nsoft exosuit\\nhuman arm\\ndc motor\\ngearbox\\nflexible cable conduit transmission\\nseries elastic force sensor\\ntransmission conduit\\ncompliant force sensor\\ntranslational steel compression spring\\nhall effect sensors\\ndeflection measurement\\ncable tension measurement\\ncable tension control\\ndynamic effect\\ncable-conduit transmission\\nuser interface\\nvirtual impedance\\nfull wearable exosuit\",\"785\":\"couplings\\npins\\nprosthetic hand\\nbones\\nsprings\\nsteel\\nimmune system\\nhandicapped aids\\nimpact (mechanical)\\nprosthetics\\nsprings (mechanical)\\ncompliant four-bar linkage mechanism\\nimpact resistant\\nmechanical failure\\naccidental impact\\nupper-limb amputations\\ncoupler links\\nmonolithic compliant bone\\nprestressed spring steel\\ngrasping performance\",\"786\":\"actuators\\nfabrics\\nforce\\nresistance\\nsoft robotics\\ninterference\\nbending\\npneumatic actuators\\nrobots\\nhybrid plastic fabric soft bending actuator\\nreconfigurable bending profiles\\nrigid actuators\\nrobotic systems\\nsoft robotic actuators\\npneumatic bending actuator\",\"787\":\"force\\nprototypes\\ngrippers\\nyoung's modulus\\npolymers\\nanalytical models\\nmanganese\\n3d-printed polymeric compliant constant-force buffering gripping mechanism\\nmanipulated biological object\\nexcessive displacement output\\nzero-stiffness mechanism\\nnegative-stiffness part\\npositive-stiffness part\\nbistable buckled fixed-guided beam mechanism\\n3d printing\\nconstant-force range\\nforce-displacement control\\nfragile object manipulation\",\"788\":\"actuators\\nanalytical models\\nrobot sensing systems\\npolymers\\nelasticity\\nsprings\\nbimetals\\nrobots\\nanalytic modeling\\ntrilayer-electro-thermal actuators\\nthin-soft robotics\\nmicronthin polymer layers\\nelectrically conductive layer\\nbimetal effect\\nsoft-thin-electrically-activated thermal actuator\\nsoft-thin eta\\nmultilayered eta\\nbilayer eta\\ntrilayer eta\\noptimal design parameter estimation\\ncurvature change\\ntrilayer actuators\",\"789\":\"force\\nhuman-robot interaction\\nsprings\\naluminum\\nmanipulators\\nsafety\\ncompliance control\\nelastic constants\\nforce control\\nindustrial manipulators\\ninertial systems\\nrobot dynamics\\nsprings (mechanical)\\ntorsion\\nmechanical compliance\\ncollision maximum impact force\\nindustrial manipulators compliance\\n2d robot link\\nrigid link\\ntorsion spring\\njoint compliant link\\nuniform compliant link\\ndynamic impact model\\nhertz contact model\\nlateral stiffness\\ninertial parameters\\nsafety concerns\",\"790\":\"iron\\nip networks\\nfinite element analysis\\nconferences\\nautomation\\nfrequency modulation\\nbiological tissues\\ndexterous manipulators\\neye\\nmedical robotics\\nmobile robots\\nsurgery\\nassisted retinal microsurgery\\nconfined intraocular space\\nphysical constraints\\nsnake-like robots\\ndexterity enhancement\\ntissues\\ndamage minimization\\nintegrated intraocular snake robot\\niris robot\\nrobotic assistant\\ncooperatively controlled steady-hand eye robot\\ncooperatively controlled sher\\nyaw motions\\npitch motions\\nenhanced intraocular dexterity\\nsclerotomy port\\nsnake-like tip actuation\\nartificial eye model\",\"791\":\"electron tubes\\nrobots\\nkinematics\\noptimization\\ncomputational modeling\\nfriction\\nnickel\\nbending\\nmedical robotics\\npipes\\nposition control\\nrobot kinematics\\nsurgery\\ntube-to-tube clearances\\nconcentric tube robot kinematics\\nmechanics-based formulations\\ntube bending\\ntube twisting\\ntube rotation\\nhysteretic tube-on-tube friction\\ncontact forces computation\\nconstrained energy minimization problem\\nclearance-constrained centerlines\\ntip position errors\\nrobotic surgery\",\"792\":\"actuators\\ndiffraction\\ndiffraction gratings\\nfilms\\nrobot sensing systems\\ncolor\\nbiocybernetics\\nlegged locomotion\\nmechanical contact\\nmechanical variables measurement\\nshape memory effects\\nchromatic surface microstructures\\ncsm films\\nbionic soft robots\\nnon-contact deformation measurement\\nbody deformation measurement\\ndiffraction gratings mold\\npolydimethylsiloxane\\npdms\\nshape memory alloy wires\\nsma wires\\npattern recording\\npattern matching\\ncontinuous deformation curvature degrees\\nsma soft actuators\\nthree-legged soft robot motions\\nobstacles grasping\\nflexible devices\",\"793\":\"robot kinematics\\ncollision avoidance\\nrobot sensing systems\\nshape\\nnavigation\\nkinematics\\nmobile robots\\nrobot shape\\nkinematic constraints\\nholonomic pointlike robot\\nag approach\\nadmissible gap method\\nreactive collision avoidance\\nmotion constraints\\nobstacle avoidance approach\\nnavigation performance\\nadmissible gap\"},\"Benchmark Setup\":{\"0\":-1,\"1\":-1,\"2\":-1,\"3\":-1,\"4\":-1,\"5\":-1,\"6\":-1,\"7\":-1,\"8\":-1,\"9\":-1,\"10\":-1,\"11\":-1,\"12\":-1,\"13\":-1,\"14\":-1,\"15\":-1,\"16\":-1,\"17\":-1,\"18\":-1,\"19\":-1,\"20\":-1,\"21\":-1,\"22\":-1,\"23\":-1,\"24\":-1,\"25\":-1,\"26\":-1,\"27\":-1,\"28\":-1,\"29\":-1,\"30\":-1,\"31\":-1,\"32\":-1,\"33\":-1,\"34\":-1,\"35\":-1,\"36\":-1,\"37\":-1,\"38\":-1,\"39\":-1,\"40\":-1,\"41\":-1,\"42\":-1,\"43\":-1,\"44\":-1,\"45\":-1,\"46\":-1,\"47\":-1,\"48\":-1,\"49\":-1,\"50\":-1,\"51\":-1,\"52\":-1,\"53\":-1,\"54\":-1,\"55\":-1,\"56\":-1,\"57\":-1,\"58\":-1,\"59\":-1,\"60\":-1,\"61\":-1,\"62\":-1,\"63\":-1,\"64\":-1,\"65\":-1,\"66\":-1,\"67\":-1,\"68\":-1,\"69\":-1,\"70\":-1,\"71\":-1,\"72\":-1,\"73\":-1,\"74\":-1,\"75\":-1,\"76\":-1,\"77\":-1,\"78\":-1,\"79\":-1,\"80\":-1,\"81\":-1,\"82\":-1,\"83\":-1,\"84\":-1,\"85\":-1,\"86\":-1,\"87\":-1,\"88\":-1,\"89\":-1,\"90\":-1,\"91\":-1,\"92\":-1,\"93\":-1,\"94\":-1,\"95\":-1,\"96\":-1,\"97\":-1,\"98\":-1,\"99\":-1,\"100\":-1,\"101\":-1,\"102\":-1,\"103\":-1,\"104\":-1,\"105\":-1,\"106\":-1,\"107\":-1,\"108\":-1,\"109\":-1,\"110\":-1,\"111\":-1,\"112\":-1,\"113\":-1,\"114\":-1,\"115\":-1,\"116\":-1,\"117\":-1,\"118\":-1,\"119\":-1,\"120\":-1,\"121\":-1,\"122\":-1,\"123\":-1,\"124\":-1,\"125\":-1,\"126\":-1,\"127\":-1,\"128\":-1,\"129\":-1,\"130\":-1,\"131\":-1,\"132\":-1,\"133\":-1,\"134\":-1,\"135\":-1,\"136\":-1,\"137\":-1,\"138\":-1,\"139\":-1,\"140\":-1,\"141\":-1,\"142\":-1,\"143\":-1,\"144\":-1,\"145\":-1,\"146\":-1,\"147\":-1,\"148\":-1,\"149\":-1,\"150\":-1,\"151\":-1,\"152\":-1,\"153\":-1,\"154\":-1,\"155\":-1,\"156\":-1,\"157\":-1,\"158\":-1,\"159\":-1,\"160\":-1,\"161\":-1,\"162\":-1,\"163\":-1,\"164\":-1,\"165\":-1,\"166\":-1,\"167\":-1,\"168\":-1,\"169\":-1,\"170\":-1,\"171\":-1,\"172\":-1,\"173\":-1,\"174\":-1,\"175\":-1,\"176\":-1,\"177\":-1,\"178\":-1,\"179\":-1,\"180\":-1,\"181\":-1,\"182\":-1,\"183\":-1,\"184\":-1,\"185\":-1,\"186\":-1,\"187\":-1,\"188\":-1,\"189\":-1,\"190\":-1,\"191\":-1,\"192\":-1,\"193\":-1,\"194\":-1,\"195\":-1,\"196\":-1,\"197\":-1,\"198\":-1,\"199\":-1,\"200\":-1,\"201\":-1,\"202\":-1,\"203\":-1,\"204\":-1,\"205\":-1,\"206\":-1,\"207\":-1,\"208\":-1,\"209\":-1,\"210\":-1,\"211\":-1,\"212\":-1,\"213\":-1,\"214\":-1,\"215\":-1,\"216\":-1,\"217\":-1,\"218\":-1,\"219\":-1,\"220\":-1,\"221\":-1,\"222\":-1,\"223\":-1,\"224\":-1,\"225\":-1,\"226\":-1,\"227\":-1,\"228\":-1,\"229\":-1,\"230\":-1,\"231\":-1,\"232\":-1,\"233\":-1,\"234\":-1,\"235\":-1,\"236\":-1,\"237\":-1,\"238\":-1,\"239\":-1,\"240\":-1,\"241\":-1,\"242\":-1,\"243\":-1,\"244\":-1,\"245\":-1,\"246\":-1,\"247\":-1,\"248\":-1,\"249\":-1,\"250\":-1,\"251\":-1,\"252\":-1,\"253\":-1,\"254\":-1,\"255\":-1,\"256\":-1,\"257\":-1,\"258\":-1,\"259\":-1,\"260\":-1,\"261\":-1,\"262\":-1,\"263\":-1,\"264\":-1,\"265\":-1,\"266\":-1,\"267\":-1,\"268\":-1,\"269\":-1,\"270\":-1,\"271\":-1,\"272\":-1,\"273\":-1,\"274\":-1,\"275\":-1,\"276\":-1,\"277\":-1,\"278\":-1,\"279\":-1,\"280\":-1,\"281\":-1,\"282\":-1,\"283\":-1,\"284\":-1,\"285\":-1,\"286\":-1,\"287\":-1,\"288\":-1,\"289\":-1,\"290\":-1,\"291\":-1,\"292\":-1,\"293\":-1,\"294\":-1,\"295\":-1,\"296\":-1,\"297\":-1,\"298\":-1,\"299\":-1,\"300\":-1,\"301\":-1,\"302\":-1,\"303\":-1,\"304\":-1,\"305\":-1,\"306\":-1,\"307\":-1,\"308\":-1,\"309\":-1,\"310\":-1,\"311\":-1,\"312\":-1,\"313\":-1,\"314\":-1,\"315\":-1,\"316\":-1,\"317\":-1,\"318\":-1,\"319\":-1,\"320\":-1,\"321\":-1,\"322\":-1,\"323\":-1,\"324\":-1,\"325\":-1,\"326\":-1,\"327\":-1,\"328\":-1,\"329\":-1,\"330\":-1,\"331\":-1,\"332\":-1,\"333\":-1,\"334\":-1,\"335\":-1,\"336\":-1,\"337\":-1,\"338\":-1,\"339\":-1,\"340\":-1,\"341\":-1,\"342\":-1,\"343\":-1,\"344\":-1,\"345\":-1,\"346\":-1,\"347\":-1,\"348\":-1,\"349\":-1,\"350\":-1,\"351\":-1,\"352\":-1,\"353\":-1,\"354\":-1,\"355\":-1,\"356\":-1,\"357\":-1,\"358\":-1,\"359\":-1,\"360\":-1,\"361\":-1,\"362\":-1,\"363\":-1,\"364\":-1,\"365\":-1,\"366\":-1,\"367\":-1,\"368\":-1,\"369\":-1,\"370\":-1,\"371\":-1,\"372\":-1,\"373\":-1,\"374\":-1,\"375\":-1,\"376\":-1,\"377\":-1,\"378\":-1,\"379\":-1,\"380\":-1,\"381\":-1,\"382\":-1,\"383\":-1,\"384\":-1,\"385\":-1,\"386\":-1,\"387\":-1,\"388\":-1,\"389\":-1,\"390\":-1,\"391\":-1,\"392\":-1,\"393\":-1,\"394\":-1,\"395\":-1,\"396\":-1,\"397\":-1,\"398\":-1,\"399\":-1,\"400\":-1,\"401\":-1,\"402\":-1,\"403\":-1,\"404\":-1,\"405\":-1,\"406\":-1,\"407\":-1,\"408\":-1,\"409\":-1,\"410\":-1,\"411\":-1,\"412\":-1,\"413\":-1,\"414\":-1,\"415\":-1,\"416\":-1,\"417\":-1,\"418\":-1,\"419\":-1,\"420\":-1,\"421\":-1,\"422\":-1,\"423\":-1,\"424\":-1,\"425\":-1,\"426\":-1,\"427\":-1,\"428\":-1,\"429\":-1,\"430\":-1,\"431\":-1,\"432\":-1,\"433\":-1,\"434\":-1,\"435\":-1,\"436\":-1,\"437\":-1,\"438\":-1,\"439\":-1,\"440\":-1,\"441\":-1,\"442\":-1,\"443\":-1,\"444\":-1,\"445\":-1,\"446\":-1,\"447\":-1,\"448\":-1,\"449\":-1,\"450\":-1,\"451\":-1,\"452\":-1,\"453\":-1,\"454\":-1,\"455\":-1,\"456\":-1,\"457\":-1,\"458\":-1,\"459\":-1,\"460\":-1,\"461\":-1,\"462\":-1,\"463\":-1,\"464\":-1,\"465\":-1,\"466\":-1,\"467\":-1,\"468\":-1,\"469\":-1,\"470\":-1,\"471\":-1,\"472\":-1,\"473\":-1,\"474\":-1,\"475\":-1,\"476\":-1,\"477\":-1,\"478\":-1,\"479\":-1,\"480\":-1,\"481\":-1,\"482\":-1,\"483\":-1,\"484\":-1,\"485\":-1,\"486\":-1,\"487\":-1,\"488\":-1,\"489\":-1,\"490\":-1,\"491\":-1,\"492\":-1,\"493\":-1,\"494\":-1,\"495\":-1,\"496\":-1,\"497\":-1,\"498\":-1,\"499\":-1,\"500\":-1,\"501\":-1,\"502\":-1,\"503\":-1,\"504\":-1,\"505\":-1,\"506\":-1,\"507\":-1,\"508\":-1,\"509\":-1,\"510\":-1,\"511\":-1,\"512\":-1,\"513\":-1,\"514\":-1,\"515\":-1,\"516\":-1,\"517\":-1,\"518\":-1,\"519\":-1,\"520\":-1,\"521\":-1,\"522\":-1,\"523\":-1,\"524\":-1,\"525\":-1,\"526\":-1,\"527\":-1,\"528\":-1,\"529\":-1,\"530\":-1,\"531\":-1,\"532\":-1,\"533\":-1,\"534\":-1,\"535\":-1,\"536\":-1,\"537\":-1,\"538\":-1,\"539\":-1,\"540\":-1,\"541\":-1,\"542\":-1,\"543\":-1,\"544\":-1,\"545\":-1,\"546\":-1,\"547\":-1,\"548\":-1,\"549\":-1,\"550\":-1,\"551\":-1,\"552\":-1,\"553\":-1,\"554\":-1,\"555\":-1,\"556\":-1,\"557\":-1,\"558\":-1,\"559\":-1,\"560\":-1,\"561\":-1,\"562\":-1,\"563\":-1,\"564\":-1,\"565\":-1,\"566\":-1,\"567\":-1,\"568\":-1,\"569\":-1,\"570\":-1,\"571\":-1,\"572\":-1,\"573\":-1,\"574\":-1,\"575\":-1,\"576\":-1,\"577\":-1,\"578\":-1,\"579\":-1,\"580\":-1,\"581\":-1,\"582\":-1,\"583\":-1,\"584\":-1,\"585\":-1,\"586\":-1,\"587\":-1,\"588\":-1,\"589\":-1,\"590\":-1,\"591\":-1,\"592\":-1,\"593\":-1,\"594\":-1,\"595\":-1,\"596\":-1,\"597\":-1,\"598\":-1,\"599\":-1,\"600\":-1,\"601\":-1,\"602\":-1,\"603\":-1,\"604\":-1,\"605\":-1,\"606\":-1,\"607\":-1,\"608\":-1,\"609\":-1,\"610\":-1,\"611\":-1,\"612\":-1,\"613\":-1,\"614\":-1,\"615\":-1,\"616\":-1,\"617\":-1,\"618\":-1,\"619\":-1,\"620\":-1,\"621\":-1,\"622\":-1,\"623\":-1,\"624\":-1,\"625\":-1,\"626\":-1,\"627\":-1,\"628\":-1,\"629\":-1,\"630\":-1,\"631\":-1,\"632\":-1,\"633\":-1,\"634\":-1,\"635\":-1,\"636\":-1,\"637\":-1,\"638\":-1,\"639\":-1,\"640\":-1,\"641\":-1,\"642\":-1,\"643\":-1,\"644\":-1,\"645\":-1,\"646\":-1,\"647\":-1,\"648\":-1,\"649\":-1,\"650\":-1,\"651\":-1,\"652\":-1,\"653\":-1,\"654\":-1,\"655\":-1,\"656\":-1,\"657\":-1,\"658\":-1,\"659\":-1,\"660\":-1,\"661\":-1,\"662\":-1,\"663\":-1,\"664\":-1,\"665\":-1,\"666\":-1,\"667\":-1,\"668\":-1,\"669\":-1,\"670\":-1,\"671\":-1,\"672\":-1,\"673\":-1,\"674\":-1,\"675\":-1,\"676\":-1,\"677\":-1,\"678\":-1,\"679\":-1,\"680\":-1,\"681\":-1,\"682\":-1,\"683\":-1,\"684\":-1,\"685\":-1,\"686\":-1,\"687\":-1,\"688\":-1,\"689\":-1,\"690\":-1,\"691\":-1,\"692\":-1,\"693\":-1,\"694\":-1,\"695\":-1,\"696\":-1,\"697\":-1,\"698\":-1,\"699\":-1,\"700\":-1,\"701\":-1,\"702\":-1,\"703\":-1,\"704\":-1,\"705\":-1,\"706\":-1,\"707\":-1,\"708\":-1,\"709\":-1,\"710\":-1,\"711\":-1,\"712\":-1,\"713\":-1,\"714\":-1,\"715\":-1,\"716\":-1,\"717\":-1,\"718\":-1,\"719\":-1,\"720\":-1,\"721\":-1,\"722\":-1,\"723\":-1,\"724\":-1,\"725\":-1,\"726\":-1,\"727\":-1,\"728\":-1,\"729\":-1,\"730\":-1,\"731\":-1,\"732\":-1,\"733\":-1,\"734\":-1,\"735\":-1,\"736\":-1,\"737\":-1,\"738\":-1,\"739\":-1,\"740\":-1,\"741\":-1,\"742\":-1,\"743\":-1,\"744\":-1,\"745\":-1,\"746\":-1,\"747\":-1,\"748\":-1,\"749\":-1,\"750\":-1,\"751\":-1,\"752\":-1,\"753\":-1,\"754\":-1,\"755\":-1,\"756\":-1,\"757\":-1,\"758\":-1,\"759\":-1,\"760\":-1,\"761\":-1,\"762\":-1,\"763\":-1,\"764\":-1,\"765\":-1,\"766\":-1,\"767\":-1,\"768\":-1,\"769\":-1,\"770\":-1,\"771\":-1,\"772\":-1,\"773\":-1,\"774\":-1,\"775\":-1,\"776\":-1,\"777\":-1,\"778\":-1,\"779\":-1,\"780\":-1,\"781\":-1,\"782\":-1,\"783\":-1,\"784\":-1,\"785\":-1,\"786\":-1,\"787\":-1,\"788\":-1,\"789\":-1,\"790\":-1,\"791\":-1,\"792\":-1,\"793\":-1},\"Experimental Results\":{\"0\":-1,\"1\":-1,\"2\":-1,\"3\":-1,\"4\":-1,\"5\":-1,\"6\":-1,\"7\":-1,\"8\":-1,\"9\":-1,\"10\":-1,\"11\":-1,\"12\":-1,\"13\":-1,\"14\":-1,\"15\":-1,\"16\":-1,\"17\":-1,\"18\":-1,\"19\":-1,\"20\":-1,\"21\":-1,\"22\":-1,\"23\":-1,\"24\":-1,\"25\":-1,\"26\":-1,\"27\":-1,\"28\":-1,\"29\":-1,\"30\":-1,\"31\":-1,\"32\":-1,\"33\":-1,\"34\":-1,\"35\":-1,\"36\":-1,\"37\":-1,\"38\":-1,\"39\":-1,\"40\":-1,\"41\":-1,\"42\":-1,\"43\":-1,\"44\":-1,\"45\":-1,\"46\":-1,\"47\":-1,\"48\":-1,\"49\":-1,\"50\":-1,\"51\":-1,\"52\":-1,\"53\":-1,\"54\":-1,\"55\":-1,\"56\":-1,\"57\":-1,\"58\":-1,\"59\":-1,\"60\":-1,\"61\":-1,\"62\":-1,\"63\":-1,\"64\":-1,\"65\":-1,\"66\":-1,\"67\":-1,\"68\":-1,\"69\":-1,\"70\":-1,\"71\":-1,\"72\":-1,\"73\":-1,\"74\":-1,\"75\":-1,\"76\":-1,\"77\":-1,\"78\":-1,\"79\":-1,\"80\":-1,\"81\":-1,\"82\":-1,\"83\":-1,\"84\":-1,\"85\":-1,\"86\":-1,\"87\":-1,\"88\":-1,\"89\":-1,\"90\":-1,\"91\":-1,\"92\":-1,\"93\":-1,\"94\":-1,\"95\":-1,\"96\":-1,\"97\":-1,\"98\":-1,\"99\":-1,\"100\":-1,\"101\":-1,\"102\":-1,\"103\":-1,\"104\":-1,\"105\":-1,\"106\":-1,\"107\":-1,\"108\":-1,\"109\":-1,\"110\":-1,\"111\":-1,\"112\":-1,\"113\":-1,\"114\":-1,\"115\":-1,\"116\":-1,\"117\":-1,\"118\":-1,\"119\":-1,\"120\":-1,\"121\":-1,\"122\":-1,\"123\":-1,\"124\":-1,\"125\":-1,\"126\":-1,\"127\":-1,\"128\":-1,\"129\":-1,\"130\":-1,\"131\":-1,\"132\":-1,\"133\":-1,\"134\":-1,\"135\":-1,\"136\":-1,\"137\":-1,\"138\":-1,\"139\":-1,\"140\":-1,\"141\":-1,\"142\":-1,\"143\":-1,\"144\":-1,\"145\":-1,\"146\":-1,\"147\":-1,\"148\":-1,\"149\":-1,\"150\":-1,\"151\":-1,\"152\":-1,\"153\":-1,\"154\":-1,\"155\":-1,\"156\":-1,\"157\":-1,\"158\":-1,\"159\":-1,\"160\":-1,\"161\":-1,\"162\":-1,\"163\":-1,\"164\":-1,\"165\":-1,\"166\":-1,\"167\":-1,\"168\":-1,\"169\":-1,\"170\":-1,\"171\":-1,\"172\":-1,\"173\":-1,\"174\":-1,\"175\":-1,\"176\":-1,\"177\":-1,\"178\":-1,\"179\":-1,\"180\":-1,\"181\":-1,\"182\":-1,\"183\":-1,\"184\":-1,\"185\":-1,\"186\":-1,\"187\":-1,\"188\":-1,\"189\":-1,\"190\":-1,\"191\":-1,\"192\":-1,\"193\":-1,\"194\":-1,\"195\":-1,\"196\":-1,\"197\":-1,\"198\":-1,\"199\":-1,\"200\":-1,\"201\":-1,\"202\":-1,\"203\":-1,\"204\":-1,\"205\":-1,\"206\":-1,\"207\":-1,\"208\":-1,\"209\":-1,\"210\":-1,\"211\":-1,\"212\":-1,\"213\":-1,\"214\":-1,\"215\":-1,\"216\":-1,\"217\":-1,\"218\":-1,\"219\":-1,\"220\":-1,\"221\":-1,\"222\":-1,\"223\":-1,\"224\":-1,\"225\":-1,\"226\":-1,\"227\":-1,\"228\":-1,\"229\":-1,\"230\":-1,\"231\":-1,\"232\":-1,\"233\":-1,\"234\":-1,\"235\":-1,\"236\":-1,\"237\":-1,\"238\":-1,\"239\":-1,\"240\":-1,\"241\":-1,\"242\":-1,\"243\":-1,\"244\":-1,\"245\":-1,\"246\":-1,\"247\":-1,\"248\":-1,\"249\":-1,\"250\":-1,\"251\":-1,\"252\":-1,\"253\":-1,\"254\":-1,\"255\":-1,\"256\":-1,\"257\":-1,\"258\":-1,\"259\":-1,\"260\":-1,\"261\":-1,\"262\":-1,\"263\":-1,\"264\":-1,\"265\":-1,\"266\":-1,\"267\":-1,\"268\":-1,\"269\":-1,\"270\":-1,\"271\":-1,\"272\":-1,\"273\":-1,\"274\":-1,\"275\":-1,\"276\":-1,\"277\":-1,\"278\":-1,\"279\":-1,\"280\":-1,\"281\":-1,\"282\":-1,\"283\":-1,\"284\":-1,\"285\":-1,\"286\":-1,\"287\":-1,\"288\":-1,\"289\":-1,\"290\":-1,\"291\":-1,\"292\":-1,\"293\":-1,\"294\":-1,\"295\":-1,\"296\":-1,\"297\":-1,\"298\":-1,\"299\":-1,\"300\":-1,\"301\":-1,\"302\":-1,\"303\":-1,\"304\":-1,\"305\":-1,\"306\":-1,\"307\":-1,\"308\":-1,\"309\":-1,\"310\":-1,\"311\":-1,\"312\":-1,\"313\":-1,\"314\":-1,\"315\":-1,\"316\":-1,\"317\":-1,\"318\":-1,\"319\":-1,\"320\":-1,\"321\":-1,\"322\":-1,\"323\":-1,\"324\":-1,\"325\":-1,\"326\":-1,\"327\":-1,\"328\":-1,\"329\":-1,\"330\":-1,\"331\":-1,\"332\":-1,\"333\":-1,\"334\":-1,\"335\":-1,\"336\":-1,\"337\":-1,\"338\":-1,\"339\":-1,\"340\":-1,\"341\":-1,\"342\":-1,\"343\":-1,\"344\":-1,\"345\":-1,\"346\":-1,\"347\":-1,\"348\":-1,\"349\":-1,\"350\":-1,\"351\":-1,\"352\":-1,\"353\":-1,\"354\":-1,\"355\":-1,\"356\":-1,\"357\":-1,\"358\":-1,\"359\":-1,\"360\":-1,\"361\":-1,\"362\":-1,\"363\":-1,\"364\":-1,\"365\":-1,\"366\":-1,\"367\":-1,\"368\":-1,\"369\":-1,\"370\":-1,\"371\":-1,\"372\":-1,\"373\":-1,\"374\":-1,\"375\":-1,\"376\":-1,\"377\":-1,\"378\":-1,\"379\":-1,\"380\":-1,\"381\":-1,\"382\":-1,\"383\":-1,\"384\":-1,\"385\":-1,\"386\":-1,\"387\":-1,\"388\":-1,\"389\":-1,\"390\":-1,\"391\":-1,\"392\":-1,\"393\":-1,\"394\":-1,\"395\":-1,\"396\":-1,\"397\":-1,\"398\":-1,\"399\":-1,\"400\":-1,\"401\":-1,\"402\":-1,\"403\":-1,\"404\":-1,\"405\":-1,\"406\":-1,\"407\":-1,\"408\":-1,\"409\":-1,\"410\":-1,\"411\":-1,\"412\":-1,\"413\":-1,\"414\":-1,\"415\":-1,\"416\":-1,\"417\":-1,\"418\":-1,\"419\":-1,\"420\":-1,\"421\":-1,\"422\":-1,\"423\":-1,\"424\":-1,\"425\":-1,\"426\":-1,\"427\":-1,\"428\":-1,\"429\":-1,\"430\":-1,\"431\":-1,\"432\":-1,\"433\":-1,\"434\":-1,\"435\":-1,\"436\":-1,\"437\":-1,\"438\":-1,\"439\":-1,\"440\":-1,\"441\":-1,\"442\":-1,\"443\":-1,\"444\":-1,\"445\":-1,\"446\":-1,\"447\":-1,\"448\":-1,\"449\":-1,\"450\":-1,\"451\":-1,\"452\":-1,\"453\":-1,\"454\":-1,\"455\":-1,\"456\":-1,\"457\":-1,\"458\":-1,\"459\":-1,\"460\":-1,\"461\":-1,\"462\":-1,\"463\":-1,\"464\":-1,\"465\":-1,\"466\":-1,\"467\":-1,\"468\":-1,\"469\":-1,\"470\":-1,\"471\":-1,\"472\":-1,\"473\":-1,\"474\":-1,\"475\":-1,\"476\":-1,\"477\":-1,\"478\":-1,\"479\":-1,\"480\":-1,\"481\":-1,\"482\":-1,\"483\":-1,\"484\":-1,\"485\":-1,\"486\":-1,\"487\":-1,\"488\":-1,\"489\":-1,\"490\":-1,\"491\":-1,\"492\":-1,\"493\":-1,\"494\":-1,\"495\":-1,\"496\":-1,\"497\":-1,\"498\":-1,\"499\":-1,\"500\":-1,\"501\":-1,\"502\":-1,\"503\":-1,\"504\":-1,\"505\":-1,\"506\":-1,\"507\":-1,\"508\":-1,\"509\":-1,\"510\":-1,\"511\":-1,\"512\":-1,\"513\":-1,\"514\":-1,\"515\":-1,\"516\":-1,\"517\":-1,\"518\":-1,\"519\":-1,\"520\":-1,\"521\":-1,\"522\":-1,\"523\":-1,\"524\":-1,\"525\":-1,\"526\":-1,\"527\":-1,\"528\":-1,\"529\":-1,\"530\":-1,\"531\":-1,\"532\":-1,\"533\":-1,\"534\":-1,\"535\":-1,\"536\":-1,\"537\":-1,\"538\":-1,\"539\":-1,\"540\":-1,\"541\":-1,\"542\":-1,\"543\":-1,\"544\":-1,\"545\":-1,\"546\":-1,\"547\":-1,\"548\":-1,\"549\":-1,\"550\":-1,\"551\":-1,\"552\":-1,\"553\":-1,\"554\":-1,\"555\":-1,\"556\":-1,\"557\":-1,\"558\":-1,\"559\":-1,\"560\":-1,\"561\":-1,\"562\":-1,\"563\":-1,\"564\":-1,\"565\":-1,\"566\":-1,\"567\":-1,\"568\":-1,\"569\":-1,\"570\":-1,\"571\":-1,\"572\":-1,\"573\":-1,\"574\":-1,\"575\":-1,\"576\":-1,\"577\":-1,\"578\":-1,\"579\":-1,\"580\":-1,\"581\":-1,\"582\":-1,\"583\":-1,\"584\":-1,\"585\":-1,\"586\":-1,\"587\":-1,\"588\":-1,\"589\":-1,\"590\":-1,\"591\":-1,\"592\":-1,\"593\":-1,\"594\":-1,\"595\":-1,\"596\":-1,\"597\":-1,\"598\":-1,\"599\":-1,\"600\":-1,\"601\":-1,\"602\":-1,\"603\":-1,\"604\":-1,\"605\":-1,\"606\":-1,\"607\":-1,\"608\":-1,\"609\":-1,\"610\":-1,\"611\":-1,\"612\":-1,\"613\":-1,\"614\":-1,\"615\":-1,\"616\":-1,\"617\":-1,\"618\":-1,\"619\":-1,\"620\":-1,\"621\":-1,\"622\":-1,\"623\":-1,\"624\":-1,\"625\":-1,\"626\":-1,\"627\":-1,\"628\":-1,\"629\":-1,\"630\":-1,\"631\":-1,\"632\":-1,\"633\":-1,\"634\":-1,\"635\":-1,\"636\":-1,\"637\":-1,\"638\":-1,\"639\":-1,\"640\":-1,\"641\":-1,\"642\":-1,\"643\":-1,\"644\":-1,\"645\":-1,\"646\":-1,\"647\":-1,\"648\":-1,\"649\":-1,\"650\":-1,\"651\":-1,\"652\":-1,\"653\":-1,\"654\":-1,\"655\":-1,\"656\":-1,\"657\":-1,\"658\":-1,\"659\":-1,\"660\":-1,\"661\":-1,\"662\":-1,\"663\":-1,\"664\":-1,\"665\":-1,\"666\":-1,\"667\":-1,\"668\":-1,\"669\":-1,\"670\":-1,\"671\":-1,\"672\":-1,\"673\":-1,\"674\":-1,\"675\":-1,\"676\":-1,\"677\":-1,\"678\":-1,\"679\":-1,\"680\":-1,\"681\":-1,\"682\":-1,\"683\":-1,\"684\":-1,\"685\":-1,\"686\":-1,\"687\":-1,\"688\":-1,\"689\":-1,\"690\":-1,\"691\":-1,\"692\":-1,\"693\":-1,\"694\":-1,\"695\":-1,\"696\":-1,\"697\":-1,\"698\":-1,\"699\":-1,\"700\":-1,\"701\":-1,\"702\":-1,\"703\":-1,\"704\":-1,\"705\":-1,\"706\":-1,\"707\":-1,\"708\":-1,\"709\":-1,\"710\":-1,\"711\":-1,\"712\":-1,\"713\":-1,\"714\":-1,\"715\":-1,\"716\":-1,\"717\":-1,\"718\":-1,\"719\":-1,\"720\":-1,\"721\":-1,\"722\":-1,\"723\":-1,\"724\":-1,\"725\":-1,\"726\":-1,\"727\":-1,\"728\":-1,\"729\":-1,\"730\":-1,\"731\":-1,\"732\":-1,\"733\":-1,\"734\":-1,\"735\":-1,\"736\":-1,\"737\":-1,\"738\":-1,\"739\":-1,\"740\":-1,\"741\":-1,\"742\":-1,\"743\":-1,\"744\":-1,\"745\":-1,\"746\":-1,\"747\":-1,\"748\":-1,\"749\":-1,\"750\":-1,\"751\":-1,\"752\":-1,\"753\":-1,\"754\":-1,\"755\":-1,\"756\":-1,\"757\":-1,\"758\":-1,\"759\":-1,\"760\":-1,\"761\":-1,\"762\":-1,\"763\":-1,\"764\":-1,\"765\":-1,\"766\":-1,\"767\":-1,\"768\":-1,\"769\":-1,\"770\":-1,\"771\":-1,\"772\":-1,\"773\":-1,\"774\":-1,\"775\":-1,\"776\":-1,\"777\":-1,\"778\":-1,\"779\":-1,\"780\":-1,\"781\":-1,\"782\":-1,\"783\":-1,\"784\":-1,\"785\":-1,\"786\":-1,\"787\":-1,\"788\":-1,\"789\":-1,\"790\":-1,\"791\":-1,\"792\":-1,\"793\":-1},\"Code Link\":{\"0\":null,\"1\":null,\"2\":null,\"3\":\"'At the input unit, an optical position encoder (Heidenhain ECI 119 with 19 bits resolution) is placed between the output shaft and the input frame to monitor the deflection. One cross-roller bearing (THK RA11008UU) is put between the input frame and the principle driven motor. This bearing is also the only one in the overall VSA system with the advantages analyzed in Section II B. The principle driving motor and the stiffness variation motor are connected in serial. Although the stiffness variation motor needs to be carried by the driven motor, the weight is as low as just 72g. Such a design can allow the output position and stiffness to be controlled independently.'\",\"4\":\"'For efficient interaction exepriments involving a human operator, we chose a rotary-type hydraulic actuator (KNR Intima-RH, double vane type, maximum torque of 400 Nm) with a 0.5m link load. Measurement devices are a pair of pressure sensors (Honeywell Model S, maximum pressure is 21 MPa) installed in each chamber of the actuator, a torque sensor (HBM TB2, maximum torque is 500 Nm) installed between the actuator and link load, and a high-resolution encoder (GPI R137, resolution: 230, 400 count\\/rev) for actuator angle measurements. Finally, a flow servovalve (Star hydraulics 200 series) is also used in the backdrivability test to compare the performance with a backdrivable servovalve.'\",\"5\":null,\"6\":null,\"7\":null,\"8\":null,\"9\":null,\"10\":\"\\\"In the next task, we apply the same walking gait to a \\u201cgap\\u201d crossing problem. In this scenario, HyQ has to reach a target point beyond a wide gap. This gap defines an area in which HyQ is not allowed to place its feet. This gap is encoded as a potential field and included as a state constraint. This constraint is only enforced at the end of each swing leg phase, i.e. at touchdown of the leg using the terminal cost of modes. As we can see from the motion sequence illustrated in Fig. 2, the optimization finds a gait which avoids stepping onto the gap. Since the gap is relatively wide compared to the robot's kinematic limits, HyQ yaws and crosses the gap in a slight diagonal configuration, visible in Fig. 3. This allows to use the hip degree of freedom for increased mobility. This behavior is probably not expected at first, but underlines the potential of our approach.\\\"\",\"11\":\"'https:\\/\\/bitbucket.org\\/castacks\\/kite_optimizer'\\n\\n'We have open-sourced a MATLAB implementation of\\\\n\\u03ba\\\\nITE at https:\\/\\/bitbucket.org\\/castacks\\/kite_optimizer. We compare\\\\n\\u03ba\\\\nITE against a baseline that uses constant-curvature arcs to turn, while trying to maintain as high a speed as possible without violating the roll limit.'\",\"12\":null,\"13\":\"'Intermediate steps of our edge segments extraction method. (b) Shows the dirmap (gradient directions). (c) Shows the edgemap. The color encodes the gradient direction (same as in dirmap). (d) Shows the final edge segment list. Each edge segment is drawn by a random color individually.'\",\"14\":null,\"15\":null,\"16\":null,\"17\":\"'Fig. 1 shows the general architecture of SE3-NETS. There are three major components: an encoder that generates a joint latent state given the input point cloud\\\\nX\\\\nand the control\\\\nu\\\\n, a decoder that predicts the object masks with the corresponding transforms and a final transformation layer that generates the transformed point cloud\\\\nY\\\\n.'\\n\\n'A. Encoder'\\n\\n'The encoder has two parts: a convolutional encoder which generates a latent state from the point cloud\\\\nX\\\\n(represented as a 3-channel image) and a fully connected network that encodes the control vector\\\\nu\\\\n. We adopt a late fusion architecture and concatenate the outputs of these two parts to produce the final encoding, which is used by the decoder for further predictions.'\\n\\n'B. Decoder'\\n\\n\\\"The decoder decomposes the motion prediction problem into two sub-problems: identifying and grouping together points that move together (we call this grouping an \\u201cobject\\u201d or a \\u201cmotion-class\\u201d) and subsequently predicting the SE(3) transformation parameters that quantify the object's motion.\\\"\\n\\n'Predicting motion masks: The mask decoder attends to parts of the scene that exhibit motion, grouping points that move together to form objects. As an example, all points belonging to a rigid object can be grouped together as they move with it. Presupposing that the scene has\\\\nk\\\\ndistinctly moving objects, we can formulate this as a k-class labeling problem where each input point can belong to one of the\\\\nk\\\\nmotion-classes. Unfortunately, this formulation is nondifferentiable due to the discreteness of the labeling. Instead, we relax it to allow each point to belong to multiple motion classes, quantified by a per-point probability distribution\\\\nM\\\\nj\\\\nover the\\\\nk\\\\nmotion-classes:'\\n\\n'SE3-net architecture. Input is a 3D point cloud and an n-dimensional action vector (bold-italics), both of which are encoded and concatenated to a joint feature vector (cat). The decoder uses this encoding to predict \\u201c\\\\nk\\\\n\\u201d object masks\\\\nM\\\\nand \\u201c\\\\nk\\\\n\\u201d SE(3) transforms which are used to transform the input cloud via the \\u201ctransform layer\\u201d to generate the output. Mask weights are sharpened and normalized before use for prediction. Conv = convolution, FC = fully connected, C. = deconvolution, CAT = concatenation'\\n\\n'The SE(3) decoder predicts\\\\nk\\\\nSE(3) transforms, one for each of the\\\\nk\\\\nmotion-classes (including background). We use a fully connected network to predict these transforms.'\",\"18\":null,\"19\":\"'Semantic segmentation is performed using a common encoder-decoder architecture (e.g. [3]) where the feature representation is progressively spatially compressed before being expanded to a full resolution per-pixel class prediction.'\\n\\n'For both datasets we built semantic classifier models using the standard SegNet convolutional encoder-decoder architecture. The same SegNet parameters were used for both datasets, with modifications only to account for the differences in input image resolution. We randomly split the input data into 75% training and 25% validation sets, performed training for 100 epochs then selected the best-performing model according to the validation set results.'\",\"20\":\"'http:\\/\\/www.poss.pku.edu.cn\\/'\",\"21\":null,\"22\":\"'https:\\/\\/youtu.be\\/o_NU23fpZhw?t=134'\",\"23\":null,\"24\":null,\"25\":\"'https:\\/\\/youtu.be\\/91UtZsriwn4'\",\"26\":null,\"27\":null,\"28\":\"'In this paper, we consider a networked multi-robot system operating in an obstacle populated planar workspace under a single leader-multiple followers architecture. We propose a decentralized reconfiguration strategy of the set of connectivity and formation specifications that assures convergence to the desired point, while guaranteeing global connectivity. In particular, we construct a low-level Decentralized Navigation Functions based controller that encodes the goals and safety requirements of the system. However, owing to topological obstructions, stable critical points other than the desired one may appear. In such case, we employ a high-level distributed discrete procedure which attempts to solve a Distributed Constraint Satisfaction Problem on a local Voronoi partition, providing the necessary reconfiguration for the system to progress towards its goal. Eventually, we show that the system either converges to the desired point or attains a tree configuration with respect to the formation topology, in which case the system switches to a novel controller based on the Prescribed Performance technique, that eventually guarantees convergence. Finally, a simulation study clarifies and verifies the approach.'\",\"29\":\"'https:\\/\\/youtu.be\\/LSiS_p3NGqE'\",\"30\":null,\"31\":\"\\\"Finding feasible, collision-free paths for multiagent systems can be challenging, particularly in non-communicating scenarios where each agent's intent (e.g. goal) is unobservable to the others. In particular, finding time efficient paths often requires anticipating interaction with neighboring agents, the process of which can be computationally prohibitive. This work presents a decentralized multiagent collision avoidance algorithm based on a novel application of deep reinforcement learning, which effectively offloads the online computation (for predicting interaction patterns) to an offline learning procedure. Specifically, the proposed approach develops a value network that encodes the estimated time to the goal given an agent's joint configuration (positions and velocities) with its neighbors. Use of the value network not only admits efficient (i.e., real-time implementable) queries for finding a collision-free velocity vector, but also considers the uncertainty in the other agents' motion. Simulation results show more than 26% improvement in paths quality (i.e., time to reach the goal) when compared with optimal reciprocal collision avoidance (ORCA), a state-of-the-art collision avoidance strategy.\\\"\\n\\n'The major difficulty in multiagent collision avoidance is that anticipating evolution of joint states (paths) is desirable but computationally prohibitive. This work seeks to address this issue through reinforcement learning-to offload the expensive online computation to an offline training procedure. Specifically, this work develops a computationally efficient (i.e., real-time implementable) interaction rule by learning a value function that implicitly encodes cooperative behaviors.'\\n\\n'Kinematics constraints need to be considered for operating physical robots. Yet, in many existing works, such constraints can be difficult to encode and might lead to a substantial increase in computational complexity [5], [12]. In contrast, it is straightforward to incorporate kinematic constraints in the RL framework. We impose rotational constraints,'\\n\\n'This work developed a decentralized multiagent collision avoidance algorithm based on a novel application of deep reinforcement learning. In particular, a pair of agents were simulated to navigate around each other to learn a value network that encodes the expected time to goal. The solution (value network) to the two-agent collision avoidance RL problem was generalized in a principled way to handle multiagent\\\\n(n>2)\\\\nscenarios. The proposed method was shown to be real-time implementable for a decentralized ten-agent system. Simulation results show more than 26% improvement in paths quality when compared with ORCA.'\",\"32\":\"'In a similar manner we can apply a matroid independence system to constrain our allocation in the communication domain as well. Notice again that cardinality constraints are generally not sufficient to encode constraints on communication topology. We assume that every requirement is associated with a spatial location\\\\nx\\\\nr\\\\nk\\\\n\\u2208\\\\nR\\\\nd\\\\nfor each\\\\nr\\\\nk\\\\n\\u2208R\\\\n. Thus when robot\\\\ni\\\\nis allocated to a requirement, the robot is also implicitly assigned a spatial location. Furthermore, we model the possible impact a functionality-requirement allocation may have on the communication capabilities of a robot\\\\ni\\\\n. By defining a fixed communication radius for each in triplet, denoted\\\\n\\u03c1\\\\n(i,\\\\nf\\\\nj\\\\n,\\\\nr\\\\nk\\\\n)\\\\n\\u2018 we capture cases where specific functionalities performed for requirements at varying locations in the environment can yield differing communication conditions. Given our proximity-limited model of communication (Section II-A), we can then map every allocation, i.e. a set of triplets\\\\n(i,\\\\nf\\\\nj\\\\n,\\\\nr\\\\nk\\\\n)\\\\n, to a communication graph\\\\nG\\\\nR\\\\nwith nodes representing each requirement for which an allocation has been made (at location\\\\nx\\\\nr\\\\nk\\\\n) and edges induced by the related communication radii. For clarity we provide in Fig. 2 an example of a requirement communication graph\\\\nG\\\\nR\\\\nfor a simple allocation in\\\\nR\\\\n2\\\\n.'\",\"33\":null,\"34\":null,\"35\":null,\"36\":\"\\\"Shared control is a key technology for various robotic applications in which a robotic system and a human operator are meant to collaborate efficiently. In order to achieve efficient task execution in shared control, it is essential to predict the desired behavior for a given situation or context in order to simplify the control task for the human operator. This prediction is obtained by exploiting Learning from Demonstration (LfD), which is a popular approach for transferring human skills to robots. We encode the demonstrated behavior as trajectory distributions and generalize the learned distributions to new situations. The goal of this paper is to present a shared control framework that uses learned expert distributions to gain more autonomy. Our approach controls the balance between the controller's autonomy and the human preference based on the distributions of the demonstrated trajectories. Moreover, the learned distributions are autonomously refined from collaborative task executions, resulting in a master-slave system with increasing autonomy that requires less user input with an increasing number of task executions. We experimentally validated that our shared control approach enables efficient task executions. Moreover, the conducted experiments demonstrated that the developed system improves its performances through interactive task executions with our shared control.\\\"\",\"37\":\"'This work was supported in part by Siemens, the DARPA SIMPLEX program, an NSF CAREER Award, and an ONR Young Investigator Award. Aviv Tamar was partially funded by the Viterbi Scholarship, Technion. Tianhao Zhang was supported by a UC Berkeley EECS Departmental Fellowship. The authors thank Ramu Chandra, Karthik Kappaganthu, and Juan L. Aparicio for fruitful discussions, and Justin Fu for useful advice, and for sharing his adaptive MPC code.'\",\"38\":null,\"39\":null,\"40\":\"'http:\\/\\/robotics.citris-uc.org\\/'\",\"41\":null,\"42\":null,\"43\":null,\"44\":null,\"45\":null,\"46\":null,\"47\":null,\"48\":null,\"49\":null,\"50\":null,\"51\":null,\"52\":\"'https:\\/\\/www.youtube.com\\/watch?v=C6wWEdUcg3Y'\",\"53\":\"'After the experiments, subjects reported they had adopted different strategies during the experiments. One of them acknowledged having relied mainly on visual cues during both experiments (Subject 4) while another expressed his preference for vibrotactile feedback because it required less mental effort to decode the information. The other two subjects adopted a more selective approach, favoring one feedback modality over the other based on the cue intensity. One of them used visual cues when they were intense and evident but relied on the vibrations when in doubt. The other proceeded in a similar way but used vibrations as the main cue. The fact that subjects had to choose one type of feedback over the other highlights the challenges of achieving sensory integration of redundant information [21].'\",\"54\":null,\"55\":null,\"56\":null,\"57\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/29057142'\\n\\n\\\"The gait control algorithm is implemented on a myRIO 1900 microcontroller (National Instruments, Inc.), which has a dual-core ARM microprocessor and a Xilinx FPGA. To achieve different torque based rehabilitation control algorithms, several features from the user's gait cycle (e.g., gait phases and joint angles) are measured by the following sensors. The phase of gait, e.g., stance vs. swing, is detected with two force sensing resistors (FlexiForce A301, Tekscan, Inc.) embedded into a flexible insole, which is placed beneath the user's foot in their shoe. These two force sensors are placed along the normal path of the center of pressure, with one under the heel and the other under the ball of the foot. The insole is printed from a rubber-like polyjet photopolymer by a Connex 350 3D printer. Two magnetic incremental encoders (6400 CPR, LM13, Renishaw, Inc.), which are located at the output shaft of the actuator, measure the ankle and knee angles. The components and I\\/O channels of the high-level gait control system are integrated through a custom Printed Circuit Board (PCB).\\\"\",\"58\":\"'Position data are obtained from the servo drives (AKD-01206 and AKD-00606, Kollmorgen, VA), which are used to control the servomotors. Encoders are attached to the motors and an analog voltage proportional to the position of the motor is transmitted to the DAC. The analog voltage is scaled such that 1 volt corresponds to 1-degree change in position. The force plate attached to the platform consists of 4 load cells at the 4 corners of the plate. The signals from the load cells are processed and transmitted as 8 channel analog signals. The first 4 signals transmit analog voltage proportional to the normal force acting on each of the load cells, while the next 4 signals transmit analog voltage proportional to the shear force acting along the 4 edges of the top face of the force plate.'\\n\\n'The position controller was implemented to provide accurate position perturbations to the ankle, which were used to evaluate postural stability and characterize impedance and reflex properties of the ankle in 2 DOFs. The controller generates analog voltage proportional to the reference input for each actuator and transmits it to the servo drive of the corresponding actuator. The drives have position, velocity and current feedback control loops with reference feed forward, which are tuned using the Kollmorgen WorkBench software. The velocity and acceleration limits for each of the motors are adjusted based on the required platform response. The feedback for the control loops is obtained from encoders attached to the servomotors. The reference for the DP actuator is set at 7281 counts\\/v and IE actuator is set at 4551 counts\\/v, which corresponds to 1 \\u00b0\\/v in the final platform. The controller was implemented on the target machine and data was collected from the force plate at 2 kHz.'\",\"59\":\"'Fig. 11 shows averaged trajectories of the hip and knee joints. Trajectories for the hip is at the top whereas trajectories for the knee are shown at the bottom. Each figures contains a desired joint trajectory, an estimated joint trajectory, and an actual joint trajectory. The estimated trajectories are calculated using position measurement at the motors and the actual trajectories are measured using the absolute encoders installed at the joints. The tracking error of the PD controller results in the differences between the desired and estimated trajectories. Additional error to the actual trajectories exists due to compliances at the harmonic gears and cable differential mechanism.'\",\"60\":null,\"61\":null,\"62\":null,\"63\":null,\"64\":\"'https:\\/\\/www.youtube.com\\/playlist?list=PLCv90iHF1jI3-VuVpUczGrNwvQOru3coZ'\\n\\n'Overview of the CoSTAR system. Symbols and predicates are produced by components such as perception, arm, and gripper, and are aggregated by predicator. The behavior tree unifies this information and uses it to encode a task, calling operations exposed by each of the individual components. Individual components can be modified or extended to add new capabilities, but the behavior tree only acts on abstracted information and operations directly.'\\n\\n'Our contributions are: (1) a modular, cross-platform system designed to emphasize capability, usability, and robustness; (2) abstract perception that exposes symbols and predicates that can be used for authoring task plans; (3) evaluation of the system on a series of increasingly complex tasks; and (4) an open source implementation on a KUKA LBR iiwa 14 R820 and a Universal Robots UR5, each with different grippers.'\",\"65\":null,\"66\":null,\"67\":null,\"68\":null,\"69\":null,\"70\":null,\"71\":\"'Transition of finger joint angles while the hand tries grasp a hand drill. Some data points jump from the reasonable trajectory due to encoder read failure. The four graphs show data of the four fingers. Three lines in each graph shows angles of MP, PIP, and DIP joint, which are under-actuated by a single tendon.'\",\"72\":null,\"73\":\"'http:\\/\\/rll.berkeley.edu\\/drl_tensegrity'\\n\\n\\\"Tensegrity robots, composed of rigid rods connected by elastic cables, have a number of unique properties that make them appealing for use as planetary exploration rovers. However, control of tensegrity robots remains a difficult problem due to their unusual structures and complex dynamics. In this work, we show how locomotion gaits can be learned automatically using a novel extension of mirror descent guided policy search (MDGPS) applied to periodic locomotion movements, and we demonstrate the effectiveness of our approach on tensegrity robot locomotion. We evaluate our method with real-world and simulated experiments on the SUPERball tensegrity robot, showing that the learned policies generalize to changes in system parameters, unreliable sensor measurements, and variation in environmental conditions, including varied terrains and a range of different gravities. Our experiments demonstrate that our method not only learns fast, power-efficient feedback policies for rolling gaits, but that these policies can succeed with only the limited onboard sensing provided by SUPERball's accelerometers. We compare the learned feedback policies to learned open-loop policies and hand-engineered controllers, and demonstrate that the learned policy enables the first continuous, reliable locomotion gait for the real SUPERball robot. Our code and supplementary material is available from http:\\/\\/rll.berkeley.edu\\/drl_tensegrity.\\\"\\n\\n'The superball tensegrity robot. This robot is composed of six identical rods and 24 cables, 12 of which can be actuated using the motors connected to the ends of each rod. This work uses the onboard imus and motor encoders on each of the end caps.'\\n\\n'One of the challenges with automated policy learning is that all requirements for the policy are generally encoded in the cost function, including task-level objectives such as desired rolling direction and hard constraints such as safety. Due to the structure of tensegrity systems, unsafe actuation of the motors can place the robot into configurations with unacceptable risk of cable or motor failure. The configurations associated with such high-tension conditions are difficult to encode analytically and even more difficult to balance against primary task objectives in the cost function. We therefore adopt a simple safety constraint approach to enable safe learning and policy execution on the SUPERball hardware. This approach is challenging to use with hand-engineered policies, which often exploit unsafe but effective actions to quickly yield a locomotion gait. However, the approach is much easier to adopt with learned policies, as it naturally embeds itself into the training procedure.'\\n\\n'By separating this safety constraint from the cost function, we avoid the need to tune the parameters of the cost function to weigh the opposing objectives of speed and hardware safety. Furthermore, we encode safety as a hard constraint using this method, and we directly prevent unsafe actions rather than just penalizing them. Utilizing these kinematic constraints is extremely helpful in transferring policies learned in simulation directly onto the real robot. In simulation, the physical limits are less restrictive, and going beyond the safe limits does not have any adverse effects, so it is possible to train a policy that exploits these inaccuracies in order to succeed. We can make sure this does not happen by enforcing stronger constraints on what actions the policy can output, and it is more likely that the policy trained with these constraints in simulation will not fail on the real robot, or even worse, cause damage and hardware problems.'\\n\\n\\\"We encode the state of the system\\\\nx\\\\nt\\\\nas the position and velocity of each of the 12 bar endpoints of SUPERball, and the position and velocity of each of the 12 motors, measured in radians, for a total dimensionality of 96. We experimented with two different representations for the observation\\\\no\\\\nt\\\\n. The \\u201cfull\\u201d 36-dimensional observation includes motor positions, and also uses elevation and rotation angles and angular velocities calculated from the robot's accelerometers and magnetometers. The \\u201climited\\u201d observation is 12-dimensional and only uses the acceleration measurement along the bar axis from each of the accelerometers. We found that interfering magnetic fields near the testing grounds at NASA Ames cause the magnetometers to be unreliable and difficult to calibrate, and because of this, the policy using the limited observation is much easier to transfer on to the real robot. The action\\\\nu\\\\nt\\\\nis the instantaneous desired position of each motor, which may not be reached if the position is far away.\\\"\\n\\n'The SUPERball simulation that we use is built off of the NTRT open-source project. Aside from speed and efficiency benefits, the simulation also allows us to systematically and easily vary the parameters of the robot and environment.'\",\"74\":\"'Simulation results for obstacle-free situation with different observation models. The information is color-coded. Lighter means less noisy observations. The dashed green line represents the initial trajectory; the solid yellow line shows the optimized trajectory. In all cases,\\\\nx\\\\n^\\\\n0\\\\n=(0,0,0),\\\\nx\\\\ng\\\\n=(2,2,2)\\\\n, and\\\\nr\\\\ng\\\\n=0.1\\\\n.'\",\"75\":\"'All controllers were coded in C++03 Stl language and compiled using Visual C++ 10.0 compiler. They were run on an Intel i7-5600U CPU.'\",\"76\":null,\"77\":null,\"78\":null,\"79\":\"'Algorithm 1: Pseudo-Code for Diffusion Wavelet Tree'\\n\\n'Algorithm 2: Pseudo-Code for Global Planning'\\n\\n'Algorithm 3: Pseudo-Code for Local Planning'\",\"80\":\"'Algorithm 2 lists pseudocode for the forward pass. During the forward pass, we ensure that the updated nominal trajectory remains feasible and continues to reduce the objective function. Although the approximated value function from the backward pass takes into account the estimated active constraints, it cannot guarantee that directly using the linear feedback to update the nominal trajectory will result in a feasible trajectory. Consequently, we fully solve a QP (line 12\\u201316) that takes into account all the constraints to guarantee the updated nominal trajectory is feasible:'\",\"81\":\"'https:\\/\\/youtu.be\\/GFgMdswWHAA'\",\"82\":null,\"83\":\"'We present an approach for reconstructing vehicles from a single (RGB) image, in the context of autonomous driving. Though the problem appears to be ill-posed, we demonstrate that prior knowledge about how 3D shapes of vehicles project to an image can be used to reason about the reverse process, i.e., how shapes (back-)project from 2D to 3D. We encode this knowledge in shape priors, which are learnt over a small keypoint-annotated dataset. We then formulate a shape-aware adjustment problem that uses the learnt shape priors to recover the 3D pose and shape of a query object from an image. For shape representation and inference, we leverage recent successes of Convolutional Neural Networks (CNNs) for the task of object and keypoint localization, and train a novel cascaded fully-convolutional architecture to localize vehicle keypoints in images. The shape-aware adjustment then robustly recovers shape (3D locations of the detected keypoints) while simultaneously filling in occluded keypoints. To tackle estimation errors incurred due to erroneously detected keypoints, we use an Iteratively Re-weighted Least Squares (IRLS) scheme for robust optimization, and as a by-product characterize noise models for each predicted keypoint. We evaluate our approach on autonomous driving benchmarks, and present superior results to existing monocular, as well as stereo approaches.'\\n\\n'The first term encourages all four points on the face (four points, since we assume a quad mesh) to be planar, while the second term encodes the constraint that the normals must be of unit magnitude. Wherever applicable, we also constrain the normals so that they are parallel to the ground plane normal. Furthermore, it is not enough if certain points are planar; they must also be rectangular. These requirements are imposed as further constraints.'\",\"84\":\"'http:\\/\\/www.subsea-tech.com.pierre.marty\\/subsea-tech.com'\",\"85\":\"'Effectiveness of the proposed robustifying methods is verified using two distinct datasets where the first one is used in many related works and the second one is generated by ourselves using tools for our outdoor robot for land moving and snow clearance. Our dataset, ground truth and code will be made publicly available.'\",\"86\":\"'https:\\/\\/github.com\\/umautobots\\/driving-in-the-matrix'\\n\\n\\\"Deep learning has rapidly transformed the state of the art algorithms used to address a variety of problems in computer vision and robotics. These breakthroughs have relied upon massive amounts of human annotated training data. This time consuming process has begun impeding the progress of these deep learning efforts. This paper describes a method to incorporate photo-realistic computer images from a simulation engine to rapidly generate annotated data that can be used for the training of machine learning algorithms. We demonstrate that a state of the art architecture, which is trained only using these synthetic annotations, performs better than the identical architecture trained on human annotated real-world data, when tested on the KITTI data set for vehicle detection. By training machine learning algorithms on a rich virtual world, real objects in real scenes can be learned and classified using synthetic data. This approach offers the possibility of accelerating deep learning's application to sensor-based classification problems like those that appear in self-driving cars. The source code and data to train and validate the networks described in this paper are made available for researchers.\\\"\\n\\n\\\"Screen shots are captured by \\u201chooking\\u201d into Direct3D 11's present callback. A process by which the native call is replaced with custom code which operates and then returns to the native call. In our custom code, we copy the graphics card's buffers. Specifically the depth and stencil data are captured by hooking into Direct3D's ID3D ll ImmediateContext:: ClearDepthStencilView and saving the buffers before each call. Because of optimizations applied by the graphics card drivers, we \\u201crehook\\u201d the clear function each frame. When saving each sample the managed plugin requests all current buffers from the native plugin and the buffers are downloaded from the GPU and copied into managed memory. Buffers are saved in tiff format to zip archives and uploaded to a cloud server.\\\"\\n\\n'https:\\/\\/github.com\\/umautobots\\/driving-in-the-matrix'\",\"87\":\"'Position. Relative position of organs and instruments is an important visual cue. We encode the position of SURF-detected keypoints with an 8\\u00d78 grid sampling of a Gaussian surface centered around the keypoint (Fig. 3a). The variance of the Gaussian defines the spatial \\u201carea of influence\\u201d of a keypoint.'\\n\\n'Shape. Shape is important for detecting instruments, which are some of most obvious visual cues for identifying the phase. Shape can be encoded with various techniques, such as the Viola-Jones object detection framework [1], using image segmentation to isolate the instruments and match against artificial 3D models [28], and other methods. For local frame descriptors we use the standard SURF descriptor as a base, and for global frame descriptor we add grid-sampled HOG descriptors [1] and DCT coefficients [1].'\",\"88\":null,\"89\":null,\"90\":\"'https:\\/\\/youtu.be\\/dO77ZYEFHIE'\",\"91\":\"'https:\\/\\/youtu.be\\/yxILvUCjZ5c'\",\"92\":null,\"93\":\"'The first set of constraints imply that each task can be done by exactly one robot. The second set of constraints encode the fact that each robot can perform exactly one task. We will call the constraints in the LAP as the linear assignment constraints.'\",\"94\":null,\"95\":null,\"96\":null,\"97\":null,\"98\":null,\"99\":\"'https:\\/\\/youtu.be\\/8gXP4O-NQGw'\",\"100\":null,\"101\":\"'https:\\/\\/youtu.be\\/xxysamdhn38'\",\"102\":\"'https:\\/\\/vimeo.com\\/182913540'\\n\\n'Our first contribution is to show how preferences can be efficiently encoded at the team behavior level using concurrent relational actions processes.'\",\"103\":null,\"104\":\"'All the code used in the present study is openly available at www.github.com\\/robotology\\/affordances.'\\n\\n'www.github.com\\/robotology\\/affordances'\",\"105\":null,\"106\":\"'https:\\/\\/bitbucket.org\\/sanjiban\\/matlab_learning_info_gain'\\n\\n'The authors thank Sankalp Arora for insightful discussions and open source code for exploration in MATLAB.'\\n\\n'Our implementation is open sourced for both MATLAB and C++ (https:\\/\\/bitbucket.org\\/sanjiban\\/matlab_learning_info_gain).'\",\"107\":\"'Although RL has favorable characteristics with respect to robotics, open problems persist for practical use scenarios. A fundamental problem involves the design of a reward function that encodes a task given to the robot. Typically, a reward function is specified by manual coding. The design of the reward function strongly affects learning performance of the robot. Therefore, the provision of an appropriate reward function is a cumbersome task for a designer. Extant research proposed potential solutions to the fore-mentioned problem by developing Inverse Reinforcement Learning (IRL) and Apprenticeship Learning (AL) [5]\\u2013[7]. RL learns policy based on a reward function. Conversely, IRL estimates a reward function based on observed demonstrations of experts in which the experts are assumed to know (nearly) optimal policy for the given task. The objective of an AL framework is to recover the policy of an expert. In order to recover the policy, an AL agent first estimates a reward function using IRL and then learns policy by using a forward RL procedure with the estimated reward function. AL has particularly useful properties for robotic control problem, and we consider an extremely useful advantage of using AL is its generalization capability.'\",\"108\":null,\"109\":null,\"110\":\"'http:\\/\\/people.csail.mit.edu\\/yuan_wz\\/hardnessdataset\\/'\",\"111\":null,\"112\":\"'http:\\/\\/limoman-project.blogspot.pt\\/p\\/material.html'\\n\\n'http:\\/\\/limoman-project.blogspot.pt\\/p\\/videos.html'\",\"113\":null,\"114\":null,\"115\":\"\\\"Demonstration of our FETCH-POMDP model correctly fetching item for user. Note the robot's understanding of implicit information between panels three and four. This reasoning is not hard-coded into our system, but emerges from the solution of our pomdp.\\\"\",\"116\":\"'From the HTM we derive the list of successors for each node and compute the total number of states and actions of the global POMDP. We then populate the matrices representing transitions, observation, and reward probabilities to encode the RM from Fig. 3, for each node as well as for node to node transitions. The topological operators introduced in Section III are accounted for when restricted models are linked together. For what concerns a sequential operator\\\\n(\\u2192\\\\nin Fig. 2), each \\u2018init\\u2019 state represents the final state of the previous model. Alternative operators\\\\n(\\u2228)\\\\nbranch out the POMDP in multiple paths with equal transition probability-the choice of the path will be dictated by their intrinsic costs or randomly in case of equal costs. Finally, it is always possible to convert a parallel operator\\\\n(\\u2225)\\\\ninto an alternative between paths containing the subtasks the operator is composed of, but in a differently ordered sequence.'\\n\\n'The framework has been released under the LGPLv2.1 open-source license, and it is freely accessible on GitHub3. Although the majority of the codebase is robot-independent, the control architecture is readily available for any Baxter robot. We test the proposed system in a proof-of-concept scenario in which the human and the robot are engaged in the joint construction of a stool. We define the problem as a sequence of 9 subtasks; this translates to a state space dimensionality of 28 (\\\\n9\\u00d73\\\\nstate for each restricted model, plus 1 final state), and an action space composed of 37 possible actions (\\\\n9\\u00d74\\\\n, where 4 is the number of possible actions described in Section III-B, plus a \\u2018wait\\u2019 action).'\",\"117\":null,\"118\":null,\"119\":null,\"120\":\"'The femur and tibia actuators are mirror images of each other, simplifying the design of the robot. Each joint is moved by a carbon fibre push-pull rod that connects the slide of the linear screw to an attachment point on the output side of the joint. This design limits the excursions of the femur and tibia joint angles, but still keeps them within the operational range required for the full range of desired body poses. The geometric configuration of the femur and tibia actuators, the joints, and the link lengths was designed to provide enough torque to enable the robot to stand up from a sitting configuration (with the body resting on the ground). We obtain significant mass reduction, while trading off between joint torque and joint speed. The femur and tibia joints have ASM PRDS27 absolute angle encoders [34] at the pivot points, providing sensing at a 50 Hz rate over a CAN bus system.'\\n\\n'Two CAN buses, one for control of the Maxon linear actuators and the other for reading the ASM absolute angle encoders.'\\n\\n'MAX waypoint following and 3D mapping in a wooded area. A 3D point cloud of the area traversed by MAX during one experiment is shown; it was generated using its dorsal 3D lidar mapper and the CSIRO CT-slam system. The trajectory followed by MAX is shown color-coded in time, with red being the start.'\",\"121\":null,\"122\":null,\"123\":null,\"124\":\"'Given that international building codes require door handles to be within 0.864m and 1.219m [23], the necessary condition on the robotic platform having sufficient actuator and\\/or body length to reach and fully disengage the lever-handle while in a static configuration 6 will often be infeasible for the Minitaur platform, which has maximum extension of only 1m. Thus, Minitaur is generally quasi-statically mismatched for the task of door opening, and must use dynamic work around methods. The specific door tested had a handle height of 1.13m, above the meter threshold for quasi-static mismatch on Minitaur. Thus, a dynamic door opening strategy is implemented on the Minitaur platform. A quick analysis of the necessary condition imposed on Minitaur for the dynamic work around shows that each leg in its full range of motion can supply 6.48J [24], and two legs jumping together provide 12.96J, more than enough energy to satisfy the minimum energy condition of 1 7 J for this particular door with handle-lever spring constant of 30.14 and a door spring constant of 0.'\",\"125\":\"'We encode the desired body velocity from the user by mapping it into a \\u2018default\\u2019 step duration and length. Additionally, the CoM trajectory should accelerate as little as possible during the phases. Note that this implicitly reduces the required joint torques. We evaluate the step duration and length in every locomotion phase\\\\ni\\\\nas follows:'\",\"126\":\"'For human being, the intensity of loud sounds is coded by the firing frequency of action potentials. The action potentials have a constant amplitude, and any change in sounds can only alter the firing frequency [16]. Therefore, the average amplitude of WPT coefficients in each node is calculated and used as an indicator of the firing frequency:'\",\"127\":null,\"128\":null,\"129\":null,\"130\":\"'A BeagleBone Black (BBB) micro-controller runs the three-level control architecture-including sensing and computation-on board the prosthetic. The low-level control of motor driving comes from two ELMO motion controllers (Gold Solo Whistle). The motion controllers are actively controlling the motion of the ankle and knee joints using feedback from two encoders at each joint and input from the BBB. An incremental encoder placed on the motor side of the joints and an absolute encoder placed on the joint output side can be used to measure any deflection of the torsion spring. User sensory feedback is provided to the device through an Inertial Measurement Unit (IMU) fixed to the knee adapter. Further environment sensing is gained from a 6-axis load cell in the foot. Two flex force sensors can also be mounted at the heel and toe of the foot to provide on-and-off ground contact feedback during more complex foot motion (e.g., multi-contact with heel strike and toe off). The whole system is powered through a 9-cell (33.3 V), 3900 mAh Li-Po battery (ThunderPower).'\\n\\n'For the preliminary testings, we neglect the effects of the torsional springs during the control and tracking. Only the incremental encoder is considered for each joint. Therefore, because of the compliant effect of the torsional springs between the joint and the motor, the tracking results, shown in Fig. 7, are not as good as the case of AMPRO1 [34], which used a rigid chain drive. More sophisticated SEA control will be a future research topic as an extension of this work. The torque profile of the ankle joint in Fig. 9 clearly indicates a foot push at the end of the stance phase, which is an essential character for natural multi-contact human walking. Note that, the foot push is also reported by the user, which is lacking during the fiat-foot style walking [34]. Therefore, we can conclude that AMPRO3 has achieved realistic human-like walking both kinematically and kinetically.'\",\"131\":\"'A: The 1-dof transmission system with associated sensors for characterizing force and position transparency. Optical encoders track input and output rotation as well as linear displacement of the needle. Force sensors measure the input torque and force experienced at the needle tip. B: Input knob for heightened tactile sensitivity.'\\n\\n'For system characterization of the second version of the system, we mounted a force\\/torque sensor (ATI Nano, ~3.1 mN resolution) between the input shaft and textured knob to measure input forces. We attached a second load cell (Honeywell FSG015WNPB, ~9.8 mN resolution) to a vertical plate, against which the needle is driven in order to record axial needle forces. Rotary optical encoders (5000 CPR with quadrature) tracked rotations at input and output shafts and a linear encoder (1000 counts\\/inch) tracked linear carriage motion. Figure 2 shows the experimental setup. Data were recorded with a custom C++ program and an Arduino Due, filtered using a third order zero-phase filter, and analyzed in MatLab. We manipulated the system under no-load conditions and with the needle guide pressed against a variety of springs.'\",\"132\":\"\\\"Given the capsule's estimated pose from either the initialization or the EKF, and whether the capsule is rotating with the applied field, the actuator dipole's pose is updated; pseudocode is given in Alg. I. If the capsule is not rotating with the field, the actuator's speed is slowed to 80 percent of the desired speed for two rotations to re-engage the capsule. If the capsule does not commence rotating with the field at this reduced speed, the actuator's speed is further decreased to 50 percent of the desired value. This was sufficient in our tested trajectories to always re-engage the capsule and begin forward motion. For more complex trajectories or in heterogeneous environments (e.g., intestines), additional steps may be required (e.g., using the uncertainty of the EKF's state estimate to re-localize if it is above a threshold).\\\"\\n\\n'Psuedocode to update the SAMM pose'\",\"133\":null,\"134\":\"'The decomposition based planning algorithm presented above has been implemented in a C++ program to generate mesh models for each component. The slicing software for conventional FDM is used to generate planar slices and tool paths according to the printing directions determined in our algorithm. G-code for AM can be generated from the planned paths and sent to the motion-control module of our system.'\",\"135\":null,\"136\":null,\"137\":\"'The search tree originates at the root motor and enumerates all possible structural designs between the root and the target motor. The visualization of physical designs represented by the search tree and its corresponding schematic representation are shown in (a) and (b) respectively. Each branch represents a different design that results in a particular target motor configuration (encoded by its leaf node, highlighted with red oval).'\\n\\n'We define a desirability cost that encodes user preferences regarding aesthetics and resource economy. The desirability of a design is measured in terms of the total number of modules used and the compactness of the resulting structure. A design that uses a lower number of modules may be more economical (and it is trivial to associate different costs to different types of modules). Similarly, a design that connects the root motor and target motor using an approximately straight structure might be more compact, and therefore more aesthetically pleasing. The desirability cost\\\\nD\\\\nof a branch in the search tree measures these two characteristics of its design, at its current node\\\\nN\\\\ni\\\\n.'\",\"138\":\"'Our decision to use PaintPots in SMORES-EP was driven by the tight space constraints inside the module. Absolute position sensing was necessary on all DoF. Optical track encoders were considered for the side wheels, but not enough space was available to fit multiple gray code tracks to measure tilt position. PaintPots proved to be a versatile, robust, and accurate solution.'\\n\\n'AprilTags are an open-source, inexpensive, marker-based motion capture system, requiring only a camera, paper tags, and open-source software [14]. Unlike many position measurement devices (like shaft encoders), they do not require mechanical fixturing: tracking two rigid bodies (PaintPot track and wiper) only requires attaching paper tags to each body. Mechanical fixturing is particularly difficult for SMORES-EP modules, which have five independently moving rigid bodies.'\",\"139\":null,\"140\":null,\"141\":\"'Control over the output stiffness, or more directly, the effective length of the torsional leaf-spring (20mm wide, 1mm thick full hard 301 stainless steel leaf) is realized by a Maxon ball-screw (10mm \\u00d7 2mm pitch) driven by a brushless DC motor (Maxon EC-i 50W) coupled to a back-drivable planetary gearbox (4.8:1 gear ratio). The active length of the spring is determined by a quadrature encoder. During the experiments, the supply current is measured. This current measurement is used to estimate the input forces required to change the length of the torsional leaf-spring. The spring is connected to the output shaft via a 2:1 gear reduction. The angular deflection of the output shaft is determined by a rotary encoder. Closed-loop motor position control is implemented using the signal provided by the motor encoder. The motor is driven by a Maxon ESCON 50V\\/5A 4-Q driver while the entire system is operated at 500Hz by a microcontroller.'\",\"142\":\"'CAD images of the prototype assembly: 1: Housing, 2: Flange attached to spring-camldamper-follower, 3: Leaf spring, 4: Damper slider, 5: Spring followers, 6: Damper cushions, 7: Damper cushion holder, 8: Spring pretension adjustment screw, 9: Damper pretension adjustment screw, 10: Deflection encoder magnetic ring (and its holder), 11: Deflection encoder magnetic board, 12: Output flange.'\",\"143\":null,\"144\":null,\"145\":null,\"146\":null,\"147\":null,\"148\":null,\"149\":null,\"150\":null,\"151\":\"'The discrete behavior encodes the sequence of labels visited by the state as it moves along its continuous trajectory. Specifically, the atomic propositions are evaluated only at the times when the label changes value. Thus, a trajectory\\\\nTraj(\\\\nx\\\\n0\\\\n, [0,T],u)\\\\nsatisfies an LTL specification\\\\n\\u03c6\\\\n, denoted as\\\\nTraj(\\\\nx\\\\n0\\\\n, [0,T],u)\\u22a8\\u03c6\\\\nif and only if its discrete behavior is in the language\\\\nL(\\\\nA\\\\n\\u03c6\\\\n)\\\\n.'\",\"152\":\"'Table 1: Object energy field methodology pseudocode'\\n\\n\\\"To generate the viable actuation space for each object, we took advantage of underactuated hands' mechanical adaptability. Each actuator's operating range was first discretized, and for each actuator, it was driven to each discretized value via position-control. The opposing actuator was then commanded to close via a constant torque, and the actuator encoder values were recorded after the object and hand elements were fully constrained. This exploration excluded cases where the hand ejected the object during grasp acquisition or where the hand configuration was visually identified as a non-caging. The object was reset to the middle of the hand workspace between each grasp acquisition test. This sparse sampling of points in the actuator space was then interpolated to produce the set of actuator inputs used in the workspace evaluation.\\\"\",\"153\":null,\"154\":\"'The first-level embeddings of images and sentences are close to the variational auto-encoder described in [19] using the following generative models:'\",\"155\":null,\"156\":null,\"157\":\"'http:\\/\\/k0b.de\\/bstld'\\n\\n'http:\\/\\/k0b.de\\/tld_icra'\",\"158\":\"'http:\\/\\/cs.unc.edu\\/~ammirato\\/active_vision_dataset_website\\/'\\n\\n'Our dataset covers a variety of scenes from office buildings and homes, often capturing more than one room. For example a kitchen, living room, and dining room may all be present in one scene. We capture a total of 9 unique scenes, but have a total of 17 scans since some scenes are scanned twice. Each scene has from 696-2, 412 images, for a total of 20, 916 images and 54, 247 bounding boxes. We use the Kinect v2 sensor and code from [29] for collection.'\",\"159\":\"'Robot warehouse automation has attracted significant interest in recent years, perhaps most visibly in the Amazon Picking Challenge (APC) [1]. A fully autonomous warehouse pick-and-place system requires robust vision that reliably recognizes and locates objects amid cluttered environments, self-occlusions, sensor noise, and a large variety of objects. In this paper we present an approach that leverages multiview RGB-D data and self-supervised, data-driven learning to overcome those difficulties. The approach was part of the MIT-Princeton Team system that took 3rd- and 4th-place in the stowing and picking tasks, respectively at APC 2016. In the proposed approach, we segment and label multiple views of a scene with a fully convolutional neural network, and then fit pre-scanned 3D object models to the resulting segmentation to get the 6D object pose. Training a deep neural network for segmentation typically requires a large amount of training data. We propose a self-supervised method to generate a large labeled dataset without tedious manual segmentation. We demonstrate that our system can reliably estimate the 6D pose of objects under a variety of scenarios. All code, data, and benchmarks are available at http:\\/\\/apc.cs.princeton.edu\\/'\\n\\n'All code, data, and benchmarks are publicly available [3].'\",\"160\":\"'http:\\/\\/winsty.net\\/cmtspl_roadseg.html'\",\"161\":\"'Additionally, those previous works only consider the use of single capacity vehicles and do not address the benefits and challenges of utilizing ridesharing. In ride sharing, multiple customers may share a ride in an MOD vehicle at the same time. Newly arrived passengers can be picked up before onboard passengers have been dropped off, allowing for more customers to be serviced with fewer vehicles. However, the reduced wait time for requested passengers comes at the expense of increased ride time of onboard passengers. With ridesharing, perceived QoS becomes dependent on customer preference (i.e. how much customers prefer one service metric over another). A large body of work has studied a form of ridesharing known as the Dial-A-Ride Problem (DARP), which is a specialization of the Vehicle Routing Problem formulated specifically for the transportation of customers. DARP problem formulations typically take either the form of an integer program or a scheduling problem. Integer program formulations encode each customer QoS metric as a decision variable and use heuristic methods such as genetic algorithms [11], simulated annealing [12], and tabu search [13] to minimize an objective, such as a cost function composed of a weighted sum of the metrics. Scheduling problem formulations enumerate the possible ways of inserting new passengers into vehicle schedules, and encode customer QoS metrics as feasibility constraints [14]\\u2013[16]. The main challenge with all of these approaches is that the weights or constraint thresholds that define customer preference may be chosen incorrectly and even the structure that encodes the QoS metrics could be wrong. In general determining customer preference can be difficult. However, many MOD systems such as Uber, Lyft, and the MIT MOD system are able to query passengers for feedback in the form of a 5-star rating using a ride request app, as shown in Figure 1 b. This work takes advantage of this available information through a ridesharing algorithm which does not encode customer preference directly, but rather utilizes a learned customer ratings model when solving the DARP scheduling problem.'\\n\\n'The primary benefit of the ridesharing algorithm is the ability to evaluate customer QoS without having to encode the customer preference structure into the algorithm. For example, other methods [14]\\u2013[16] encode feasibility constraints on customer metrics such as wait time or ride time, where customers are rejected if these are not met. Instead, a more general approach is taken in Algorithm 2 where a competing bid is made to reject a customer, and the rejection is made only when the overall QoS of the system would be improved by doing so. This approach opens the door for a ratings based cost function where bids are made without constraining the customer metrics directly.'\",\"162\":\"'We propose a learning-based instance-level behavior-induction potential map as well as its learning mechanism both online and offline. The key advantage is that the desired decision, path and speed are encoded for each instance according to its category (state of operation). The potential functions are not manually defined or from special demonstrations, but learned from the real-time online information or the naturalistic offline driving data of the same circumstances in the past. Such a potential map can make the ego vehicle behave more like human drivers, which is crucial for the harmony in the future mixed traffic between the autonomous vehicles and the human-driven cars.'\",\"163\":null,\"164\":\"'http:\\/\\/mapir.uma.es\\/rgomez'\",\"165\":null,\"166\":null,\"167\":null,\"168\":\"'The merging of the robot data occurs in multiple steps. The first step is to determine what the merged island names (i.e. nodes on the graph) will be. Each robot has its set of island names which is the result of its past interactions. First, following the pseudocode of Algorithm 3, both lists of island names are combined into one large list. Then, each island name is compared against the other island names to check if there are any inhabiting robots in common, which indicates that the two islands are in fact the same island. The union of these two sets become the new island name. This is repeated until no island names have any robot IDs in common. A superscript of \\u201c-\\u201d indicates the variable has yet to be merged and a superscript of \\u201c+\\u201d means the variable has been merged. A clarifying example of Algorithm 3 is shown below.'\",\"169\":\"'Having introduced the weighting machinery meant to encode the sensing constraints considered in this work, we now discuss a suitable measure of bearing rigidity that will be exploited by the rigidity maintenance controller. We will first consider the unweighted case\\\\n(W=\\\\nI\\\\n3|E|\\\\n)\\\\nand then explicitly introduce the weights\\\\nw\\\\nij\\\\nin the design.'\",\"170\":\"'http:\\/\\/arc.cs.rutgers.edu\\/mvp\\/'\\n\\n'https:\\/\\/youtu.be\\/gXayWyRWDsw'\\n\\n'microMVP is an affordable, portable, and open source micro-scale mobile robot platform designed for robotics research and education. As a complete and unique multi-vehicl...'\\n\\n\\\"microMVP is an affordable, portable, and open source micro-scale mobile robot platform designed for robotics research and education. As a complete and unique multi-vehicle platform enabled by 3D printing and the maker culture, microMVP can be easily reproduced and requires little maintenance: a set of six micro vehicles, each measuring 8 \\u00d7 5 \\u00d7 6 cubic centimeters and weighing under 100 grams, and the accompanying tracking platform can be fully assembled in under two hours, all from readily available components. In this paper, we describe microMVP's hardware and software architecture, and the design thoughts that go into the making of the platform. The capabilities of microMVP APIs are then demonstrated with several single- and multi-robot path and motion planning algorithms. microMVP supports all common operation systems.\\\"\\n\\n'In this paper, we introduce an affordable, portable, and open source multi-vehicle hardware and software platform, MICROMVP1 (Fig. 1(a)), for research and education efforts requiring single or multiple mobile robots. MICROMVP consists of highly compact micro-vehicles, a state tracking camera system, and a supporting software stack. Each micro-vehicle (Fig. 1(b)) has a rigid 3D-printed shell allowing the precise (snap-on) fitting of the essential components-the Arduino-based sensorless vehicle measures less than 8-cm in length and can be controlled wirelessly at a frequency of over 100Hz. The external state-tracking system consists of a single USB webcam for estimating the configurations of the vehicles (in SE(2)). The overall system is capable of feedback control of the entire vehicle fleet at a control update frequency of 30Hz and above. The components in each vehicle costs less than 90 USD and the tracking platform costs about 80 USD. We expect the cost of MICROMVP to drop significantly with the release of future iterations of the platform.'\\n\\n\\\"MICROMVP is a capable, simple, affordable mobile robot platform with a very small footprint. First and most importantly, as we will demonstrate, MICROMVP is highly capable as an experimental platform for both centralized and distributed multi-robot planning and coordination tasks. Secondly, it presents a solution that is fairly portable and compact, suitable for showcasing multi-robot systems in action in limited space, making it ideal for both research and education. Last but not least, MICROMVP's open source design, utilizing 3D printing technology, is extremely simple and robust. Significant care is also taken to ensure that only readily available components are used, which makes MICROMVP a truly readily reproducible mobile robot platform.\\\"\\n\\n'The chilitags library provides open source APIs for extracting tags locations from images. The reported tag location (e.g., the\\\\n(x, y)\\\\ncoordinates of the four corners of a tag within a raster image), combined with known physical size of the tag and known camera orientation\\/calibration, allows the estimation of the SE (3) position and orientation of the tags. As vehicles in MICROMVP live on the floor, there is no need to extract the SE (3) configurations of the tags; S E (2) is sufficient. For continuous image acquisition through the USB camera, one may use OpenCV (Open Source Computer Vision Library) [8]. With a calibrated camera and the right parameters (e.g., exposure, white balance, and so on), we are able to track 50 tags simultaneously at 30 frames per second and rarely miss any of the tags. It appears that the limiting factor with respect to the frame rate of the system mainly hinges on the frame rate of the USB camera.'\\n\\n'In this paper, we summarized the design, implementation, and capabilities of MICROMVP. MICROMVP is intended to serve as a testbed for multi-robot planning and coordination algorithms and as an educational tool in the teaching of robotics subjects including mobile robots and multi-robot systems. Enabled by 3D-printing and the maker culture, MICROMVP is highly portable, readily affordable, low maintenance, and yet highly capable as an open source multi-vehicle platform.'\\n\\n\\\"MICROMVP will be continuously improved in its current and future iterations. On the hardware side, with the rapid development of IC technologies and improved design, the vehicles will become smaller, more accurate, and at the same time more affordable. In particular, we expect the release of a smaller vehicle costing around 35 USD in in the near future. We will also add on-board sensing capabilities to the vehicles while maintaining the platform's affordability. On the software side, to improve the accuracy of vehicle state estimation, we are working on a Extended Kalman Filter (EKF) to improve the sensing accuracy. Additional vehicle control APIs, including high level path planning with obstacle avoidance, will also be added to MICROMVP. Last, this open source effort hopes to solicit designs from all interested parties to make MICROMVP a community-based effort to promote robotics research and education.\\\"\",\"171\":\"'and the safety preferences encoded by'\\n\\n'safety preferences encoded as'\",\"172\":null,\"173\":\"'Self-driving vehicles are poised to become one of the most pervasive and impactful applications of autonomy. However, difficult challenges still remain before their widespread deployment, many of which concern the system as a whole, rather than single components in isolation. Examples include the codesign of hardware components and algorithms, the coupled interactions between perception and control, the optimal allocation of finite computational resources to concurrent processes, and safe multi-agent behaviors.'\\n\\n'Traffic lights at intersections sequentially communicate a \\u201cgo\\u201d signal to one of the incoming roads while signalling a \\u201cstop\\u201d in the other directions. Signals are encoded in the blinking frequency of LEDs. As Duckiebots interpret these signals they avoid \\u201cjamming\\u201d the center of the intersection ensuring smooth traffic flow. When a Duckiebot arrives at a stop line, it starts detecting the frequency of the LEDs in its field of view and once it detects the frequency corresponding to the \\u201cgo\\u201d signal, it starts maneuvering through the intersection.'\\n\\n'Duckietown is an open, inexpensive and flexible platform for autonomy education and research. The platform comprises small autonomous vehicles (\\u201cDuckiebots\\u201d) built from off-the-shelf components, and cities (\\u201cDuckietowns\\u201d) complete with roads, signage, traffic lights, obstacles, and citizens (duckies) in need of transportation. The Duckietown platform offers a wide range of functionalities at a low cost. Duckiebots sense the world with only one monocular camera and perform all processing onboard with a Raspberry Pi 2, yet are able to: follow lanes while avoiding obstacles, pedestrians (duckies) and other Duckiebots, localize within a global map, navigate a city, and coordinate with other Duckiebots to avoid collisions. Duckietown is a useful tool since educators and researchers can save money and time by not having to develop all of the necessary supporting infrastructure and capabilities. All materials are available as open source, and the hope is that others in the community will adopt the platform for education and research.'\\n\\n'All materials are available under open source\\/free software licenses; pointers to the materials can be found at the website duckietown.mit.edu. Our hope is that others in the robotics community will adopt the platform and contribute to its growth.'\\n\\n'A simplified version of the finite state machine used to control the vehicle. To see the full version, please visit our github repository.'\",\"174\":null,\"175\":null,\"176\":null,\"177\":\"'We begin by learning the task in the local side, where the operator demonstrates a number of motions that are encoded online. In the example of Fig. 2(a), 3 motions are demonstrated incrementally, resulting in a model with 6 Gaussian components. Note that components are added to the model as motions are being demonstrated. Fig. 3 shows the transition matrix and duration probabilities of the learned motion model. Note that the 3 demonstrations resulted in 3 paths as shown by the graph connectivity.'\\n\\n'We presented a general approach for online learning and optimal control of manipulation tasks in a supervisory teleoperation context. We used an online Bayesian nonparametric learning algorithm to build models of manipulation motions encoded as TP-HSMMs that accurately capture the spatiotemporal characteristics of demonstrated motions. We showed how the probabilistic representation can be combined with an MPC controller to generate online control commands in a receding horizon manner that is both robust to noise and changes in the environment. We presented how this framework can be used to automate common and recurring tasks, allowing the operator to focus only on the aspects of the tasks that genuinely require human intervention. We compared against a state-of-the-art approach and demonstrated how our method leverages the task-parametrized formulation to increase generalization, both in terms of extrapolation and online adaptability.'\",\"178\":\"'The features we use can be divided into three categories. The first category encodes proxemics to the people present in the scene, i.e., the social features. Within this category we consider two variations, for reasons explained in the following section.'\\n\\n'The second category of features encodes the distance from the target location using linear, exponential, and logarithmic functions. The third category encodes the obstacle cost using a stable function of the reciprocal of the distance from the nearest obstacle. Figure 1 b shows an example cost function over the whole configuration space for the configuration in Figure 1a. We use different functions for human and target proximity, to allow for more degrees of freedom when modelling the underlying cost function. Sufficient regularisation ensures that that the model does not overfit.'\",\"179\":null,\"180\":null,\"181\":null,\"182\":null,\"183\":null,\"184\":null,\"185\":null,\"186\":\"'https:\\/\\/youtu.be\\/_lbbx_oxtba'\\n\\n'\\u201cCloud Robotics and Automation\\u201d describes robots and automation systems that share data, re-use code, and perform necessary but expensive computation on remote cloud servers. It builds on emerging research in Cloud Computing, Deep Learning, Big Data, and government\\/industry initiatives such as the \\u201cInternet of Things\\u201d, \\u201cIndustry 4.0\\u201d, and \\u201cMade in China 2025\\u201d.'\\n\\n\\\"Because robust grasp configurations are pre-computed and stored in the cloud, Dex-Net can empower robots with limited memory and computing power to manipulate complex objects encountered in tasks such as warehouse order fulfillment and home decluttering. Furthermore, users of BRASS do not have to install any software to take advantage of Dex-Net's services. A simple web API exposes all necessary Dex-Net functionality to BRASS users, and updates to Dex-Net's codebase are immediately and transparently available to all usersds. BRASS also includes a collective learning system which stores success rates for grasps executed by its clients, allowing multiple robots to share their experiences with the goal of collectively learning better grasping configurations over time.\\\"\\n\\n'Brass is a prototype RAaaS webserver that presents a generic API for robotic services over the internet. By presenting a uniform, well-defined API, Brass abstracts away the complexities of its internal services and enables end-users to build code against a stable interface. Internally, Brass starts an instance of each of its services and connects to them using their own built-in communication protocols. When a request arrives, Brass queries these services, aggregates results, and returns them to the client in a well-defined format. In our experimental setup, Brass receives HTTP requests from the local RCU and sends responses (lists of parametrized grasps) as JSON.'\\n\\n'Our first experiment evaluated how using Dex-Net grasp recommendations affects grasp reliability when compared against hard-coded grasps that do not take piece geometry into account. This experiment was divided into two scenarios:'\",\"187\":\"'This section outlines the implementation details of the proposed project. The MDARQN code was built on the baseline [4] [8] and is implemented in torch\\/lua1. The robot side programming is done in python. The system used for training MDARQN has 3.40GHz\\u00d78 Intel Core i7 processor with 32 GB RAM and GeForce GTX 980 GPU. The rest of the section explains various modules of the project.'\\n\\n'In order to facilitate the implementation of the proposed MDARQN, we release the source code of our complete project together with the depth dataset collected during 14 days of experiment4. Although the dataset used for training comprised of both grayscle and depth images but due to privacy concerns, only the depth dataset is made publicly available.'\\n\\n'I. Source Code and Data Availability'\",\"188\":null,\"189\":\"'Visual Programming Interface-The system should provide a graphical user interface for programming the lights. It should provide the same range of light behaviors as the software library but require no programming knowledge. It should also generate the corresponding code using the software library for users to embed in their own programming applications.'\\n\\n'The C++ library was created to provide functions to help users easily create complex light behaviors. This also removes the need for users to directly program the microcontroller and facilitates integration of light signaling code with preexisting software used to control robots.'\\n\\n'In order to make the system more useful for roboticists, we have provided a simple ROS integration. The ROS package, ros.rnodlight, contains a ROS node which subscribes to the topic lightbehavior_cmd and publishes its status to modlight_status. A sample is provided in the code repository.'\\n\\n'After configuring the LEDs, GUI can be used to either upload the code directly to Arduino or generate the main.cpp file which uses the NeoPixel Code Converter library. The generated main.cpp file can be compiled later to generate the. ino files for flashing the Arduino microprocessor.'\\n\\n'Recent work has shown the potential for lights to act as simple, yet expressive signaling mechanisms for use in a variety of human-robot applications. However, the wide range of robot shapes and sizes makes it difficult for researchers to quickly prototype and evaluate different light configurations and signal designs. In this work, we present the design of ModLight, a modular research tool consisting of a set of low cost light blocks that can be easily reconfigured to fit a myriad of robots and applications. ModLight also provides researchers, designers, and students with open-source software tools that enable them to visually design new signals and easily integrate them into existing systems. This work also serves to motivate the need for further research in developing light behaviors for use in human-robot interaction. Towards this goal, we present our design rationale including a brief analysis of the signaling needs of several robots and applications.'\\n\\n'For hardware, we chose open-source components that are widely available and commonly used in research and hobbyist applications. We chose the Adafruit Neopixel RGBW LEDs for their affordability, software library, and support. For controlling the LEDs, we used an Arduino Mega microcontroller board. Arduino boards are popular, easy to use, flexible, and provide software tools and support for several operating systems. Users can also adapt the ModLight to work with the Arduino UNO, a lower cost, entry level platform.'\\n\\n'The open-source nature of these components as well as ModLights design and software tools makes it possible for users to easily add new functionalities. Users can also customize the size, shape, and connections of each module to greater fit their own needs.'\\n\\n\\\"In addition, this work also serves to motivate the need for further research in non-humanoid signaling. Towards this goal, we present design guidelines taken into account when creating ModLight including those related to the signaling needs of several types of non-humanid robots and selective use cases. We alsoo provide links to all of the necessary information to construct and program ModLight as it is an open source system that users can continue to add functionalities and new designs to. This community-driven approach will save researchers time and allow them to leverage past users' experiences.\\\"\\n\\n'NeoPixel Code Converter Library is a generic library that generates ino files based on the input configuration. These generated ino files utilizes the Arduino system calls to execute the desired Light Pattern behaviours. NeoPixel Code Converter Library hides away the complexity of maintaining LED states and also wraps the logic of updating LEDs with correct delay and color combinations.'\\n\\n'Code for the NeoPixel Code Converter Library is built using cmake that generates a static library, libNeoPixelCode-Converter.a. The main.cpp file generated by the GUI depends on this static library. Examples of various light behaviors can be found under\\/Examples folder.'\\n\\n'LightSignal Arduino Library is built as a third party library for Arduino. This library handles the logic to update LEDs with different light behaviors. Code for this library is present in Arduino. Libs\\/Lightxignal folder. Arduino call the library inside the loop () function using the mainLoop () function.'\\n\\n'Light Patterns also have additional parameters like start time, end time, total run cycles, brightness level etc. (All parameters can be found under struct LightParameter in LightParameter.h). Code for the GUI application is present under the\\/GUI_Code\\/BlockTrial folder. The project is created using Qt Creator IDE and can be opened and built using the BlockTrial.pro project file.'\",\"190\":\"'In this paper, we present a method for real-time 3D sound sources mapping using an off-the-shelf robotic perception sensor equipped with a linear microphone array. Conventional approaches to map sound sources in 3D scenarios use dedicated 3D microphone arrays, as this type of arrays provide two degrees of freedom (DOF) observations. Our method addresses the problem of 3D sound sources mapping using a linear microphone array, which only provides one DOF observations making the estimation of the sound sources location more challenging. In the proposed method, multi hypotheses tracking is combined with a new sound source parametrisation to provide with a good initial guess for an online optimisation strategy. A joint optimisation is carried out to estimate 6 DOF sensor poses and 3 DOF landmarks together with the sound sources locations. Additionally, a dedicated sensor model is proposed to accurately model the noise of the Direction of Arrival (DOA) observation when using a linear microphone array. Comprehensive simulation and experimental results show the effectiveness of the proposed method. In addition, a real-time implementation of our method has been made available as open source software for the benefit of the community.'\",\"191\":\"'http:\\/\\/sdk.rethinkrobotics.com\\/wiki\\/arms'\\n\\n'To this end, we propose a new representation for social affordances, i.e., social affordance grammar as a spatiotemporal AND-OR graph (ST-AOG), which encodes both important latent sub-goals for a complex interaction and the fine grained motion grounding such as human body gestures and facing directions. We learn the grammar from RGB-D videos of human interactions as Fig. 1 depicts. Our grammar model also enables short-term motion generation (e.g., raising an arm) for each agent independently while providing long-term spatiotemporal relations between two agents as sub-goals to achieve for both of them (e.g., holding the right hand of each other), which simultaneously maximizes the flexibly of our motion inference (single agent action) and grasps the most important aspects of the intended human-robot interactions (sub-goals in joint tasks).'\",\"192\":null,\"193\":\"\\\"As a part of future work, we plan to validate and verify our approach on a real robot placed in a dense human crowd. The task would be, given a start and goal location, the robot should be able to navigate safely and efficiently through the crowd. In addition to validating our approach, we intend to tackle the drawbacks of the approach as stated before. We are also looking to extend the model by coming up with latent representations of trajectories that encode time-varying information such as pedestrian's intention, planned future path and velocities, that can be used instead of an occupancy grid in our approach.\\\"\\n\\n'The authors would like to thank Peter Trautman for sharing the code for IGP and insightful discussions, and the anonymous reviewers for their helpful suggestions. This work was conducted in part through collaborative participation in the Robotics Consortium sponsored by the U.S Army Research Laboratory under the Collaborative Technology Alliance Program, Cooperative Agreement W911NF-10-2-0016. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory of the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.'\",\"194\":\"\\\"As a shared, remotely accessible, multi-robot facility, the Robotarium's main purpose is to lower the barrier of entrance into multi-agent robotics. Therefore, for the Robotarium to fulfill its intended use effectively, it has to implement a number of high-level design requirements aimed at accessibility, ease of maintenance, intuitive interaction, and safe and secure code execution.\\\"\\n\\n'Enable intuitive interaction with and simple data collection from the Robotarium through a public web interface that facilitates code submission and data\\/video retrieval.'\\n\\n'System architecture overview. The robotarium includes components that are executed locally on robotarium infrastructure as well as user-facing components that run on remote user machines (web front end). Three components interact directly with the robot hardware\\u2014 tracking, wireless communication, and virtualization. The remaining components handle user management, code verification and upload to the server, as well as coordination of user data and testbed-generated data.'\\n\\n'The simulation capabilities of the Robotar- ium are leveraged in three distinct ways: prototyping of user code, verification of user-provided code, and adding virtual robots. The simulators enable users to prototype and test their algorithms on their own machines before submitting them for execution on the Rob-otarium. 5 Once submitted, but before being executed on the testbed, the same simulation infrastructure verifies collision-free execution of user code (see Section IV-A). Additionally, the simulator also allows adding virtual robots to the testbed arena that are capable of interacting with the physical robots through the server back end.'\\n\\n\\\"The server application is the central co- ordinating instance responsible for executing user code, routing commands and data to and from robots, transmitting global position data to the robots, and managing simulated virtual robots. In addition the server logs all generated data and makes them available to users. Note that the robots execute a velocity controller onboard. However, the user's control code is executed on the server and essentially remote controls the robots by providing velocity control inputs to the robots. This centralized execution increases overall robustness of the Robotarium, simplifies data logging a\\\\ns\\\\nwell as establishing formal safety guarantees, and facilitates automatic maintenance. 8 Note that centralization can lead to communication and computation bottlenecks. Given the total bandwidth of 802.11g WiFi of 54 MBit\\/s and typical bandwidth requirements of 3 KBytes\\/s\\/robot the theoretical upper limit is 18, 000 robots. Clearly, WiFi collisions, buffering issues, interference, and other issues will practically lower that number. However, operating hundreds of robots simultaneously is well within the limits of the Robotarium's WiFi-based communication architecture. Computational scalability is addressed in Section IV-B.\\\"\\n\\n'This section highlights the main usage features of the Robotarium: continuous operation and auto-recharging of robots, safe remote access for external users, and the characterization and closing of the simulation-hardware gap that can prevent the successful execution of controls code on physical robots. The following sections detail each of these features.'\\n\\n'Enable inexpensive replication of the Robotarium through low-cost, open-source robots (currently up to 20 robots are available).'\",\"195\":null,\"196\":null,\"197\":null,\"198\":null,\"199\":null,\"200\":null,\"201\":null,\"202\":\"'Once the robot reaches to the fixed location, the system algorithm moves to the automatic mouth position tracking stage. At this moment, the algorithm starts to track the position of the mouth of the user within the video frame. In order to track the mouth, it is necessary to identify the mouth shape in the video frame and to realize this, a Haar Cascade classifier implemented in OpenCV is used. OpenCV Haar classifier is an effective object detection classifier which is used in many applications to do object detection. In order to track the mouth, a pre-trained open source classifier [19] is applied. Furthermore, the classifier is modified to identify the mouths within 10\\u201330 cm distance from the camera. This process omits any mouth shape objects in the background beyond that threshold and allows the program to identify only mouth shapes within the seating area.'\",\"203\":null,\"204\":null,\"205\":null,\"206\":null,\"207\":null,\"208\":null,\"209\":null,\"210\":null,\"211\":null,\"212\":\"'https:\\/\\/youtu.be\\/bsk7NbaCb5E'\\n\\n'https:\\/\\/youtu.be\\/pqXF-ymJidk'\\n\\n'Forward kinematics of the 6-6 general parallel manipulator using Real Coded Genetic Algorithms'\",\"213\":null,\"214\":\"'To measure joint angles, all six joints are equipped with absolute encoders. Off-the-shelf encoders (Mini4096J) are used on J1-J3, while permanent magnets are embedded on the shafts of J4-J6 because of the tight space, and 3 pieces of AMS5048A ICs are used to detect the absolute angle.'\\n\\n'This section presents fabrication and validation results on the proposed SHELINDER actuator and the soft manipulator. 200 inner chambers were fabricated by inject molding using flexible polyvinyl chloride. Push-in tubing connectors were fitted to each chamber as air vent. The inject-molding process ensured excellent sample repeatability and stability of the chambers, while also achieved a fabrication cost of as low as US $0.2 per piece. The complete soft manipulator, including the arm and the tri-fingered hand, were fabricated, mostly using 3D-printing of polylactide, reinforced by carbon fiber and metallic auxiliary components. Air tubing, angular encoders, driving cables and transmission sheathes were all fitted as previously presented.'\",\"215\":null,\"216\":\"'The electrical system of the mobile platform consists of actuation parts and the 3D scanner. The microcontroller, which is raspberry PI 2, for the 3D scanner controls the rotational speed of the gimbal and measures the orientation of the laser ray. It generates the orientation from the synchronization signal from the 2D LIDAR and the encoder on the gimbal.'\\n\\n'When the LIDAR sensor and the encoder of the gimbal system generate a polar coordinate of the shooting laser, it occupies one voxel in an octree [11] with the resolution of 2cm \\u00d72cm x2cm. We register the shape of the top plate of the mobile platform as a triangular plane, and voxels outside of the plane are considered to be separate objects. So far, all the voxels in the space are separated into two groups: platform voxels and object voxels. To identify whether there is an object making a contact with the platform, we measure the distance from each object voxel and the triangular plane, and if the distance is less than a given threshold, we identify the voxel as just next to the platform. Fig. 4 shows the platform voxels and the object voxels which are making contacts with the platform. The object voxels are grouped together, and the mean position of the voxels in each group corresponds to the location of the contact which is used in the subsequent section.'\",\"217\":null,\"218\":\"\\\"J\\\\nMPCC\\\\nalready encodes the penalization of the deviation from the reference path which results in a slight nudging behavior into a beneficial direction. It also takes the driver's goal of making progress along the road into account.\\\"\",\"219\":null,\"220\":null,\"221\":null,\"222\":null,\"223\":null,\"224\":null,\"225\":\"'https:\\/\\/youtu.be\\/h5osekag42w'\",\"226\":\"'In addition, we extract CNN features to estimate 3D object poses. In our experiment, visualizations of filters learned in early layers indicate successive operations of convolution and max-pooling processes make robust invariances to local translations and rotation. For this reason, we separately made a new representation with a new guidance for supervising the poses of similar object shapes. Once a 3D model is categorized, we encode the ensuing CNN architecture, illustrated inFig. 5. The pose regression network is composed of five convolutional layers, four max pooling layers, and two fully connected layers. A rectified linear unit (ReLU) is followed by each convolutional layer as an activation function. The final loss layer for three dimensional output activation is defined in the following:'\\n\\n'Extending Denoising AutoEncoders for Feature Recognition'\",\"227\":null,\"228\":null,\"229\":\"'We release our Bayesian CNN sun estimator (Sun-BCNN) as open-source code.'\\n\\n'We use the open-source libviso2 package[28] to detect and track keypoints between stereo image pairs. Based on these keypoint tracks, a three-point Random Sample Consensus (RANSAC) algorithm generates an initial guess of the inter-frame motion and rejects outlier keypoint tracks by thresholding their reprojection error. We compound these pose-to-pose transformation estimates through our chosen window and refine them using a local bundle adjustment, which we solve using the nonlinear least-squares solver Ceres[30]. The objective function to be minimized can be written as'\\n\\n'We present a method to incorporate global orientation information from the sun into a visual odometry pipeline using only the existing image stream, where the sun is typically not visible. We leverage recent advances in Bayesian Convolutional Neural Networks to train and implement a sun detection model that infers a three-dimensional sun direction vector from a single RGB image. Crucially, our method also computes a principled uncertainty associated with each prediction, using a Monte Carlo dropout scheme. We incorporate this uncertainty into a sliding window stereo visual odometry pipeline where accurate uncertainty estimates are critical for optimal data fusion. Our Bayesian sun detection model achieves a median error of approximately 12 degrees on the KITTI odometry benchmark training set, and yields improvements of up to 42% in translational ARMSE and 32% in rotational ARMSE compared to standard VO. An open source implementation of our Bayesian CNN sun estimator (Sun-BCNN) using Caffe is available at https:\\/\\/github.com\\/utiasSTARS\\/sun-bcnn-vo.'\",\"230\":null,\"231\":null,\"232\":null,\"233\":null,\"234\":\"'http:\\/\\/nimbus.unl.edu\\/tools\\/'\\n\\n\\\"Changes to robotic systems as they are updated or upgraded often affect the flow of control and sensor data. Developers and users spend a significant amount of time tracing the impact of these changes that could otherwise have negative impacts on the robot's performance and behavior. Changes to the rates at which data is published from sensors, controllers, and other parts of the system are particularly subtle and difficult to detect. These rate changes, even if minor (e.g. lowering the frame rate of a camera), can propagate throughout the system and have broad impacts. In this work, we develop and implement an approach to help identify the set of components whose rate may be impacted by a system change. The approach builds on the insight that certain code patterns render component's outgoing data rate independent of the component's incoming data rate. We use that insight to reduce the number of components reported as affected by the change to minimize the number of components that must be reevaluated by the developer. A study of an implementation of the approach on three ROS systems shows that it can reduce the size of the impact set by up to 41% in cases when the changes have broad data impacts. The analysis is performed at compile time and only adds a third more to the compilation time.\\\"\\n\\n\\\"In this work, we add the rate dimension, which is particularly relevant to robotic systems that explicitly rely on timing properties or implicitly rely on rate assumptions. We build on the insight that certain code patterns render component's outgoing data rate independent of its incoming data. We use that insight to reduce the number of components reported as affected by the change. Our contributions are:\\\"\\n\\n\\\"A novel approach to impact analysis focused on the rate of incoming and outgoing data, an aspect overlooked by existing impact analysis approaches. The analysis incorporates component's source code patterns that render data production rates independent of the incoming data rates (and hence independent of changes that may affect those incoming rates).\\\"\\n\\n'A tool implementing the approach, targeting systems built in C++ using the Robot Operating System (ROS) middleware. The tool performs a static code and configuration analysis to identify what data flows between components and recognizes the patterns defined by the approach to infer rate independence.'\\n\\n'This graph representing the publish-subscribed architecture of COB also encodes a conservative approximation of the nodes dependencies. In essence, if there is a path through the edges from one node to another, then the former can impact the later. In the case of COB, for example, if the change occurred in the process handling of the laser scanner (marked with a star infigure 2), then a traditional impact analysis would traverse this dependency graph starting from the star node and propagating the effect along the edges to all reachable nodes. Using such approach would render all the nodes in the graph inFigure 2 as potentially impacted by the change. The impact set contains 19 affected nodes that a developer will have to check.'\\n\\n'Crucial to the cost-effectiveness of this approach is the analysis of nodes to identify whether their publishing edges are independent. Through this work we identify a common set of code patterns that are highly likely to render a publisher independent. For a node like\\\\nA\\\\n, a sample code pattern is shown in Code 1, where the publishing rate is fixed as the semantics of the <rate_var>. sleep () (line 8) call enforce a wait period before the next iteration through the loop to publish again. For a dependent node, like\\\\nB\\\\n, a sample code pattern is shown in Code 2. In this example, the call to <publisher>. publish (<msg>) (line 2) occurs within a subscription callback function so the publishing rate of this node will depend on the rate of received messages. The identification of these code patterns followed an iterative process, starting with a pool of candidate patterns based on our development experience and recommended practices, followed by several refinement steps as we searched for those patterns in other code bases. We have also built a tool that automatically recognizes these patterns and labels the publish-subscribe graph. Further details about the approach and the implemented tool are provided in the next section.'\\n\\n'Figure 4 shows the high-level architecture of the proposed approach. It is divided into two phases: Dependency Analysis (DA) and Impact Analysis (IA). DA takes as input the system code and its launch file (a file to configure the system deployment through parameters and node and topic remappings). DA outputs a dependency graph where edges from a publisher to a topic are labeled as either \\u2018dependent on\\u2019 or \\u2018independent of\\u2019 the rate of incoming messages. IA takes this rate dependency graph and the list of changed component(s) as input. It then performs a depth-first traversal of the graph, starting from those changed components and stopping when a leaf node or a rate-independent publisher is found. IA reports the reachable set of nodes that constitutes the Impact Set for the changed component(s).'\\n\\n'Pseudocode from Cob_Obstacle_Distance_Moveit Package Exhibiting the Timer Based Pattern'\\n\\n\\\"Once the approach has generated the graph, it further examines the source code, analyzing every path leading to a publisher's publish call to identify certain code patterns that render those edges as rate-independent. We now introduce three initial patterns (others are mentioned inSection VII) with their particular instantiation in ROS\\\"\\n\\n'Summary for source code 2.'\\n\\n\\\"Our approach implementation builds heavily on the source code analysis tool Clang[2], which works as a compiler front-end for C++. We use Clang to help us detect the subscribing and publishing channels and identify the patterns associated with independent publishing edges. More specifically, we use AnalysisDeclContext to generate the code's Control Flow Graph (CFG), the CFG object for code traversal, CXXMemberCallExpr for detecting member function calls, getArg to retrieve the required argument values, Call-Expr to identify regular function calls, CXXCtorlnitializer to identify the base or member initializer for ROS objects, and DeclStmt to retrieve variable names. We utilize the YAML-CPP library[6] to store and parse the summaries as YAML files, and PUGI XML[12] for parsing and extracting partial information from ROS launch configuration files. Finally, we use Graphviz DOT[9] to generate visual depictions of the dependency graphs to facilite their interpretation and debugging of the tool. Our tool RSIA (Rate based Static Impact Analysis) is available for download from http:\\/\\/nimbus.unl.edu\\/tools\\/.\\\"\\n\\n'We assess the proposed approach in three phases. First, we evaluate the precision and recall of the tool at generating the dependency graph. To do this, we manually generated a ground truth dependency graph. Generating the graph entailed the inspection of each system (source code, launch files, and also runtime publish-subscribe graphs) through a mixed process of automated and manual analysis, intermingled with sessions where all authors reviewed code samples and hard-to-determine dependencies. This process resulted in a dependency graph, with edges labeled as dependent or independent, that we deemed to be correct and treated as the ground truth for the study. First part of the study compared this ground truth graph versus the one constructed by the tool. We also break down the evaluation among publishers and subscribers that were detected and named.'\\n\\n\\\"Second, to compare the impact sets, we implemented the traditional IA approach by performing a DFS from a changed node on the ground truth dependency graph of each system. We used the same ground truth graph to assess the ideal implementation of our approach. To evaluate the IA portion of the tool, we used the tool's generated graph with user input to complete the names of those topics that the tool recognized but could not name unequivocally (because the names were defined in configuration files or used code constructs or API calls not yet supported by the tool implementation).\\\"\\n\\n\\\"We recognize that the study presents several threats that will limit the validity of the results. From an external validity perspective, we only studied three systems using ROS. The selected systems and ROS, however, are quite popular and large, covering a range of similar systems. Furthermore, we note that the cost of studying more systems and middleware is non-trivial. It requires extensive and careful manual analysis to determine the ground truth that took months for the studied systems. From an internal perspective, we recognize that analyses involving a manual process are susceptible to bias. We attempted to control that bias by having multiple participants examining sample code. For cases that were hard to interpret, we compared the manual and automated results to address any potential incompleteness in the manually computed graph. Similarly, the code may exhibit other dependencies that we failed to identify either manually or with the provided tool. We provide a link to the analyzed code to enable the reproduction and assessment of the results. We acknowledge that the performance of the approach may not be indicative of what happens in practice as the engineer's familiarity with the code may introduce more variability into the IA process. With these limitations in mind, we proceed to share and analyze the study results.\\\"\\n\\n\\\"We present the results in three stages. First, we present the tool's capability to detect system component dependencies. Second, we perform a three-way comparison of the generated impact sets by traditional impact analysis using the ground truth dependency graph (Trad) generated manually, the proposed approach using the ground truth dependency graph (A-GT) generated manually, and the automated version of the proposed approach as implemented in the tool (A-Tool) which generates the dependency graph through code analysis. Third, we compute the overhead of the automated approach.\\\"\\n\\n'Dynamic impact analysis techniques rely on the execution of the code, rendering results that depend on particular inputs used to drive the execution. They typically consume execution trace data, where trace can be, for example, executed functions[13]. Given such traces, these techniques analyze the temporal relations of the elements in the trace (e.g., always before, always after) to derive their potential dependencies. In the context of distributed systems, Cai and Thain[7] recently introduced a dynamic IA targeting communication channels. Our work is different in that we focus on publish and subscribe constructs, and in particular their rates. From the perspective of the proposed approach, we recognize the potential of dynamic impact analysis to help us observe the publish and subscribe channels linked to launch configuration files. Incorporating such information into our tool would result in a hybrid impact analysis approach, conceptually similar to others like SD-Impala[16] but still unique in its focus on the rates of publish and subscribe channels.'\\n\\n'We presented an approach to support developers of robotic systems in understanding the subtle impacts of code changes that affect the rate at which data is produced or consumed. The approach is more precise than existing impact analysis approaches. We have shown its potential through a manual examination and an automated tool for ROS. In the three case studies, the tool reduced the impact set that developers must process by up to 41% of alternative approaches.'\\n\\n'The approach and tool, however, are still at an early development stage. The approach could incorporate a richer set of patterns, including those that attempt to synchronize different communication channels, concurrency publishing patterns, and special real-time publishing patterns. The tool could also be improved by adding support for dynamic library detection and by performing a more precise code analysis. We are also interested in extending the approach to analyze the effect of changes on the system performance, as well as exploring the potential of incorporating dynamic analysis to improve the effectiveness of the approach. We will be exploring such improvements and further applying the tool to a larger number of systems.'\\n\\n'SECTION Code 1:'\\n\\n'SECTION Code 2:'\\n\\n'SECTION Code 3:'\\n\\n\\\"Robotic middleware often provides support for a function to be invoked at fixed intervals. In ROS, such a function can be registered as a callback function against ros:: Timer or ros:: WallTimer. The registered callback function is invoked every time the given duration equivalent to the ros:: Timer has passed, executing the callback function at fixed intervals. Code 3, shows an example of such a pattern. Since the callback function will be invoked at fixed time intervals, the publisher's publish call will also be invoked at fixed intervals making the path from the timer callback to the publisher's publish call an independent publisher path. To detect this pattern, we locate a call to function createTimer and then we extract the argument which gives the callback function name which will be invoked at a fixed rate.\\\"\\n\\n\\\"Robotic middleware like ROS often provides adaptive sleep functions which take execution time of a cycle into account and sleep for the leftover time of the initialized duration, ensuring that the loop is executed at a fixed rate. In ROS, this can be done by initializing an ros:: Rate object which specifies the rate at which the loop should be executed. Then, inside a loop, ros:: Rate object's sleep function is called to sleep until the next execution should start. For example, in Code 1, the function publishTransform is called at a fixed rate as the loop will be executed at a fixed rate because of the adaptive ros:: Rate based sleep call. To detect this pattern, we locate a ros:: Rate object followed by a loop and a ros:: Rate based sleep call. Then we label any function call or publish call independent within the loop body.\\\"\",\"235\":null,\"236\":null,\"237\":null,\"238\":null,\"239\":null,\"240\":\"'Rotational angle of the driving mechanism has to be detected by the module for automatic control of slide distance. Although it is easy to mount rotary encoders on the DC motors, this may cause a detection error when the timing belt slips to the timing pulleys. Thus, we placed hall effect sensors A1324LUA-T (Allegro MicroSystems) in the proximity of the helically magnetized axes as shown inFigure 14. By detecting the magnetic field generated by the axes, the module estimates the rotation angles. Figure 15 shows an example of output voltage from the hall effect sensor while the corresponding axis is rotated. We can see that the output voltage has a simple periodic waveform in each rotation.'\",\"241\":\"'https:\\/\\/ropemanipulation.github.io\\/'\\n\\n'https:\\/\\/ropemanipulation.github.io\\/'\",\"242\":null,\"243\":null,\"244\":\"'https:\\/\\/sites.google.com\\/site\\/modularpolicynetworks\\/'\",\"245\":\"'http:\\/\\/motion.pratt.duke.edu\\/sidechannel\\/'\",\"246\":\"'https:\\/\\/youtu.be\\/hgQzQGcyu0Q'\\n\\n'https:\\/\\/youtu.be\\/hgqzqgcyu0Q'\",\"247\":null,\"248\":null,\"249\":null,\"250\":null,\"251\":\"'By contrast, in our approach the auto-encoder (specifi-cally a sparse coding algorithm) itself determines the most relevant high-level features of the unlabeled pressure image data. These high-level features are then used to classify the pressure image data with an SVM. The SVM classifier chooses the most relevant features (from among the high-level features) for distinguishing between the two groups, a task to which this type of classifier is well-suited [21]. By encoding the data and finding most relevant high-level features, we are hypothesizing that this will lead to knowledge of the combination of high-level features that most strongly correlates with the group of successful grasps (and likewise for the group of failed grasps). Thus the algorithm and SVM are working together to find the common denominators behind all successful (and all failed) grasps.'\\n\\n'In this section, we describe the techniques we used to encode the raw data for automatic feature extraction, and then explain the approach we used to optimize the prediction algorithm. Much like previous work [19], [15], we consider our static tactile pressure data to be an image. Here, we use tactile image to refer to the two pressure images from the sensors that were recorded at the moment of the grasp and placed side-by-side to make one composite pressure image (an example of a filtered sensor image can be seen in Fig. 12).'\\n\\n'To solve these mathematical problems, we used the MAT-LAB code made available by [22]. Fig. 2 illustrates how the dictionary is used to reconstruct a patch of our sensor image. The sparse vector\\\\n\\u03b1\\\\nis obtained using eq. 3.'\",\"252\":\"'Fig. 6(a) and (b) show the fitted LS with the convex 4th-order polynomial (cvx4thPoly) and the ellipsoidal model of this contact with fewer wrench data, indicated with red dots. The code for the LS fitting is provided by Zhou [6]. It is easy to see that many wrench data points are inside the ellipsoidal LS, while the most data points are on the surface of the cvx4thPoly LS. Hence, the ellipsoidal LS has a larger fitting error than the cvx4thPoly. Fig. 6(c) shows the fitting error of both LS models with the curved contact model for all 35 grasp locations along the\\\\nx\\\\n: -axis of the test object.'\",\"253\":null,\"254\":null,\"255\":null,\"256\":null,\"257\":null,\"258\":null,\"259\":\"'http:\\/\\/youtu.be\\/Dk5XVQBDJpU'\\n\\n'The second major category of human motion prediction focuses on analyzing how people move and plan natural paths without predicting specific goal locations. One such method employs motion capture data to encode skeletal motion patterns as Hidden Markov Models, with the goal of encoding likely transitions between motion patterns [12].'\",\"260\":\"\\\"This paper investigates how a robot that can produce contingent listener response, i.e., backchannel, can deeply engage children as a storyteller. We propose a backchannel opportunity prediction (BOP) model trained from a dataset of children's dyad storytelling and listening activities. Using this dataset, we gain better understanding of what speaker cues children can decode to find backchannel timing, and what type of nonverbal behaviors they produce to indicate engagement status as a listener. Applying our BOP model, we conducted two studies, within- and between-subjects, using our social robot platform, Tega. Behavioral and self-reported analyses from the two studies consistently suggest that children are more engaged with a contingent backchanneling robot listener. Children perceived the contingent robot as more attentive and more interested in their story compared to a non-contingent robot. We find that children significantly gaze more at the contingent robot while storytelling and speak more with higher energy to a contingent robot.\\\"\\n\\n'For each storytelling episode, the nonverbal behaviors of both the listener and storyteller were manually coded using a video-annotation software by four coders (Fig. 4). Three additional coders were recruited to simulate themselves being a listener and mark the moments when they wanted to BC. After this simulation, coders reviewed the audio snippets surrounding these moments to further categorize the type of speaker cues perceived (pitch, energy, pause, filled pause, long utterance, clause ending, other).'\\n\\n\\\"The coders' labels were compared to create three levels of consensus dataset. Within a time frame (1000ms), if all three coders tagged a same label, then that label in that time frame is assigned level 3, and so on. In the following, we compare the results of our speaking binary classifier and BC opportunity prediction algorithm to the labels in the consensus dataset for performance evaluations.\\\"\\n\\n'In this section, we present four rule-based BC opportunity prediction (BOP) models based on the most frequently observed child speaker prosodic cues (pitch, energy, long pause, and long utterance) and their patterns that prompt listener response. In the following, the values for the model parameters were iterated at steps of 100ms to minimize least square errors based on human coder labels.'\",\"261\":\"'Deep learning approaches have been used to perform classification in several applications with high-dimensional input data. In this paper, we investigate the potential for deep learning for classifying affective touch on robotic skin in a social setting. Three models are considered, a convolutional neural network, a convolutional-recurrent neural network and an autoencoder-recurrent neural network. These models are evaluated on two publicly available affective touch datasets, and compared with models built to classify the same datasets. The deep learning approaches provide a similar level of accuracy, and allows gestures to be predicted in real-time at a rate of 6 to 9 Hertz. The memory requirements of the models demonstrate that they can be implemented on small, inexpensive microcontrollers, demonstrating that classification can be performed in the skin itself by collocating computing elements with the sensor array.'\\n\\n'We are interested in using deep learning techniques, such as convolutional (CNN) and recurrent neural networks (RNN), for classifying social touch gestures in the context of robotic materials. To the best of our knowledge, deep learning approaches for social touch recognition has not been explored, with the exception of using deep autoen-coders to compress individual frames in [10]. Deep learning approaches have shown several advantages over hand-engineered features: CNNs are useful for automatically generating features from training data, features exhibit invariance to translation and scaling, and RNNs can provide predictions at each point in a sequence, rather than one prediction for a sequence as a whole.'\\n\\n'We explore three deep neural network architectures: CNNs, CNN-RNNs and Autoencoder-RNNs. The CNNs performed classification using frames in a short window of time. The CNN-RNNs extend the CNNs by incorporating a recurrent layer to utilize temporal information about the gesture. In a similar manner, the Autoencoder-RNN extends the autoencoders used in [10], which were used to reduce the dimensionality of each frame to 10 real-valued numbers, by using the code layer as input to a recurrent network.'\\n\\n'D. Autoencoder-Rnn'\\n\\n'The final architecture extends the autoencoder used in [10] by connecting the output of the code layer to an RNN layer, as shown in Figure 3. In [10], an autoencoder [15] was used to reduce the size of individual frames from 64 units to 10 linear units. This output was used as observations for hidden Markov models (HMM) to estimate the likelihood that a sequence of frames belonged to each type of gesture. In this investigation, the HMM was replaced with a recurrent layer. The resulting architecture has the advantage of allowing the autoencoder portion to be pre-trained to reconstruct individual frames (as in [10]) prior to training the classifier. Additionally, training the network for classification refines the encoding portion of the network so that the encoded frame provides better information for classification, as opposed to simply performing data compression.'\\n\\n'The autoencoder portion of the architecture used matches that in [10]: the encoding layers consist of four fully connected layers with 200, 100, 50 and 25 units, followed by a code layer of 10 units. The decoding layer is simply a mirror of the encoding layer: 25, 50 100, and 200 units. In [10], the code layer used a linear activation function, while the encoding and decoding layers consisted of sigmoid units. Here, rectified linear units were used instead of sigmoid units, as these types of units learn faster than sigmoid units.'\\n\\n'Autoencoder-rnn architecture'\\n\\n'To investigate the results in more detail, confusion matrices were generated for each model and dataset. The confusion matrices for the HAART dataset using the CNN, CNN-RNN and Autoencoder-RNN models are given in Tables II, III, and IV, respectively. For all three models, the No Touch, Constant and Scratch are generally classified correctly. Tickle and Scratch are commonly confused, and to a lesser extent, Pat and Stroke. These specific confusions were also seen in the models summarized in [5], and is specifically noted in [8], and is attributed to the assumed similarity between the gestures.'\\n\\n'The confusion matrices for the CoST dataset using the CNN, CNN-RNN and Autoencoder-RNN architectures is given in Tables V, VI, and VII. As with the HAART results, the confused gestures (e.g., slap and pat) are similar to those found in the Social Touch Challenge. The Autoencoder-RNN, which resulted in poor classification accuracy, demonstrates a bias towards the Tickle gesture, though the cause of this is unknown.'\\n\\n'For the two sets of models, the Autoencoder-RNN requires the largest amount of FLASH memory, primarily due to the large number of full connections. In contrast, the convolutional kernels in the CNN and CNN-RNN models provide a large amount of weight sharing, which greatly reduces the memory requirements compared to fully connected layers. Consequently, the FLASH footprint of the CNN and CNN-RNN models are much less. Including the recurrent layer also requires only a minimal amount of additional memory, namely the additional full connection from the CNN output to the recurrent layer input, and the amount of neurons in the recurrent layer. This increase in memory requirement is a small trade-off for the large increase in overall accuracy.'\\n\\n'Table IV: Confusion matrix for the haart dataset using autoencoder-rnn architecture'\\n\\n'Table VII: Confusion matrix for the cost dataset using autoencoder-rnn architecture'\\n\\n'We present three deep learning models for the task of identifying affective touch for social robots: a CNN model, a CNN-RNN model and an Autoencoder-RNN model. These model provide similar performance in terms of accuracy as those presented in the 2015 Social Touch Challenge. While none of the models outperform the best models in the Social Touch Challenge in terms of overall accuracy, the deep learning models explored here provide a touch gesture prediction in real-time at a rate of 6 to 9 times per second, while the models in the Social Touch Challenge only provide predictions once the entire gesture is captured. Additionally, our models automatically extract meaningful features from training data, rather than requiring hand-engineered features to be designed and evaluated.'\",\"262\":null,\"263\":null,\"264\":null,\"265\":null,\"266\":null,\"267\":null,\"268\":null,\"269\":\"'http:\\/\\/robotics.citris-uc.org\\/'\",\"270\":null,\"271\":null,\"272\":null,\"273\":null,\"274\":null,\"275\":null,\"276\":null,\"277\":null,\"278\":null,\"279\":null,\"280\":null,\"281\":null,\"282\":null,\"283\":null,\"284\":null,\"285\":null,\"286\":null,\"287\":\"'https:\\/\\/youtu.be\\/atqlehx-7sk'\\n\\n'https:\\/\\/youtu.be\\/brln-imtztw'\\n\\n'As a post-processing step, the depth maps resulting from the optimisation are fused into a global volumetric model based on truncated signed distance function, using the open-source InfiniTAM system [36]. The overall framework is summarized in Fig. 3.'\",\"288\":null,\"289\":\"'The normal prediction runs on a PC with Nvidia Titan X graphics card and takes about 0.2s per frame. The running time of other components with fast architecture is about 1.4 seconds per stereo pair (640 \\u00d7 480 resolution) with Matlab code on a 4 core i5-4590 3.30GHz CPU without GPU acceleration. We also implement C++ code and accelerate the solving of the sparse linear system by conjugate gradient algorithm with GPU implementation. We found that using conjugate gradient algorithm with 200 iterations is generally enough, which takes 0.23s on a PC with GTX 960 display card. Thus, with GPU acceleration of linear equation solver, the whole process of our fast version takes about 0.75s per frame with resolution of 640\\u00d7480, which is acceptable for some real-time applications.'\",\"290\":\"'One of the key novel ideas in this work is to create a new type of map based on signals from hydrophone excitation of the metal pipe. This leads to a map of pipe vibration amplitude over space. The problem is that the only way of calibrating the spatial component of the map is by a dead reckoning sensor such as a motor encoder. We assume that the robot will make multiple passes up and down the pipe between two known locations. This means that the map calibration can be improved by spatial averaging. However, taking a direct average of the data would be likely to lead to smoothing of the peaks and troughs in the map, degrading features required for localisation. Instead, the second key novel idea we propose is to use a signal alignment technique to warp the maps in the spatial direction before averaging. This improves the spatial calibration without overly smoothing the map features. The signal alignment and averaging algorithm is based on dynamic time warping (DTW) and is known as DTW barycentre averaging (DBA) [9].'\\n\\n'We demonstrate in this work that the robot can obtain a map of pipe vibration amplitude over space by traveling through the pipe and exciting pipe vibration using a hydrophone. Corresponding locations of the robot can be calibrated using dead reckoning, e.g. from a motor encoder. However, any drift in the dead reckoning estimate will result in an incorrectly spatially calibrated map. A solution to this problem is for the robot to make multiple passes back and forth through the pipe in order to generate a set\\\\nS\\\\nof\\\\nn\\\\nm\\\\nindependent sequences of map data, in order to average out drift errors, where'\",\"291\":null,\"292\":null,\"293\":\"'Skimap encodes seamlessly a full 3D reconstruction of the environment (left), a height map (center) and a 2D occupancy grid (right). The three representations can be delivered on-line with decreasing time complexity. The displayed maps have been obtained on the freiburg campus dataset.'\",\"294\":null,\"295\":null,\"296\":\"\\\"A popular algorithm to encode human activity's temporal patterns is the Conditional Random Field (CRF) [1] method, which is a discriminative graphical model that avoids encoding the distribution of the input. However, CRFs are limited in that they lack the capability to combine latent variables that can capture underlying patterns within the observation [2]. For example, a robot coach may need to model a complex activity \\u201ctennis serve,\\u201d where atomic temporal motion patterns, such as \\u201cball tossing\\u201d and \\u201cracquet swinging,\\u201d are unknown, and thus must be modeled using latent variables. To address this problem, Hidden Conditional Random Fields (HCRFs) [2] were used to combine CRF model's strengths with latent variables. Due to the latent variable's capability to model temporal patterns of a sequence, HCRF methods are widely applied in sequence labeling, such as human activity recognition.\\\"\\n\\n'These previous HCRFs did not well model the uncertainty in the latent temporal pattern; therefore, the latent variables that encode temporal patterns are eliminated either by summation in HCRFs based on maximum likelihood estimation (MLE) [2] or through maximization in max-margin (MM) HCRFs [3]. The latent temporal pattern often provides useful information for improving prediction accuracy [4], [5]. Also, there are many scenarios in which a robot must confidently understand the latent temporal pattern itself. For example, a robot coach teaching \\u201ctennis serve\\u201d must maximize its confidence on the chronological order of \\u201cball tossing\\u201d and \\u201cracquet swinging\\u201d in the temporal-motion pattern.'\",\"297\":null,\"298\":null,\"299\":null,\"300\":\"'http:\\/\\/hcr.mines.edu\\/code\\/FABL.html'\\n\\n'We make the code that implements our FABL approach available at: http:\\/\\/hcr.mines.edu\\/code\\/FABL.html. The remainder of this paper is structured as follows. Related work is described in Section II. Then, our FABL approach is detailed in Sections III and IV. Experimental results are presented in Section V. After discussing several attributes of the proposed FABL method in Section VI, we conclude this paper in Section VII.'\\n\\n'http:\\/\\/hcr.mines.edu\\/code\\/FABL.html'\\n\\n'Our FABL approach is implemented using a combination of Matlab and c++ on a Linux machine with an i7 3.4GHz CPU and 16GB memory. The Matlab code is used to validate our approach on two public datasets: MSR Action3D Dataset [26] and Cornell Activity Dataset [6], while the C++ program is employed for validation on a Baxter robot in a real-world \\u201cserving drinks\\u201d task.'\",\"301\":\"'Plot of the result of each pour using our model-free method as input to the controller. The x-axis is the target amount that the robot was attempting to reach, and the y-axis is the actual amount the robot poured. The points are color-coded by the target container. The black dashed line shows a 1:1 correspondence for reference.'\",\"302\":null,\"303\":\"'The contributions of this paper to the research community are as follows: (1) a free cloud service for learning using simulation in the domain of personal robotics that researchers and robots can interface with remotely, (2) adaptability to other domains thanks to generic and open source implementation and (3) making the data generated from simulation publicly accessible for promoting open-research.'\",\"304\":null,\"305\":\"'(Top) Observed tracklets from 5 uncalibrated cameras (top view). These tracklets correspond to pedestrians that are observed to come in and out of the FOV of the cameras. Different color codes correspond to different track ids. (Bottom) We aim to infer the relative placement of the cameras in the scene.'\",\"306\":null,\"307\":null,\"308\":null,\"309\":null,\"310\":\"'Concerning the firmware itself, the ArduPilot project is written in C++ and supports several overarching frame types including fixed wing plane, rover, antenna tracker, and many copter type UAV. The Coand\\u00e5 effect drone falls under the copter frame category, however no native frame type for the Coand\\u00e5 effect drone exists within the code base. The ArduPilot project is versatile in that the vehicle specific directories allow for any number of flight modes, mission directives, and frame types to be added without drastic code alteration. For this project it was necessary to add a new frame type to the common libraries directory shared by all vehicle specific directories. For initial testing of the developed motor mappings in (7), (8), (9), and (10), the developed PID based APM attitude controller files were utilized to output a desired roll, pitch, yaw, and throttle, while our preliminary motor mapping was implemented in new Coanda frame descriptor files in the motors library [13]. In this way, the desired thrust and torque for control can be affected using the proper servo commands. Several successful flight tests were performed using a preliminary version of the motor mapping, and a still of the prototype mid-flight was captured in figure 8.'\",\"311\":\"'http:\\/\\/flyingmachinearena.org\\/people\\/'\",\"312\":\"'https:\\/\\/youtu.be\\/wfmf-eJ89T4'\\n\\n'https:\\/\\/www.ted.com\\/talks\\/raffaello_d_andrea_meet_the_dazzling_flying_machines_of_the_future'\",\"313\":\"\\\"In this paper, we employ a nominal keyframe-based SLAM system that fuses sensing cues from a monocular camera and an Inertial Measurement Unit (IMU) featuring onboard the UAV's sensor-suite. Since the SLAM map is generated incrementally throughout the flight, we develop a path-planner that can handle changes in the plan on the fly as new unexplored areas of the environment are discovered. Exhibiting such replanning capabilities is particularly important in real missions, as one can never assume that a even a preacquired map of the environment will not change. As a result, this property of the proposed system is key in ensuring the applicability and the robustness of this framework. While the proposed approach is agnostic to the particular Monocular-Inertial SLAM (MIS) system used, in this paper, we present experiments using the open source 1 keyframe-based SLAM system of [3] and [4]. A snapshot of the proposed pipeline in action is visible in Fig. 1.\\\"\",\"314\":null,\"315\":\"'In this paper we introduce a gesture-based robot control framework, we discuss the adopted design principles and we report results about its evaluation with humans. Gesture-based control using wearable devices may constitute a novel form of human-robot interaction, but its implications have not been discussed in the literature. We discuss the main challenging issues, possible design guidelines and an open source, freely available implementation using commercially available devices and robots. The overall performance of the architecture, as well as its validation with 27 untrained volunteers, is reported.'\\n\\n'open source'\\n\\n'Here, we propose a system to guide a mobile robot via gestures obtained using wearable devices. We motivate our design choices on the basis of practical guidelines inspired by the automotive industry. The framework, available open source, has been tested both with respect to performance aspects and considering qualitative human evaluation. Specifically, 27 previously untrained volunteers shared their experiences in using our framework. It is noteworthy that the system has been showcased at the IEEE ICRA 2016 conference in Stockholm, Sweden, where conference attendees had the opportunity to give it a try at the exhibitions.'\",\"316\":null,\"317\":\"'Algorithm 1 describes our approach in pseudo code. The algorithm takes the following arguments as its input (Line 1): a cropped image of the target object\\\\nI\\\\n; two lists of labels which determine the dynamic\\\\n(\\\\nC\\\\nD\\\\n)\\\\nand the static\\\\n(\\\\nC\\\\nS\\\\n)\\\\ncontext in the scene; and two parameters\\\\nn\\\\nand\\\\nt\\\\nwhich control the filtering process (here we used\\\\nn=7\\\\nand\\\\nt=.8)\\\\n). The algorithm returns a label for the target object\\\\nl\\\\n\\u2217\\\\n. First, we initialize the set of candidate labels (Line 3). We then predict a set of labels and their corresponding confidences from the cropped image\\\\nI\\\\nusing a trained CNN (Line 4). After selecting the\\\\nn\\\\nbest labels from the CNN (Line 5), we iterate over these labels, and relate them to all context labels by computing the WUP score (Line 8). If the WUP score is larger than the predefined threshold\\\\nt\\\\n(Line 9), we add the CNN label to the list of candidates (Line 10). Eventually we select the label with the highest confidence from all candidates (Line 14) and return it (Line 15).'\\n\\n'Provision of the software tools used to produce this work as open source software.'\",\"318\":\"'We provide quantitative comparisons to three baselines, with the aim of evaluating whether or not our video prediction model has learned a meaningful and nontrivial notion of objects and physical interaction. Recall that object identity, inertia, and contact dynamics are not provided to nor encoded in the model explicitly, but must be learned entirely from data. Correspondingly, our baselines do not use any knowledge about the objects in the scene, but are reasonably effective for the short horizon pushing tasks that we consider.'\",\"319\":\"'http:\\/\\/www.robobarista.org\\/dme\\/'\\n\\n'First, we pre-train the layers leading up to these layers using sparse de-noising autoencoders [30], [31]. Then, our process for pre-training\\\\nh\\\\n2,pl\\\\nis similar to our approach to fine-tuning a semantically meaningful embedding space for\\\\nh\\\\n3\\\\npresented above, except now we find the most violating language\\\\nl\\\\n\\u2032\\\\nwhile still relying on a loss over the associated optimal trajectory:'\\n\\n'Our Model without Multiple Segmentations: Our model trained only with expert segmentations, without taking utilizing all candidate segmentations in auto-encoders and multiple correct segmentations of the same part during training.'\\n\\n'When our full DME model utilizes two variations of same part and uses all candidates as a training data for the auto-encoder, our model performs at 68.4% compared to 65.1% which only used expert segmentations.'\\n\\n'Commanding mobile robot movement based on natural language processing with RNN encoder\\\\xaddecoder'\",\"320\":\"'http:\\/\\/jaeyongsung.com\\/haptic_feedback\\/'\\n\\n'For controlling robots online, a deep auto-encoder can learn lower-dimensional embedding from images and model-predictive-control (MPC) is used for optimal control [31]. DeepMPC [14] predicts its future end-effector position with a recurrent network and computes an appropriate amount of force. Convolutional neural network can be trained to directly map images to motor torques [3], [32]. As mentioned earlier, we only take input of haptic signals, which suffers from perceptual aliasing, and contains a lot less information in a single timestep compared to RGB images.'\\n\\n'We jointly back-propagate on neural networks for both sets of encoder\\\\n\\u03d5\\\\nand decoder\\\\n\\u03b8\\\\nparameters with mini-batches to maximize the lower bound using AdaDelta [38].'\",\"321\":\"'Algorithm 1 contains detailed pseudo-code for an algorithm based on these ideas, called BOX, which stands for Blackbox Optimization with eXperience. It takes as input:\\\\nw\\\\nn+1\\\\n, the \\u201ctest\\u201d planning problem instance;\\\\nC\\\\n, a constant governing the magnitude of the bounds;\\\\nk\\\\n, the number of solution constraints to evaluate;\\\\n\\u0398\\\\n^\\\\n, the set of solution constraints in the training set;\\\\n\\u03bc\\\\n^\\\\nand\\\\n\\u03a3\\\\n^\\\\n, the parameters for prior distribution of\\\\n\\u03a6(\\\\nw\\\\nn+1\\\\n);J\\\\n, the scoring function; and\\\\n\\u03c0\\\\n, the planner.'\",\"322\":null,\"323\":null,\"324\":null,\"325\":null,\"326\":null,\"327\":null,\"328\":\"'https:\\/\\/youtu.be\\/_2qcU4FcGyE'\\n\\n'https:\\/\\/youtu.be\\/P7utkiVhU-I'\\n\\n'https:\\/\\/youtu.be\\/KhcvUUO-ZE0'\",\"329\":null,\"330\":null,\"331\":null,\"332\":null,\"333\":null,\"334\":\"'Intervention rules are the key component in this IEG architecture and are the data structures that encode the intervention procedures. In developing the system, several rules for robot intervention were defined based on evidence drawn from the medical literature [20]\\u2013[22]. Currently, two prohibition rules and two obligation rules were predefined according to the literatures. These rules have also been reviewed and modified by the PD expert from Tufts University we are collaborating with. The two prohibition rules are \\u201cangry\\u201d and \\u201cquiet\\u201d prohibitions, and the two obligation rules are \\u201cstay in the room\\u201d and \\u201csafety-first\\u201d rules. Brief descriptions of these rules are presented in Table 1. The detailed data structure and computation formalization for each rule are described in the previous paper [19]. For this paper, we describe a procedure used to evaluate these predefined intervention rules, simulating four situations where these rules are fired, so that the robot generates appropriate restorative actions.'\\n\\n\\\"This interview study is a semi-structured one, and therefore we gather mostly qualitative data from the participants. As part of the data gathering process, all interview sessions are recorded. For the analysis, the experimenter watches the recorded interview videos and codes all responses based on an interview-coding sheet. This interview-coding sheet enables the video data to be analyzed in a consistent manner and helps in finding patterns or common opinions among different participants' responses without any bias. Figure 5 illustrates exemplar questions from the interview-coding sheet. After all interview responses are coded, to validate the coding process, the final data is also compared to the co-experimenter's notes, which were taken during the interview sessions.\\\"\\n\\n\\\"To implement this IEG architecture on the robotic system, we use multiple sensors. First, \\u201cangry\\u201d and \\u201cquiet\\u201d prohibitions are detected by the volume of voices. In addition, the \\u201csafety-first\\u201d rule in our scenario requires a speech recognition process. For this purpose, we use an external audio sensor (microphone) with speech recognition method. In implementing this part, we use Sphinx4, an open source speech recognition library [23]. Using the external audio sensor and Sphinx4 API, IEG can detect human speech and volume, which are used to trigger \\u201cangry\\u201d, \\u201cquiet\\u201d, and \\u201csafety-first\\u201d rules. In the current implementation, microphones are used as the external audio sensor and detect the caregiver's and patient's audio data. If the audio volumes are over (or less than) the threshold volume, they are determined as violations of the \\u201cangry\\u201d or \\u201cquiet\\u201d rules. The threshold volumes and times are determined empirically by the experimenter in the current version.\\\"\\n\\n\\\"There are several ways to detect a human's absence for the \\u201cstay in the room\\u201d obligation. As an initial implementation, we use a camera sensor, so the system can detect and track human faces. In other words, when the patient's face is continuously undetected more than the threshold time (i.e., the time to absence the tracked patient's face is over the threshold), the robot can trigger the \\u201cstay\\u201d obligation to be fired. For facial recognition and tracking, we use OpenCV, an open source computer vision library [24]. Alternatively, a sensor in the chair could also be used in the future.\\\"\",\"335\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/28966797'\",\"336\":null,\"337\":null,\"338\":\"'An update for the encoded TCP trajectory\\\\nx\\\\n\\u2032\\\\nd,k\\\\n(\\u03be)\\\\nis then given by'\",\"339\":null,\"340\":null,\"341\":null,\"342\":null,\"343\":null,\"344\":null,\"345\":\"'Longitudinal velocity estimation; a thin line indicates a longitudinal velocity by numerical differentiation with signals from encoders while a think line a longitudinal velocity estimated by the kalman filter.'\",\"346\":null,\"347\":null,\"348\":null,\"349\":null,\"350\":null,\"351\":null,\"352\":null,\"353\":\"'Traditionally, classical approaches from statistics are used to encode descriptors while maximizing their information content. The most commonly used linear technique, principal component analysis [7], performs a mapping to the hyperplane maximizing data variance. Other techniques try to generalize this idea to non-linear mappings by either using the kernel trick [15] or with graph based methods [16]\\u2013[18]. However, such unsupervised projections are not tuned on the final matching task.'\\n\\n'In this paper, we will generalize the techniques mentioned above to encode any given type of image patch descriptor in a compact Euclidean space while increasing discriminability. With our results, establishing the 2D-3D matches required by image-based localization algorithms is both reliable and efficient, even in challenging environments.'\",\"354\":null,\"355\":null,\"356\":\"'Most place recognition pipelines eventually perform absolute or relative pose estimation to either localize in a given map or to ensure that the retrieved place is geometrically consistent with the query frame. Our loop closure detection algorithm is concerned with the latter case. Implementations of the following camera pose computation methods are open source and published in [17].'\",\"357\":null,\"358\":\"'In order for autonomous robots to operate in unstructured environments, several perceptual capabilities are required. Most of these skills cannot be hard-coded in the system beforehand, but need to be developed and learned over time as the agent explores and acquires novel experience. As a prototypical example of this setting, in this work we consider the task of visual object recognition in robotics: Images depicting different objects are received one frame at a time, and the system needs to incrementally update the internal model of known objects as new examples are gathered.'\\n\\n'B. Incremental Recoding\\\\nThe main algorithmic difference between standard RLSC and the variant with recoding is in the matrix\\\\nY\\\\ncontaining output training examples. Indeed, according to the recoding strategy, the vector\\\\ne\\\\ny\\\\nk\\\\nassociated to an output label\\\\ny\\\\nk\\\\nis coded into\\\\nc(\\\\ne\\\\ny\\\\nk\\\\n)=\\\\ne\\\\ny\\\\nk\\\\n\\/\\u03c1(y=\\\\ny\\\\nk\\\\n)\\\\n. In the batch setting, this can be formulated in matrix notation as\\\\nW=(\\\\nX\\\\n\\u22a4\\\\nX+\\u03bb\\\\nI\\\\nd\\\\n)\\\\n\\u22121\\\\nX\\\\n\\u22a4\\\\nY\\u0393,\\\\nView Source where the original output matrix is replaced by its encoded version\\\\nY\\\\n(c)\\\\n=Y\\u0393\\u2208\\\\nR\\\\nn\\u00d7T\\\\n, with\\\\n\\u0393\\\\nthe\\\\nT\\u00d7T\\\\ndiagonal matrix whose t-th diagonal element is\\\\n\\u0393\\\\ntt\\\\n=1\\/\\u03c1(y=t)\\\\n. Clearly, in practice the\\\\n\\u03c1(y=t)\\\\nare estimated empirically (e.g. by\\\\n\\u03c1\\\\n^\\\\n(y=t)=\\\\nn\\\\nt\\\\n\\/n\\\\n, the ratio between the number\\\\nn\\\\nt\\\\nof training examples belonging to class\\\\nt\\\\nand the total number\\\\nn\\\\nof examples).\\\\nThe above formulation is favorable for the online setting. Indeed, we have\\\\nX\\\\n\\u22a4\\\\nk\\\\nY\\\\nk\\\\n\\u0393\\\\nk\\\\n=\\\\nb\\\\nk\\\\n\\u0393\\\\nk\\\\n=(\\\\nb\\\\nk\\u22121\\\\n+\\\\nx\\\\n\\u22a4\\\\nk\\\\ny\\\\nk\\\\n)\\\\n\\u0393\\\\nk\\\\n,\\\\n(21)\\\\nView Source where\\\\n\\u0393\\\\nk\\\\nis the diagonal matrix of the (inverse) class distribution estimators\\\\n\\u03c1\\\\n^\\\\nup to iteration k.\\\\n\\u0393\\\\nk\\\\ncan be computed incrementally in O(T) by keeping track of the number\\\\nk\\\\nt\\\\nof examples belonging to\\\\nt\\\\nand then computing\\\\n\\u03c1\\\\n^\\\\nk\\\\n(y=t)=\\\\nk\\\\nt\\\\n\\/k\\\\n(see Alg.1 for how this update was implemented in our experiments). Note that the above step requires O(dT), since updating the (uncoded) bk from\\\\nb\\\\nk\\u22121\\\\nrequires O(d) and multiplying bk by a diagonal matrix requires O(dT). All the above computations are dominated by the product\\\\nA\\\\n\\u22121\\\\nk\\\\nb\\\\nk\\\\n, which requires\\\\nO(T\\\\nd\\\\n2\\\\n)\\\\n. Therefore, our algorithm is computationally equivalent to the standard incremental RLSC approach.\\\\nCoding as a Regularization Parameter\\\\nDepending on the amount of training examples seen so far, the estimator\\\\nk\\\\nt\\\\n\\/k\\\\ncould happen to not approximate\\\\n\\u03c1(y=t)\\\\nwell. In order to mitigate this issue, we propose to introduce a parameter\\\\n\\u03b1\\u2208[0,1]\\\\nand raise\\\\n\\u0393\\\\nk\\\\nelement-wise to the power of\\\\n\\u03b1\\\\n(indicated by\\\\n(\\\\n\\u0393\\\\nk\\\\n)\\\\n\\u03b1\\\\n). Indeed, it can be noticed that for\\\\n\\u03b1=0\\\\nwe recover the (uncoded) standard RLSC, since\\\\n(\\\\n\\u0393\\\\nk\\\\n)\\\\n0\\\\n=\\\\nI\\\\nT\\\\n, while\\\\n\\u03b1=1\\\\napplies full recoding. In Sec VI-C we discuss an efficient heuristic to find\\\\n\\u03b1\\\\nin practice.\\\\nIncremental Rebalancing\\\\nNote that the loss-rebalancing algorithm (Sec. III-D) cannot be implemented incrementally. Indeed, the solution of the rebalanced empirical RLSC is\\\\nW\\\\nk\\\\n=(\\\\nX\\\\n\\u22a4\\\\nk\\\\n\\u2211\\\\nk\\\\nX\\\\nk\\\\n+\\u03bb\\\\nI\\\\nd\\\\n)\\\\n\\u22121\\\\nX\\\\n\\u22a4\\\\nk\\\\n\\u2211\\\\nK\\\\nY\\\\nk\\\\n,\\\\n(22)\\\\nView Source with\\\\n\\u03a3\\\\nk\\\\na diagonal matrix whose i-th entry is equal to\\\\n(\\\\n\\u03a3\\\\nk\\\\n)\\\\nii\\\\n=1\\/\\\\n\\u03c1\\\\n^\\\\n(y=\\\\nt\\\\ni\\\\n)\\\\n, with\\\\nt\\\\ni\\\\nthe class of the i-th training example. Since\\\\n\\u03a3\\\\nk\\\\nchanges at every iteration, it is not possible to derive a rank-one update rule for\\\\n(\\\\nX\\\\n\\u22a4\\\\nk\\\\n\\u03a3\\\\nk\\\\nX\\\\nk\\\\n+\\u03bb\\\\nI\\\\nd\\\\n)\\\\n\\u22121\\\\nas for the standard RLSC.'\",\"359\":null,\"360\":null,\"361\":null,\"362\":null,\"363\":\"'https:\\/\\/www.youtube.com\\/watch?v=cp1201phPts'\\n\\n'Algorithm 1 presents the pseudocode for the human face detection and tracking algorithm. The algorithm has two modes: face detection and KLT tracking. 1) The algorithm detects the human face using Haar features for the first several frames to prevent misdetection. Once a human face is detected, it extracts the feature points within the face region for the tracking mode. 2) In the face tracking mode, the algorithm matches the corner feature points of the new frame with the corner feature points from the previous frame, and it estimates the geometric displacement between these two sets of corner points. The displacement vector is applied to the previous face bounding box to obtain the new bounding box, so the algorithm can continuously track the human face. Once the number of corner points is below a certain threshold\\\\nb\\\\n, the mode switches back to face detection. A frame of the blimp video processed with algorithm 1 is shown in figure 4. The yellow rectangle is the bounding box that the algorithm recognizes as the area of the human face and the white crosses are the corner feature points.'\",\"364\":null,\"365\":null,\"366\":null,\"367\":null,\"368\":null,\"369\":\"'In contrast to the aforementioned methods, the goal of this paper is to modify the trajectories in a provably safe manner that is compatible with existing control and planning techniques, while exploiting the nonlinear dynamics (allowing significant deviation from hovering state and large Euler angles) of teams of quadrotors. To achieve this objective, all collision-free states of the quadrotors are encoded in a safe set. Then, Safety Barrier Certificates are synthesized based on the differential flatness property, and a class of non-conservative control barrier functions [2], [21], [14] are used to ensure the forward invariance of the safe set. Control barrier functions were used in [19], [20] to avoid static\\/moving obstacles for a single planar or 3D quadrotor. And Safety Barrier Certificates have been applied to teams of ground mobile robots as well for collision avoidance [17], [16]. As such, in this paper, the certificates are extended to more complicated multi-quadrotor systems.'\",\"370\":\"\\\"We have described a system architecture for robust, synchronized, dynamic control of the largest indoor quadcopter swarm to date. Our system fully utilizes the vehicles' onboard computation, allowing for robustness against unreliable communication and a rich set of trajectory planning methods requiring little radio bandwidth. Tests show good scalability for both latency and tracking performance with respect to the swarm size. For a swarm of 49 vehicles, only 3 radios are required and we obtain a latency below 30 ms, allowing moderately aggressive flight maneuvers using onboard state estimation with mean tracking errors below 2 cm. Our full source code, including tuned parameters such as EKF variances and controller gains, is available at https:\\/\\/github.com\\/USC-ACTLab\\/crazyswarm.\\\"\\n\\n'Here we describe the system architecture for a swarm of 49 very small quadcopters operating indoors. The vehicles use a motion-capture system for localization and communicate over three shared radios. Our system uses off-the-shelf hardware and performs most computation onboard. We publish the software as open-source1, making our work easily reusable for other researchers. To our knowledge, the system described here is the largest indoor quadcopter swarm to date, and the largest number of quadcopters controlled per radio.'\\n\\n'In future work, we plan to improve reliability by detecting controller failures, improving object tracking failure recovery, and including better planning methods which take aerodynamic effects such as downwash into account explicitly. We have made all software components available as open-source, and hope that our work will have a significant impact as a testbed for experimental verification of existing and new UAV swarming algorithms. In general, our system can serve as a foundation for a wide range of future work in multi-robot planning, coordination, and control.'\",\"371\":null,\"372\":null,\"373\":null,\"374\":null,\"375\":null,\"376\":null,\"377\":null,\"378\":null,\"379\":\"'https:\\/\\/sites.google.com\\/site\\/deeproboticmanipulation'\\n\\n'https:\\/\\/sites.google.com\\/site\\/deeproboticmanipulation'\",\"380\":null,\"381\":null,\"382\":null,\"383\":null,\"384\":\"'In manufacturing, logistics, and other industrial domains, many tasks involve handling of objects. To automate such tasks using a robotic manipulator, object positions are usually fixed so that robot movements can be hard-coded into the automation solution. Whenever objects, positions or tasks change frequently this approach cannot be applied. Potentially, the manipulation task at hand has never been encountered before. In such cases, the actions of the robot need to planned autonomously. An illustration of a manipulation task with one object is given in Fig. 1.'\\n\\n'The implementation of the algorithms uses the open source library FCL [25] for collision checks which is accessed via the planning scene of MoveIt! [26]. For nearest neighbor search we use randomized\\\\nk\\\\n-d trees [27] implemented in the FLANN library [28]. To speed up roadmap construction it is run in parallel using OpenMP [29]. All experiments are run on a ten-core Intel Xeon E5-2650v3.'\",\"385\":null,\"386\":null,\"387\":null,\"388\":\"\\\"A friction cone constraint was also coded into the simulation, assuming a friction coefficient of 1 for rubber on solids between a finger and object. This friction coefficient is conservative, as the material combination of rubber on solids has an estimated friction coefficient in the range of 1\\u20134 according to [15]. This creates a friction cone of O.785rad about the axis of each finger's surface normal at the point of contact. Because the GR2 is modeled as a closed linkage, the contact forces must be collinear, otherwise a net torque would be applied to the object, breaking the assumption of quasistatic manipulation. Thus, if the fingers configure in such a way that the line connecting the contact forces moves outside of the friction cones, this constraint is violated and the tracing ends for that grasper.\\\"\",\"389\":null,\"390\":null,\"391\":null,\"392\":null,\"393\":\"'This preliminary study separately validated the algorithms in two planar cases under different simulation software and programming languages, so future work is to port the code and integrate them into one codebase for the control of 3D walking. Although the control strategy currently uses only these two proposed nonlinear models, other models can also be utilized for accomplishing other tasks, e.g., a SLIP model for running. A more challenging research is to combine our forward model approach together with the state of the art inverse dynamics method, which, to some extent, is comparable to the mechanism how the cerebellum produces motor control [17].'\\n\\n'Algorithm 1: Determine Foot Placement (Pseudo Code)'\",\"394\":\"'Optical encoders measuring the absolute angle for the inner leg, and the angle between the legs were installed, from which q1 and q2 could be calculated in real-time. An observer based on the linearized pendulum dynamics was designed to observe velocities\\\\nq\\\\n\\u02d9\\\\n1\\\\nand\\\\nq\\\\n\\u02d9\\\\n2'\",\"395\":null,\"396\":null,\"397\":null,\"398\":null,\"399\":null,\"400\":\"'Developmental robotics seeks to build robots that learn to interact with the environment largely autonomously. These robots can calibrate their sensorimotor competencies on their own, much like developing children. In this paper, we build a developmental model of image stabilization based on the active efficient coding (AEC) framework and apply the model to a real robotic platform. In the visual system of primates, the optokinetic response (OKR) and the vestibulo-ocular reflex (VOR) cooperate to ensure image stabilization during relative motion between the observer and the environment. Inspired by these biological findings, our model integrates visual, inertial and motor encoder sensory cues. The sensory processing and the motor policy co-develop. The visual processing is based on a sparse coding algorithm. Motor behavior is learned using reinforcement learning. Our results show that the stabilization performance is improved by integrating visual and inertial inputs. Importantly, the weighting between the two inputs is learned automatically as the robot interacts with the environment.'\\n\\n'We model the visual sensory and motor processing by populations of model visual cortical and motor neurons, whose weight matrices are learned as the robot behaves in the environment. Both perception (determined by the wiring from visual input to the visual cortical neurons) and behavior (determined by the wiring from model visual neurons and from the inertial inputs and wheel encoder inputs to the motor neurons) develop simultaneously. The connections from the retina to visual cortical neurons are learned according to a sparse coding model. The efficient coding hypothesis has been modeled mathematically by sparse coding algorithms [12]. The connections to the motor neurons, which control eye movements, are learned by reinforcement learning using the natural actor critic algorithm described in [13].'\\n\\n'Figure 4 shows the evolution of the average correlation during training by including and excluding the inputs from wheel encoders. In Figure 4 (a), the head position during training and testing was fixed at pan angle 30 degrees and tilt angle 0 degree, where angles are measured relative to the direction of forward motion. In Figure 4 (b), the head moved randomly in both pan and tilt directions. The velocity in each direction was chosen uniformly between\\\\n\\u00b130\\\\ndeg\\/s. If the head position is fixed, the inputs from body movements increase the learning speed and the performance (correlation 0.95 versus 0.93). If the head moves, the inputs from body movements do not improve the learning speed and performance much.'\\n\\n'Next, we investigate the learned weighting of visual and inertial inputs. The visual system is representative of the OKR and the inertial system is representative of the VOR. In these experiments, the head moves during training and we include the wheel encoder inputs. During testing, the body remains stationary and only the head rotates. Figure 5 shows the evolution of the visual and inertial gains during training. The gain is computed by averaging the ratio between eye velocity and head velocity over time and over the different sequences. The weighting of the two cues is learned automatically and the final gains of each system are consistent with biological data [11]. Our model predicts that if the correlation between the visual and inertial cues is low, the robot will rely more visual cues for image stabilization and that the performance of the inertial system will degrade. The correlation of the two cues depends on the statistics of the motion of the head, the body, and the environment. If both the body and environment are static, the learned gain of the inertial system is close to 1 as used in the initialization'\",\"401\":\"'Algorithm 1: Pseudo code of the Adaptive L\\u00e9vy Taxis algorithm'\\n\\n\\\"The pseudo-code above provides an overview of the proposed ALT. In this algorithm, at the beginning of each step, the position of the agent as well as the local wind direction and the odor concentration are logged. Then the odor gradient is calculated using the last step's log. Using this information,\\\\nM\\\\nl\\\\nand\\\\nT\\\\na\\\\nare calculated to determine the goal towards which the agent has to walk. Once the source is found, which is determined thanks to an external input, the agent declares success and terminates the algorithm. In case the robot reaches the limits of the experimentation area, it declares failure and terminates. On top of that, we used a limit for the number of steps, for the agent to avoid spending too much experimentation time wandering far from the source. If this steps limit is reached, the algorithm also declares failure.\\\"\",\"402\":null,\"403\":null,\"404\":null,\"405\":\"\\\"To evaluate TRINA's capabilities, we identified twenty-six patient-care tasks frequently practiced by nurses, and carried out trials in a simulated patient room at Duke University School of Nursing. Results indicate that TRINA controlled by an expert operator can perform many routine nursing tasks including preparing and serving food, beverages and medicine to patients, moving medical devices (e.g., a medical cart, patient transfer bed, portable computer, walker, etc.), collecting medical devices (e.g. medicine bottles, syringe packages, IV tubing packages, etc.), operating storage cabinets, scanning bar codes on medical supplies, moving patients, and cleaning patient room debris. It can also take measurements from the patient room environment (e.g., temperature and humidity) using wireless sensors, and collect vital signs of conscious patients (e.g., blood oxygen saturation and blood pressure).\\\"\",\"406\":\"'http:\\/\\/hamlyn.doc.ic.ac.uk\\/vision\\/'\",\"407\":null,\"408\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/29218235'\",\"409\":\"'In our previous research, we had built the \\u201cTeach and Play\\u201d function in the joint space, which can repeat the complicated trajectory by the recording the encoder value in each joint motor.'\",\"410\":null,\"411\":\"'http:\\/\\/sydney.edu.au\\/acfr\\/agriculture'\\n\\n'Typically, prior work utilises hand engineered features to encode visual attributes that discriminate fruit from non-fruit regions [2]\\u2013[4]. Although these approaches are well suited for the dataset they are designed for, feature encoding is generally unique to a specific fruit and the conditions under which the data were captured. More recently, advances in the computer vision community have translated to agrovision (computer vision in agriculture), achieving state-of-the-art results with the use of Deep Neural Networks (DNNs) for object detection and semantic image segmentation [5], [6]. These networks avoid the need for hand-engineered features by automatically learning feature representations that discriminately capture the data distribution.'\",\"412\":\"'The robotic manipulator for stalk strength measurements: (a) Maxon motor ec16 brushless DC motor; (b) maxon motor gp16S ball screw; (c) acetal plunger block; (d) v-block for centering plants; (e) code laboratories duo3d stereo camera; (f) sun shield; (g) needle for penetrating stalk walls; (h) futek llb215 load cell; (i) track for actuating fingers; (j) instrumentation amplifier and a2D converter.'\\n\\n'Robot Operating System (ROS) and a variety of its open source packages are used for the software framework. Nodes were written or sourced to communicate with sensor hardware, to communicate with the base platform remotely to query data and send commands, to perform co- ordinate frame transform calculations for individual sensors, to fuse sensor data and perform state estimation, and to visualize sensor data.'\",\"413\":\"'http:\\/\\/www.ece.ust.hk\\/-eeshaojie\\/icra2017jing.mp4'\",\"414\":null,\"415\":null,\"416\":null,\"417\":null,\"418\":\"'An experiment was conducted to determine the effect of actuation tension on the displacement change of the sensing wire due to the sheath compression. Actuation tension from 1 N to 50 N was applied, and the encoder signal indicating the displacement of the sensing wire was measured to see how the sheath compressed. This experiment was conducted with three bend angles (0\\u00b0, 90\\u00b0, and 180\\u00b0) to check whether the bend angle of the sheath affects compression and the assumption in (5) is reasonable. It is shown in Fig. 8 that the displacement of the sensing wire increases proportional to the input tension of the actuation wire. There exists a hysteresis in the relationship between the input tension and the displacement change which originated from friction along the wire. But the hysteresis can be roughly approximated to a linear relation as is assumed in (5). In addition, there is no distinct difference between different bend angles with a linear slope of 2.0 N\\/count. Therefore, the equation estimating the bend angle of the sheath, (5), can be used to calculate the bend angle of the Bowden-cable actuation system.'\",\"419\":null,\"420\":\"'Electric Corporation, ZKG-5YN, maximum on-state torque: 0.5 Nm), an encoder, a constant force spring (wire drawing force: 0.2 kgf), a wire (maximum length: 1500 mm, diameter: 0.8 mm), a pulley, and three gears. A servo brake, a pulley for winding wire, and an encoder are geared, and the gear ratio is 1: 2: 6. The wire length is measured using the encoder, and the braking torque is exerted by the brake units, which are connected to a controller box with a control period of 1 msec.'\\n\\n\\\"Note that the constant force spring is used to wind the wire, thus preventing the loss of tension. This is because the passive system, unlike active systems, cannot generate continuous wire tension. Also, there is a limitation on the feasible force because the passive system cannot generate the driving force itself. That is, when the user moves towards a braking unit, the braking force will make the wire loose i.e. in an uncontrollable state. Hence, considering the plane perpendicular to the traveling direction of the wire, we arranged the units so as to be always behind the plane. However, this brake units' arrangement imposes a burden on the user, since the forces acting in the direction to stop the user's motion are increased. Therefore, in order to reduce the burden, we arranged three units without servo brakes and encoders on the opposite side of the brake units, each of them with a constant force spring (wire drawing force: 0.4 kgf), a pulley, and a wire.\\\"\",\"421\":null,\"422\":\"'The experimental setup used for analyzing the passive return mechanisms uses for actuation a Maxon DC motor (RE 25mm, 20 Watt) equipped with an optical encoder (HEDL-5540) with the resolution of 2000 CPT. A through-hole load cell (Dongshin CWFS-50) is used for measuring buckling force, and it is placed between the motor and passive return mechanism. A linear potentiometer (Radian Co. RDP-100) is used for measuring the displacement during contraction and lengthening of TSA. The experimental setup was placed in a horizontal configuration, with a ball-bearing slider allowing smooth positioning of the load driven by the TSA. Dyneema string with length of 16 cm and radius of 1 mm is chosen. The twisted string is placed so that most of the length is covered by return mechanism. The experimental setup for testing the two passive return mechanisms (slit and telescopic) is shown in Fig 8.'\",\"423\":null,\"424\":null,\"425\":null,\"426\":null,\"427\":null,\"428\":null,\"429\":null,\"430\":null,\"431\":null,\"432\":null,\"433\":null,\"434\":null,\"435\":\"\\\"We encode the calibration errors in a set of parameters\\\\n\\u03b2\\\\nrepresenting offsets in the robot's arm joints, i.e.:\\\\nq\\\\nr\\\\n=q+\\u03b2\\\\n, where\\\\nq\\\\nr\\\\nare the real angles and q are the measured angles. Given an estimate of the joint offsets\\\\n\\u03b2\\\\n^\\\\n, a better end-effector's pose estimate can be computed by:\\\"\",\"436\":null,\"437\":\"'Our data set comes with the source code for both evaluation metrics, with and without scaling, and decomposing the errors in x, y and\\\\nz\\\\ndirections for testing trajectories provided by pure 2D approaches. This should make the benchmark accessible to a wide variety of algorithms. For RPE, we express errors in percentages by dividing all distances with the average path length l, similar to the KITTI benchmark [5]. The identical program will be run to measure the accuracy of trajectories for the test sequences with hidden ground truth.'\\n\\n\\\"We present PennCOSYVIO, a new challenging Visual Inertial Odometry (VIO) benchmark with synchronized data from a VI-sensor (stereo camera and IMU), two Project Tango hand-held devices, and three GoPro Hero 4 cameras. Recorded at UPenn's Singh center, the 150m long path of the hand-held rig crosses from outdoors to indoors and includes rapid rotations, thereby testing the abilities of VIO and Simultaneous Localization and Mapping (SLAM) algorithms to handle changes in lighting, different textures, repetitive structures, and large glass surfaces. All sensors are synchronized and intrinsically and extrinsically calibrated. We demonstrate the accuracy with which ground-truth poses can be obtained via optic localization off of fiducial markers. The data set can be found at https:\\/\\/daniilidis-group.github.io\\/penncosyvio\\/.\\\"\\n\\n'We present PennCOSYVIO, a new challenging in-door\\/outdoor VIO data set for hand held devices that covers both indoors and outdoors environments and comes with ground truth trajectories for benchmarking. For more details please visit https:\\/\\/daniilidis-group.github.io\\/penncosyvio\\/.'\",\"438\":\"'We open source our implementation of MSGD with all the datasets (https:\\/\\/github.com\\/chaogao-cam\\/MSGD).'\\n\\n'To evaluate the performance of MSGD we compare it to open source implementations of g2o3, Toro4, and SGD. We implemented the latter using C++ to provide a direct comparison with MSGD. The SGD implemented here randomly selected a constraint to process each time (as in [19]) rather than iterating through all constraints in a fixed order (as in [20]) because we found randomisation (which is better for escaping local minima) gave much better performance for all our datasets.'\",\"439\":\"'https:\\/\\/youtu.be\\/L9rHht8fE5E'\",\"440\":null,\"441\":null,\"442\":null,\"443\":null,\"444\":\"'As wireless radio link, we use an 433 MHz open source radio platform named SiK Telemetry Radio (formerly known as 3DR Radio). The very small and lightweight module (approximately 4 g without antenna) features air data rates up to 250 kbps, Frequency Hopping Spread Spectrum (FHSS), adaptive Time Division Multiplexing (TDM), and built-in error correcting code, which can correct up to 25% data bit errors, to name but a few.'\",\"445\":null,\"446\":null,\"447\":null,\"448\":null,\"449\":null,\"450\":\"'We present two systems that use a joint optimisation approach to improve curvature and pose estimates on syn- thetic and real-world datasets. We show that this approach can not only be used to improve offline dataset accuracy over state of the art techniques such as dense ICP bundle adjustment but can also be incorporated into a real-time system to greatly reduce pose drift to improve the results of re-localisation and loop-closure. We provide all described systems as open-source to be used freely in robotic vision applications, which will be provided upon publication. The current implementation of joint optimisation across multiple frames has not been fully optimised, but has been designed such that a GPU implementation should be a relatively simple extension of this work.'\",\"451\":null,\"452\":\"'The hand-arm relationship is encoded as edge relationship between the hand and the arm. We check if there is a hand node close to the arm node and enforce the constraint that the hand is along the direction of the arm.'\",\"453\":\"'In this paper we propose an efficient solution to jointly estimate the camera motion and a piecewise-rigid scene flow from an RGB-D sequence. The key idea is to perform a two-fold segmentation of the scene, dividing it into geometric clusters that are, in turn, classified as static or moving elements. Representing the dynamic scene as a set of rigid clusters drastically accelerates the motion estimation, while segmenting it into static and dynamic parts allows us to separate the camera motion (odometry) from the rest of motions observed in the scene. The resulting method robustly and accurately determines the motion of an RGB-D camera in dynamic environments with an average runtime of 80 milliseconds on a multi-core CPU. The code is available for public use\\/test.'\\n\\n'The code, together with the demonstration video, can be found here:'\",\"454\":\"'We present two experiments. The first demonstrates that contact information from the GelSight sensor can be used to quantitatively improve tracking performance for manipulation. The second employs our tracking framework to track manipulation of a small tool, and demonstrates qualitative improvement of tool pose during the manipulation. Both experiments run the same code, with the only difference being minor parameter changes made between experiments to increase the stability of the tracking of the small tool.'\",\"455\":null,\"456\":null,\"457\":null,\"458\":\"\\\"The source code for the experiments can be found on the author's webpage.\\\"\",\"459\":null,\"460\":null,\"461\":null,\"462\":\"'Since we assume there is uncertainty in the state of robot and objects, we need to encode uncertainty into the state of the graph. In this work, we represent a state of a graph s as a belief state which is a set of particle sub-states\\\\nP={\\\\nP\\\\n0\\\\n, \\\\nP\\\\n1\\\\n, \\u2026, \\\\nP\\\\nm\\\\n}\\\\n(see Fig. 1). Each particle\\\\nP\\\\nj\\\\nconsists of the pose information of the robot and objects\\\\n{(\\\\np\\\\nr\\\\n, \\\\nR\\\\nr\\\\n), (\\\\np\\\\no1\\\\n, \\\\nR\\\\no1\\\\n), \\u2026, (\\\\np\\\\non\\\\n, \\\\nR\\\\non\\\\n)}\\\\n.'\",\"463\":null,\"464\":null,\"465\":null,\"466\":\"'To validate the reference spreading hybrid control, we have created a simulation environment starting from an available code to compute the free-floating dynamics of the humanoid robot iCub [13], and adding suitable contact detection and velocity reset maps for the intended impacting motion task.'\",\"467\":null,\"468\":null,\"469\":\"'We wish to thank the Simulation and Optimization group of H. G. Bock at Heidelberg University for providing the optimal control code MUSCOD.'\",\"470\":null,\"471\":null,\"472\":null,\"473\":null,\"474\":null,\"475\":\"'Robotic finger testbed with customizable tendon routing, originally designed and manufactured by si tech engineering (snoqualmie, wa). Tendons are connected to force-controllable moving coil linear actuators (lca50-050-75-2, SMAC corporation, carlsbad, ca) with in-line tension load cells (mlp-10, transducer techniques, LLC, temecula, ca). Finger joints contain embedded angle sensors (as5048 magnetic rotary encoder, ams AG, premstaetten, austria). For fingertip force analysis, a grounded six-axis force\\/torque transducer (f\\/t nano17 SI-50-0.5, ATI industrial automation, garner, nc) is connected to the fingertip using an adapter that constrains fingertip position but allows free rotation of the distal link.'\",\"476\":null,\"477\":null,\"478\":null,\"479\":null,\"480\":null,\"481\":null,\"482\":null,\"483\":\"'Fig. 6 shows the joint GSM distributions for the four use cases. As can be seen, the GSMs for the fridge, table, and block tower use cases encode precisely what we would expect: in the first two cases, the expected success drops near the passive bottles (and the edge of the shelf for the fridge); in the last case, success can only be expected within the boundaries of the passive block. We can also note that the container use case has no GSM along y; this is because the compartments in\\\\nC\\\\n\\u03b4\\\\nhave no\\\\ny\\\\nseparation whatsoever, so the joint GSM is a one-dimensional distribution.'\",\"484\":\"'Supermarket self-checkout - With Pepper acting as the cashier, the children scans their purchase using QR codes and pays with coins, which Pepper has to count using its camera.'\",\"485\":\"'http:\\/\\/www.actioncores.org\\/'\\n\\n'The probabilistic first-order knowledge bases used for inference by the Prac system are encoded in Markov logic networks [23]. So far, Prac is capable of proficiently analyzing single-sentence instructions and extracting explicit information from them as well as inferring knowledge that is not explicitly given by performing a missing information inference through semantic information retrieval. Such inferred knowledge may be which tools to use for executing a certain task, which spice to be used for seasoning certain food types or the amount and unit of a substance. As in the example instruction mentioned above, there is no explicit information given about the spice to be used, but the system is able to fill the missing role spice from the trained model with, for example, salt and\\/or pepper. For a more detailed discussion of the Prac learning and reasoning system, we refer to [20], [21].'\\n\\n'Commanding mobile robot movement based on natural language processing with RNN encoder\\\\xaddecoder'\",\"486\":\"'All of these approaches have in common is that they are data-intensive und learn rather shallow mappings between natural-language terms and perceptual attributes in mostly unsupervised manners. To the best of our knowledge, our approach is the first that makes heavy use of available knowledge and ontological information, which leverages costly data acquisition and preprocessing steps. It can deal with concepts and terms that have never been encountered in any training data, since every term in the system has a well-defined semantics and disambiguation, extraction and mapping of visual attributes takes into account their similarities that are encoded in the underlying taxonomy of concepts.'\\n\\n'In this work, we use the Robosherlock system as an implementational basis for performing robot perception. Robosherlock is an open-source framework that allows easy creation of processing pipelines consisting of arbitrary perception and image processing algorithms. The basic pipeline works as follows. In a first step, a scene that is perceived as an RGB-D image is segmented into multiple regions of interest, so-called subjects of analysis (SofA), which potentially correspond to objects in the scene. In a second step, the single SofAs are analyzed for their visual attributes by multiple perceptual routines, called annotators, whose outputs are attached to each SofA. An annotator can wrap any arbitrary perception algorithm and hence can be thought of an \\u2018expert\\u2019 with respect to the expertise of that algorithm. The \\u2018color\\u2019 annotator, for example, analyzes a SofA with respect to colors and attaches symbolic color values such as red and yellow to it. Complementary, the \\u2018shape\\u2019 annotator performs primitive shape fitting and attaches symbols like box or cylinder to the SofA. Other annotators perform optical character recognition to extract text from the SofA or use web services like Google goggles in order to find brand logos on the object under consideration.'\",\"487\":null,\"488\":\"'We implemented a sparse online variant of GP (SOGP) built upon the open-source library libgp [3]. A careful downsampling of ROMS data to a desired resolution is performed to alleviate the computational cost for generating informative sampling locations. The resolution of the grid map is\\\\n351\\u00d7\\\\n391, whereas the resolution for the sampling spots generation (path planning) is\\\\n12\\u00d712\\\\n.'\",\"489\":null,\"490\":null,\"491\":null,\"492\":null,\"493\":null,\"494\":null,\"495\":\"'http:\\/\\/scidraw.nd.edu\\/'\",\"496\":null,\"497\":\"'In contrast to the previously mentioned methods, our approach does not alter the BVH approach directly. We introduce an early-out before the BVH traversal. But of course, the previously presented acceleration approaches of a BVH can be used in conjunction with our method in order to further improve the sampling performance in a motion planner. In this work, we use the BVH implementation of the open source Flexible Collision Library (FCL) [11] and the Proximity Query Package (PQP) [12].'\",\"498\":null,\"499\":null,\"500\":null,\"501\":null,\"502\":null,\"503\":null,\"504\":null,\"505\":null,\"506\":\"\\\"We'd like to thank Rogerio Richa for his help with the code. Also, we'd like to thank Ankush Roy et al. from University of Alberta for their open source tracking framework and tracking benchmark.\\\"\",\"507\":null,\"508\":null,\"509\":null,\"510\":null,\"511\":null,\"512\":\"'http:\\/\\/visual.cs.uel.ae.uk\\/pubs\\/eofusion\\/index.html'\\n\\n'For reasons of robustness and efficiency this optimization is embedded in a coarse-to-fine approach using a 4-layer spatial pyramid. Our GPU implementation builds on the open source code release of [30].'\",\"513\":null,\"514\":null,\"515\":null,\"516\":\"'http:\\/\\/www.albertpumarola.com\\/research\\/pl-slam\\/'\",\"517\":\"'By construction, the control point generation is highly related with the change rate in the first and second derivative of the curve to be modeled and, therefore, to its shape. In consequence, we prefer its use over other models because spline models encode the curvature level: in smooth trajectories, the control points tend to be close to the curve and evenly separated. On the other hand, in trajectories with high changes in shape, the control points tend to be separated from the curve and with larger distances between them.'\",\"518\":null,\"519\":\"'We implemented the first-order variant included in the open source code of [32], which is well-performing according to [32] and uses the derivatives of a Gaussian with standard deviation 1 as convolution kernels:\\\\nf\\\\n1\\\\n=\\\\nG\\\\nx\\\\n,\\\\nf\\\\n2\\\\n=\\\\nG\\\\ny\\\\n.'\",\"520\":null,\"521\":\"\\\"In monocopter flight, two important parameters are required for control: angular rates and heading direction. Small monocopters fly at a very high speed (more than 600rpm), which can be out of the typical gyroscope limit. Very high speed gyroscopes do exist, but the price is high and it can only measure a single axis rotation. This paper presents an alternative approach to measure angular rates by using three accelerometers. The readings of the accelerometers are subtracted to calculate the angular rates in all three axes (x, y, and z). This paper also proposes to use the Extended Kalman Filter (EKF) to estimate the heading direction based on the magnetometer reading and the angular rates. The angular rates direction is used as the vertical direction reference. The proposed method has been applied on two setups: DC Motor setup (for quantifying the method's performance) and Monocopter setup. In the DC Motor setup, the motor encoder is used as the ground truth for the heading direction. The result is compared with the usual method of using only the magnetometer to obtain the heading direction of monocopters. The EKF result is more accurate and stable even in the presence of strong magnetic disturbances. In addition, the angle of attack and the coning angle can also be determined by the proposed method.\\\"\\n\\n'Two sets of experiments have been conducted: in the first set, the sensors system are rotated using a DC motor with encoder (to provide the ground truth for the heading direction). In the second set of experiments, the sensors are mounted on the monocopter, and sensor readings from the monocopter flight are used to estimate the heading direction.'\\n\\n'In the DC motor setup, the sensors (with the mounting) are attached to a 12V DC motor. The motor encoder has 464.64 count per revolution (0.77\\u00b0\\/count). The motor can go up to 1030rpm. The sensors are not positioned horizontally, but at an angle, to simulate the angle of attack in monocopter flight. The value of the angle in this setup is 12.65\\u00b0.'\\n\\n'For the DC motor setup, the heading estimate from the proposed method is compared with the reading from the motor encoder as the around truth.'\",\"522\":\"'http:\\/\\/www.ece.ust.hk\\/~eeshaojie\\/icra2017tianbo.mp4'\",\"523\":\"'http:\\/\\/www.ece.ust.hk\\/-eeshaojie\\/icra2017zhenfei.mp4'\\n\\n'Observations with higher depths are usually more uncertain for both RGB-D and RGB mapping. We encode the uncertainty using the dynamic truncation distance. Suppose the standard deviation of the depth measurement in the inverse depth id is\\\\n\\u03c3\\\\nid\\\\n, then the standard deviation of the depth measurement in depth\\\\nd\\\\nis'\\n\\n'In this work, we present a solution to real-time monocular dense mapping. A tightly-coupled visual-inertial localization module is designed to provide metric and high-accuracy odometry. A motion stereo algorithm is proposed to take the video input from one camera to produce local depth measurements with semi-global regularization. The local measurements are then integrated into a global map for noise filtering and map refinement. The global map obtained is able to support navigation and obstacle avoidance for aerial robots through our indoor and outdoor experimental verification. Our system runs at 10Hz on an Nvidia Jetson TX1 by properly distributing computation to CPU and GPU. Through onboard experiments, we demonstrate its ability to close the perception-action loop for autonomous aerial robots. We release our implementation as open-source software 1 .'\\n\\n'We design and implement a dense mapping system including localization, local depth measurements, global map fusion that runs real-time on an Nvidia Jetson TX1. We release our system as open-source software.'\\n\\n'Instead of simply stitching all local depth maps, we maintain an occupancy map and continuously update it using uncertainty-aware TSDF fusion. Fusing the depth maps is not only to maintain a global map that is meaningful for autonomous flight, but also to filter the noisy measurements in a probabilistic way. Our implementation is based on the open-source software Chisel [10], with subtle but important modifications detailed below.'\",\"524\":\"\\\"Table I: Comparison between DPPTAM and the proposed method on the fr3_nostructure_texture_near_withloop sequence of [7]. The DPPTAM depth error measures as well as the average recall per frame are extracted directly from [16] (no standard deviation from the mean is provided). The average computation time per frame has been recorded on the same hardware using the author's original code and includes the time for tracking and mapping, while we show the difference of performing (or not) the superpixel (sp) estimation step for each method.\\\"\",\"525\":\"'Especially when the robot explores an unknown environment, new features are initialized into the map. This imposes the need to reobserve previous features in order to reduce the growth in localization and mapping error. To encode this behavior into the planning process, each admissible branch of\\\\nT\\\\nM\\\\nis evaluated regarding the uncertainty of the robot belief about its pose and the tracked landmarks along its edges as explained in subsection IV-B.2. Then for the derived pose and tracked landmarks covariance matrix\\\\n\\u03a3\\\\np,f\\\\n(subset of\\\\n\\u03a3\\\\nl\\\\n)\\\\n, BeliefGain computes its D-optimality (D-opt) [7] metric which evaluates the area of the uncertainty ellipsoids and has its roots in the theory of optimal experiments.'\\n\\n'For the purposes of robot navigation, a visual-inertial odometry framework is employed due to the superior robustness and accuracy such methods provide. In particular, the open-source Robust Visual Inertial Odometry (ROVIO) is utilized [29]. Within this paper, a necessarily brief summary will be provided as its formulation is also used for belief propagation. ROVIO closely couples the tracking of multilevel image patches with the Extended Kalman Filter (EKF) through the direct use of image intensity errors to derive the filter innovation term and uses a QR-decomposition to reduce the dimensionality of the error terms, therefore keeping the Kalman filter update step computationally tractable. Its formulation is robocentric, therefore the landmarks are estimated with respect to the camera pose. The estimated landmarks are decomposed into a bearing vector, as well as a depth parametrization. The Inertial Measurement Unit (IMU) fixed coordinate frame\\\\n(B)\\\\n, I the camera fixed frame\\\\n(V)\\\\nand the inertial frame\\\\nW\\\\nare considered and the employed state vector with dimension\\\\nl\\\\nand associated covariance matrix\\\\n\\u03a3\\\\nl\\\\nis:'\\n\\n'The proposed uncertainty-aware exploration and mapping planning strategy is evaluated in a challenging experimental environment, while computational complexity analysis is also provided. The experimental studies were conducted using an aerial robot performing visual-inertial localization indoors without support of motion capture systems. The planned paths, and the derived volumetric and dense maps are presented along with analysis plots and visual comparison with an offline reconstructed map. The algorithm implementation is released as an open source package accompanied with a relevant dataset [16].'\",\"526\":\"'The hexarotor UAV with 55 em diameter fuselage and six 12 inch propellers is used for experiments. All the system codes are implemented in an on-board computer for fast response. The position and velocity data are obtained from the VICON motion capture system, and sent to the on-board computer at 100Hz. The attitude data are retrieved from the built-in IMU at 500Hz. The flight control computer calculates the desired rotation speed for each motor. The current states are then sent to the ground controller for monitoring. The operator can set the desired position or gains of the controller using the uplink of the ground control system.'\",\"527\":null,\"528\":\"'Table II Binary encoding results on the kitti labelled benchmark using 256-bit codes'\\n\\n'Fig. 8 shows the tradeoff between labelling accuracy and the number of bits in the binary code, for both LSH and BRR. BRR provides better search performance at shorter code lengths; by 256 bits the two methods are comparable.'\\n\\n'Mean per-class accuracy versus binary code length.'\\n\\n'We have presented a model-free approach to 3D semantic scene parsing that differs from conventional practice in its use of search-based label transfer instead of discriminative classification. MF3D achieves competitive labelling accuracy and is easily extensible to new categories as no model training is required. We plan to investigate whether supervised hashing can achieve better accuracy at shorter code lengths.'\\n\\n'B. Large-Scale Search with Binary Codes'\",\"529\":\"'(a) An area proposal pipeline provides high quality category independent candidate regions. (b) A neural network takes each of the regions and predicts the most likely function. (b) System output denoted using the color code from fig. 2.'\\n\\n\\\"To better demonstrate the system's performance, we use bounding boxes with different colors to indicate the functional areas detected. The correspondence between the functionality category and the color code can be found in Fig 2.\\\"\\n\\n\\\"We also demonstrate the detection results on the NYU testing data using bounding boxes with the same color code (shown in Fig. 8). We can see that though some objects, such as sofa and bed, didn't exist in the kitchen scene, the meaningful functionality \\u201csittable\\u201d can still be correctly detected (Fig. 8(a,b,d,e)). These experimental results on the NYU testing data support our hypothesis that the functional recognition model learned in the kitchen environment is well generalizable to other indoor scenarios.\\\"\",\"530\":\"'Pseudocode for ESEC clustering.'\\n\\n'Action differentiation by ESECs is compared to our earlier method based only on touching and not-touching events encoded in the older SEC (Semantic Event Chain) framework [8]. Both frameworks do not require object recognition and they ignore movement trajectories. Because in the original SECs touching and not-touching are the only defined spatial relations, the discriminative power of SECs is more limited than that of the here proposed Enriched SECs. This is shown by the difference between 96.625% action recognition accuracy for ESECs as compared to 87.5% for SECs using MANIAC. Also for the data from [9] we find improved performance and 5 more actions can be discriminated with ESECs. In addition, we found that several actions that had been 100% similar using the SEC framework begin to show differences when using ESECs (e.g. 83% similarity only). All this clearly shows that ESECs have a higher discriminative power than SECs. Because of this ESEC are necessarily also more robust against noise during action observation.'\",\"531\":\"'We use two state-of-the-art single modality CNN models for providing the input depth-map and semantic segmentation prediction map. For depth input, we use the inference code with pretrained model of Eigen et al. [24] which is publicly available2. For semantic segmentation prediction maps, we use the FCN model of Long et al. [20].'\",\"532\":null,\"533\":\"'Example of the type of CRF graph used in this paper. Pairwise potentials are indicated by the edges, while the additional constraints are indicated by the two shaded areas, A and b. These areas encode sets of nodes which are required to be assigned the same label.'\",\"534\":\"'http:\\/\\/deepscene.cs.uni-freiburg.de\\/'\\n\\n'http:\\/\\/deepscene.cs.uni-freiburg.de\\/'\",\"535\":null,\"536\":\"'The actuation comprises four actuators for the bending and two actuators for the translation. As actuators we use brushless DC motors with integrated gears and encoders for position control (Maxon Motor AG, Sachseln, Switzerland). The position control is achieved by using a controller board DMC4040 and amplifiers AMP-43040 (Galil Motion Control, Rocklin, CA, USA). As our kinematic model is based on tendon force input and we seek to compensate the unmodeled tendon elongation, we use tension sensors RFS100 (Honig-mann Industrielle Elektronik GmbH, Wuppertal, Germany) with measurement ranges up to 50 N. One tension sensor and one actuator per antagonistic tendon pair is used as shown in Fig. 6. The antagonistic tendon pair is routed over three pulleys and the tension sensor. The tendons are fixed at the motor shaft such that shaft rotation results in bending of the respective element. The tendons are routed around the tension sensor symmetrically, such that the resulting forces are aligned in the measuring sensor plane and the winding angle around the sensor is constant during actuation. This enables force measurements in both tendons with one sensor, where the forces manifest in values with different signs. We use Labview (National Instruments, Austin, TX, USA) to read out sensor values and control the tendon forces. Both tendons are routed in parallel on different pulleys, such that friction and knotting between them is avoided. All pulleys are mounted on metal ball bearings. Each element of the manipulator is equipped with two aforementioned actuation\\/sensing modules for two antagonistic tendon pairs and ensembled into one carrier module. Each carrier module can be translated independently on lead screws, with a pair of gears actuated by the DC motors.'\",\"537\":null,\"538\":null,\"539\":\"'http:\\/\\/juxi.net\\/dataset\\/apb'\\n\\n'https:\\/\\/github. com\\/amazon-picking-challenge\\/team_acrv'\\n\\n\\\"We will curate a list of submissions and a leaderboard, where teams can submit scores (and new tasks). A video to verify the robot's score and show the robot in operation will be required. The recording allows the verification of the results, and the adding of scoring metrics retrospectively. In addition, the teams can provide links to systems descriptions, publications, and code. The following guidelines are proposed for fair comparing and ranking of submissions.3\\\"\\n\\n\\\"We leverage the Robot Operating System (ROS) framework and additional open source software to speed up development of the system and promote modularity, standardisation and reproducibility. The baseline system's source code is publicly available at: https:\\/\\/github. com\\/amazon-picking-challenge\\/team_acrv. Software packages integrated in the system include:\\\"\\n\\n'This paper is motivated by our experience in the 2016 Amazon Picking Challenge (APC). The challenge is a very effective way to drive progress, but it occurs only annually and is limited to 16 participant teams who are provided with the appropriate physical artifacts: standard shelf, standard set of objects. To drive progress we believe that it is essential to make the challenge conditions more widely available. We propose a benchmark, based on commonly available shelves and objects, to allow for an easier reproduction of robotic picking, hopefully allowing for more thorough analysis and better comparison. In addition, we describe an open-source baseline system for this shelf picking benchmark. Our system is based on a Baxter robot (depicted picking from two shelves in Fig. 1) and includes extensions which we made publicly available to enable replication. We report our systems performance on four exemplary setups of our benchmark.'\\n\\n'https:\\/\\/github. com\\/amazon-picking-challenge\\/team_acrv'\",\"540\":null,\"541\":\"'Approaches for state estimation which have been tested on humanoid robots fuse proprioceptive measurements from joint encoders, contact sensors and inertial sensors. Drift in the estimate is reflected by mis-alignment of consecutive point clouds. However, point cloud registration algorithms are highly sensitive to the properties of the input clouds, such as structural features (the presence of planar surfaces), the initial alignment error and the degree of overlap.'\",\"542\":null,\"543\":null,\"544\":null,\"545\":null,\"546\":null,\"547\":null,\"548\":null,\"549\":null,\"550\":null,\"551\":\"'SECTION II.\\\\nMotion Planning\\\\nWe transcribe the motion generation problem to a nonlinear program\\\\nmin\\\\n\\u2211\\\\nj\\\\n\\u03b1\\\\nj\\\\nf\\\\nj\\\\n(p)s.t. g(p)=0, h(p)\\u22640\\\\n(1)\\\\nView Source by discretizing the state trajectories of the robot over a finite horizon. The high-level motion goals (traveling distance) and physical constraints are encoded in the objective function as well as in the equality constraints\\\\nh(p)\\\\nand inequality constraints\\\\ng(p)\\\\n. We formulate the objective function as weighted sum of individual objectives\\\\nf\\\\nj\\\\n(p)\\\\nwith weight\\\\n\\u03b1\\\\nj\\\\n,\\\\nTo keep the number of optimization variables small, we only search for state variables on position-level and approximate the velocities and accelerations through finite-differences. We approximate the dynamics and predefine the contact schedule to create a problem that is fast to solve with modern sparse solvers. To further speed up the optimization, we introduce auxiliary variables which allow us to formulate the constraints in a linear form. The remaining nonlinear equality constraints are included in the objective functions as least-squares problem, which accelerates the convergence of most off-the-shelf solvers in our experience.\\\\nFor each sample point\\\\ni\\\\n, we search for the following parameter vector:\\\\np\\\\ni\\\\n=[\\\\nq\\\\ni\\\\n,\\\\nx\\\\ni\\\\n,\\\\ne\\\\n1,i\\\\n,\\u2026,\\\\ne\\\\n4,i\\\\n,\\\\nw\\\\n1,i\\\\n,\\u2026,\\\\nw\\\\n4,i\\\\n],\\\\n(2)\\\\nView Source where\\\\nq\\\\ni\\\\n=\\\\n[\\\\nP\\\\nr\\\\nPB\\\\n,\\\\nR\\\\nPB\\\\n,\\\\n\\u03c6\\\\n1\\\\n,\\u2026,\\\\n\\u03c6\\\\n12\\\\n]\\\\nis the state of the robot including the position\\\\nP\\\\nr\\\\nPE\\\\nand orientation\\\\nR\\\\nPB\\\\nof the base of the robot and the joint positions\\\\n\\u03c6\\\\n. The auxiliary variable\\\\nx\\\\ni\\\\n=[\\\\nx\\\\ni,x\\\\n, \\\\nx\\\\ni,y\\\\n, \\\\nx\\\\ni,z\\\\n]\\\\nrepresents the COM position of the robot, whereas\\\\ne\\\\nk,i\\\\n=[\\\\ne\\\\ni,x\\\\n,\\\\ne\\\\ni,y\\\\n]\\\\ncorresponds to the k-th end-effector position. The height of the foot position is defined by the terrain during the stance phase and by a predefined foot clearance trajectory during swing phase. In addition, each end-effector has a corresponding scalar weight\\\\nw\\\\nk,i\\\\nfor defining the stability margin.\\\\nThe complete motion plan is presented by\\\\nN\\\\nparameter vectors\\\\np\\\\ni\\\\nover a finite horizon, the contact flags\\\\n[\\\\nc\\\\n1,1\\\\n,\\u2026,\\\\nc\\\\n4,N\\\\n]\\\\n, which indicate whether the k-th end-effector is in contact with the ground\\\\n(\\\\nc\\\\nk,i\\\\n=1)\\\\nor not\\\\n(\\\\nc\\\\nk,i\\\\n=0)\\\\n, and the time\\\\nt\\\\ni\\\\nof each sample point\\\\ni\\\\n. The end-effector and COM positions are consistent with the state of the robot, if the following constraints are met:\\\\nr\\\\nCOM\\\\n(\\\\nq\\\\ni\\\\n)\\u2212\\\\nx\\\\ni\\\\n=0\\\\nr\\\\nEE\\\\nk\\\\n(\\\\nq\\\\ni\\\\n)\\u2212\\\\ne\\\\nk,i\\\\n=0, \\u2200k,\\\\n(3)\\\\nView Source where\\\\nr\\\\nCOM\\\\n(.)\\\\nand\\\\nr\\\\nEE\\\\nk\\\\n(.)\\\\nare the forward kinematics function. Due to the nonlinearity of the forward kinematics, these constraints are formulated as least-squares objective and are added to the objective function with a high weighting term.\\\\nThe physical constraints are enforced by preventing any motion of the grounded end-effectors with\\\\n(\\\\ne\\\\nk,i\\u22121\\\\n\\u2212\\\\ne\\\\nk,i\\\\n)\\\\nc\\\\nk,i\\\\n=0 \\u2200k,2\\u2264i\\u2264N,\\\\n(4)\\\\nView Source by minimizing the accelerations to ensure temporal consistency formulated as objective\\\\n\\u2211\\\\ni=2\\\\nN\\u22121\\\\n\\u2225\\\\n\\u2225\\\\n\\u2225\\\\n\\u2225\\\\nq\\\\ni\\\\n\\u2212\\\\nq\\\\ni\\u22121\\\\nt\\\\ni\\u22121\\\\n\\u2212\\\\nt\\\\ni\\\\n\\u2212\\\\nq\\\\ni+1\\\\n\\u2212\\\\nq\\\\ni\\\\nt\\\\ni+1\\\\n\\u2212\\\\nt\\\\ni\\\\nt\\\\ni+1\\\\n\\u2212\\\\nt\\\\ni\\u22121\\\\n\\u2225\\\\n\\u2225\\\\n\\u2225\\\\n\\u2225\\\\n2\\\\n,\\\\n(5)\\\\nView Source and by limiting the joint velocities to avoid actuator saturations by\\\\n\\u2212\\\\n\\u03c6\\\\n\\u02d9\\\\nmax\\\\n\\u2264\\\\n\\u03c6\\\\nk,i+1\\\\n\\u2212\\\\n\\u03c6\\\\nk,i\\\\nt\\\\ni+1\\\\n\\u2212\\\\nt\\\\ni\\\\n\\u2264\\\\n\\u03c6\\\\n\\u02d9\\\\nmax\\\\n,\\u2200k,1\\u2264i\\u2264N\\u22121,\\\\n(6)\\\\nView Source where\\\\n\\u03c6\\\\n\\u02d9\\\\nmax\\\\n= 10 rad\\/s is the maximal speed of the actuator. Furthermore, joint limits are included as boundary constraints\\\\n\\u03c6k,min\\u2264\\u03c6k,i\\u2264\\u03c6k,max\\\\nin the optimization problem.\\\\nTo ensure stable walking, we require the plan to meet a dynamic stability criterion, which keeps the approximated center of pressure (COP) within the support polygon at all times. The relation between the COM and the COP can be obtained by using the model of an inverted pendulum [16], [15]:\\\\nr\\\\nCOP,i\\\\n=\\\\nx\\\\ni\\\\n\\u2212\\\\nx\\\\nz,i\\\\nx\\\\n\\u00a8\\\\ni\\\\nx\\\\n\\u00a8\\\\nz,i\\\\n+g\\\\n,\\\\n(7)\\\\nView Source where the gravitational acceleration is denoted by\\\\ng\\\\n= 9.81 m\\/s2. The COP lies automatically within the support polygon if it is equal to the weighted average of the grounded end-effector positions, which we can achieve by adding the constraint:\\\\n\\u2211\\\\nk=1\\\\n4\\\\nc\\\\nk,i\\\\nw\\\\nk,i\\\\ne\\\\nk,i\\\\n\\u2212\\\\nr\\\\nCOP,i\\\\n,=0, \\u2200i,\\\\n\\u2211\\\\nk=1\\\\n4\\\\nc\\\\nk,i\\\\nw\\\\nk,i\\\\n\\u22121=0, \\\\nw\\\\nmin\\\\n\\u2264\\\\nw\\\\nk,i\\\\n\\u22641, \\u2200i.\\\\n(8)\\\\nView Source\\\\nBy modulating the weights\\\\nw\\\\nk\\\\n, the COP can be shifted within the support polygon. We let the optimizer select the appropriate weights. By introducing a lower boundary\\\\nw\\\\nmin\\\\non the weight, a safety margin to the boundary of the support polygon can be realized.\\\\nThe motion tasks are defined by\\\\nx\\\\ne\\\\n\\u2212\\\\nx\\\\ns\\\\n=\\u0394x,\\\\n\\u03c8(\\\\nq\\\\ne\\\\n)\\u2212\\u03c8(\\\\nq\\\\ns\\\\n)=\\u0394\\u03c8,\\\\n(9)\\\\nView Source where\\\\n\\u0394x\\\\nis the desired traveling distance between sample point\\\\ns\\\\nand target point\\\\ne\\\\n, and\\\\n\\u0394\\u03c8\\\\nis the desired turning angle which is obtained from the robot pose by\\\\n\\u03c8(.)\\\\n.\\\\nA periodic motion is encoded in the problem by constraining the joint positions at the last sample point with the start sample point\\\\np\\\\nof the periodic motion:\\\\n\\u03c6\\\\nk,N\\\\n\\u2212\\\\n\\u03c6\\\\nk,p\\\\n=0,  1\\u2264k\\u226412.\\\\n(10)\\\\nView Source\\\\nBecause multiple solutions can potentially exist for the aforementioned problem, we additionally add a regularizer term to the objective function.\\\\nWe minimize the constrained optimization problem with sequential quadratic programming (SQP) using OOQP [17] to obtain the search direction as in [15]. To compute the Jacobians of the end-effectors, which are needed to compute the gradient of the objective function, we make use of the\\\\nC++\\\\nlibrary RBDL [18] and compute the Hessians according to [19].\\\\nAn example of a resulting motion plan is shown in Fig. 1, where each point indicates a sample point either of the end-effector positions (red), COM trajectory (green) or base motion (yellow).'\\n\\n'A periodic motion is encoded in the problem by constraining the joint positions at the last sample point with the start sample point\\\\np\\\\nof the periodic motion:'\",\"552\":null,\"553\":null,\"554\":null,\"555\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/28890841'\",\"556\":null,\"557\":null,\"558\":null,\"559\":null,\"560\":\"'A visualisation of the graph structure. The stacked nodes encode the speed incoming to the node, blue is 0, red is +1, green is \\u22121. The purple lines indicate the edges of the graph, notice they will not allow a transition between +1 and \\u22121 speed or the reverse. In a realistically proportioned graph there is a parameter speed change which defines the allowable change in speed at each node. The shadowed lines at the bottom of the image indicate the edges of the basic tree structure. The purple edges will inherit their edge costs from this base graph, notice there is often more than one edge representing the same physical movement.'\",\"561\":null,\"562\":null,\"563\":null,\"564\":null,\"565\":null,\"566\":null,\"567\":null,\"568\":null,\"569\":\"'In this work we propose a new method for online motion planning in the task-space for hydraulic actuated soft robots. Our solution relies on the interactive resolution of an inverse kinematics problem, that takes into account the properties (mass, stiffness) of the deformable material used to build the robot. An accurate modeling of the mechanical behavior of hydraulic components is based on a novel GPU parallel method for the real-time computation of fluid weight distribution. The efficiency of the method is further increased by a novel GPU parallel leveraging mechanism. Our complete solution has been integrated within the open-source SOFA framework. In our results, we validate our simulation with a fabricated silicone cylinder and we demonstrate the usage of our approach for direct control of hydraulic soft robots.'\",\"570\":null,\"571\":\"'https:\\/\\/youtu.be\\/h8p4wbfqtgq'\\n\\n'But there is also a price to pay for softness when it comes to sensing. Due to their ability to deform in many different ways, the configuration of a soft robotic system can only be described accurately with a very large number of parameters. Many sensors would be required to determine all of them. In addition, most traditional sensor technology, e.g. joint and motor encoders [5] or inelastic tactile sensing [6], are not suitable for the integration with soft actuators because of the softness of the materials. At the same time, extrinsic sensing, e.g. through visual tracking [7], [8], limits the field of operation and is susceptible to (self-) occlusions. Still, there is an unbroken need for sensing in soft systems. As we will see in Section IV, even applications particularly well-suited for the soft robotics paradigm still benefit substantially from sensing. Taken together, sensing-and in particular proprioception-remains an open problem in soft robotics.'\",\"572\":\"'Algorithm 1: Pseudocode for Collision Detection'\",\"573\":null,\"574\":null,\"575\":null,\"576\":null,\"577\":null,\"578\":null,\"579\":null,\"580\":null,\"581\":null,\"582\":\"'https:\\/\\/youtu.be\\/wrmfIZMHVkY'\\n\\n'https:\\/\\/youtu.be\\/i815T2GUGo4'\\n\\n'https:\\/\\/youtu.be\\/HHf0B431uIs'\\n\\n'https:\\/\\/youtu.be\\/KPhWVgrnhBk'\",\"583\":null,\"584\":null,\"585\":\"'Each paragraph is conceptually divided in three sections including a brief reasoning behind the algorithm selection along with the definition of new terms, the overview of the algorithm according to the pseudocode diagrams, and discussion of algorithm implementation details.'\\n\\n'Pseudocode of the Ground Plane Fitting Methodology for One Segment of the Point Cloud'\\n\\n'Algorithm 2: Pseudocode of the Scan Linerun Clustering'\",\"586\":\"'3D surface reconstruction methods based on active stereo using coded structured light has been widely researched from their practical usefulness. A typical categorization of these methods are temporal and spatial coding techniques [16]. Temporal coding methods are superior in spatial resolutions, but inferior in temporal resolutions.'\\n\\n'Previously, most active stereo methods are based on explicitly coded patterns, where the positional information is embedded into the pattern images with some rules. However, as recent increases in computational powers of PCs, matching-based active stereo methods have been studied recently [3], [7], [9], where the captured images and the pattern signals are directory compared and matched. These methods can be considered as \\u201cimplicit\\u201d coding of the projected patterns.'\\n\\n'In our method, images are mapped\\/encoded into a low dimensional representation. If the surface around a point\\\\np\\\\nis assumed as a local plane, the homography\\\\nH\\\\nto calculate the corresponding point of\\\\np\\\\nis determined by the plane parameters, the orientation and depth of the plane. In this paper, the intensity of an input image at the point\\\\np\\\\nis modeled as follows:'\\n\\n'The cnns consist of two layers to encode the local pattern. The input patch is\\\\n21\\u00d721\\\\nin size with 2 channels in this paper, and the dimension of output feature vector is 20.'\\n\\n'Since the projecting pattern usually consists of specific pattern features encoded in a small area in the patches that are discriminative each other, the first layer is a convolutional layer of small window size, which is\\\\n5\\u00d75\\\\npixels in this paper, to detect the structure of the pattern feature. Since the features are detected by applying the convolution, it is not necessary to explicitly extract the pattern features. An implicit encoding such as random dots can be used.'\\n\\n'Table I The rms errors are calculated by comparing the results to the ground truth, which is obtained by the time-multiplexing 3d scanning method that uses gray codes. The unit is millimeter.'\",\"587\":null,\"588\":\"'https:\\/\\/bitbucket.org\\/planc509\\/optical-distance'\",\"589\":null,\"590\":null,\"591\":null,\"592\":null,\"593\":\"\\\"Currently, there are high quality algorithms and open source implementations of both the sparse and semi-dense approaches, and there is an unclear choice between these two quite different paradigms in applications. Following an approach inspired by Strasdat et al.'s \\u2018Why Filter?\\u2019 comparison of filtering and optimisation methods in sparse SLAM [13], [14], we have developed a framework for rigorous comparison of several aspects of dense and sparse monocular SLAM front-ends. We focus on experimentally answering a specific question: which approach offers the most accurate motion estimation as a function of computational cost? In this paper we start by looking into whether the weight of data in semi-dense VO surpasses the more principled joint optimisation of trajectory and map in the sparse approach. Our novel software framework allows us to abstract away the implementation details of systems and concentrate on the fundamental algorithmic differences. We evaluate the systems against high quality synthetic image data with ground-truth trajectory. See Figure 1 for an example of dense and sparse output from our system. Our framework uses optimisation uniformly based on Ceres Solver [15] with a very careful choice of measurement and evaluation methods.\\\"\\n\\n'Runtime measurements from open source real-time systems which we use for computational cost modelling, where we plot average processing time per frame as a function of the number of points used. (a) Sparse system SVO [4]; (b) semi-dense system LSD-SLAM [21]. The straight line fits shown are the processing cost models which we bring into our comparative results in Section V-C.'\",\"594\":\"'https:\\/\\/github.com\\/jbriales\\/PGO-LagInit.'\\n\\n'https:\\/\\/github.com\\/jbriales\\/PGO-LagInit.'\",\"595\":\"'https:\\/\\/github.com\\/kskin\\/UWbundle'\\n\\n'https:\\/\\/github.com\\/kskin\\/UWbundle'\",\"596\":\"'https:\\/\\/github.com\\/jaehak\\/rrd.rslam'\\n\\n'https:\\/\\/github.com\\/jaehak\\/rrd.rslam'\",\"597\":\"'http:\\/\\/mars.cs.umn.edu\\/research\\/VINSodometry.php'\\n\\n'In this paper, we present a vision-aided inertial navigation system (VINS) for localizing wheeled robots. In particular, we prove that VINS has additional unobservable directions, such as the scale, when deployed on a ground vehicle that is constrained to move along straight lines or circular arcs. To address this limitation, we extend VINS to incorporate low-frequency wheel-encoder data, and show that the scale becomes observable. Furthermore, and in order to improve the localization accuracy, we introduce the manifold-(m)VINS that exploits the fact that the vehicle moves on an approximately planar surface. In our experiments, we first show the performance degradation of VINS due to special motions, and then demonstrate that by utilizing the additional sources of information, our system achieves significantly higher positioning accuracy, while operating in real-time on a commercial-grade mobile device.'\\n\\n'Most ground vehicles are equipped with wheel encoders that provide low-frequency, often noisy, and maybe only intermittently, reliable measurements of the motion of each wheel. On the other hand, these measurements contain scale information necessary for improving the accuracy of VINS under constant-acceleration motions. In particular, the wheel-encoder data can be transformed into local 2D linear and rotational velocity measurements by employing the odometer intrinsics,4 i.e.,'\\n\\n'We further test the localization accuracy of our system on the Pioneer robot. Five datasets are collected by driving the Pioneer each time for ~ 1 km through a large building. In addition to the IMU-camera data, the Pioneer wheel encoders provide readings at 10 Hz. We compare the localization results among the following setups: (i) VINS only, (ii) VINS plus odometer (VO), (iii) VINS plus odometer plus deterministic planar constraint (VOD), and (iv) VINS plus odometer plus stochastic planar constraint (VOS). The ground truth is computed from the batch least squares (BLS) offline, using all available (visual, inertial, and odometric) measurements.'\\n\\n\\\"In this paper, we proved that the VINS scale, or 2 additional dof of its global orientation, become unobservable when the robot moves with constant acceleration, or it is not rotating\\u2019 respectively. For this reason, and as demonstrated in our experiments, directly employing VINS on a wheeled robot results in inaccurate pose estimates. To address this issue, we incorporated wheel-encoder measurements into VINS and showed that the scale becomes observable. Furthermore, we introduced mVINS that properly models the ground robot's almost-planar motion and directly employs this information in the estimator. Experimental results showed that special motions indeed lead to larger positioning errors when using VINS on a wheeled robot. Incorporating, however, odometry measurements, as well as stochastic constraints modeling the vehicle's planar motion, provide additional information and lead to significant improvements in positioning accuracy.\\\"\",\"598\":null,\"599\":null,\"600\":null,\"601\":\"'http:\\/\\/tiny.cc\\/dnn-imprornptutracking'\",\"602\":null,\"603\":null,\"604\":\"'https:\\/\\/git.openrobots.org\\/projects\\/tk3-mikrokopter'\\n\\n'Table II. Implementation of ABAG control algorithm in C language. The longest code path is about 140 instructions that require about 220 clock cycles, i.e., 27.5 \\u00b5s at 8 MHz. The parameters used are given in'\\n\\n'For maximum efficiency, the ABAG algorithm is implemented using only additions, comparisons and shifts. The actual C code is shown in table II. The longest code path runs in about\\\\n27.5\\u03bcs\\\\nat 8 MHz (note that all other code paths are about the same length). This relatively light complexity allows to run the controller directly from the ISR routine that measures the current spinning velocity and controls the phase bridge. This is an important property since the controller, by its nature, provides a very discontinuous PWM duty cycle input u, the faster it runs the less chattering will actually be visible from the motor coils. This also guarantees that the controller runs each time a velocity measurement is available. Typically, for a 14 poles motor spinning from 20 Hz to 100 Hz this means that the controller runs at frequencies ranging from 840 Hz to 4.2 kHz.'\\n\\n'This paper introduces the adaptive bias and adaptive gain (ABAG) algorithm for closed-loop electronic speed control (ESC) of the brushless direct current (BLDC) motors typically used to spin the propellers in multi-rotor aerial robots. The ABAG algorithm is adaptive and robust in the sense that it does not require the knowledge of any mechanical\\/electrical parameter of the motor\\/propeller group and that neither a pre-calibration nor the knowledge of the feedforward\\/nominal input is needed. The ABAG algorithm is amenable to an extremely low complexity implementation. We experimentally prove that it can run in 27.5 \\u03bcs on a 8 MHz microcontroller with no floating point unit and limited arithmetic capabilities allowing only 8-bit additions, subtractions and multiplications. Besides the controller implementation we present a self-contained open source software architecture that handles the entire speed control process, including clock synchronization, and over-current and blockage safeties. The excellent performance and robustness of ABAG are shown by experimental tests and aerial physical interaction experiments.'\\n\\n'Furthermore, we present an open source implementation of the algorithm (available at https:\\/\\/git.openrobots.org\\/projects\\/tk3-mikrokopter) in a self contained software architecture that provides also additional features such as, e.g., clock synchronization, mechanical and electrical safeties, and speed reversibility. Then we provide an experimental campaign that validates the great adaptiveness and robustness of the algorithm, able to achieve very good performances with no specific gain tuning despite the change of motor and propeller types, and other external disturbances. Finally we show the major benefit of employing the proposed propeller speed control in physically interactive aerial robotic tasks.'\",\"605\":null,\"606\":null,\"607\":null,\"608\":null,\"609\":null,\"610\":\"'http:\\/\\/www.roboticvision.org\\/'\",\"611\":null,\"612\":\"\\\"Place recognition in 3D data is a challenging task that has been commonly approached by adapting image-based solutions. Methods based on local features suffer from ambiguity and from robustness to environment changes while methods based on global features are viewpoint dependent. We propose SegMatch, a reliable place recognition algorithm based on the matching of 3D segments. Segments provide a good compromise between local and global descriptions, incorporating their strengths while reducing their individual drawbacks. SegMatch does not rely on assumptions of `perfect segmentation', or on the existence of `objects' in the environment, which allows for reliable execution on large scale, unstructured environments. We quantitatively demonstrate that SegMatch can achieve accurate localization at a frequency of 1Hz on the largest sequence of the KITTI odometry dataset. We furthermore show how this algorithm can reliably detect and close loops in real-time, during online operation. In addition, the source code for the SegMatch algorithm is made publicly available.\\\"\\n\\n\\\"This framework has been exhaustively evaluated on the KITTI dataset. We first analysed the impact of using a random forest classifier to learn an adequate feature distance metric for the purpose of matching segments. We have then shown that the algorithm is able to accurately localize at a frequency higher than 1Hz in the largest map of the KITTI dataset. We also demonstrated how it is possible to robustly detect loops in an online fashion, and how these can be fed to a pose-graph trajectory estimator. Thanks to the framework's modular approach, we have furthermore illustrated that it can easily be applied to different scenarios by simply changing building blocks of the algorithm. The source code for the entire framework is available online, offering real-time segmentation and loop-closure detection for streams of 3D point clouds.\\\"\\n\\n'An open source implementation of SegMatch for online, real-time loop-closure detection and localization.'\",\"613\":\"'In this work, we propose a framework to deal with cross-modal visuo-tactile object recognition. By cross-modal visuo-tactile object recognition, we mean that the object recognition algorithm is trained only with visual data and is able to recognize objects leveraging only tactile perception. The proposed cross-modal framework is constituted by three main elements. The first is a unified representation of visual and tactile data, which is suitable for cross-modal perception. The second is a set of features able to encode the chosen representation for classification applications. The third is a supervised learning algorithm, which takes advantage of the chosen descriptor. In order to show the results of our approach, we performed experiments with 15 objects common in domestic and industrial environments. Moreover, we compare the performance of the proposed framework with the performance of 10 humans in a simple cross-modal recognition task.'\",\"614\":\"'Our proposed controller can be implemented using standard sensing capabilities of robot manipulators (encoders and possibly tachometers). The precision of these measurements is crucial for avoiding highly noisy estimates of the joint accelerations and jerks through the use of the elastic-joint torques and respective derivatives. However, an effective filtering solution has been proposed in the event that high precision torque sensing is not available and related interesting robustifying effects have been discussed.'\",\"615\":null,\"616\":\"\\\"Information on latent states is implicitly encoded in the measured historic states and inputs. Different lengths of history might be required for individual parts of the system's state depending on the dynamics' time scales. We optimize the number of historic states individually for end effector position, pendulum position and control input. The NSGA II optimizer [26] is employed to compute the pareto front of the model's prediction error (using the same dataset as previously used for hyperparameter tuning) and the size of the NARX history. For our problem, we ended up with a new state of dimensionality 14 given by\\\\nx\\\\nNARX\\\\n:=(\\\\nx\\\\nt\\\\n,\\u2026,\\\\nx\\\\nt\\u22123\\\\n,\\\\n\\u03d5\\\\nt\\\\n,\\u2026,\\\\n\\u03d5\\\\nt\\u22122\\\\n,\\\\nu\\\\nt\\\\n,\\u2026,\\\\nu\\\\nt\\u22126\\\\n)\\\\n. The hidden dynamics between commanded input and executed acceleration (cf. Fig. 4) requires a longer history in the input state to capture all relevant effects.\\\"\",\"617\":\"'In this work we present a whole-body optimization methodology for non-periodic tasks on quadrupedal systems. We encode the high-level goals using a task specific cost function, which provides an intuitive way of defining the desired outcome. Although tuning the relative weights of such cost functions is a manual process, a heuristic encoding of the same behavior would require a significantly higher effort. The resultant trajectories and their performance indicate the capability of the approach to deliver diverse sets of motions, without prior definitions for the feet placements.'\\n\\n'Another major challenge is solving such high-level tasks without the use of pre-defined heuristics such as hard-coded sequences or feet placements [18]. Trajectory optimization for multi-legged robotic systems that operate in complex environments is challenging, due to the varying number of contacts. By allowing predefined elements, part of the burden is alleviated, but at the same time the solutions obtained might be suboptimal and their generality can also be affected. Recently, the work in [19] has combined optimal control and learning of movement primitives to generate gaits for a humanoid system, but the work is restricted to open-loop control.'\\n\\n'In our work we try to address this issue by providing a generalized approach of delivering whole body movement solutions. The high-level tasks are encoded using a cost function, while trying to avoid pre-specifying how these tasks should be solved (i.e., no predefined contact points or sequences). As the accuracy of the model is a crucial requirement, we choose to perform the optimization using the whole body dynamics.'\\n\\n'For complex robotic systems such as HyQ2Max, the main challenge consists of determining the suitable joint motions which achieve the desired movement for each given task. Using a direct optimization approach on the time-parametrized joint or torque trajectories would involve an inconveniently large search space. Hence, we use a parametrized policy to encode these profiles, represented as a weighted average of Gaussian kernels:'\\n\\n'Example of a policy encoded as a weighted average of gaussian kernels: The means\\\\n\\u03bc\\\\ni\\\\nare equally spaced and the variances are all fixed to 0.01 and the weights have been sampled from [-1, 1].'\\n\\n'We present the results obtained on a realistic simulation of the HyQ2Max robotic platform, as detailed in the previous section. All policies are encoded with a fixed set of M= 16 Gaussian kernels evenly spaced in the time interval between 0 to\\\\nT\\\\nseconds, while their variance\\\\n\\u03c3\\\\n2\\\\nis fixed to 0.01. The number of samples for each task is determined by the CMAS-ES algorithm, based on the number of decision variables.'\\n\\n'Fig. 2 (right) shows the final pose reached by the system under the resultant policy, as imposed by the requirements on the position and orientation of the trunk, encoded in the terminal cost p. In the case of rearing we designated these only as the desired torso pitch (-1.0472 rad) and CoM (center of mass) height (90 cm), leaving the other dimensions free for the optimization. The target pose was achieved with an accuracy of 0.006 rad and 10 cm, the performance is reflecting the relative ratios of the cost function weights.'\\n\\n'Using a realistic simulation of the hydraulically actuated HyQ2Max quadrupedal system we investigate two distinctive tasks: rearing and posture recovery. Task specific cost functions encode the high-level goals in each scenario. We employ a generalized form for the cost function, while adjusting the relative gains of each term according to the current task. Although tuning the relative weights of such cost functions is a manual process, a heuristic encoding of the same behavior would require a significantly higher effort. By exploiting the whole body model in order to obtain the solution, the optimization does not have to depend upon heuristics and can overcome errors caused by the use of simplified models. The resultant trajectories and the accuracy with which the user defined goals are achieved are reflecting the relative ratios of the weights on the individual cost function terms.'\",\"618\":\"'https:\\/\\/youtu.be\\/EBW31prltB8'\",\"619\":null,\"620\":null,\"621\":null,\"622\":null,\"623\":null,\"624\":null,\"625\":null,\"626\":\"'The parameters (\\u0398) are all coded as rad in order to keep consistent with the real robot. The algorithm is implemented in Matlab on an ordinary PC with Intel i7 3.6GHz processor and 16GB RAM and it takes about five seconds for each frame. The pose transferred to real robot is coded with Python through Choregraphe\\u2122.'\\n\\n\\\"1) For some self-interactive motions like his\\/her hand touching the head, the interaction may not be maintained by the robot since we haven't enforced interaction constraints explicitly in our formulation. 2) Due to non-optimized Matlab code and motionless assumption, the whole process is not real-time. These are two of our major works to be improved in the future.\\\"\",\"627\":\"'We thank David Labak who helped out with writing code and gathering data early in this work.'\",\"628\":null,\"629\":null,\"630\":\"'Table I. Pseudo-code for roi-specific self-focusing'\",\"631\":null,\"632\":\"'http:\\/\\/www.vicon.com\\/'\",\"633\":\"'The brushless DC motor three-phase commutation was implemented onboard of the microcontroller at rate of 50kHz. The wing stroke angle was measured with motor magnetic encoder at the bottom of the motor (FAULHABER Brushless DC-Servomotors 0620B) with 256 counts\\/rev and calculated according to the gear transmission with gear ratio of 10: 1, which gives total 2\\u03c0 \\/2560 radial resolution on angle measurement. The IMU data fusion is implemented onboard of the microcontroller at the rate of 1KHz. The motor control loop is implemented onboard of the microcontroller at the rate of 2KHz. The body controller is implemented onboard of the microcontroller at the rate of 100Hz.'\",\"634\":null,\"635\":\"'To identify the desired identified parameters the measurements obtained by the system sensors are required. Here, it is assumed that an Inertial Measurement Unit (IMU) and joint encoders are available on an SMS.'\\n\\n'The output of the motor encoder is also noisy, [15]:'\",\"636\":null,\"637\":\"\\\"In addition to the motor's incremental encoder, each actuator includes an AMS AS5040 absolute magnetic encoder to measure the position of the output shaft. A radially-polarized rare-earth magnet is adhered to the tip of the output shaft; the encoder and PCB are mounted to the housing cap.\\\"\\n\\n'The driver layer consists of driver code for each interface board on the PC\\/104 stack.'\",\"638\":null,\"639\":null,\"640\":null,\"641\":\"'Figure 2 examines the space of available techniques for capturing texture, plotted on axes of window size and orientation resolution. In terms of window size, gradient (3\\u00d71) is lower than Sobel, Prewitt, and LBP (all 3\\u00d73) which are lower than Haar and Gabor (arbitrarily large) and co-occurrence matrices (also arbitrary, often the full image). In terms of orientation resolution, gradient, Sobel, Prewitt, and Haar filters can only be oriented horizontally or vertically; LBPs additionally encode diagonal information; Gabor filters can be defined at arbitrarily high angular resolution, and co-occurrence matrices use information from all pixels regardless of their relative orientation.'\",\"642\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/29379672'\",\"643\":null,\"644\":null,\"645\":null,\"646\":\"'We control the soft quadruped robot using a modified version of an open-source control board [33]. This board controls the airflow through three to six independent solenoid valves (VQ100 Series, Steven Engineering) depending on the gait sequence. A common pressure regulator controls the input pressure\\\\nP\\\\nin\\\\napplied to each chamber. The controller (Mega 2560, Arduino) actuates the solenoid valves using ON-OFF control to achieve the gait sequences described above.'\",\"647\":\"'https:\\/\\/youtu.be\\/awpesqr4hii'\\n\\n'With one end of a pressurized FREE fixed in place (not shown), this sensor test setup uses linear and rotary encoders to measure the axial and rotational displacements of the other end.'\",\"648\":\"'The ability to estimate both the force and displacement of pneumatic artificial muscles exclusively using PAM-integrated sensors eliminates the requirement for external encoders and sensors. This facilitates a more modular approach to the design of PAM-actuated wearable devices, wherein PAMs can be configured to meet both the kinematic and dynamic requirements of the device without additional consideration for sensor placement.'\",\"649\":null,\"650\":null,\"651\":null,\"652\":null,\"653\":\"'To simultaneously encode multiple trajectories, we add additional edges to this multi-chain factor graph that connect temporally neighboring states across spatially neighboring chains (the spatial neighborhood of a state is based on its initialization). This structure is elaborated through an example in Fig. 3b. We refer to this graphical model as a net-graph because it resembles a fishing net. In the net-graph, the new edges connect the states through the same GP prior factor derived from the same LTV-SDE in (1). Every path forward in time now represents a trajectory. Although these trajectories are connected with GP prior factors derived from the LTV-SDE, the marginal paths are no longer sampled from the same GP prior due to the complex interactions between different paths. However, the collective graph is now associated with a new vector-valued GP with a sparse inverse kernel (precision matrix) similar to (13) that still allows for structure exploiting efficient inference. The extra connections made between spatially neighboring chains only fills in the off diagonal blocks in A\\u22121 in (14) giving a block tridiagonal structure. Thus the precision matrix remains largely sparse.'\",\"654\":null,\"655\":null,\"656\":null,\"657\":null,\"658\":\"'We used the C++ source code for the Super4PCS algorithm available in [12] and made the necessary modifications to implement our method. For all PCs, the normals to each point were computed using the PlanePCA algorithm [11] with a neighbourhood of 20 points. All tests were performed on a AMD Quad-Core Processor A6-3400M with a speed of 2.30 GHz and 6GB of RAM.'\",\"659\":null,\"660\":null,\"661\":null,\"662\":null,\"663\":null,\"664\":\"\\\"The simplest manner to localize a robot is wheel odometry which involves the calculation of the robot's body displacement from encoders readings. Odometry is commonly enhanced with inertial sensors to estimate the robot's attitude which the heading is the less observable angle. Odometry and inertial sensors are combined together in a dead-reckoning process to integrate accumulative displacements as an initial guess of the robot's pose. The estimation is perturbed by systematic [5], [6] or non-systematic errors due to poor traction performance [7]. Systematic errors are well characterized in the literature [8], [9]. However, non-systematic errors are complex, difficult to predict and not possible to fully correct unless other perception means are present. Visual odometry [10] has gained robustness in the last decade with excellent results.\\\"\\n\\n'Vision based distance measurement system using two-dimensional barcode for mobile robot'\",\"665\":\"'https:\\/\\/github.com\\/siam1251\\/Fast-SeqSLAM'\\n\\n'https:\\/\\/github.com\\/siam1251\\/Fast-SeqSLAM'\",\"666\":\"'Table I Performance of different open source vision based slam packages on underwater data; for a detailed analysis please refer to quattrini li et al. [29]'\",\"667\":\"'Predicted images for active SLAM with their divergence distance with respect to the current image. Divergence values are also depicted with color-coded patches on top-left corner of each predicted image. The color bar shows the divergence values.'\",\"668\":\"'The presented algorithm in this paper has been implemented in the popular open-source autopilot system Paparazzi [4] and it is ready to be used by the general public.'\",\"669\":null,\"670\":null,\"671\":null,\"672\":null,\"673\":null,\"674\":null,\"675\":\"'https:\\/\\/youtu.be\\/KO3XfspsXJY'\",\"676\":\"'The equivalent structural model of the proposed fixed-wing UAV model was encoded into a graph representation. Software was written under the ROS framework [21], which implemented the Fault Diagnostic functionality in real-time.'\",\"677\":null,\"678\":null,\"679\":null,\"680\":null,\"681\":\"'We use the Robot Operation System (ROS) to access pressure sensor data and IMU data as well as to send valve and pressure commands. Our controller code is operating in non-realtime on an Ubuntu workstation. Data for the pressure sensors can be read at approximately 1000 Hz. Pressure for each bladder is controlled by an underlying PID controller also operating at approximately 1000 Hz. Commanded pressures are relayed using ROS, and the valves are actuated to achieve commanded pressure values.'\",\"682\":null,\"683\":null,\"684\":null,\"685\":null,\"686\":null,\"687\":null,\"688\":null,\"689\":\"\\\"We utilized a PILCO open source code [29] and modified it for multi-task learning. The subject and robot states in Eq. (1) were\\\\nx=[q \\\\nq\\\\n\\u02d9\\\\n E\\\\nb\\\\n E\\\\nt\\\\n]\\\\n\\u22a4\\\\n, where\\\\nq\\\\nwas the robot's joint angle,\\\\nq\\\\n\\u02d9\\\\nwas the angular velocity, and\\\\nE\\\\nb\\\\nand\\\\nE\\\\nt\\\\nwere the filtered-biceps and -triceps EMGs that were averaged for 0.2 s.\\\\nu\\\\nwas the input pressure of the PAM's MPa. The control period of assistive strategy dt was 0.2s, and the prediction horizon was 2.0 s. The weight of the cost function was\\\\nT\\\\nv\\\\n= diag([2.0 4.0]) and the cost width\\\\n\\u03c3\\\\nc\\\\nwas 0.5 in Eq. (3). The number of basis functions\\\\nN\\\\nin Eq. (9) was 100. One multi-\\/single-task learning session was composed of five initial trials for the data collections and five learning trials on each task.\\\"\",\"690\":null,\"691\":\"'The pseudo code in Alg. 1, which is optimised for clarity rather than efficiency, summarises the proposed algorithm. We have implemented it with the Anglican probabilistic programming language [7].'\",\"692\":null,\"693\":null,\"694\":\"'UM7 9-DOF Inertial Measurement Units (IMUs) mounted on each SRL provide roll and pitch information to a PC running Windows 10 via Bluetooth. An onboard Arduino Due 32-bit microcontroller aggregates all encoder and proximity sensor data and interfaces with the ESCON motor controllers.'\",\"695\":null,\"696\":null,\"697\":\"'The following experiments were performed using a slightly modified robot. This robot is functionally equivalent but uses VelociRoACH robots made with a polycarbonate structure and rip-stop nylon flexures. The control board is mounted on the back robot instead of on the front and encoders are used to control the leg trajectories of only the back robot. The transmissions of the robots, the joint connecting the robots, and the battery mounting location are the same as in previous experiments. The total mass of the modified robot is 75 g.'\",\"698\":\"'Schematic of the HAMR transmission (rear right leg) with flexures labeled and subsystems color-coded'\\n\\n'Solidworks rendering of experimental setup for resonance characterization and control system evaluation in air with positioning fixtures color coded. A HAMR-vi single leg is shown in the inset with components labeled.'\",\"699\":null,\"700\":null,\"701\":null,\"702\":null,\"703\":null,\"704\":null,\"705\":null,\"706\":null,\"707\":null,\"708\":\"'Each action is coded via a set of elementary tasks, each described by a suitable task function of the system state, and arranged in priority order as described in [1]. The reference system velocity is computed inverting the task function at a kinematic level and by projecting the contribution of each task into the null space of the higher priority ones so as to remove the velocity components that would conflict with it.'\",\"709\":null,\"710\":null,\"711\":null,\"712\":null,\"713\":null,\"714\":\"'Methods to detect the assembly mode of a robot have already been investigated. The introduction of measurement redundancy (using passive instrumented legs or encoders in passive joints) allows to achieve it, but the placement of encoders needs to be chosen carefully [15]. External measurement with vision, either to monitor directly the pose of the platform [16] or the orientation of the legs of the mechanism [17], has also been investigated. Both of those approaches come at an extra cost and might be difficult to integrate in an industrial environment.'\\n\\n'Algorithm 1 provides the pseudo-code of the end-effector pose and velocity tracking algorithm. The procedure read reads measurement of the joint coordinate and velocity (the latter being usually approximated using possibly filtered finite differences). It returns true in case of successful acquisition, false otherwise when the motion is finished. The procedure contract uses standard IA-based algorithms (numerical constraint propagation, including the interval Newton and the interval Gauss-Seidel operators [18], the forward-backward contractor [30], etc.) in order to contract the domains\\\\n[x\\\\n]\\\\nk\\\\nand\\\\n[\\\\nx\\\\n\\u02d9\\\\n]\\\\nk\\\\nsubject to the given constraints. The domains\\\\n[\\u03be],[\\\\n\\u03b5\\\\nq\\\\n]\\\\nand\\\\n[\\\\n\\u03f5\\\\nq\\\\n\\u02d9\\\\n]\\\\nare considered as parameters of the constraint system and are not contracted.'\",\"715\":null,\"716\":\"'The actuators of Veloce are the TMB0140-100-3RBS ETEL direct-drive motors. They can provide a maximum peak torque of 127 Nm and are able to reach 550 rpm of speed. Each actuator is equipped with a non-contact incremental optical encoder providing a total number of 5000 pulses per revolution. The global structure of the manipulator is able to reach 10 m\\/s of maximum velocity of the traveling plate, 200 m\\/s2 of maximum acceleration and is able to handle a maximum payload of 10 Kg. The control architecture of the Veloce robot is implemented using Simulink from from M athworks\\\\nlnc\\\\n, and compiled using\\\\nXPC\\\\nTarget and the Real-Time toolboxes. The resulting low-level code is then uploaded to the target PC; an industrial computer cadenced at 10 KHz (i.e. sample time of 0.1 ms). The experimental testbed is shown in Fig. 3.'\",\"717\":null,\"718\":null,\"719\":null,\"720\":null,\"721\":null,\"722\":null,\"723\":null,\"724\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/31489254'\",\"725\":\"'We present a mobile robot motion planning approach under kinodynamic constraints that exploits learned perception priors in the form of continuous Gaussian mixture fields. Our Gaussian mixture fields are statistical multi-modal motion models of discrete objects or continuous media in the environment that encode e.g. the dynamics of air or pedestrian flows. We approach this task using a recently proposed circular linear flow field map based on semi-wrapped GMMs whose mixture components guide sampling and rewiring in an RRT* algorithm using a steer function for non-holonomic mobile robots. In our experiments with three alternative baselines, we show that this combination allows the planner to very efficiently generate high-quality solutions in terms of path smoothness, path length as well as natural yet minimum control effort motions through multi-modal representations of Gaussian mixture fields.'\\n\\n'We present a planning approach that generates smooth and optimal trajectories over a field of gaussian mixtures. Left: the figure shows an example from the studied simulated intersect scenario where multiple flows of people encounter each other. Right: an example path (in green) generated among the circular linear flow field (cliff) map which associates a gaussian mixture model to each location, whose components encode multiple weighted flow directions.'\\n\\n'Visualisation of cliff distributions obtained for a set of wind measurements. The red arrows represent the directions of the modes while colour coded ones represent the raw measurements. [22]'\",\"726\":\"'https:\\/\\/github.com\\/jmodares\\/UB-ANC-Planner'\\n\\n'In future work, we plan to extend the proposed framework to integrate network performance metrics into the path planning optimization, e.g., to optimize connectivity, throughput, or delay. We implemented UB-ANC Planner based on the algorithms mentioned in the paper. UB-ANC Planner is available as open-source at https:\\/\\/github.com\\/jmodares\\/UB-ANC-Planner.'\\n\\n'https:\\/\\/github.com\\/jmodares\\/UB-ANC-Planner'\",\"727\":\"'The main drawback of CWave is its implementation complexity (about 1500 lines of C++ code) handling numerous special cases. To discover all of them, a test framework was designed and a time-consuming debugging process took place. This calls for a deeper analysis that would generalize some cases, particularly for arc tips.'\",\"728\":null,\"729\":null,\"730\":null,\"731\":\"'Drone Path Planning and Object Detection via QR Codes; A Surrogate Case Study for Wind Turbine Inspection'\",\"732\":\"'http:\\/\\/robotcar-dataset.robots.ox.ac.uk\\/'\",\"733\":null,\"734\":null,\"735\":null,\"736\":\"'We compare the performance of our method against three state-of-the-art, open-source motion estimation frameworks: DVO [4], LSD [7], [8] and ICP [10]. For best performance, we apply \\u201cSmoothed + Gradient\\u201d for extracting the semi-dense region, t-distribution based IRLS and the constant velocity motion model. All methods are evaluated on published and challenging indoor benchmark datasets from the TUM RGB-D [26] series. The datasets we picked for evaluation and the corresponding results are listed in Table III. DVO, LSD-SLAM and our method perform comparably efficiently on a laptop with only CPU resources (30 Hz, 30 Hz and 25Hz respectively) while ICP achieves 60 Hz on a GPU (NVIDIA Tesla K40). It can be easily observed that our method provides the best overall performance on TUM datasets.'\",\"737\":null,\"738\":\"'This term encodes the fact that roads of the same type as the one estimated by our Road-Type-CNN should have higher likelihood. We use a Bernoulli distribution'\",\"739\":null,\"740\":null,\"741\":null,\"742\":null,\"743\":\"'An illustration of the two-tier architecture that is maintained and stored in a graph-based data layer with nodes represented by the keyframes (consisting of RGB and depth imagery from the turtlebot) and edges (in blue: connecting the keyframes via odometry estimates from the wheel encoders on the turtlebot). The SLAM estimates are stored in a lightweight and queryable neo4j layer, while the large sensory information such as RGB and depth imagery corresponding to the associated keyframes are stored in a mongodb key-value store with simple key-based lookup from the neo4j layer.'\\n\\n'User-defined procedures allow more comprehensive code to be embedded server-side and if (as in the case above) we can optimize the search on the server, the foveate query can be succinctly expressed as:'\",\"744\":\"'http:\\/\\/www.ece.ust.hk\\/~eeshaojie\\/icra2017fei.mp4'\\n\\n'http:\\/\\/www.ece.ust.hk\\/~eeshaojie\\/icra2017fei.mp4'\",\"745\":\"'The optimal guidance command is also generated by the ground computer. We use an open-source solver [12], and the problem with five-step prediction horizon\\\\n(\\\\nN\\\\np\\\\n=5)\\\\nrequires 15ms of calculation time on the ground station. Also, we set\\\\n\\u0394t\\\\nas O.\\\\n1s\\\\n, the standard deviation of the w as\\\\n0.05rad\\/s\\\\n, and the probability\\\\np\\\\nas 95%. Also, we implement the control algorithm as described in [6].'\",\"746\":null,\"747\":null,\"748\":\"\\\"We choose to formulate our problem as a POMDP to take advantage of the framework's previous work and n-look-ahead planning capabilities. Using a POMDP instead of a simple Markov Decision Process enables us to encode the fact that the robot takes actions only based on noisy observations of the objective function\\\\nf\\\\n. The state of the system\\\\n{f, p}\\\\n, fully described by\\\\nf\\\\nand the robot's pose\\\\np\\\\n, is never completely given to the robot. However, because we are not interested in learning the transitions of the system, the transition function\\\\nT\\\\nis explicitly encoded so that the robot can simulate sequences of actions. Similarly, the robot is also given an approximate reward function\\\\nR\\\\n~\\\\n({b(f), p}, a)\\\\nbased its current belief\\\\nb(f)\\\\nin lieu of\\\\nf\\\\n. The approximate reward function is based on Equation 4, encoding the desired exploration-exploitation trade-off.\\\"\",\"749\":null,\"750\":null,\"751\":null,\"752\":null,\"753\":\"'The trajectory of the generalized motion is encoded using a Gaussian Processes and Dynamic Movement Primitives (DMPs) as introduced in [6]. More importantly, a model for the time dependent variability is learned from data as described in Section IV. The required optimization (12) is solved offline.'\\n\\n'Since high variability indicates sufficient freedom in the environment, we allow the manipulator to deviate further from the mean of demonstrations which is encoded in a lower stiffness. This allows for higher safety level in the presence of humans in case of unintended collision. It also allows the robot to be actively guided by an expert during specific phases of the task.'\",\"754\":\"\\\"We use imitation learning to initialize the weight parameters of the DMP and optimize for the goal position and velocity. The initial trajectory used for imitation learning was generated using a hand coded player following [25]. Once the policy is initialized, we run 100 iterations of each of the RL algorithms. The reward optimized by these algorithms is inversely proportional to the distance between a target point6 and the location where the ball first enters the table plane after being returned by the robot. If the robot doesn't hit the ball, the reward is the negative minimum distance between the racket and the ball throughout the trajectory. In all the experiments we ran 5 trials for each algorithms for 100 iterations using 50 samples per iteration.\\\"\",\"755\":\"'Reinforcement Learning (RL) algorithms are aimed at solving complex robotic tasks autonomously by interacting with the environment; circumventing the reliance on hand coded policies and human intervention. However, for many tasks \\u2018flat\\u2019 RL algorithms are ill suited as they are unable to uncover and exploit the structure of high dimensional state and action spaces. For example, to play table tennis, a robot needs to be able to execute several strokes such as backhand and forehand strokes. From a flat RL perspective this task requires to find an appropriate trade-off between i) policy complexity to encompass the various strokes and ii) data efficiency as simpler policies are more data efficient. However, a Hierarchical RL (HRL) approach can use hierarchy to decompose such complex behavior into simple sub-policies for each stroke and a simple gating network to choose the correct stroke. Such a structure also allows learning multiple kinds of forehand and backhands strokes. Having multiple solutions for the same sub-task gives us backup solution should the optimal sub-policy become inadequate (e.g. because of wear or damage to a robot). However, to use the solutions as effective backup we need them to be diverse.'\",\"756\":null,\"757\":null,\"758\":\"'Figure 4[a] shows an overview of the experimental setup used to evaluate the proposed method. In the experimental setup, the load is simply mounted on top of the servo motor with a gear. In order to control the motor position, an encoder signal is sent to the position controller to generate the current reference. The generated current reference is provided to the current controller with a power amplifier to drive the motor. However, the friction torque level of the experimental setup is too low to emulate the friction in various kinds of motion control systems, for example a robot arm, X-Y table positioning system [5], NC machine tools, head positioning system of an HDD [13], and Galvano scanner [2]. The mechanical clamp between the load and coupling shown in Fig. 4[b] is used to increase the friction torque level.'\\n\\n'Experimental setup. This experimental seutp is simply constructed by motor, gear, load and encoder to emulate one axis of the industrial machine. The friction level can be adjusted by clamp shown in [b].'\\n\\n'Two tasks remain for future work. The first is the application of a designed neural network model for motion control; fast and precise positioning and sensorless torque estimation for an industrial robot arm are expected for a first application example. The other is adding a torque sensor to measure more accurate torque. And increasing the resolution of the motor encoder and\\/or providing additional encoder at the output of the gear will be required to acquire a more accurate angle of load. Accurate data will strongly improve the supervised learning of the RNN.'\",\"759\":null,\"760\":null,\"761\":null,\"762\":null,\"763\":\"'We have collected wheel speed measurements (via encoders) and native command inputs (joystick commands) from our wheelchair robot (Fig. 1). Our training data (Fig. 3\\u20135, Fig. 11\\u201312), consists of 37.5 minutes (2250 seconds) of driving data from various test runs under standard step, sinusoid, and random command signals of varying magnitude. It contains total of 37500 samples with sampling time of 0.06 sec. From the collected measurements, we have extracted uniformly spaced\\\\nM=3800\\\\n(overlapping) trajectory segments of length\\\\nN=50\\\\n(3 seconds) for calibration.'\\n\\n'(Best viewed in color) Zoomed-in view of the robot-controlled driving in the time interval [180,230]. Note that the model prediction quickly recovers from large deviation near t = 183, where unaligned castor wheels caused near 2 second delay in vehicle response. Castors and unmodeled effects can cause large disturbances, but due to the steady-state guarantee our model can quickly recover to the steady-states encoded in the fitted model parameters.'\",\"764\":null,\"765\":null,\"766\":\"'In the mode of obstacle distance description, each of the 10 columns encodes a different direction away from the user towards the obstacles. The rows of each column indicate how far away an obstacle is along that particular direction. The range distances are matched to the settings in the haptic belt. For object recognition, we encode four different object types using one braille symbol per object type:\\\\no\\\\nfor obstacle,\\\\nc\\\\nfor chair,\\\\nt\\\\nfor table, and\\\\na\\\\nspace for free space. The first row of cells encodes long distance\\\\n(>1m)\\\\nand the second row encodes short distance.'\\n\\n'Initial BVI user training tasks of (a) obstacle detection and (b) shorelining. The walking trajectories are recorded by a motion capture system and color-coded for each user.'\",\"767\":null,\"768\":null,\"769\":null,\"770\":null,\"771\":\"'Communication with a robot using brain activity from a human collaborator could provide a direct and fast feedback loop that is easy and natural for the human, thereby enabling a wide variety of intuitive interaction tasks. This paper explores the application of EEG-measured error-related potentials (ErrPs) to closed-loop robotic control. ErrP signals are particularly useful for robotics tasks because they are naturally occurring within the brain in response to an unexpected error. We decode ErrP signals from a human operator in real time to control a Rethink Robotics Baxter robot during a binary object selection task. We also show that utilizing a secondary interactive error-related potential signal generated during this closed-loop robot task can greatly improve classification performance, suggesting new ways in which robots can acquire human feedback. The design and implementation of the complete system is described, and results are presented for realtime closed-loop and open-loop experiments as well as offline analysis of both primary and secondary ErrP signals. These experiments are performed using general population subjects that have not been trained or screened. This work thereby demonstrates the potential for EEG-based feedback methods to facilitate seamless robotic control, and moves closer towards the goal of real-time intuitive interaction.'\\n\\n\\\"Towards this end, a feedback system is developed for human-robot collaboration that hinges upon online identification of error-related potentials. In particular, a Rethink Robotics Baxter robot performs object selection while being observed by a human. The human operator's EEG signals are collected and decoded in real time; if an ErrP signal is detected, the robot immediately corrects its trajectory. Figure 1 depicts the system's operation during a sorting task, which is a simple extension of the object selection task.\\\"\\n\\n\\\"Open-Loop implies that the robot performs the task without any feedback from the human. The robot is still observed by the human and EEG data is acquired, but it is not decoded in real time to command the robot. The human's role may seem similar to the closed-loop scenario, but the lack of collaboration significantly affects the subject's engagement.\\\"\\n\\n'Due to the nature of real-world robotic applications, this work focuses on developing an online closed-loop system. EEG data is acquired for brief windows during the task and decoded in a few hundred milliseconds to provide immediate feedback to the robot. 12 subjects participated, only one of which had ever used an EEG system before, and none had been previously trained for the task. One of the subjects was in a meditative state, and the data of that subject was excluded from the present analysis for consistency. The classifier used in online sessions was trained on a single-experiment basis using only 50 initial trials. Offline analysis is also presented, with optimal classification parameters using all available data; with advances in computation and hardware, similar results could eventually be achieved online.'\\n\\n\\\"Experiment codes that describe events such as stimulus onset and robot motion are sent from the experiment controller to the Arduino, which forwards these 7-bit codes to the EEG system by setting the appropriate bits of the parallel port. All bits of the port are set simultaneously using low-level Arduino port manipulation to avoid synchronization issues during setting and reading the pins. Codes are held on the port for 50 ms before the lines are reset. The EEG system thus learns about the experiment status and timing via these codes, and uses this information for classification. In turn, it outputs a single bit to the Arduino to indicate whether an error-related potential is detected. This bit triggers an interrupt on the Arduino, which then informs the experiment controller so that Baxter's trajectory can be corrected. The experiment controller listens for this signal throughout the entirety of Baxter's reaching motion.\\\"\\n\\n'The classification pipeline used to analyze the data has a pre-processing step where the raw signals are filtered and features are extracted. This is followed by a classification step where a learned classifier is applied to the processed EEG signals, yielding linear regression values. These regression values are subjected to a threshold, which was learned offline from the training data. The resulting binary decision is used to control the final reach of the Baxter robot. The same signal classification pipeline was applied to all experiment scenarios, including both open-loop and closed-loop settings. During offline analysis (using data from the open-loop condition) the frequency range, XDAWN filter order, number of electrodes, type of features, cost function, and decoder were optimized via 10 iterations of 10-fold cross-validation. The following subsections describe the steps for closed-loop online classification in more detail.'\\n\\n'Figure 8b demonstrates the existence of the secondary ErrP in an analogous format to that described for the primary ErrP. Since no hardware switch is available for secondary feedback onset time, however, the signals are aligned using status codes sent from the experiment controller and a measured offset time from the primary switch liftoff. EEG activity is again centered towards the middle of the scalp.'\\n\\n'By focusing on the detection of naturally occurring error-related potential signals, an online closed-loop EEG system has been developed that enables intuitive human-robot interaction even for general population subjects that have not been previously trained on the task or EEG systems. The existence of ErrPs for a real-world robotic application is demonstrated, and a classification pipeline is developed to decode the EEG activity. Once trained offline using a small sample of open-loop trials, the pipeline can decode brain signals fast enough to be used online.'\",\"772\":\"\\\"Other authors have contributed high performing work that implicitly encodes key pose information. For example, Devanne et al. [20] modeled skeletal pose transitions as curves through a Riemannian manifold. In this work, activity trajectories are projected into a higher dimensional space, where an elastic metric used to compare various curve shapes is combined with a k-nearest neighbor classification strategy. A similar approach was pursued by Slama et al. [21], who classified activities with a linear SVM over bundles of vectors tangent to a given trajectory's position on a learned Grassmann manifold. In this approach, temporal modeling and classification are performed using a combination of time warping, a Fourier temporal pyramid trajectory representation, and a linear SVM classifier.\\\"\",\"773\":null,\"774\":null,\"775\":\"'The experiments have been done first in air and then in vacuum under the following protocol: (i) a sawtooth voltage with a fixed amplitude, frequency and ramp slope is applied on the piezoelectric element of the actuator, (ii) the displacement of the slider is measured during several seconds with 35 kHz sampling frequency using the integrated optical encoder, (iii) the average velocity is calculated based on the experimental displacement measurement. This experiment is repeated for sawtooth voltages with the following frequencies: 50 Hz, 1 kHz, 2 kHz, 3 kHz, 4 kHz, 5 kHz, 6 kHz, 7 kHz, 8 kHz, 9 kHz, 10kHz and 11 kHz. For each frequency, different amplitudes are applied, namely 10 V, 20 V, 40 V, 60 V, 80 V and 90 V. The same experiment is then repeated by changing the sign of the ramp slope of the sawtooth voltage. In total, the average velocity of the actuator has been identified for 144 operating points in air and 144 operating points in vacuum. In this latter case, the nano-robotic system has been put inside the SEM with a vacuum pressure of\\\\n3.16\\u00d7\\\\n10\\\\n\\u22124\\\\nPa.'\",\"776\":null,\"777\":null,\"778\":\"'The adaptive algorithms were coded on the real time controller (RTLinux, running control loop at 1kHz) of an ABLE exoskeleton designed by the CEA-LIST [20], a four active degrees of freedom (DOF) robot, with 3-DOF for the shoulder (for abduction\\/adduction, internal\\/external rotation, and flexion\\/extension) and one for the elbow (for flex-ion\\/extension), see figure 1. ABLE has interesting features for robotics rehabilitation, that are a large workspace (it allows 110\\u00b0 of rotation at the first three axes, and about 130\\u00b0 at the elbow), a force\\/torque range compatible with human ones (18Nm available on the first two joints, 13Nm on the last two, producing an equivalent maximum force at the hand of 50N), and above all high backdriveability, thanks to a patented screw-cable mechanical transmission together with a model-based gravity compensation, providing a transparent behaviour, with the robot that can be easily moved without detecting any motion intention of the human operator.'\",\"779\":null,\"780\":null,\"781\":\"'The hybrid knee prototype uses development electronics based on a System on Module (SOM) (MyRIO 1900, National Instruments), which is fully contained within the knee cover and powered through the on-board 3000 mAh, 6S Li-Ion battery. The SOM runs custom control algorithms that analyze the output from embedded sensors and defines the desired torque and position of the primary motor and the AVT. The primary motor is controlled in current using a servo-amplifier (Gold Twitter G-TWI 30\\/60SE, Elmo) which receives the current set-point from the SOM using differential analog signals. The AVT motor is feedback controlled in velocity using a 1-quadrant PWM driver (DEC 24\\/2, Maxon Motors). Magnetic encoders are used to measure the shaft position of the primary and AVT motors as well as the absolute position of the knee joint. Four force sensing resistors (FlexiForce, Tekscan) are embedded in the pylon connector to detect contact with the ground. A 9-dof IMU (MPU9250, Invsense) is used to gather information on leg orientation and movement in space. Table I shows the weight breakdown for the development electronics and the protection cover. Although it is far from the weight, dimensions, and efficiency of the embedded systems typically used for commercial products, this development electronics allowed us to quickly test the performance of the proposed knee mechanics on the bench and during ambulation.'\",\"782\":\"'The low-level motor positioning is performed by an EPOS2 motor controller (Maxon Motors, Switzerland). A single board Linux computer (Raspberry Pi Zero, Raspberry Pi Foundation, Cambridge, UK) sends desired position to the motor controller via the step-direction method (similar to open-loop stepper motor control). Each pulse is scaled to move the slider by 1 mm, which provides ample resolution for stiffness modulation. The computer also reads ankle position, measured by a 14-bit absolute encoder (AS5048A AMS, Premstaetten, Austria), via Serial Peripheral Interface. Stiffness modulation is prevented when the ankle is outside of \\u00b11\\u00b0 of neutral, as measured by the encoder\\u2014when the ankle is outside this range, the spring is compressed beyond the preload, and movement of the slider is not possible with the available motor torque. The onboard computer communicates with a host computer over Wi-Fi, A 14.8 V, 430 mA-hour Lithium-Polymer battery (Venom, Rashdrum, ID, USA) powers the electronics and motor. The onboard computer, motor controller, and battery are housed in an electronics box, which can be mounted to the prosthesis socket, making the design entirely mobile for non-tethered operation.'\\n\\n\\\"The torque-angle relationship was measured using a custom rotational dynamometer and the encoder on the ankle joint. The dynamometer consists of a motor (BSM90N-3150AF, Baldor, Fort Smith, AR) and 6-axis load cell on the motor output (45E15A M63J, JR3, Inc., Woodland, CA). The ankle encoder was sampled at 100 Hz by the onboard computer, and the load cell was sampled at 1 kHz. The ankle was fixed to a pyramid adapter on the dynamometer, and the ankle axis was aligned with the axis of the dynamometer. The dynamometer moved the ankle at constant speed in either plantarflexion or dorsiflexion up to and back from the peak angle over eight seconds. The peak angle tested was smaller at stiffer settings, so as not to overload the spring, cam follower, or frame. The test was repeated at 10 slider positions across the slider's range of motion.\\\"\",\"783\":null,\"784\":\"'To meet the requirements for soft exoskeleton design targeting the upper limb, we propose the following series elastic actuator design: a cable-conduit actuator with in-line compliance. We selected a 200 W, 48 V EC-4 Pole Maxon Motor with a 246: 1 planetary gearbox and 500 counts per revolution optical encoder. The motor combination can provide a continuous torque of 8 N-m, with intermittent torques up to 12 N -m, and a continuous speed of 195 deg\\/s. A flexible cable-conduit transmission, or Bowden cable, relocates the motor away from the load. The transmission consists of a Vectran\\u2122 cable coupled with a coiled steel conduit with Teflon\\u2122 lining, providing low friction and resistance to cable creep. To keep the actuator package small and limit the need for additional gearing at the user interface, the lever arm for the motor to cable interface was kept small with a gearbox pulley of 36 mm.'\",\"785\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/29527386'\",\"786\":null,\"787\":null,\"788\":null,\"789\":\"'The part mimicking human operator can be lifted up and released at a certain angle, then obtain a specific desired impact velocity. The rotation speed is monitored by an encoder. A pointer with a gridded disk are assist in order to ensuring repeatability of the tests. Numerous testings of lifting and releasing the operator link at a certain angle have been done and the results confirmed the repeatability. Acceleration sensors labeled \\u201814\\u2019 (PCB 356A15) and \\u201811\\u2019 (PCB 352C03) are installed on the operator block and load block respectively. A force sensor labeled \\u201813\\u2019 (PCB 208C04) is assembled between the load and the impactor dome. The sensor data are measured by a signal conditioner (PCB 482C05) and collected by a controller (NI cRIO-9014).'\\n\\n\\\"The experiment setup of impact test: 1. Encoder on the operator side, 2. Labeled disk, 3. Pointer, 4. Link on the operator side, 5. Link on the robot side, 6. NI controller, 7. Power supply, 8. Signal conditioner, 9. Encoder on the robot side, 10. Laptop, 11. Acceleration sensor on the robot side, 12. Payload, 13. Force sensor, 14. Acceleration sensor on the operator's side.\\\"\",\"790\":\"'https:\\/\\/pubmed.ncbi.nlm.nih.gov\\/30135744'\",\"791\":null,\"792\":null,\"793\":\"'http:\\/\\/getwww.uni-paderborn.de\\/research\\/videos\\/admiss_gap'\"},\"Stars\":{\"0\":-1,\"1\":-1,\"2\":-1,\"3\":-1,\"4\":-1,\"5\":-1,\"6\":-1,\"7\":-1,\"8\":-1,\"9\":-1,\"10\":-1,\"11\":-1,\"12\":-1,\"13\":-1,\"14\":-1,\"15\":-1,\"16\":-1,\"17\":-1,\"18\":-1,\"19\":-1,\"20\":-1,\"21\":-1,\"22\":-1,\"23\":-1,\"24\":-1,\"25\":-1,\"26\":-1,\"27\":-1,\"28\":-1,\"29\":-1,\"30\":-1,\"31\":-1,\"32\":-1,\"33\":-1,\"34\":-1,\"35\":-1,\"36\":-1,\"37\":-1,\"38\":-1,\"39\":-1,\"40\":-1,\"41\":-1,\"42\":-1,\"43\":-1,\"44\":-1,\"45\":-1,\"46\":-1,\"47\":-1,\"48\":-1,\"49\":-1,\"50\":-1,\"51\":-1,\"52\":-1,\"53\":-1,\"54\":-1,\"55\":-1,\"56\":-1,\"57\":-1,\"58\":-1,\"59\":-1,\"60\":-1,\"61\":-1,\"62\":-1,\"63\":-1,\"64\":-1,\"65\":-1,\"66\":-1,\"67\":-1,\"68\":-1,\"69\":-1,\"70\":-1,\"71\":-1,\"72\":-1,\"73\":-1,\"74\":-1,\"75\":-1,\"76\":-1,\"77\":-1,\"78\":-1,\"79\":-1,\"80\":-1,\"81\":-1,\"82\":-1,\"83\":-1,\"84\":-1,\"85\":-1,\"86\":24,\"87\":-1,\"88\":-1,\"89\":-1,\"90\":-1,\"91\":-1,\"92\":-1,\"93\":-1,\"94\":-1,\"95\":-1,\"96\":-1,\"97\":-1,\"98\":-1,\"99\":-1,\"100\":-1,\"101\":-1,\"102\":-1,\"103\":-1,\"104\":2,\"105\":-1,\"106\":-1,\"107\":-1,\"108\":-1,\"109\":-1,\"110\":-1,\"111\":-1,\"112\":-1,\"113\":-1,\"114\":-1,\"115\":-1,\"116\":-1,\"117\":-1,\"118\":-1,\"119\":-1,\"120\":-1,\"121\":-1,\"122\":-1,\"123\":-1,\"124\":-1,\"125\":-1,\"126\":-1,\"127\":-1,\"128\":-1,\"129\":-1,\"130\":-1,\"131\":-1,\"132\":-1,\"133\":-1,\"134\":-1,\"135\":-1,\"136\":-1,\"137\":-1,\"138\":-1,\"139\":-1,\"140\":-1,\"141\":-1,\"142\":-1,\"143\":-1,\"144\":-1,\"145\":-1,\"146\":-1,\"147\":-1,\"148\":-1,\"149\":-1,\"150\":-1,\"151\":-1,\"152\":-1,\"153\":-1,\"154\":-1,\"155\":-1,\"156\":-1,\"157\":-1,\"158\":-1,\"159\":-1,\"160\":-1,\"161\":-1,\"162\":-1,\"163\":-1,\"164\":-1,\"165\":-1,\"166\":-1,\"167\":-1,\"168\":-1,\"169\":-1,\"170\":-1,\"171\":-1,\"172\":-1,\"173\":-1,\"174\":-1,\"175\":-1,\"176\":-1,\"177\":-1,\"178\":-1,\"179\":-1,\"180\":-1,\"181\":-1,\"182\":-1,\"183\":-1,\"184\":-1,\"185\":-1,\"186\":-1,\"187\":-1,\"188\":-1,\"189\":-1,\"190\":-1,\"191\":-1,\"192\":-1,\"193\":-1,\"194\":-1,\"195\":-1,\"196\":-1,\"197\":-1,\"198\":-1,\"199\":-1,\"200\":-1,\"201\":-1,\"202\":-1,\"203\":-1,\"204\":-1,\"205\":-1,\"206\":-1,\"207\":-1,\"208\":-1,\"209\":-1,\"210\":-1,\"211\":-1,\"212\":-1,\"213\":-1,\"214\":-1,\"215\":-1,\"216\":-1,\"217\":-1,\"218\":-1,\"219\":-1,\"220\":-1,\"221\":-1,\"222\":-1,\"223\":-1,\"224\":-1,\"225\":-1,\"226\":-1,\"227\":-1,\"228\":-1,\"229\":30,\"230\":-1,\"231\":-1,\"232\":-1,\"233\":-1,\"234\":-1,\"235\":-1,\"236\":-1,\"237\":-1,\"238\":-1,\"239\":-1,\"240\":-1,\"241\":-1,\"242\":-1,\"243\":-1,\"244\":-1,\"245\":-1,\"246\":-1,\"247\":-1,\"248\":-1,\"249\":-1,\"250\":-1,\"251\":-1,\"252\":-1,\"253\":-1,\"254\":-1,\"255\":-1,\"256\":-1,\"257\":-1,\"258\":-1,\"259\":-1,\"260\":-1,\"261\":-1,\"262\":-1,\"263\":-1,\"264\":-1,\"265\":-1,\"266\":-1,\"267\":-1,\"268\":-1,\"269\":-1,\"270\":-1,\"271\":-1,\"272\":-1,\"273\":-1,\"274\":-1,\"275\":-1,\"276\":-1,\"277\":-1,\"278\":-1,\"279\":-1,\"280\":-1,\"281\":-1,\"282\":-1,\"283\":-1,\"284\":-1,\"285\":-1,\"286\":-1,\"287\":-1,\"288\":-1,\"289\":-1,\"290\":-1,\"291\":-1,\"292\":-1,\"293\":-1,\"294\":-1,\"295\":-1,\"296\":-1,\"297\":-1,\"298\":-1,\"299\":-1,\"300\":-1,\"301\":-1,\"302\":-1,\"303\":-1,\"304\":-1,\"305\":-1,\"306\":-1,\"307\":-1,\"308\":-1,\"309\":-1,\"310\":-1,\"311\":-1,\"312\":-1,\"313\":-1,\"314\":-1,\"315\":-1,\"316\":-1,\"317\":-1,\"318\":-1,\"319\":-1,\"320\":-1,\"321\":-1,\"322\":-1,\"323\":-1,\"324\":-1,\"325\":-1,\"326\":-1,\"327\":-1,\"328\":-1,\"329\":-1,\"330\":-1,\"331\":-1,\"332\":-1,\"333\":-1,\"334\":-1,\"335\":-1,\"336\":-1,\"337\":-1,\"338\":-1,\"339\":-1,\"340\":-1,\"341\":-1,\"342\":-1,\"343\":-1,\"344\":-1,\"345\":-1,\"346\":-1,\"347\":-1,\"348\":-1,\"349\":-1,\"350\":-1,\"351\":-1,\"352\":-1,\"353\":-1,\"354\":-1,\"355\":-1,\"356\":-1,\"357\":-1,\"358\":-1,\"359\":-1,\"360\":-1,\"361\":-1,\"362\":-1,\"363\":-1,\"364\":-1,\"365\":-1,\"366\":-1,\"367\":-1,\"368\":-1,\"369\":-1,\"370\":233,\"371\":-1,\"372\":-1,\"373\":-1,\"374\":-1,\"375\":-1,\"376\":-1,\"377\":-1,\"378\":-1,\"379\":-1,\"380\":-1,\"381\":-1,\"382\":-1,\"383\":-1,\"384\":-1,\"385\":-1,\"386\":-1,\"387\":-1,\"388\":-1,\"389\":-1,\"390\":-1,\"391\":-1,\"392\":-1,\"393\":-1,\"394\":-1,\"395\":-1,\"396\":-1,\"397\":-1,\"398\":-1,\"399\":-1,\"400\":-1,\"401\":-1,\"402\":-1,\"403\":-1,\"404\":-1,\"405\":-1,\"406\":-1,\"407\":-1,\"408\":-1,\"409\":-1,\"410\":-1,\"411\":-1,\"412\":-1,\"413\":-1,\"414\":-1,\"415\":-1,\"416\":-1,\"417\":-1,\"418\":-1,\"419\":-1,\"420\":-1,\"421\":-1,\"422\":-1,\"423\":-1,\"424\":-1,\"425\":-1,\"426\":-1,\"427\":-1,\"428\":-1,\"429\":-1,\"430\":-1,\"431\":-1,\"432\":-1,\"433\":-1,\"434\":-1,\"435\":-1,\"436\":-1,\"437\":-1,\"438\":3,\"439\":-1,\"440\":-1,\"441\":-1,\"442\":-1,\"443\":-1,\"444\":-1,\"445\":-1,\"446\":-1,\"447\":-1,\"448\":-1,\"449\":-1,\"450\":-1,\"451\":-1,\"452\":-1,\"453\":-1,\"454\":-1,\"455\":-1,\"456\":-1,\"457\":-1,\"458\":-1,\"459\":-1,\"460\":-1,\"461\":-1,\"462\":-1,\"463\":-1,\"464\":-1,\"465\":-1,\"466\":-1,\"467\":-1,\"468\":-1,\"469\":-1,\"470\":-1,\"471\":-1,\"472\":-1,\"473\":-1,\"474\":-1,\"475\":-1,\"476\":-1,\"477\":-1,\"478\":-1,\"479\":-1,\"480\":-1,\"481\":-1,\"482\":-1,\"483\":-1,\"484\":-1,\"485\":-1,\"486\":-1,\"487\":-1,\"488\":-1,\"489\":-1,\"490\":-1,\"491\":-1,\"492\":-1,\"493\":-1,\"494\":-1,\"495\":-1,\"496\":-1,\"497\":-1,\"498\":-1,\"499\":-1,\"500\":-1,\"501\":-1,\"502\":-1,\"503\":-1,\"504\":-1,\"505\":-1,\"506\":-1,\"507\":-1,\"508\":-1,\"509\":-1,\"510\":-1,\"511\":-1,\"512\":-1,\"513\":-1,\"514\":-1,\"515\":-1,\"516\":-1,\"517\":-1,\"518\":-1,\"519\":-1,\"520\":-1,\"521\":-1,\"522\":-1,\"523\":-1,\"524\":-1,\"525\":-1,\"526\":-1,\"527\":-1,\"528\":-1,\"529\":-1,\"530\":-1,\"531\":-1,\"532\":-1,\"533\":-1,\"534\":-1,\"535\":-1,\"536\":-1,\"537\":-1,\"538\":-1,\"539\":-1,\"540\":-1,\"541\":-1,\"542\":-1,\"543\":-1,\"544\":-1,\"545\":-1,\"546\":-1,\"547\":-1,\"548\":-1,\"549\":-1,\"550\":-1,\"551\":-1,\"552\":-1,\"553\":-1,\"554\":-1,\"555\":-1,\"556\":-1,\"557\":-1,\"558\":-1,\"559\":-1,\"560\":-1,\"561\":-1,\"562\":-1,\"563\":-1,\"564\":-1,\"565\":-1,\"566\":-1,\"567\":-1,\"568\":-1,\"569\":-1,\"570\":-1,\"571\":-1,\"572\":-1,\"573\":-1,\"574\":-1,\"575\":-1,\"576\":-1,\"577\":-1,\"578\":-1,\"579\":-1,\"580\":-1,\"581\":-1,\"582\":-1,\"583\":-1,\"584\":-1,\"585\":-1,\"586\":-1,\"587\":-1,\"588\":-1,\"589\":-1,\"590\":-1,\"591\":-1,\"592\":-1,\"593\":-1,\"594\":12,\"595\":0,\"596\":-1,\"597\":-1,\"598\":-1,\"599\":-1,\"600\":-1,\"601\":-1,\"602\":-1,\"603\":-1,\"604\":-1,\"605\":-1,\"606\":-1,\"607\":-1,\"608\":-1,\"609\":-1,\"610\":-1,\"611\":-1,\"612\":-1,\"613\":-1,\"614\":-1,\"615\":-1,\"616\":-1,\"617\":-1,\"618\":-1,\"619\":-1,\"620\":-1,\"621\":-1,\"622\":-1,\"623\":-1,\"624\":-1,\"625\":-1,\"626\":-1,\"627\":-1,\"628\":-1,\"629\":-1,\"630\":-1,\"631\":-1,\"632\":-1,\"633\":-1,\"634\":-1,\"635\":-1,\"636\":-1,\"637\":-1,\"638\":-1,\"639\":-1,\"640\":-1,\"641\":-1,\"642\":-1,\"643\":-1,\"644\":-1,\"645\":-1,\"646\":-1,\"647\":-1,\"648\":-1,\"649\":-1,\"650\":-1,\"651\":-1,\"652\":-1,\"653\":-1,\"654\":-1,\"655\":-1,\"656\":-1,\"657\":-1,\"658\":-1,\"659\":-1,\"660\":-1,\"661\":-1,\"662\":-1,\"663\":-1,\"664\":-1,\"665\":9,\"666\":-1,\"667\":-1,\"668\":-1,\"669\":-1,\"670\":-1,\"671\":-1,\"672\":-1,\"673\":-1,\"674\":-1,\"675\":-1,\"676\":-1,\"677\":-1,\"678\":-1,\"679\":-1,\"680\":-1,\"681\":-1,\"682\":-1,\"683\":-1,\"684\":-1,\"685\":-1,\"686\":-1,\"687\":-1,\"688\":-1,\"689\":-1,\"690\":-1,\"691\":-1,\"692\":-1,\"693\":-1,\"694\":-1,\"695\":-1,\"696\":-1,\"697\":-1,\"698\":-1,\"699\":-1,\"700\":-1,\"701\":-1,\"702\":-1,\"703\":-1,\"704\":-1,\"705\":-1,\"706\":-1,\"707\":-1,\"708\":-1,\"709\":-1,\"710\":-1,\"711\":-1,\"712\":-1,\"713\":-1,\"714\":-1,\"715\":-1,\"716\":-1,\"717\":-1,\"718\":-1,\"719\":-1,\"720\":-1,\"721\":-1,\"722\":-1,\"723\":-1,\"724\":-1,\"725\":-1,\"726\":6,\"727\":-1,\"728\":-1,\"729\":-1,\"730\":-1,\"731\":-1,\"732\":-1,\"733\":-1,\"734\":-1,\"735\":-1,\"736\":-1,\"737\":-1,\"738\":-1,\"739\":-1,\"740\":-1,\"741\":-1,\"742\":-1,\"743\":-1,\"744\":-1,\"745\":-1,\"746\":-1,\"747\":-1,\"748\":-1,\"749\":-1,\"750\":-1,\"751\":-1,\"752\":-1,\"753\":-1,\"754\":-1,\"755\":-1,\"756\":-1,\"757\":-1,\"758\":-1,\"759\":-1,\"760\":-1,\"761\":-1,\"762\":-1,\"763\":-1,\"764\":-1,\"765\":-1,\"766\":-1,\"767\":-1,\"768\":-1,\"769\":-1,\"770\":-1,\"771\":-1,\"772\":-1,\"773\":-1,\"774\":-1,\"775\":-1,\"776\":-1,\"777\":-1,\"778\":-1,\"779\":-1,\"780\":-1,\"781\":-1,\"782\":-1,\"783\":-1,\"784\":-1,\"785\":-1,\"786\":-1,\"787\":-1,\"788\":-1,\"789\":-1,\"790\":-1,\"791\":-1,\"792\":-1,\"793\":-1},\"Forks\":{\"0\":-1,\"1\":-1,\"2\":-1,\"3\":-1,\"4\":-1,\"5\":-1,\"6\":-1,\"7\":-1,\"8\":-1,\"9\":-1,\"10\":-1,\"11\":-1,\"12\":-1,\"13\":-1,\"14\":-1,\"15\":-1,\"16\":-1,\"17\":-1,\"18\":-1,\"19\":-1,\"20\":-1,\"21\":-1,\"22\":-1,\"23\":-1,\"24\":-1,\"25\":-1,\"26\":-1,\"27\":-1,\"28\":-1,\"29\":-1,\"30\":-1,\"31\":-1,\"32\":-1,\"33\":-1,\"34\":-1,\"35\":-1,\"36\":-1,\"37\":-1,\"38\":-1,\"39\":-1,\"40\":-1,\"41\":-1,\"42\":-1,\"43\":-1,\"44\":-1,\"45\":-1,\"46\":-1,\"47\":-1,\"48\":-1,\"49\":-1,\"50\":-1,\"51\":-1,\"52\":-1,\"53\":-1,\"54\":-1,\"55\":-1,\"56\":-1,\"57\":-1,\"58\":-1,\"59\":-1,\"60\":-1,\"61\":-1,\"62\":-1,\"63\":-1,\"64\":-1,\"65\":-1,\"66\":-1,\"67\":-1,\"68\":-1,\"69\":-1,\"70\":-1,\"71\":-1,\"72\":-1,\"73\":-1,\"74\":-1,\"75\":-1,\"76\":-1,\"77\":-1,\"78\":-1,\"79\":-1,\"80\":-1,\"81\":-1,\"82\":-1,\"83\":-1,\"84\":-1,\"85\":-1,\"86\":101,\"87\":-1,\"88\":-1,\"89\":-1,\"90\":-1,\"91\":-1,\"92\":-1,\"93\":-1,\"94\":-1,\"95\":-1,\"96\":-1,\"97\":-1,\"98\":-1,\"99\":-1,\"100\":-1,\"101\":-1,\"102\":-1,\"103\":-1,\"104\":6,\"105\":-1,\"106\":-1,\"107\":-1,\"108\":-1,\"109\":-1,\"110\":-1,\"111\":-1,\"112\":-1,\"113\":-1,\"114\":-1,\"115\":-1,\"116\":-1,\"117\":-1,\"118\":-1,\"119\":-1,\"120\":-1,\"121\":-1,\"122\":-1,\"123\":-1,\"124\":-1,\"125\":-1,\"126\":-1,\"127\":-1,\"128\":-1,\"129\":-1,\"130\":-1,\"131\":-1,\"132\":-1,\"133\":-1,\"134\":-1,\"135\":-1,\"136\":-1,\"137\":-1,\"138\":-1,\"139\":-1,\"140\":-1,\"141\":-1,\"142\":-1,\"143\":-1,\"144\":-1,\"145\":-1,\"146\":-1,\"147\":-1,\"148\":-1,\"149\":-1,\"150\":-1,\"151\":-1,\"152\":-1,\"153\":-1,\"154\":-1,\"155\":-1,\"156\":-1,\"157\":-1,\"158\":-1,\"159\":-1,\"160\":-1,\"161\":-1,\"162\":-1,\"163\":-1,\"164\":-1,\"165\":-1,\"166\":-1,\"167\":-1,\"168\":-1,\"169\":-1,\"170\":-1,\"171\":-1,\"172\":-1,\"173\":-1,\"174\":-1,\"175\":-1,\"176\":-1,\"177\":-1,\"178\":-1,\"179\":-1,\"180\":-1,\"181\":-1,\"182\":-1,\"183\":-1,\"184\":-1,\"185\":-1,\"186\":-1,\"187\":-1,\"188\":-1,\"189\":-1,\"190\":-1,\"191\":-1,\"192\":-1,\"193\":-1,\"194\":-1,\"195\":-1,\"196\":-1,\"197\":-1,\"198\":-1,\"199\":-1,\"200\":-1,\"201\":-1,\"202\":-1,\"203\":-1,\"204\":-1,\"205\":-1,\"206\":-1,\"207\":-1,\"208\":-1,\"209\":-1,\"210\":-1,\"211\":-1,\"212\":-1,\"213\":-1,\"214\":-1,\"215\":-1,\"216\":-1,\"217\":-1,\"218\":-1,\"219\":-1,\"220\":-1,\"221\":-1,\"222\":-1,\"223\":-1,\"224\":-1,\"225\":-1,\"226\":-1,\"227\":-1,\"228\":-1,\"229\":17,\"230\":-1,\"231\":-1,\"232\":-1,\"233\":-1,\"234\":-1,\"235\":-1,\"236\":-1,\"237\":-1,\"238\":-1,\"239\":-1,\"240\":-1,\"241\":-1,\"242\":-1,\"243\":-1,\"244\":-1,\"245\":-1,\"246\":-1,\"247\":-1,\"248\":-1,\"249\":-1,\"250\":-1,\"251\":-1,\"252\":-1,\"253\":-1,\"254\":-1,\"255\":-1,\"256\":-1,\"257\":-1,\"258\":-1,\"259\":-1,\"260\":-1,\"261\":-1,\"262\":-1,\"263\":-1,\"264\":-1,\"265\":-1,\"266\":-1,\"267\":-1,\"268\":-1,\"269\":-1,\"270\":-1,\"271\":-1,\"272\":-1,\"273\":-1,\"274\":-1,\"275\":-1,\"276\":-1,\"277\":-1,\"278\":-1,\"279\":-1,\"280\":-1,\"281\":-1,\"282\":-1,\"283\":-1,\"284\":-1,\"285\":-1,\"286\":-1,\"287\":-1,\"288\":-1,\"289\":-1,\"290\":-1,\"291\":-1,\"292\":-1,\"293\":-1,\"294\":-1,\"295\":-1,\"296\":-1,\"297\":-1,\"298\":-1,\"299\":-1,\"300\":-1,\"301\":-1,\"302\":-1,\"303\":-1,\"304\":-1,\"305\":-1,\"306\":-1,\"307\":-1,\"308\":-1,\"309\":-1,\"310\":-1,\"311\":-1,\"312\":-1,\"313\":-1,\"314\":-1,\"315\":-1,\"316\":-1,\"317\":-1,\"318\":-1,\"319\":-1,\"320\":-1,\"321\":-1,\"322\":-1,\"323\":-1,\"324\":-1,\"325\":-1,\"326\":-1,\"327\":-1,\"328\":-1,\"329\":-1,\"330\":-1,\"331\":-1,\"332\":-1,\"333\":-1,\"334\":-1,\"335\":-1,\"336\":-1,\"337\":-1,\"338\":-1,\"339\":-1,\"340\":-1,\"341\":-1,\"342\":-1,\"343\":-1,\"344\":-1,\"345\":-1,\"346\":-1,\"347\":-1,\"348\":-1,\"349\":-1,\"350\":-1,\"351\":-1,\"352\":-1,\"353\":-1,\"354\":-1,\"355\":-1,\"356\":-1,\"357\":-1,\"358\":-1,\"359\":-1,\"360\":-1,\"361\":-1,\"362\":-1,\"363\":-1,\"364\":-1,\"365\":-1,\"366\":-1,\"367\":-1,\"368\":-1,\"369\":-1,\"370\":214,\"371\":-1,\"372\":-1,\"373\":-1,\"374\":-1,\"375\":-1,\"376\":-1,\"377\":-1,\"378\":-1,\"379\":-1,\"380\":-1,\"381\":-1,\"382\":-1,\"383\":-1,\"384\":-1,\"385\":-1,\"386\":-1,\"387\":-1,\"388\":-1,\"389\":-1,\"390\":-1,\"391\":-1,\"392\":-1,\"393\":-1,\"394\":-1,\"395\":-1,\"396\":-1,\"397\":-1,\"398\":-1,\"399\":-1,\"400\":-1,\"401\":-1,\"402\":-1,\"403\":-1,\"404\":-1,\"405\":-1,\"406\":-1,\"407\":-1,\"408\":-1,\"409\":-1,\"410\":-1,\"411\":-1,\"412\":-1,\"413\":-1,\"414\":-1,\"415\":-1,\"416\":-1,\"417\":-1,\"418\":-1,\"419\":-1,\"420\":-1,\"421\":-1,\"422\":-1,\"423\":-1,\"424\":-1,\"425\":-1,\"426\":-1,\"427\":-1,\"428\":-1,\"429\":-1,\"430\":-1,\"431\":-1,\"432\":-1,\"433\":-1,\"434\":-1,\"435\":-1,\"436\":-1,\"437\":-1,\"438\":1,\"439\":-1,\"440\":-1,\"441\":-1,\"442\":-1,\"443\":-1,\"444\":-1,\"445\":-1,\"446\":-1,\"447\":-1,\"448\":-1,\"449\":-1,\"450\":-1,\"451\":-1,\"452\":-1,\"453\":-1,\"454\":-1,\"455\":-1,\"456\":-1,\"457\":-1,\"458\":-1,\"459\":-1,\"460\":-1,\"461\":-1,\"462\":-1,\"463\":-1,\"464\":-1,\"465\":-1,\"466\":-1,\"467\":-1,\"468\":-1,\"469\":-1,\"470\":-1,\"471\":-1,\"472\":-1,\"473\":-1,\"474\":-1,\"475\":-1,\"476\":-1,\"477\":-1,\"478\":-1,\"479\":-1,\"480\":-1,\"481\":-1,\"482\":-1,\"483\":-1,\"484\":-1,\"485\":-1,\"486\":-1,\"487\":-1,\"488\":-1,\"489\":-1,\"490\":-1,\"491\":-1,\"492\":-1,\"493\":-1,\"494\":-1,\"495\":-1,\"496\":-1,\"497\":-1,\"498\":-1,\"499\":-1,\"500\":-1,\"501\":-1,\"502\":-1,\"503\":-1,\"504\":-1,\"505\":-1,\"506\":-1,\"507\":-1,\"508\":-1,\"509\":-1,\"510\":-1,\"511\":-1,\"512\":-1,\"513\":-1,\"514\":-1,\"515\":-1,\"516\":-1,\"517\":-1,\"518\":-1,\"519\":-1,\"520\":-1,\"521\":-1,\"522\":-1,\"523\":-1,\"524\":-1,\"525\":-1,\"526\":-1,\"527\":-1,\"528\":-1,\"529\":-1,\"530\":-1,\"531\":-1,\"532\":-1,\"533\":-1,\"534\":-1,\"535\":-1,\"536\":-1,\"537\":-1,\"538\":-1,\"539\":-1,\"540\":-1,\"541\":-1,\"542\":-1,\"543\":-1,\"544\":-1,\"545\":-1,\"546\":-1,\"547\":-1,\"548\":-1,\"549\":-1,\"550\":-1,\"551\":-1,\"552\":-1,\"553\":-1,\"554\":-1,\"555\":-1,\"556\":-1,\"557\":-1,\"558\":-1,\"559\":-1,\"560\":-1,\"561\":-1,\"562\":-1,\"563\":-1,\"564\":-1,\"565\":-1,\"566\":-1,\"567\":-1,\"568\":-1,\"569\":-1,\"570\":-1,\"571\":-1,\"572\":-1,\"573\":-1,\"574\":-1,\"575\":-1,\"576\":-1,\"577\":-1,\"578\":-1,\"579\":-1,\"580\":-1,\"581\":-1,\"582\":-1,\"583\":-1,\"584\":-1,\"585\":-1,\"586\":-1,\"587\":-1,\"588\":-1,\"589\":-1,\"590\":-1,\"591\":-1,\"592\":-1,\"593\":-1,\"594\":3,\"595\":1,\"596\":-1,\"597\":-1,\"598\":-1,\"599\":-1,\"600\":-1,\"601\":-1,\"602\":-1,\"603\":-1,\"604\":-1,\"605\":-1,\"606\":-1,\"607\":-1,\"608\":-1,\"609\":-1,\"610\":-1,\"611\":-1,\"612\":-1,\"613\":-1,\"614\":-1,\"615\":-1,\"616\":-1,\"617\":-1,\"618\":-1,\"619\":-1,\"620\":-1,\"621\":-1,\"622\":-1,\"623\":-1,\"624\":-1,\"625\":-1,\"626\":-1,\"627\":-1,\"628\":-1,\"629\":-1,\"630\":-1,\"631\":-1,\"632\":-1,\"633\":-1,\"634\":-1,\"635\":-1,\"636\":-1,\"637\":-1,\"638\":-1,\"639\":-1,\"640\":-1,\"641\":-1,\"642\":-1,\"643\":-1,\"644\":-1,\"645\":-1,\"646\":-1,\"647\":-1,\"648\":-1,\"649\":-1,\"650\":-1,\"651\":-1,\"652\":-1,\"653\":-1,\"654\":-1,\"655\":-1,\"656\":-1,\"657\":-1,\"658\":-1,\"659\":-1,\"660\":-1,\"661\":-1,\"662\":-1,\"663\":-1,\"664\":-1,\"665\":23,\"666\":-1,\"667\":-1,\"668\":-1,\"669\":-1,\"670\":-1,\"671\":-1,\"672\":-1,\"673\":-1,\"674\":-1,\"675\":-1,\"676\":-1,\"677\":-1,\"678\":-1,\"679\":-1,\"680\":-1,\"681\":-1,\"682\":-1,\"683\":-1,\"684\":-1,\"685\":-1,\"686\":-1,\"687\":-1,\"688\":-1,\"689\":-1,\"690\":-1,\"691\":-1,\"692\":-1,\"693\":-1,\"694\":-1,\"695\":-1,\"696\":-1,\"697\":-1,\"698\":-1,\"699\":-1,\"700\":-1,\"701\":-1,\"702\":-1,\"703\":-1,\"704\":-1,\"705\":-1,\"706\":-1,\"707\":-1,\"708\":-1,\"709\":-1,\"710\":-1,\"711\":-1,\"712\":-1,\"713\":-1,\"714\":-1,\"715\":-1,\"716\":-1,\"717\":-1,\"718\":-1,\"719\":-1,\"720\":-1,\"721\":-1,\"722\":-1,\"723\":-1,\"724\":-1,\"725\":-1,\"726\":17,\"727\":-1,\"728\":-1,\"729\":-1,\"730\":-1,\"731\":-1,\"732\":-1,\"733\":-1,\"734\":-1,\"735\":-1,\"736\":-1,\"737\":-1,\"738\":-1,\"739\":-1,\"740\":-1,\"741\":-1,\"742\":-1,\"743\":-1,\"744\":-1,\"745\":-1,\"746\":-1,\"747\":-1,\"748\":-1,\"749\":-1,\"750\":-1,\"751\":-1,\"752\":-1,\"753\":-1,\"754\":-1,\"755\":-1,\"756\":-1,\"757\":-1,\"758\":-1,\"759\":-1,\"760\":-1,\"761\":-1,\"762\":-1,\"763\":-1,\"764\":-1,\"765\":-1,\"766\":-1,\"767\":-1,\"768\":-1,\"769\":-1,\"770\":-1,\"771\":-1,\"772\":-1,\"773\":-1,\"774\":-1,\"775\":-1,\"776\":-1,\"777\":-1,\"778\":-1,\"779\":-1,\"780\":-1,\"781\":-1,\"782\":-1,\"783\":-1,\"784\":-1,\"785\":-1,\"786\":-1,\"787\":-1,\"788\":-1,\"789\":-1,\"790\":-1,\"791\":-1,\"792\":-1,\"793\":-1},\"Citations\":{\"0\":2,\"1\":17,\"2\":7,\"3\":2,\"4\":5,\"5\":15,\"6\":12,\"7\":1,\"8\":5,\"9\":32,\"10\":80,\"11\":12,\"12\":14,\"13\":18,\"14\":3,\"15\":1,\"16\":43,\"17\":221,\"18\":20,\"19\":91,\"20\":5,\"21\":170,\"22\":25,\"23\":11,\"24\":11,\"25\":22,\"26\":2,\"27\":10,\"28\":6,\"29\":15,\"30\":18,\"31\":218,\"32\":41,\"33\":41,\"34\":23,\"35\":18,\"36\":38,\"37\":44,\"38\":16,\"39\":8,\"40\":53,\"41\":4,\"42\":17,\"43\":21,\"44\":21,\"45\":9,\"46\":4,\"47\":32,\"48\":10,\"49\":31,\"50\":1,\"51\":4,\"52\":4,\"53\":3,\"54\":3,\"55\":4,\"56\":8,\"57\":34,\"58\":7,\"59\":2,\"60\":2,\"61\":1,\"62\":0,\"63\":5,\"64\":97,\"65\":5,\"66\":6,\"67\":2,\"68\":5,\"69\":0,\"70\":2,\"71\":8,\"72\":34,\"73\":77,\"74\":10,\"75\":9,\"76\":14,\"77\":12,\"78\":14,\"79\":4,\"80\":54,\"81\":26,\"82\":3,\"83\":56,\"84\":14,\"85\":3,\"86\":364,\"87\":47,\"88\":18,\"89\":15,\"90\":19,\"91\":12,\"92\":10,\"93\":12,\"94\":9,\"95\":3,\"96\":1,\"97\":4,\"98\":12,\"99\":12,\"100\":4,\"101\":3,\"102\":22,\"103\":32,\"104\":12,\"105\":27,\"106\":24,\"107\":0,\"108\":13,\"109\":25,\"110\":96,\"111\":14,\"112\":58,\"113\":6,\"114\":3,\"115\":53,\"116\":64,\"117\":6,\"118\":19,\"119\":6,\"120\":14,\"121\":9,\"122\":14,\"123\":0,\"124\":15,\"125\":62,\"126\":6,\"127\":5,\"128\":10,\"129\":42,\"130\":27,\"131\":17,\"132\":36,\"133\":5,\"134\":84,\"135\":5,\"136\":5,\"137\":20,\"138\":8,\"139\":17,\"140\":8,\"141\":5,\"142\":5,\"143\":4,\"144\":7,\"145\":4,\"146\":5,\"147\":1,\"148\":28,\"149\":126,\"150\":30,\"151\":8,\"152\":19,\"153\":68,\"154\":4,\"155\":392,\"156\":30,\"157\":139,\"158\":115,\"159\":335,\"160\":12,\"161\":45,\"162\":2,\"163\":18,\"164\":1,\"165\":22,\"166\":17,\"167\":41,\"168\":5,\"169\":28,\"170\":16,\"171\":43,\"172\":3,\"173\":109,\"174\":6,\"175\":20,\"176\":258,\"177\":20,\"178\":25,\"179\":1,\"180\":86,\"181\":41,\"182\":20,\"183\":18,\"184\":64,\"185\":97,\"186\":24,\"187\":28,\"188\":21,\"189\":6,\"190\":15,\"191\":30,\"192\":8,\"193\":65,\"194\":235,\"195\":23,\"196\":300,\"197\":293,\"198\":21,\"199\":6,\"200\":11,\"201\":5,\"202\":26,\"203\":15,\"204\":20,\"205\":6,\"206\":10,\"207\":7,\"208\":14,\"209\":2,\"210\":3,\"211\":29,\"212\":19,\"213\":11,\"214\":17,\"215\":5,\"216\":5,\"217\":11,\"218\":66,\"219\":10,\"220\":19,\"221\":27,\"222\":1,\"223\":7,\"224\":95,\"225\":2,\"226\":3,\"227\":286,\"228\":9,\"229\":23,\"230\":442,\"231\":1,\"232\":21,\"233\":28,\"234\":5,\"235\":9,\"236\":8,\"237\":12,\"238\":6,\"239\":41,\"240\":9,\"241\":186,\"242\":14,\"243\":97,\"244\":264,\"245\":8,\"246\":26,\"247\":3,\"248\":3,\"249\":2,\"250\":6,\"251\":31,\"252\":7,\"253\":5,\"254\":6,\"255\":6,\"256\":13,\"257\":18,\"258\":8,\"259\":23,\"260\":6,\"261\":15,\"262\":4,\"263\":19,\"264\":6,\"265\":4,\"266\":44,\"267\":6,\"268\":19,\"269\":80,\"270\":9,\"271\":12,\"272\":43,\"273\":3,\"274\":14,\"275\":5,\"276\":8,\"277\":2,\"278\":38,\"279\":7,\"280\":6,\"281\":4,\"282\":9,\"283\":16,\"284\":18,\"285\":3,\"286\":12,\"287\":19,\"288\":18,\"289\":14,\"290\":10,\"291\":13,\"292\":3,\"293\":17,\"294\":19,\"295\":7,\"296\":2,\"297\":21,\"298\":33,\"299\":83,\"300\":8,\"301\":72,\"302\":27,\"303\":12,\"304\":6,\"305\":8,\"306\":28,\"307\":3,\"308\":26,\"309\":12,\"310\":6,\"311\":6,\"312\":36,\"313\":18,\"314\":27,\"315\":20,\"316\":0,\"317\":19,\"318\":559,\"319\":26,\"320\":29,\"321\":58,\"322\":12,\"323\":7,\"324\":27,\"325\":24,\"326\":21,\"327\":1,\"328\":39,\"329\":3,\"330\":16,\"331\":39,\"332\":63,\"333\":4,\"334\":21,\"335\":11,\"336\":2,\"337\":0,\"338\":10,\"339\":65,\"340\":2,\"341\":217,\"342\":59,\"343\":6,\"344\":5,\"345\":5,\"346\":6,\"347\":0,\"348\":16,\"349\":10,\"350\":15,\"351\":11,\"352\":3,\"353\":21,\"354\":14,\"355\":30,\"356\":26,\"357\":6,\"358\":32,\"359\":9,\"360\":236,\"361\":5,\"362\":3,\"363\":44,\"364\":12,\"365\":25,\"366\":21,\"367\":9,\"368\":7,\"369\":59,\"370\":165,\"371\":11,\"372\":18,\"373\":123,\"374\":23,\"375\":1017,\"376\":9,\"377\":34,\"378\":127,\"379\":970,\"380\":5,\"381\":8,\"382\":46,\"383\":14,\"384\":36,\"385\":11,\"386\":18,\"387\":5,\"388\":27,\"389\":4,\"390\":4,\"391\":41,\"392\":19,\"393\":2,\"394\":10,\"395\":35,\"396\":10,\"397\":9,\"398\":3,\"399\":11,\"400\":1,\"401\":5,\"402\":6,\"403\":1,\"404\":0,\"405\":46,\"406\":27,\"407\":41,\"408\":12,\"409\":3,\"410\":10,\"411\":279,\"412\":82,\"413\":14,\"414\":9,\"415\":25,\"416\":5,\"417\":2,\"418\":13,\"419\":12,\"420\":4,\"421\":2,\"422\":2,\"423\":4,\"424\":8,\"425\":11,\"426\":7,\"427\":11,\"428\":12,\"429\":9,\"430\":15,\"431\":7,\"432\":9,\"433\":5,\"434\":6,\"435\":15,\"436\":42,\"437\":59,\"438\":9,\"439\":90,\"440\":52,\"441\":57,\"442\":42,\"443\":33,\"444\":21,\"445\":7,\"446\":37,\"447\":11,\"448\":14,\"449\":19,\"450\":1,\"451\":32,\"452\":1,\"453\":76,\"454\":55,\"455\":6,\"456\":14,\"457\":14,\"458\":49,\"459\":14,\"460\":64,\"461\":39,\"462\":6,\"463\":5,\"464\":4,\"465\":10,\"466\":17,\"467\":8,\"468\":3,\"469\":4,\"470\":12,\"471\":18,\"472\":4,\"473\":6,\"474\":1,\"475\":6,\"476\":1,\"477\":9,\"478\":6,\"479\":5,\"480\":3,\"481\":13,\"482\":11,\"483\":5,\"484\":5,\"485\":8,\"486\":7,\"487\":16,\"488\":43,\"489\":2,\"490\":34,\"491\":3,\"492\":5,\"493\":7,\"494\":32,\"495\":74,\"496\":12,\"497\":2,\"498\":11,\"499\":3,\"500\":1,\"501\":3,\"502\":7,\"503\":9,\"504\":17,\"505\":2,\"506\":16,\"507\":3,\"508\":8,\"509\":15,\"510\":16,\"511\":96,\"512\":130,\"513\":6,\"514\":8,\"515\":15,\"516\":199,\"517\":10,\"518\":1,\"519\":57,\"520\":5,\"521\":7,\"522\":9,\"523\":45,\"524\":14,\"525\":100,\"526\":19,\"527\":10,\"528\":9,\"529\":34,\"530\":18,\"531\":58,\"532\":380,\"533\":2,\"534\":134,\"535\":0,\"536\":16,\"537\":28,\"538\":22,\"539\":56,\"540\":8,\"541\":22,\"542\":5,\"543\":3,\"544\":10,\"545\":26,\"546\":31,\"547\":10,\"548\":5,\"549\":1,\"550\":19,\"551\":7,\"552\":3,\"553\":0,\"554\":16,\"555\":7,\"556\":28,\"557\":20,\"558\":8,\"559\":15,\"560\":6,\"561\":11,\"562\":5,\"563\":5,\"564\":40,\"565\":33,\"566\":2,\"567\":7,\"568\":0,\"569\":12,\"570\":14,\"571\":39,\"572\":36,\"573\":5,\"574\":21,\"575\":36,\"576\":25,\"577\":8,\"578\":5,\"579\":17,\"580\":7,\"581\":29,\"582\":20,\"583\":23,\"584\":76,\"585\":134,\"586\":4,\"587\":11,\"588\":24,\"589\":12,\"590\":8,\"591\":89,\"592\":63,\"593\":14,\"594\":8,\"595\":11,\"596\":6,\"597\":66,\"598\":2,\"599\":4,\"600\":41,\"601\":52,\"602\":99,\"603\":68,\"604\":49,\"605\":19,\"606\":19,\"607\":8,\"608\":31,\"609\":16,\"610\":16,\"611\":4,\"612\":185,\"613\":36,\"614\":7,\"615\":0,\"616\":21,\"617\":5,\"618\":30,\"619\":15,\"620\":4,\"621\":9,\"622\":10,\"623\":5,\"624\":10,\"625\":17,\"626\":15,\"627\":13,\"628\":2,\"629\":9,\"630\":8,\"631\":4,\"632\":34,\"633\":41,\"634\":17,\"635\":16,\"636\":28,\"637\":55,\"638\":7,\"639\":14,\"640\":20,\"641\":7,\"642\":83,\"643\":13,\"644\":9,\"645\":12,\"646\":105,\"647\":13,\"648\":17,\"649\":12,\"650\":80,\"651\":41,\"652\":0,\"653\":20,\"654\":48,\"655\":5,\"656\":8,\"657\":80,\"658\":24,\"659\":3,\"660\":53,\"661\":4,\"662\":20,\"663\":8,\"664\":21,\"665\":46,\"666\":34,\"667\":29,\"668\":26,\"669\":53,\"670\":55,\"671\":74,\"672\":68,\"673\":124,\"674\":18,\"675\":2,\"676\":3,\"677\":1,\"678\":14,\"679\":17,\"680\":16,\"681\":4,\"682\":3,\"683\":8,\"684\":9,\"685\":5,\"686\":22,\"687\":130,\"688\":10,\"689\":8,\"690\":21,\"691\":22,\"692\":12,\"693\":6,\"694\":23,\"695\":16,\"696\":33,\"697\":3,\"698\":10,\"699\":10,\"700\":2,\"701\":7,\"702\":2,\"703\":4,\"704\":22,\"705\":20,\"706\":3,\"707\":6,\"708\":38,\"709\":2,\"710\":24,\"711\":5,\"712\":28,\"713\":0,\"714\":2,\"715\":3,\"716\":9,\"717\":11,\"718\":6,\"719\":40,\"720\":41,\"721\":27,\"722\":16,\"723\":10,\"724\":24,\"725\":23,\"726\":55,\"727\":4,\"728\":3,\"729\":10,\"730\":9,\"731\":38,\"732\":6,\"733\":35,\"734\":10,\"735\":25,\"736\":13,\"737\":14,\"738\":33,\"739\":32,\"740\":10,\"741\":10,\"742\":10,\"743\":8,\"744\":22,\"745\":37,\"746\":52,\"747\":37,\"748\":29,\"749\":24,\"750\":2,\"751\":3,\"752\":7,\"753\":12,\"754\":4,\"755\":12,\"756\":1,\"757\":3,\"758\":15,\"759\":4,\"760\":17,\"761\":4,\"762\":8,\"763\":0,\"764\":16,\"765\":14,\"766\":112,\"767\":6,\"768\":18,\"769\":1,\"770\":0,\"771\":108,\"772\":24,\"773\":3,\"774\":1,\"775\":12,\"776\":5,\"777\":0,\"778\":2,\"779\":32,\"780\":7,\"781\":11,\"782\":28,\"783\":14,\"784\":6,\"785\":21,\"786\":21,\"787\":6,\"788\":1,\"789\":15,\"790\":15,\"791\":5,\"792\":0,\"793\":3}}"